This paper addresses an important topic, it summarises arguments for and against blinding
patients and clinicians, and it challenges what might be a common misperception - that

blinding patients and clinicians is always equally important and should always be done when
it is possible.
I have two main suggestions.
1. I found the use of blinding confusing. The focus is on blinding of patients and clinicians. I
suggest making that clear in the title and abstract and that you use language that makes it
clear when you are talking about blinding of patients and clinicians, when you are talking
about blinding more broadly, and when you are talking about blinding outcome assessors or
others. Also, I found statements like “blinding and the commonly associated placebo”
confusing.
You use the terms ‘double or triple blind trials’ (Line 100). Those terms are problematic in
that they are used in different ways and understood to mean different things to different
people. You might want to note this, as well as being careful to be clear what you mean
throughout. (See: Devereaux, P.J., Manns, B.J., Ghali, W.A., Quan, H., Lacchetti, C.,
Montori, V.M., Bhandari, M. and Guyatt, G.H. (2001) ‘Physician interpretations and textbook
definitions of blinding terminology in randomized controlled trials’. JAMA, 285 (15),
2000–3.)
2. Miller’s three questions (line 229-231) are good. I think they get at what is or should be
the key message, and I think you could improve on those questions. I’m not convinced that
they should be yes/no questions. It might be more helpful to frame them in terms of
whether the advantages of blinding patients and/or clinicians outweighs the disadvantages;
e.g. something like:
• How likely is it that there might be a placebo effect, and how important is it to separate
that effect from whatever effect there might be beyond a placebo effect?
• How likely is it that patients will behave differently if they know the treatment to which
they are allocated and could that bias the results?
• If it is important to know the effect of the intervention on a patient reported outcome,
how likely is it that if patients know the treatment to which they are allocated that could
bias outcome reporting?
• How likely is it that clinicians will behave differently if they know the treatment to which a
patient is allocated and could that bias the results?
• If it is important to know the effect of the intervention on an outcome that clinicians need
to assess and it is not possible to use independent, blinded outcome assessors, how likely is
it that if clinicians know the treatment to which patients are allocated this could bias their
assessments?
And a similar set of questions about potential problems with recruitment, retention,
production and costs of a placebo, and patient safety.
Examples would be helpful for each question.
You might, of course, disagree with this suggestion, and I don’t mean to suggest that you
should write something different than what you intended. But I think a set of questions
more along those lines could be helpful both for trialists and for clinicians considering the
results of trials.

Some other things that you might want to address are:
Line 114: You say: “The primary purpose of blinding . . .” Are there other purposes? In
addition, it should be ‘purposes’, since you identify two, and it should specify ‘blinding of
patients and clinicians’.
Line 135: You write “is highlighted”. I’m not sure what that means. It would be good if you
said what the findings are for blinding of patients and clinicians.

Practical negative implications of “blinding and placebos”: It seems likely to me that
adverse effects of blinding patients and clinicians, placebo effects, and nocebo effects may
depend on what people are told. For example, in a classic study, Thomas found that being
positive had an effect on patients symptoms with or without a placebo, but did not find an
effect of the placebo (Thomas K B. General practice consultations: is there any point in
being positive? Br Med J (Clin Res Ed) 1987; 294 :1200). Other studies have also found
effects of positive communication (Howick J, Moscrop A, Mebius A, Fanshawe TR, Lewith G,
Bishop FL, Mistiaen P, Roberts NW, Dieninytė E, Hu XY, Aveyard P. Effects of empathic and
positive communication in healthcare consultations: a systematic review and meta-analysis.
Journal of the Royal Society of Medicine. 2018 Jul;111(7):240-52.) It would be helpful if
you considered this literature and its implications for designing trials without blinding
patients.
Line 220-223: You might want to interpret the Hróbjartsson paper a bit more cautiously.
Although they found “limited evidence of powerful clinical effects” from those studies, they
did find some evidence and there is other evidence. Suggesting that there is “poor evidence
of the placebo having any significant clinical effect on outcomes” also seems to conflict with
what you argue in the second example in the box (table 2), which seems to assume that
there are important placebo effects.
Does a cream reduce facial acne?: I did not find this hypothetical example convincing. I
think most people would want to know which cream to buy, not just whether to use any
cream or not, since there would likely be many to choose from, with different prices and
different ingredients. It would be relevant to know if a cream with ingredients that claimed
to be effective and cost more worked any better than a cream without any purported magic
ingredients. How a cream compares to some other treatment (a different approach) is a
different question that might also be relevant. It is not necessarily a better question. People
might also want to know if they should use both a cream (and then which cream) together
with some other treatment.
Pragmatism and what happens in the real world: I think it would be helpful to note that use
of a placebo is one of several dimensions that can distinguish pragmatic from explanatory
trials, and that trials are not purely pragmatic or purely explanatory - there’s a continuum.
(see e.g. Thorpe KE, et al. A pragmatic-explanatory continuum indicator summary
(PRECIS): a tool to help trial designers. Journal of Clinical Epidemiology 62 (2009)
464e475.) There are questions that are largely pragmatic where comparison to a placebo is
relevant.
Line 270: For me, PROBE is confusing jargon and a quick look at the reference explaining
PROBE did not clarify for me what PROBE is besides jargon. That might just reflect my
ignorance, but it might help others besides me if you avoided what seems to be
unnecessary jargon and explained in plain language what the methods are and how they
protect against dissimilar attention and care from clinicians or dissimilar expectations or
behaviours of patients, if that is a concern and they are not blinded. Randomisation and
blind outcome assessment should be done whenever possible, and they address different
risks of bias, so it is not clear to me how that is relevant.
Objective outcomes: It would be good if you defined “objective” and “subjective” outcomes
and gave examples; e.g. similar to what is used in the reference you cite. I don’t
understand your suggestions for making outcomes less subjective. Surrogate outcomes
(e.g. laboratory tests) often are more objective than important outcomes, so it is not
obvious to me what sorts of surrogate outcomes you have in mind. In addition, isn’t it a
good idea to avoid surrogate outcomes anyway? And I don’t understand what you mean by
“limiting the change to a given clinical parameter by limiting the assessment of effect.