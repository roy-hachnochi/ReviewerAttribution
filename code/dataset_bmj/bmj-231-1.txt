<b>Overall</b>
This article compares the presence of 25 positive words in the title and abstract of biomedical articles
available on PubMed between women first and last authors versus otherwise. In a retrospective study of
~ 100,000 clinical medical articles and ~ 6.2M biomedical articles, they identify that the title and
abstract of articles with women first and last authors on average tend to mention these words less. This
appears to be the case in the multivariable analyses of the few clinical medical articles (with a small
absolute difference in effect), but not the many biomedical articles. The difference in use of such words
between all-women lead authors vs otherwise on average appears larger in titles/abstracts published in
journals of impact factor > 10, even though this was never tested.
I again congratulate the authors for their thorough work as well as the following important changes:
referring to the words as “positive words”, incorporating granular information about MeSH terms in their
analyses, extensive sensitivity analyses (including that of nouns following the positive words, length of
abstract and examining the “dose-response curve”), using the STROBE guidelines and very clearly
illustrating how the sample was obtained. However, the effects are still misleading or misrepresented,
and it is still hard to justify that these results are not the product of residual confounding, chance or data
dredging. Furthermore, I do not get the feeling of a witty, clever paper – instead of the typical drier
research paper – that I would expect for the Christmas BMJ.
As such, I still recommend that this study undergoes major review before it can be published in a journal
of as wide readership and influence as BMJ.

<b>Main concerns</b>
1. <b>Choice of words remains biased.</b> As mentioned in my last review, Vinkers et al. (2015) used
positive, neutral and negative words. Only using positive words introduces bias and potentially
misleading results with no appropriate control. The authors have not changed their analysis, nor have
they provided justification as to why they chose to only implement part of the Vinkers et al. analysis.
2. <b>Presentation of effects remains misleading.</b> First, the abstract misleadingly states that the
results were replicated in PubMed journals – this is only true in the minority (5%) with Journal Impact
Factor (JIF) > 10. Second, as mentioned in my last review, the data are presented as 1 minus relative
risk, which is a very misleading metric. For example, the absolute effect across 25 words led to a
relative difference of 12%, which appears much larger than the absolute difference of 1.3 %
(12.2%-10.9%), which essentially implies that for every 77 women first and last authors, we would have
one extra title/abstract with a positive word if these were not two women – a small effect. If we further
divide 1.3/25 for each word, then the effect is tiny. A table of statistics (absolute and relative difference)
across all characteristics for articles authored by female-female versus others would mitigate this
concern.

3. <b>Residual confounding remains a concern.</b> Even though the authors vastly improved on their
previous treatment of potential confounding by field of study, their modelling approach of using the
median prevalence of positive words across MeSH terms is rather odd and as such its coefficient, and by
extension the coefficient of gender, are difficult to interpret. I would suggest that (a) the authors use a
matched analysis to adjust for MeSH terms without having to account for all of them in a regression
model or (b) study gender differences within specific journals of narrow field focus as a sensitivity
analysis.
4. <b>Heterogeneity of treatment effect remains untested.</b> As stated in my last review, even
though the manuscript claims on several occasions that the observed effect is larger within journals with
journal impact factor (JIF) >10, the multiplicative or additive interaction is never quantified and tested –
instead, it is only tested within the group of articles with JIF < 10 or JIF > 10, but not between the
groups, which is inadequate.
5. <b>Protocol remains unregistered.</b> As indicated in my last review, such studies make data
dredging extremely tempting and are hard to believe without a pre-registered protocol (on say services,
like the Open Science Foundation). For example, in its first version, the manuscript included 9 million
articles with a prevalence of positive words of 3.3% in female-female versus 3.7% in other combinations
of first-last author. In this new version, this is 6.6 million with 10.9% versus 12.2%, respectively. These
numbers are roughly 3 times larger than the previous ones, but neither the change in sampling nor the
reason are immediately clear.
6. <b>Choice of title-abstract remains ambiguous.</b> As mentioned in my last review, there is no
good justification (p.8, lines 10-15) as to why use the title and abstract, instead of say only the title,
only the abstract, or parts of the full text - different combinations of such and other decisions may well
sway the small effect identified to either direction. I had suggested that the authors test 100 full text
articles for positive words as a sensitivity analysis, which has not been done.
7. <b>Transparency remains imperfect. </b>The authors have taken great steps to mitigate this by
completing the STROBE guidelines. However, please share all of your data and all of your code (some of
which is already shared, thank you) to help readers and the scientific community understand exactly
what was done, facilitate appropriate peer review and improve the replicability of this work; possible
repositories include GitHub, Open Science Foundation and Figshare.

<b>Minor concerns</b>
1. Please mention the average positive predictive value for Genderize in the main text.
2. How was the gender designation by Genderize tested in Figure S5?
3. P.8, Line 30. PubMed does not have ISSN numbers for all journals – what was done when no ISSN
was available?
4. Figures 2, 4 and 5 are difficult to interpret without knowing the unadjusted estimates. Indeed, a Table
presenting statistics across the characteristics included in the multivariable analyses for female-female
vs others is missing.
5. There is no adequate explanation for using a linear probability model instead of a logistic model. I do
not believe many doctors have even heard of this type of modelling before, let alone understand what it
is. This is why it is very important to explain in the Supplementary material what it is and why it was
used instead of more familiar alternatives.

6. Table S12 indicates that 17% of abstract lengths were imputed – those abstracts are most probably
not missing at random and 17% is a huge number to treat with median imputation. More information is
needed as to why those abstracts were missing and how those 17% of articles compared to the rest.
7. No diagnostic tests shown to confirm fit. No methods to improve estimate of confidence intervals and
p-values used (bootstrapping, sandwich estimator).
8. Figure S18 is very useful, thank you.