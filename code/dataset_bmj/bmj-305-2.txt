
This paper appears to extend the findings of Levis B et al (2017) who also used IPDMA to examine
operating characteristics of the PHQ-9 in a smaller study population (n = 5743 during a 5-year study
period vs 17,357 during a 15-year study period). Both studies, however, arrive at similar conclusions,
that is, a cut-off of 10 “may maximize sensitivity and specificity of the PHQ-9” (p. 961 in Levis B et al,
2017). In fact, the present study concludes that sensitivity estimates based on IPDMA “were
substantively higher than previously reported”.
The authors devote considerable time, attention, and ink to substantiation of this conclusion, as well as
the conclusion that PHQ-9 operating characteristics are pretty much the same across sub-groups
identified by sex, age, medical subpopulation, etc.
But there is one ‘fly-in-the-ointment’: PHQ-9 positive predictive values were low.
The authors are quite clear about this very important point, but introduce it “quietly” almost as an afterthought overshadowed by the mountain of data on PHQ-9 sensitivity and specificity across diverse study
subgroups. Only two figures - 2a and 2b - are devoted to positive and negative predictive values based
on the single cutpoint of 10. Nearly all other tables – too numerous to count – focus on comparative
sensitivities and specificities.
To their credit the authors target this issue recommending further study “estimating probabilities of
depression across the full spectrum of PHQ-9 screening scores”. But, why wait? Hasn’t the data been
collected that would provide estimates of positive and negative predictive values at different cutpoints?
If not, the reader at least deserves a more complete discussion of the meaning of this apparent paradox.
What significance do high sensitivity and specificity have in the face of low positive predictive values
resulting in high numbers of false positives? It’s almost like you’ve described an automobile with an
unusually appealing interior and exterior and great gas mileage except for one thing– “Oh, by the way,
the tires are manufactured from high-grade pine . . . . “
Contributing to this overall feeling of being misled, is the reference to differing national guidelines on use
of routine depression screening. As a clinician who values the PHQ-9, I am quick to accept it for what it
is, a screening rather than diagnostic tool that must be interpreted in light of depression severity and
other clinical variables such as patient motivation for further evaluation and treatment. I do pay greater
attention to scores of 15 or higher, assess the score in the context of other important clinical variables
and also find it of value as a serial measure of longitudinal outcome. I recommend either adding these
positive attributes of the test to your discussion, or eliminate reference to the controversy at all, that is,
pending availability of further data on estimating depression probabilities.
Among the strengths of this paper is the finding that reference standard used significantly impacts
sensitivity and specificity scores. Though it may seem obvious, it wouldn’t hurt to emphasize that future
investigations validating the PHQ-9 should favor use of semistructured interviews (such as the SCID) as
the preferred reference standard.
