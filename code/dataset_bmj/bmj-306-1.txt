I concur with the main message of the paper, namely that the development of
nutritional guidelines would be aided by the inclusion of the following steps in the
guidelines process: 1) formulate research questions, clearly differentiating the
different types; 2) utilise logic models that clarify the proposed mechanisms
involved; 3) select the evidence most appropriate for answering the research
questions; and 4) synthesise the evidence. The rationale provided by the authors
for using these steps is clear.
It is, the first half of the paper that I take issue with. The thesis stated by the
authors is that “available data and existing methods for evidence synthesis, rather
than the questions that need to be answered, are driving the selection and
evaluation of evidence, and ultimately the relevance and quality of nutrition
guidelines.”

While it is true that most guidelines in eLENA and most Cochrane reviews focus on
single nutrient assessments, this is not necessarily a result of the availability of
certain types of data or the use of particular methods of evaluation.
Currently, research on foods, diets and nutrients employs mainly observational
designs, rather than RCTs, as implied by the authors. That review authors
frequently choose topics involving RCTs of single nutrient reviews may simply reflect
the narrow (mainly downstream) interests of those (often clinicians) who are
conducting syntheses. Additionally, the attention given to nutrients in trials and
evidence syntheses may, in part, be due to the influence of industry – there is a
large and growing market for the sale of ‘supplements.’ Furthermore, expert
guidelines are often shaped by advocates of particular foods, diets and nutrients
with financial and/or non-financial conflicts of interest often playing a role in
decisions.
Having formulated their thesis, as stated above, the authors identify ‘borrowed
methods’ as the underlying problem. They contend that SR methods are ‘optimised’
for synthesing RCTs and that RCTs are suitable for evaluating single nutrients and
not for complex interventions. I think this overstates the case.
SR methodologies have been developing rapidly in recent years and are currently
able to accommodate both qualitative and quantitative study designs. RCTs, of
course, have their limitations for assessing nutritional interventions, as outlined by
the authors. However, RCTs can, and have been used to study long term effects of
nutritional interventions, other than single nutrients e.g. Mediterranean diet; and
have also been used to evaluate complex interventions in other fields e.g. health
systems research. The use of pragmatic trial designs often helps address concerns
about external validity.
The second argument put forward by the authors concerns the limitations of the
tools used for assessing the risk of bias in observational studies. They claim that the
“variety of tools can lead to confusion….” While currently available tools are not
perfect, they are improving. Rather than dismissing these tools as unsuitable, the
emphasis should rather be on evaluating those considered most appropriate in the
nutrition field and developing consensus around their use. This has been the case
with the Cochrane RoB tool and GRADE, both of which are still evolving.
With respect to the third argument: GRADE favours research asking narrow
questions studies with RCTs. I don’t agree. GRADE rates RCTs as high quality, not
because of the type of intervention being assessed, but because RCTs are inherently
more reliable for addressing bias than observational studies. The potential for
confounding in nutrition research is large, and no matter the strengths of
observational designs they lack the power of RCTs to adjust for confounding bias.
This is evidenced by the substantial number of observational studies reporting either
an increased or decreased mortality risk from consumption of the same food group.
Also, the inconsistent findings between cohort studies and RCTs raise concerns
about the problem of confounding in observational studies. Starting with lower
quality rating and upgrading, as recommended in GRADE, therefore seems to be
have a sound rationale.
It is my view that authors’ call for expanding the scope of nutrition topics and for the
incorporation of a wider range for study types is valid. However, these points do not
require a return to the previous ‘paradigm wars’ in which ‘reductionism’ is
problematized, as is apparent in the current version of the article. A further
suggestion for strengthening the paper would be to provide some reflection on the
current shortcomings in the nutritional guideline development process, such as the

lack of transparency, lack of inclusivity of a broad range of expertise, and
inadequate attention to bias and conflicts of interest.
