Thank you for giving me the opportunity to review this very interesting paper.
Niederkrontenthaler et al. have endeavored an ambitious task that many scholars and
preventers interested in suicidal contagion have been waiting for. They propose a
comprehensive, systematic review about the association between media broadcast of suicide
stories and subsequent changes in rates of suicidal behaviors. By applying meta-analytical
models over the quantitative outcomes of these studies, they argue that the risk of suicide
or suicide attempt is multiplied by a significant 1.49 or 1.39 coefficient after the publication
of suicide stories, depending on whether the articles concern celebrity or non-celebrity
suicide respectively. In addition, the authors found that the similarity of the suicide method
with this depicted in the media was the main predictor of the association between the
publication of suicide stories and the increase of suicide/suicide attempt rate.
Beyond the strong interest that this paper could raise in the suicide prevention community, I
do think that it would fit the scope and expectations of a prestigious and generalist
journalist, such as the BMJ is. Indeed, for more than 50 years, many evidence have robustly

converged to highlight the role of mass media as a possibly modifiable risk factor of suicidal
behaviors. However, the scientific community still lacks a strong, synthetic and decisive
argument to get a step forward in raising political awareness, fostering interest in the
community, stimulating research and supporting ambitious prevention campaigns. Because
they are leaders in the domain, the authors have a strong legitimacy to provide this
argument. The manuscript they submit here demonstrates scientific rigor, honesty, and
in-depth knowledge of the literature.
However, the strengths of the paper are also its weaknesses. It appears that the authors
have sought the exhaustivity, embracing all possible ecological evidence about the effect of
media coverage of suicide. Unfortunately, it is according to me at the expense of the
coherence, interpretability, and strength of their findings. Notably, a quick overview of the
paper’s results give the impression that the meta-analysis that the authors conducted could
only capture the great variability of included papers, resulting in almost non-interpretable
outcomes. The unbalance between the exhaustivity ambitions and the synthetic efforts
appears in the different sections of the manuscript : the objective lacks clarity and
justification, the methods give the impression of setting arrangements to deal with
heterogeneity, the results show major unexplained variability and the discussion appears to
understate both the value of the results and the importance of the limitations.
I wish that the BMJ editorial board won’t see these comments as prohibitive for the
publication of the paper. On the contrary, I think that some revisions could considerably
improve the parsimony of the analysis, the scope of the findings and make the paper a
major reference.
MAJOR COMMENTS
1. Clarify the objectives of the paper
• It is unclear from the introduction whether the review aim at providing a substratum for
the WHO recommendations, comparing the consequence of celebrity vs non celebrity
suicides coverage, or gaining insight in the predictors of media impacts on suicide/suicide
attempt rates. By the way, the conclusion is at the image of this hesitation, failing to provide
a clear answer to a clear research question. I would expect authors to define a single explicit
objective and bring it with a more structured progression.
• Authors should also work at reinforcing provide their introduction, notably by clearly
explaining what “gap” does their review intend to fill and how it addresses a matter of
collective importance. Tightening their justification around two or three majors points,
avoiding specialized theoretical references (eg. reference to audience-reception studies) and
highlighting how the results could translate in terms of research, prevention or clinical
practice could help.
• If judged necessary (cf. infra), all the ancillary analysis (such as the meta-regression) and
methodological choices (eg. stratification of the meta-analysis on the celebrity status) should
be announced as secondary objectives in the introduction, justified, and put in coherence
with the main objective.
2. Consider restraining the focus of the paper
• Although specificities remain poorly known, it is highly likely that the psycho-social
processes that link media coverage of suicide on the one hand and suicide rates versus
suicide attempt rates on the other hands are not quite overlapping. I think that including the
effect of media coverage of suicide on suicide attempt rates brings poorly justifiable
variability and needlessly alters the interpretability of the results. By the way, the authors
don’t mention suicide attempts in the title.
• It unclear to me whether broadcasts of fictional suicides are included in the study
(although suggested by the keywords “movie”, “film”, “book”, “play”). If yes, this is an
important source of variability that needs to be taken in account. At the minimum, authors

should add this variable as a predictor in the meta-regression model. However, given that
the specificity of suicidal contagion induced by fictional suicide remain poorly known (despite
recent regain in interest) authors could consider excluding the corresponding papers.
• To our opinion, the complementary meta-regressions that are applied to the sub-group of
papers dealing with celebrity suicides are poorly justified in regards of the main objective.
3. Reinforce the scientific soundness
• The significant publication bias that the funnel plot reveals seriously threatens the
representativity of selected paper as regards of the whole scientific corpus dealing with the
subject, and alters the validity of the results. We see several possible causes to this
important bias that should definitely be addressed by the authors. Answering the following
questions could help :
o How do authors explain that the database searching allowed to retrieve only 20% of the
references? This suggests incompleteness of the algorithm. Did authors tried to add
contagion-related terms such as “trigger”, “model*”, or “suggestion” to the equation?
o How do authors explain that 17 studies were not “amenable to extraction of quantitative
effect sizes”, although matching the selection criteria? Did authors try to contact the
corresponding researchers to get the data or information as required in the meta-analysis
standards ? This should be acknowledged in the manuscript.
o How did authors explored the grey literature (and did they do so) ? This should also be
acknowledged in the manuscript.
• I also have questions about how the authors pooled and/or treated the data
o I don’t understand why authors stratified their analysis on the type of estimate, since
relative risks can easily be calculated instead of risk differences when data is available. As I
can see that most of the papers from which the RD are extracted have been published by
one of the authors, such calculation should be feasible.
o OR, RR and SMR correspond to specific designs and their meaning is not equivalent.
Although their combination is formally correct, I wonder whether the interpretation that
authors make of the pooled RR is misleading, and to what extent such “melting-pot”
contribute to the heterogeneity of the results. Similarly, how did authors deal with
auto-regressive and other time-adjusted longitudinal models such as ARIMAs? Did they
consider the excess of suicides in comparison of the baseline pre-publication rate or in
comparison of the model-predicted rates? Once again, this should be specified, and
acknowledged as a source of interpretation difficulty. Based on these considerations, I
wonder whether a stratification on study designs would be more relevant than the choice of
the authors to stratify on the nature of the effect size indicator.
• Authors pre-calculated effect-size estimations with random-effect models in articles where
several estimates were reported. When integrated to the overall meta-analysis, this leads to
a double nested random-effect model that increases the sources of variance. I’d like authors
to address this point.
• The “A-list” criterion appear poorly operationalized, and somewhat redundant with the
“level of recognition” criterion. As a more objective, robust proxy, the later criterion appears
sufficient.
• An important point is why authors decided to stratify their analysis on the celebrity status
of the suicide victim. This necessarily leads to an inflation of the alpha risk. Instead, it would
be both more meaningful and rigorous to compute the pooled RR altogether, and to add the
celebrity status as a predictor in the meta-regression
• In the meta-regression, I would be curious of the number of studies in each levels of the
predictors. I’m a little concerned about the power of the analysis.
4. Provide better qualitative insights
Because of the huge variability in the data, qualitative information would be as valuable as
quantitative synthesis. To that respect, I think that a summary table of the included papers,
where designs, risks of bias, type of reported stories, etc. would be of a great value.

Together with a narrower scope meta-analysis, it would greatly improve the equilibrium of
the paper.

MINOR COMMENTS
• Although I’m not English-native myself, I can see that the manuscript needs a mild English
editing
• How did author deal with conflicting criteria to select overlapping studies (i.e. was there a
hierarchy in the criteria?)
• The explanation of the qualitative summary procedure (p9, l3-4) appears useless
• Authors should consider adding subheadings to clarify the manuscript
• The placement of the arrows in the flowchart is a bit weird.
