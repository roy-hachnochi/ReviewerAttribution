SUMMARY

This reports a quantitative meta-analysis of ecological studies that examined suicide rates
before and after media reports of a celebrity or a noncelebrity suicide. There is reason to be
concerned that media reports that sensationalize suicides could make it more likely that a
suicidal individual would attempt or complete suicide, perhaps in a way that emulates the
methods used by the figure in the media report. Previous meta-analyses have been
conducted but no one has tried to obtain a pooled estimate of the association. This study
includes a comprehensive literature search that netted over 8000 abstracts for review and
yielded 87 for the analysis. The authors did a careful evaluation to exclude studies that used
overlapping events and outcomes data. They report quantitative results on 64 studies, 52 for
pooled relative risks and 12 for risk differences. The overall pooled relative risk was 1.36
(1.49 for celebrity suicides). Both relative and absolute risk was higher for celebrity suicides.
The overall pooled absolute risk difference was 0.39 per 100,000. There was evidence for
study heterogeneity and publication bias. In a meta-regression, there was a much stronger
association in studies that examined suicide by the same method as was publicized in the
media. All variables accounted for 55% of the effect size heterogeneity. The findings
persisted in a sensitivity analysis; however the relative risk associated with studies at low
risk of bias was attenuated, at 1.09 but still statistically significant.
The authors conclude that “the study provides clear and compelling evidence that available
media guidelines on responsible media reporting need to be promoted and that collaboration
between suicide prevention experts and media professionals is an essential part of any
suicide prevention plan.”
GENERAL COMMENTS
This study represents an important advance in our understanding of the literature on media
reporting and suicide. The results warrant publication in a major medical journal, with an
editorial that addresses what the appropriate public health action should be. Strengths
include an exhaustive literature search, careful attention to weeding out studies that
examined the same event using the same outcome data, grading for risk of bias,
quantitative assessment that allowed for pooled relative risks to be reported, assessment to
explain heterogeneity, risk of bias assessment, and a sensitivity analysis that offered relative
risk estimates for studies thought to have lower risk of bias.
I think the study would be more impactful if the authors were somewhat more conservative
in the way they report the results and conclusions.
MAJOR COMMENTS
How to report the relative risk findings. The authors should stick to reporting relative risks
with 95% confidence intervals in the abstract and elsewhere and refrain from statements like
“risk of suicide or attempted suicide increased by 36%”, which tends to exaggerate what is a
modest (but important) association.
Keeping in mind that the association is modest, that this is an ecological meta-analysis, that
there is unexplained heterogeneity, that there is risk of publication bias, and that the
association is attenuated by 75% in studies at low risk of bias, I do not think that the
conclusion merits a statement like “the study provides clear and compelling evidence that
available media guidelines on responsible media reporting need to be promoted.” “clear and
compelling” statement about current media guidelines. That statement implies not only that
there is an association between sensationalized media and suicide risk, but also that
responsible media reporting would change that risk, the second statement being well beyond
the scope of the study.
What the authors do show is that the literature to date provides convincing evidence that
there is a modest but potentially important association between celebrity suicides and
subsequent increases in suicide rates. The fact that the association is much stronger when
the study is restricted to suicides by the same method as publicized in the media is telling to

me; it offers evidence to support the notion of “copycat suicide” a term that appears in many
of the citations. This could be discussed more in the discussion section.
I appreciate the publication of both relative risk and absolute risk difference. I don’t
understand why the authors were unable to extract risk difference from so many studies.
Did they not publish the suicide rates before and after the event? Can the relative risk be
applied to the base rate to estimate a follow up rate for those that only report a relative risk?
MINOR COMMENTS
Page Lines Comment
14 30-39 I think it is important to contextualize the findings against the suicide rate. It
looks like it’s about 10-12 per 100,000 in the US. That would work out to a rate of about
1/100,000 per month. This paragraph was the first time in the paper it was made clear that
the absolute risk difference is a per-month difference. This should be made clear in Figure
3.
Since this is an international study, it would be helpful to the readers to have a feel for how
rates of suicide differ across countries. For example, many of the studies derive from Korea,
and the authors point out that copycat suicides may be higher in Asian countries. Suicide
rates are higher in South Korea (25+ per 100K) and in Eastern Europe (Russia is
30/100,000).
This paragraph applies the absolute rate to compare with a rate of 1 per 100,000,
suggesting that a highly publicized suicide might increase the rate by 50% or more. But if
the base rate was 3 per 100.000, as it is in Russia, this would be a smaller increment.
I wonder, for places where the base rate is higher, whether it would be appropriate to apply
the relative risk to determine how much more suicide would result. Hopefully the authors
can clarify why they chose to use the absolute rate, given that this averages the variation in
rate across countries.
15 33 Could the authors address whether there could be another source of bias,
ascertainment bias. Could medical examiners be more likely to classify a death as a suicide
after a highly publicized suicide?
15 19 It seems to me like publication bias is probably a bigger issue for observational vs.
interventional studies. Many observational studies begin with an investigator using available
data to test a hypothesis, an analysis that may not see the light of day if the hypothesis
proves to be null.
15 28 I would steer clear of using the term “effect size” throughout. The association is
weaker for studies with lower risk of bias. This suggests that the bias is in the direction of
overestimating the effect size. You might consider using the relative risk from the low risk of
bias studies as a more realistic appraisal of the association, or at least admit that this might
be the case.
