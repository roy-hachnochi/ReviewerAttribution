I thank the authors for their response to my previous review. The revision is improved,
and the conclusions tempered somewhat as appropriate. Most aspects have been
addressed well, but a few queries have sadly been dismissed outright. In particular, I
asked the authors for more detail on the actual analysis methods, as previously they had
simply referred to using a statistical software package. As a BMJ Statistics Editor for over
10 years, I am well aware that transparent and clear reporting is important to the BMJ, not
just for a clinical audience (who may indeed apply the results in practice as the authors
note) but also for those appraising the review and its findings (methodologists, reviewers,
those conducting umbrella reviews, and indeed clinicians and health professionals).
Therefore, to simply dismiss the need for more transparency of the analysis methods is
rather alarming.

For example, the authors say “We consider it impractical to provide exhaustive detail of the
statistical methods for conducting the network meta-analysis, and alternative ways of
conducting the analyses, due to both space constraints and the fact that these would be of
limited interest to, and potential confusing for, a readership that is composed
predominantly of primary care clinicians looking for up-to-date evidence on which to base
their day-to-day practice. We believe we have already provided adequate information
regarding the type of network meta-analysis and the software used. There are other
resources available elsewhere, which we have referenced, should readers wish to obtain
more detail regarding performance of network meta-analysis.”
In response to this, I would like to emphasise that there are no space constraints. The BMJ
publishes the full article on-line. Further, the details requested (estimation method and
assumptions made, and whether uncertainty is fully accounted for when producing
confidence intervals) are pivotal for understanding whether the methods used are
appropriate. The authors are not appreciating the importance of this, and the additions
would just take 2-3 sentences, so it is unclear why this is just dismissed. There are many
opportunities to disseminate their key findings in a briefer form (e.g. abstract, press
release, what this study adds, etc), but the full article must adhere to reporting guidelines
and be transparent.
That being said, most of the responses I find adequate, so I don’t want this issue to detract
from the generally well conducted work. But I hope the authors will reconsider their stance
to not addressing my comments for a few more details.
Further comments
1) The authors say: “Estimates of τ2 of approximately 0.04, 0.16, and 0.36 are considered
to represent a low, moderate, and high degree of heterogeneity, respectively” – why are
these numbers valid? Surely this depends on the actual outcome being analysed, the scale
of analysis, and the magnitude of the pooled effect (variability around a OR of 1.1 may be
more important than variability around an OR of 5 say).
2) I asked for the authors to give study-specific results, not just the pooled results. But
they feel this is an unreasonable request. I see that the authors report that they do
adhere to the PRISMA extension to network meta-analysis. Therefore, I refer them to item
20 in the PRISMA extension to network meta-analysis that says: “Results of individual
studies: For all outcomes considered (benefits or harms), present, for each study: 1)
simple summary data for each intervention group, and 2) effect estimates and confidence
intervals. Modified approaches may be needed to deal with information from larger
networks” This is not a large network, so I do not see the issue of at least presenting
study-specific results in the supplementary material for each outcome (or at least the main
outcomes). Again, this is to ensure transparency of the evidence.
3) The authors says: “As there were direct comparisons between all of the management
strategies, we were able to perform consistency modelling to check the correlation between
direct and indirect evidence.” – change the word correlation to agreement.
4) The authors say: “there was no evidence of inconsistency after applying the χ2 test of
the Q statistic (1.91, P = 0.93).” There is potential confusion here, because the Q statistic
is used to examine between-study heterogeneity, and not inconsistency. This (and later
occurrences) must be revised using the correct method for conducting a global test for the
presence of inconsistency. They refer to my paper (ref 35), but this does not recommend
using the Q statistic to do this. References that show the correct approach are as follows:
Higgins JPT, Jackson D, Barrett JK, Lu G, Ades AE, White IR. Consistency and inconsistency
in network meta-analysis: concepts and models for multi-arm studies. Res Synth Method.
2012;3:98-110.

White IR, Barrett JK, Jackson D, Higgins JPT. Consistency and inconsistency in network
meta-analysis: model estimation using multivariate meta-regression. Res Synth Method.
2012;3: :111-25.
5) “When data were pooled, there was no statistical heterogeneity (τ2 = 0.007)” – rather
say there is very little observed heterogeneity; as tau-squared is > 0 this is some small
heterogeneity. Same issue occurs at later points too.
In summary, many responses are entirely appropriate and I thank the authors for that. I
hope the few outstanding issues will be addressed in the next revision.
Best wishes,
Prof Richard Riley, BMJ Statistics Editor.
