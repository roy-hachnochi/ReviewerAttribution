Interpretations from 115 pathologists of 240 breast biopsy specimens (atypia, DCIS, and invasive cancer, one slide
per case, were used to establish baseline accuracy of single observers’ diagnoses. These were compared to accuracy
based on independent interpretations by pairs of pathologists (N=191,760 paired interpretations). The authors then
evaluated twelve strategies aimed to reduce misclassification rate, with the “true” classification based on expert review
of 3 expert breast pathologists. This is an informative and detailed study of a very clinically relevant problem
encountered frequently in daily practice.
The strategy of creating pairs and triplets for the analysis is clever and statistically efficient. However, the title is
misleading in that the study actually compares the misclassification rate if the first and second opinions agree and the
accuracy of the third opinion if the first and second opinions disagree.
Were there cases where there were 3 separate and different opinions? If so, how were these cases handled—were they
excluded from the analysis?
Most of the misclassification appears to arise in the diagnoses of atypia and DCIS. How often did the 3 expert opinions
differ in their adjudication of atypia vs DCIS? The most clinically significant misclassification lies in upstaging of atypia
to DCIS or downstaging of DCIS to atypia. Can any conclusions be reached about those cases which were most
frequently misclassified?
Were there any “outliers” who consistently achieved highest concordance with expert review? If so, can any
conclusions be reached about this group?
