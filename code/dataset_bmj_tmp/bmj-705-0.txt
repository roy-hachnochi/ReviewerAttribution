Thank you for the opportunity to review this very interesting paper. The investigators tackle the issue of timely trial result
dissemination, focusing on trials affiliated with academic institutions. The paper has a number of strong merits: the writing is
clear, the methods well-explained, the results logically presented and supported by relevant figures, and the discussion and
conclusions informative and appropriate for the findings. Overall, this work is relevant to a number of stakeholders in the
clinical and research arena and a general medical journal would be appropriate.
There have been a number of prior studies using ClinicalTrials.gov to examine trial publication and results reporting, so this
study is not entirely original from that standpoint. However, results in these studies suggested concern around the
commitment of academic institutions to timely result reporting, which justifies a focused examination of result reporting
patterns by academic institutions, as was done here.
I have a few suggestions that might improve the manuscript:
- Given the focus on academic medical centers, the definition of these is critical:
-The investigators state they used the ‘role’ and ‘affiliation’ fields in the registry to identify PIs affiliated with academic medical
centers, though I am unable to find these. Perhaps they are referring to the information under ‘Investigators’?
- The academic centers listed in Table 2 and Figure 2 appear to be a combination of universities and individual
hospitals/centers (e.g. Memorial Sloan-Kettering, Massachusetts General Hospital, Brigham and Women’s Hospital, etc).
Should individual hospitals belonging to the same academic medical center be combined?
- Could the authors include information on how many centers were excluded due to <40 clinical trials?
- Trials with a “withdrawn” status were excluded. Trials in the registry can also have a status of “suspended” and “terminated”.
Were these also excluded?
- For the publication search, it is typical to have 2 investigators perform an independent search for each trial or to attempt to
contact the PI for further publication information, though I recognize this may not have been feasible in this case given the
large trial cohort examined.
- The authors should provide additional explanation on why they chose to use both PubMed and Scopus and why they used
different search protocols in each. Many publications still do not include the NCT number and will therefore not be identified in
PubMed using the search approach they describe.
- There were a number of trials (5%) with publication dates that preceded the listed completion date. This is prominently
mentioned throughout the paper, including the methods and multiple times throughout the results. Did the authors consider
contacting PIs for some of these trials to investigate this discrepancy? They mention in the limitations that this most likely
represents errors in data entry, but we cannot assume this.
- Certain sections of the method and results are a bit repetitive and could be presented more concisely. For example, on page
6, the section beginning with “Since the dates are reported by only the month and year,….” is presented, almost verbatim,
twice.
- The first sentence of the results should specify that the 5020 interventional trials identified are limited to those with academic
affiliations.
- In the results section, another trial characteristic that might be worth examining is randomization status.
- Table 2 might be better suited to an appendix table since many of the relevant results from this table are presented in the
text and Figure 2.
- The authors state that the academic institutions examined include some of the nation’s “most prominent” research
institutions. Since this is not something that was specifically measured (and the reader can look at the academic centers listed
by name in the table and figure), I wouldn't highlight this.

Florence Bourgeois, MD, MPH
I have no competing interests to declare.