Comments from Joseph P. Drozda, Jr., M.D.
This is an observational study of innovative medical devices with first-in-human studies published in 2000-2004 that
were subsequently approved by the U.S. FDA. The authors found that just less than half of devices received regulatory
approval, that the 510(k) pathway was the most common route to approval, and that industry collaboration was
associated with significantly greater success in achieving FDA approval. These authors previously published a study of
the translation of innovative devices from the laboratory to first-in-human studies.
In general, this is a methodologically sound study that was likely to capture most studies of novel devices that were
published during the specified time period. It explores further a matter of increasing policy interest, i.e., the processes
by which medical devices are developed, approved, disseminated, evaluated with respect to real world effectiveness,
and iterated to improve performance or removed from the market for lack of effectiveness or safety issues. An
understanding of these processes is important in an era of health care delivery and payment reform because of the
simultaneously increasing utility and costs of medical devices. The FDA is currently evaluating this medical device
ecosystem with respect to both premarket approval and postmarket surveillance. Most clinicians are unaware of the
details of the medical device approval process and would benefit from the information presented in this study. For
instance, it appears odd that the most common pathway for regulatory approval of innovative devices is the 510(k)
process, which is designed for devices that are substantially similar to existing devices.
I have the following specific comments:
• The following sentence appears in the abstract (lines 56-7): “The proportion of devices receiving regulatory approval
was then compared using the Chi-square test.” This leaves the reader wondering, “Compared to what?” The question
is answered in the Methods section of the paper (lines 164-171). I know that this paragraph cannot be reproduced in
the abstract but a brief statement regarding the comparison should be included.
• An important part of this study as stated in the Introduction was the assessment of the roles of academia and
industry in obtaining regulatory approval. According to the Methods section (lines118-120), the involvement of
industry was determined in the papers describing the first-in-human study. I would think a better source of that
information would be the FDA regulatory documents since it is possible that industry could have become involved with
a device after the first-in-human study or could have abandoned the product before regulatory approval (less likely).
• The most significant concern from a methodological perspective is the process by which studies were selected for
analysis. This process winnowed the 5,574 papers identified in the PubMed screen down to 218 included studies and
involved significant judgment at each step, e.g., 5,081 records excluded based on titles and abstracts. The methods
used for making these judgments should be clarified. For example, were all abstracts reviewed and scored
independently by 2 or more investigators? If so, what was the process for adjudicating differences in scoring?
• The first heading in the Discussion section contains a spelling error. It should read “Principal findings.”
• The conclusions appear appropriate with the most significant and most concerning one being the large proportion of
innovative medical devices being approved through the 510k process without rigorous clinical trial data on safety and
effectiveness.