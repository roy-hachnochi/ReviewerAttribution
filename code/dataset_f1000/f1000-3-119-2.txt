Improving reproducibility is a key challenge and topical area in the life sciences. The submitted manuscript provides a well written and interesting commentary on the topic and suggests two key approaches to improve reproducibility, based on technical review and incentivizing replication. I think the paper is suitable for publication, but suggest the authors consider the following comments if they produce a revised version. It is fair to praise Nature and EMBOs recent efforts, but many scientists would put some blame for current problems on cut down methods sections, driven by space constraints which were/are imposed by some journals such as Nature and EMBO. Standardised methodologies would need to be implemented carefully to avoid stifling scientific progress in developing methods and I suggest this would need to involve scientists as well as publishers? I believe that clearer and longer methods sections are an important and easily achievable way to help improve reproducibility, we have written comments on one small aspect of this, the reporting of antibody use (Helsby MA, Fenn JR and Chalmers AD (2013) Reporting research antibody use: how to increase experimental reproducibility [v2; ref status: indexed, http://f1000r.es/1np ] F1000Research 2013, 2:153 (doi: 10.12688/f1000research.2-153.v2). The authors mention the important RII, but I suggest they could give more prominence to the importance of comprehensive reporting of methods, controls and reagents. It would link directly to their point about better technical review as this is impossible without having well documented methods. The section (2) on different ways to carry out replication could more specifically mention individual scientists trying to replicate findings for their own research, this work is already carried out so involves no additional funding. The key (as mentioned) is then incentivising scientists to publish this work. I wonder what the authors think of initiatives like PubMed commons, aimed at collecting comments on papers, would this provide a format for shorter comments on the ability to reproduce key findings where the scientist concerned might not feel the data warranted a full publication? Is this another useful example of crowd-sourced post publication review? 