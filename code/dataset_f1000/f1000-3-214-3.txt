This paper reports an attempt to develop an original tool that simulates alanine scanning mutagenesis to probe residues involved in the process of ligand recognition in proteins. More precisely, the work describes the development of a work flow that implements known methodologies for homology modeling of alanine single-point mutants of a protein and for molecular docking. Even though, this can be viewed as a methodological paper. We have some serious concerns regarding this work. The authors claim that they performed a "validation" of their tool on a dataset that comprises "79 entries" carefully selected from PDB (also cf point 2 below). Their evaluation is based on finding a correlation between docking scores with experimentally determined binding affinities. In their paper, the authors provide evidence of this validation by providing results of "Experimental correlation" for only one example (Figure 2) which relates to binding of rat 3-alpha-hydroxysteroid dehydrogenase (PDB: 1AFS) to testosterone and progesterone. Since they must have it, clearly, the authors should provide their evaluation of this correlation on all "79 entries". I would expect at least that they provide a new Figure 2 that comprises all data points coming from these "79 entries" to sustain their claim and help readers to evaluate the global performance of their tool. They attempted to provide few additional results on their website ( http://proline.biochem.iisc.ernet.in/abscan/validation ). It is more confusing because the results provided for the vitamin D receptor (PDB: 1IE9) is not about binding affinities but "translational activity". Im here suggesting that detailed data for all mutations taken from all "79" entries are provided to the community in the form of a table or downloadable flat or excel-type file. The amount of independent PDB entries in their dataset is not 79. In fact, in some of PDB entries, multiple ligands were observed. Surprisingly, they consider these as separate entries. So their data is redundant with respect to the proteins. When generating homology models for protein variants, even if these are single point mutants, assessment of the quality of the models is a critical step. Selecting best models may not be that trivial. The authors need to clarify how they implement in their work flow the assessment of the quality of the models and consequently, what criteria they used for selecting the best models (and how many of them) that will be subjected to molecular docking. Regarding the alanine scanning procedure, there are issues regarding the treatment of alanine and proline. They should both be discarded from the alanine scanning protocol: alanine is already present in the structure while proline is not suitable for mutations because of the major protein backbone rearrangements that should be performed to properly mutate it. For such a tool, it is at stake to evaluate its performance using different homology modeling and molecular docking methods. The rational behind the choice of Modeler over other methods like Rosetta is not indicated. Likewise, the reason why Autodock and not Dock etc or even Autodock Vina is not explained. The efficiency of molecular docking using AutoDock is also dependent on the docking protocol used. In such an automated "screen", care should be taken about the preparation of the receptor, the ligand and the grid. For example, are the ligands kept flexible ? In the manuscript, there are no indications about how the authors dealt with this central issue. The authors are encouraged to describe precisely and discuss their docking protocol. According to the AutoDock 4.0 article, the median error range in energy estimation for any protein-ligand evaluation is 1.5-2.0 kcal/mol. In their study, the ∆∆G differences for ligand binding between mutant and native forms of the proteins are far below 2.0 kcal/mol. Thus, it is difficult to rank the mutants. Also, how the authors chose the 0.5 kcal/mol ∆∆G threshold is not clear. There is no discussion how this threshold compares with the intrinsic limits in precision of AutoDock. The definition of ligand in the tool is problematic. In case of oligo or polysaccharides, the carbohydrate residues are erroneously considered separately. For example, in the 1J84 entry from PDB, the carbohydrate-binding module (CBM) is bound to cellotretraose, a 1,4--D-glucan composed of four -D-glucose residues linked by -1,4 osidic linkages. When this PDB entry is submitted to ABS-Scan, it erroneously splits the oligomer into smaller entities that correspond to the chemical IDs of its constituents (BGC 401, 402, 403, 404). This is a serious flaw in their software. While it is common to see people to reuse available codes, the authors do not properly cite the source of their codes they posted on Github and used for providing a complete service to the community: at least 80% of the code comes from either MODELLER examples ( http://salilab.org/MODELLER/wiki/Mutate_model ) or AutoDock code ( http://mgltools.scripps.edu/api/AutoDockTools/AutoDockTools.Utilities24.compute_AutoDock41_score-pysrc.html ). 