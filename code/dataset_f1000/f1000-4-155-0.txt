Chakraborty et al. implemented a workflow for error estimation and correction, functional annotation and abundance estimation in RNA-seq data. They explored a methodology of analyzing longest ORFs of transcripts, using BLAST, as means to identify important genes. Although BLAST has been very commonly used for annotation, the authors proposed a very systematic approach of dividing the annotations into four sets based on the quality of the ORFs and their functional assignments. Overall comments: The authors have done a good deal of work in exploring an important topic. The article gives many ideas worth exploring and directions for annotating data from de novo transcriptome sequencing. However, I suggest that the authors pay special attention to the usage of different terms (genome, transcriptome, RNA-seq, reads etc.) and be consistent in their usage throughout the manuscript. Additionally, the figure legends need complete re-writing and the perl scripts need to be included in the supporting information. Several explanations need to be provided throughout the manuscript (details below). A single round of proofreading will hugely improve the manuscript. Specific suggestions/questions: The title states that YeATS identifies a highly transcribed putative extension. This is a bit misleading. YeATS takes as input already assembled transcripts from Trinity, estimates their expression, employs BLAST to try and assign a function to the most highly transcribed gene, and finds no known homologs. Only from the manual examination of the amino acid content of its longest ORF do the authors come to the conclusion that it is a putative extension. It will perhaps be better to mention the error-detection and estimation capabilities of YeATS as its strongest points. Introduction: What evidence is there to suggest that a putative protein with a high percentage of leucine, histidine and valine is a probable extension? Where does Algorithm 1 fit in? Why is it needed? Merging of transcripts is mentioned for the first time in methods, without an explanation of why it is important and where are its potential applications? The authors should explain the algorithm and how it serves in detecting error in assembly/sequencing, and what kind of transcripts should be used in merging. Algo 1 - Why is the length range defined as 5 to 15? Is there an explanation behind the selection? Also, 5-15 is nucleotides or amino acids? Algo 1 - Please clarify why 2-letter strings have been called a 'repetitive'? They should be ignored, agreeably, because they are too short to give any reliable results, but it is misleading to call them repetitive? In algorithm 1, what is meant by 'prefix' of transcripts? If the workflow, YeATS, is so strictly dependent on the Trinity transcript headers, it needs to be clearly mentioned in the article. Is 'TRS' equivalent to 'transcript'? Please include a list of abbreviations used in the manuscript at the beginning of the manuscript. Is there a rationale behind running BLAST a second time, when from the very first BLAST run, which gives the best ORF selection, the gene functional annotation can also be obtained? This could make use of the Algorithm 2 and reduce the overall runtime. Algo2 - The genome does not picture anywhere here, therefore, is misleading to say 'identifying homologous genes in the genome based on the transcriptome.' Algo2 - is 'lengthcutoff' a % or number of nucleotides or amino acids? 'Input' says %, whereas in the algo it is simple difference. Algo2 - 'Both these transcripts are now potential genes', which 2 transcripts are the authors talking about? Equation 1 - Which raw counts are these? How are they obtained? What is 'score' in equation 1? Sequence alignment of what was done using ClustalW? What was it used for? In vitro methods The authors should list the 19 different samples whose cDNA libraries were sequenced. Were these combined and assembled as a single transcriptome? Is this used a reference for read alignment and counts estimation? If not, what is the reference for read count estimation? All bases below quality score 35 were trimmed? That is a very stringent criterion. You would lose a lot of data if not a single base below 35 quality score is retained post-trimming. Why did the authors choose to use this? TZ - please expand the abbreviation. bwa aln gives aligned files, not counts. What was used to generate the raw counts? Also, bwa is not a splicing aware aligner. Authors should use Bowtie instead to do this, which may prove to be a better alternative. All the figures need to be improved. In all figures, the sequence in question should be highlighted / boxed to make it easier for the reader to follow what is being talked about. Figure 5 legend - 'shows the repeat'. which repeat? Authors should clearly mention that there are 2 contiguous repeats of the same 39aa sequence in the transcript C55368_G1_I3. Also, there are 2 different reasons mentioned why the assembler could not merge the 2 transcripts in question. Please clarify which is the case. GitHub repository The README file requires substantial work. Some of the commands are quite confusing, comments are not clear, and perl scripts are not to be found. The numerous manual steps make the tool virtually un-useable.