This article describes a multiple-week ecological exercise that has both field and laboratory components and combines opportunities for collaborative learning, peer assessment, and individual work, with instructor feedback included at several stages. An important component of the three-stage assignment is the pivotal role of technology, in the form of free Google online tools, in order to facilitate the collaboration between students and the delivery of feedback from the instructor. The introduction does a nice job of providing context and articulating the rationale behind the design of the method described. The assignment is well-conceived, and there is a natural progression from group work and collaboration toward individual demonstration of learning outcomes. Especially valuable is the opportunity for the students to engage in assessment of their peers, a high-impact activity that the authors noted led to higher achievement in the final stage of the assignment for those students who fully participated in the peer-review. This method should be easy to implement for instructors willing to do so. General comments to consider during revision: Change peer assignment to peer assessment better reflects the nature of the activity, less confusing. Make the abstract a bit more explicit; for example, in the third paragraph it states that the assignment was a success. Based on? How so? The answers are there, but the reader has to wait for them and is not certain if she has correctly identified them. Go all the way when making a statement; dont lead the reader part of the way there, and expect him to complete the thought the way you intended. Be explicit. This comment goes for the article in general. In the introduction, the authors refer to the Challenger Philosophy the hyperlink requires additional log-in information and is not generally accessible. Please summarize the key points and remove the hyperlink. The authors repeatedly reference the Minimum Undergraduate Standards, which appear on pages 27-32 of a 79-page PDF that is hosted elsewhere online. These standards should at a minimum be summarized (so that the reader doesnt have to find them in the aforementioned document in order to know what type of criteria are included). Since the PDF that contains them is likely to be updated regularly the by School of Biological Sciences at University of Essex, therefore causing the page reference to change, the authors may wish to create a static, free-standing document containing this information. Under Methods, Stage 1: What kind of information was disseminated via Moodle to prepare students for the habitat visits? What background information did the students have? I was often distracted by the lack of information provided about the field and laboratory portion of this assignment (although I could clearly follow the collaborative and individual written work). What size quadrats did the students use? How did they go about species identification? When the soil samples were collected, the authors state that the vegetation was put in one labeled sample bag and the soil in a second. Was that the upper, vegetative layer of the soil sample, and for what purpose? How were the insects collected? By Berlese funnel from the soil samples? Were they just the invertebrates that were observed while the students were in the field? Add more information about Instructor Feedback in the Methods section; what kind of feedback was provided at each stage? Were students assessed primarily based upon the presentation criteria (following guidelines regarding Tables and Figures, etc.) or were they also assessed to some degree on accuracy/correctness of information presented (for example, in Figure 2, the student notes state that Plantago major is a monocotyledon, which is erroneous; it is a Eudicot)? Based on the article title, a reader will expect more information about this aspect of the research. I like the examples of student generated work. It might be nice to include a few more examples under Supplemental Materials for those who would like to view them. I was a bit surprised by the amount of students who didnt participate in stage 2 (26%). Any suggestions for how to resolve this issue? Why the low buy in by these students? I think it would be nice to include a little more information about the lecturers experience. Could some of this be added to the Results and/or Discussion? The final paragraph of the paper ends oddly. It seems to reference a future event (having students use Google Apps for their third year project) but talks about it in the past tense (but this time they took ownership consider revising. It is not a good idea to end an article with a parenthetical comment (weakens it). Quick fixes: Data are plural (see 5 th paragraph under Results) Second to last paragraph under Results, Stage 1: The large number of data sheets generated (21) meant I think the number in parentheses should be 28. Overall, a nice teaching module that I would encourage instructors to try; I can envision several standard laboratory or field exercises that could be modified and expanded to include the collaborative group work, peer assessment, and individual analyses presented here. It is a really nice model. The article itself can be strengthened by providing more details, where relevant, and by being more explicit. 