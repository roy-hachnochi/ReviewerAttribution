There is certainly demand for software to assess the functional impact of sequence variants within the noncoding majority of the genome, and the FORGE tool is intended to help address this. The choice of DNase I hotspots at a general indicator of regulatory activity is justified, and the interactive presentation of enrichment results in the web tool is useful. However, the manuscript gives the impression of having been put together in a hurry, arguably lacking the depth of exploration necessary to generate robust analyses or a sufficiently flexible tool. I make some specific suggestions for improvements below. Major revisions The authors adopt a sampling strategy to discover significant enrichments of a set of variants within datasets of annotated regulatory regions. Both the regulatory regions and the SNPs represented on genotyping platforms are not uniformly distributed across the genome, and show some degree of clustering. For example, both might be expected to be enriched in and around genes. It is not clear that the authors sampling approach can generate a null distribution that faithfully represents this clustering, and there is therefore a danger that the significance of enrichments are exaggerated. Alternative approaches, such as Genome Structure Correction (cited by the authors) and circular permutation (eg Kindt et al, 2013, BMC Genomics 14:108) exist that could generate an appropriate null distribution, and the results could be compared to those from the sampling approach. As the authors point out in the Discussion, the results of these enrichment tests are dependent upon the background set used. For users to generate meaningful results they must select the appropriate genotyping platform as background. However, the web tool offers two background options, with the default as "GWAS typing arrays". Firstly, it is not clear what this option means, perhaps the union of SNPs for all NHGRI GWAS platforms? Secondly, given the notorious differences in ascertainment bias between genotyping platforms, this would seem to make it likely that most web tool users will use an inappropriate background (ie not matched to the platform they have used). Users employing the command line tool will face the task of tailoring each analysis to the appropriate background set, which may become labour intensive. This problem could be circumvented by using a general strategy (such as circular permutation) to produce a null distribution for each test. At the moment the DNAse datasets for different tissues are implicitly treated as independent, with each enrichment reported separately, which the authors admit is inaccurate. However, where the dependencies of these datasets are discussed the issue seems to be confused with controlling the false positive rate. The manuscript would benefit from a fuller discussion of this, and ideally some exploration of the interdependencies present eg using multiple regression I suspect the question most readers will be left with after reading this manuscript is, how does this tool relate to the others already available? If the intention is not to rigorously compare statistical methods, the authors could at least compare the features of other competing tools. The HaploReg tool (referenced by the authors) for example seems to include similar tests with more flexible LD calculations, and a greater range of functional annotation. Minor revisions It would probably make sense to order the enrichment results by the significance of enrichment, which does not appear to happen at the moment. A more flexible LD threshold for the web tool is desirable, at the moment only two values (0.1, 0.8) can be selected. The option of an FDR correction for the results would be a welcome addition to the Bonferroni correction implemented. Many journals now consider it unacceptable to use the comment "data not shown" to support assertions in the text, and this comment appears twice in this manuscript, along with one instance of "results not shown". 