This paper lays out a clear and relatively concise example of a linear workflow for analysing an RNA-seq based Differential Gene Expression experiment. The workflow focuses on doing all the analysis steps within R using the author's preferred tools (Rsubread edgeR) and extends usefully to common aspects of pathway analysis with GO terms, Kegg terms and Gene Set testing. While I'm sure this paper will be useful for a section of the community (particularly newcomers to this kind of analysis), I find the paper to be quite simplistic and lacking in depth and discussion. In particular, there is no discussion of the subtleties involved in performing this kind of analysis at the coalface of scientific research. Some particular points I would like to have seen discussed are: How many replicates should be used for this kind of analysis. The example study uses a very poorly replicated dataset. In this case two replicates per condition *may* be sufficient, but not only is it not discussed but for most experiments this is highly misleading! For new RNA-seq experiments a significantly higher number of replicates should be used, both to guard against problem samples/libraries and to ensure sufficient statistical power to identify significant differential expression (in particular because it is rare to know how large the changes in the data will be before you do the experiment). How might one identify problematic issues with datasets that aren't as cooperative as the example dataset. For example, what would significant structure or curvature in the point cloud of the MD plot signify? If the samples don't cluster nicely on the MDS plot by condition, what might this mean (mislabelling, bad replicates, etc)? How one might remedy or deal with the problems in such uncooperative datasets. For example, what general approaches could be used for isolating the root cause of the observed problems? How might we adjust the analysis to ameliorate the problems and their downstream impact (dropping datasets, changing mapping parameters, filtering the data)? How one might go about choosing sensible selections and thresholds for the data. In my opinion the use of 'standard' and/or 'default' parameters, thresholds and selections (e.g. unique=TRUE, FDR0.05, log2(FC)1, cpm0.5, etc) is a significant and endemic problem in this field. Often these are used solely because they have been used widely before, rather than considering whether they are appropriate for the specific data being analysed. What caused the authors to choose the values they use for this data and what key plots or pieces of information are valuable for choosing these appropriately? How the various selection steps, thresholds and even the version of the software used, might impact on the downstream results. For example, if you change the FDR threshold from 0.05 to 0.01, how does this impact the downstream pathway analysis? Are some of these analyses insensitive to threshold values (e.g. gene set analysis) and does this make them better/more useful? If you change the cpm threshold to 1.0, or if you allow non-unique read mappings, how does this impact the number of identified SDE genes and the downstream pathway analyses? I am not suggesting that the authors should have given an exhaustive account of the issues. Rather, I think the paper would benefit from briefly discussing some of the more subtle and complex issues surrounding these types of analyses and perhaps highlight some key problems, parameters and thresholds that should be thought about carefully. Without this the paper really presents a very linear, idealized, example of what, in practice, are complex analyses that may require considerably more thought and investigation. I also encountered some more specific issues: The link provided does not (currently) link to the actual bioconductor workflow. I ran all the R commands and they all work (except 'fry' see point 4 below), however I didn't get exactly the same results when (and after) filtering out genes without a symbol. The paper has: head(y$genes) Length Symbol 497097 3634 Xkr4 100503874 3259 Gm19938 100038431 1634 Gm10568 19888 9747 Rp1 20671 3130 Sox17 27395 4203 Mrpl15 y - y[!is.na(y$genes$Symbol), ] dim(y) [1] 26357 12 I had: head(y$genes) Length Symbol 497097 3634 Xkr4 100503874 3259 Gm19938 100038431 1634 Gm10568 19888 9747 Rp1 20671 3130 Sox17 27395 4203 Mrpl15 y - y[!is.na(y$genes$Symbol), ] dim(y) [1] 26608 12 The change is relatively small but it cascades causing differences in the genes that pass cpm filtering, differences in the normalization factors and differences in the DE results and the downstream analyses. I suspect this is the result of using a slightly older version of org.Mm.eg.db (3.2.3, vs 3.3.0) due to using an older version of R (3.2 vs 3.3). This goes nicely to point (5) above. There is no real description of the reasoning behind scaling of the heatmap values to a mean of zero and std dev of one. The 'fry' command failed for me, producing the error: fry(y, index=cyt.go.genes, design=design, contrast=B.VvsL) Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x), : 'data' must be of a vector type, was 'NULL' 