The authors present a honest evaluation of an operational research project to innovate a new tool for recording, visualising and sharing medical data in response to the challenging needs of a high risk infectious situation in a humanitarian emergency, namely the outbreak of Ebola in West Africa 2014-15. This is an interesting and valuable paper about developing a clinical information and patient management system based on tablet computers that can be used in Ebola Treatment Centres and similar high risk environments. It is mainly a narrative paper with little in the way of quantitative results. The lessons learned are fairly generic to any project management challenge, and go beyond those of innovation in humanitarian settings. They describe the process of developing a tablet and new software to respond to the complex requirements of high bio-hazard infection control, and compare this tool with standard practice in this setting. They note the urgency of the project, which was intended to improve clinical care, and by implication outcomes, for patients by helping medical staff make more efficient use of the limited time they could spend in the red zone due to the constraints of personal protective equipment. The title is appropriate and the abstract is generally clear, although I felt that the description of the comparison of tablet and paper-based data was not clear. It was not just tablet data that were analysed, and what is meant by ‘record “pairs”’ is not clear just from reading the abstract. The background and methods are mostly clear and appropriate. I am not an expert on computer hardware or software, so cannot comment on the appropriateness of the systems selected. The researchers used a mixed methods approach appropriate for the different aspects of the project they wished to evaluate: namely need identification, buy-in, implementation, tool functionality and maintenance, and a measurement of data quality. They have identified key issues that delayed the process of development and the limited testing of the tool they were able to achieve. I am astonished at the cost of development of the system, which seems to have been driven largely by the salary costs and person-hours involved, as well as producing customised hardware. It was not clear to me quite how the data collected in the high risk zone were exported for further analysis and storage. Was this by disinfecting the tablets in chlorine and physically removing them from the high risk zone, or was it through connection some form of local area network that allowed the data collected in the high risk zone to be electronically transmitted outside? This could be made clearer. I wondered about issues of confidentiality of patient data being transferred from Sierra Leone to the MSF headquarters in Europe (panel 2). How were these addressed, approved and overseen? I was surprised that no data were collected on clinical management according to panel 3. This seems like a missed opportunity, as further research into optimal management of cases of ebola is still required. There is comment about this at the end of the discussion (page7), but was this an oversight when the system was being developed? Did this study undergo any ethical scrutiny in Sierra Leone? I would imagine that it should have done, but this is not mentioned. Methods para 6: Suggest rephrasing the second sentence to make it clear that this part of the paragraph refers to data extraction for the tablet, and the latter to the paper/excel database. Is it a correct understanding that only the first tablet entry of the day was taken into account? If so, could you mention why it was not possible to take account of subsequent entries given the relatively small number of records under analysis Did practitioners entering data in the high risk zone review their own entries once out? Our question refers to the comment in the first para of the discussion about opportunity for correction. It might be useful to include a paragraph on the procedure for using the tablet. The results are very interesting, and it is good to see an honest description of the problems encountered with this project. Their results highlight areas of tension in the process and detail the successes (a functioning tool with good data capture) and failures (implementation too late to have impact on patient care, and lacking one of the initial requirement – a way to find patients in a large facility) of the project. From both they draw out lessons for future innovation between humanitarian and technological enterprises. They also detail the technical specifications and overview costings for the tool. I was not clear what was meant by ‘transfer of knowledge of the hardware from Google to MSF did not occur’ (page 5). Further on in the discussion section of the paper there is a comment about the transfer of knowledge, but this appears to be related to the software rather than the hardware. Indeed, it seems that this problem has been overcome and the software has been adapted for use in other emergencies (page 6). I would have appreciated more information about the ‘significant work needed to clean and analyse the exported data’ from the tablet. Why was that necessary? The results are generally clearly described, and suggest that the tablet may be at least as good as paper records, though the analysis currently does not appear to take into account the role of chance, and a proportion of records (17% ?) had to be excluded. The qualitative study is quite weak. It appears that different data were collected systematically using the two different systems, so only some of the data were collected using both methods. Further comments on the quantitative study are: If we understand correctly the agreement between the two methods was calculated by simple percentage agreement: would it be possible to perform a Kappa test to take into account chance? What was the range of interaction pairs per patient? Was any difference seen in the recording by either method related to the severity of the patient’s illness, or the number of people admitted at the time? Is it possible to state the percentage of missing data overall and/or by recording method and comment on the implications for the agreement results? On rough calculation overall it seems to be 17% (204-(85x2) = 34, 34/204) missing data in one or other system. The agreement between data sources ranged between 69 and 95%. This is rated as ‘high consistency’ but I was not sure on what basis. It was not clear to me, which collection method was felt to be the gold standard, or even if this was determined before the comparison. I sense from the discussion, the tablet was thought to perform better than the paper method, but I am not convinced about this from the results. There was clearly a tension between MSF wanting a ‘good-enough‘ product, and Google being perfection-driven. I suspect this was not just a question of communication, there is likely to be some underlying differences in corporate culture, which might be hard to bridge even with all the time in the world. What is meant by ’Google’s haste to move onto the next project’ (page 6). Was this ebola-related, or simply reflecting that this department at Google was busy with a range of different projects? The discussion was well written and interesting. The authors claim that this is the first such device to be developed. How did they search for other evidence of similar projects? I heard anecdotally of other projects, but am not aware whether they reached fruition, or have ever been published in any form. It would be good to have a thorough systematic search to establish what else has been developed. Is it correct to assume that the more frequent and detailed data available with the tablet related to the recording of vital signs, which were not entered from the paper record at the time of analysis? Could you comment on the value gained from the additional encounters recorded in the tablet and whether users found recording real-time information was clinically useful? It is not clear to what extent this system can be made available to others. The reference to the consortium being established is to a website that is being prepared. What data are available from MSF in Amsterdam? Are they data related to the development of this tablet computer based system or the patient data from this Ebola Treatment Centre? This is not clear to me. In our view, however, the authors present a well-targeted piece of operational research undertaken in challenging circumstances with transparent insights into where the development process fell short. They make it clear that their results are limited, but provide a foundation for moving forward. 