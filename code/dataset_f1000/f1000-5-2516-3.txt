The research article “The refined biomimetic NeuroDigm GEL TM Model of neuropathic pain in the mature rat” describes a new neuropathic pain animal model designed to be more relevant to the development of chronic neuropathic pain in humans. The authors describe a model using mature adult rats with a percutaneous implant of GEL TM into the tibial nerve. The model is characterised for 5 months by assessing pain-related behavioural responses to mechanical stimuli and the effect of morphine, celecoxib, gabapentin and duloxetine. Histology of the nerve was also assessed. A pilot study is also reported assessing the pain-related behavioural response to the injection of human erythropoietin. The rationale for the development of a model of neuropathic pain that more closely mimics the human condition is sound. I agree that the most commonly used neuropathic pain models do not mirror the pathophysiology of the delayed onset of neural pain without debility as seen in many neuropathic pain patients. The authors provide detailed description of their methods and rationale and include an ARRIVE guidelines checklist. I am concerned that the Sham animals are not used as controls to characterise this model. The authors acknowledge that the sham animals are not homogenous in their pain-related behavioural responses (5 out of 8 animals develop pinprick-induced pain-related behaviours). However, I believe that this is the most appropriate control for this new model of neuropathic pain. I disagree with the claim that this model meets the NC3Rs criteria for refinement. Refinement refers to methods that minimise the pain, suffering, distress or lasting harm that may be experienced by animals. The longer duration of this model and the development of similar pain-related behaviours as observed in other neuropathic pain models does not meet refinement criteria. Specific recommendations: Title Description of the model as refined needs to be clarified in the article. How is this a refined model? Abstract Research objectives should be stated in the abstract. Strain of animal should be stated in the abstract. I do not think the results of the pilot study should be stated in the conclusions of the abstract. The main study characterising the model, which is appropriately powered, should be the focus. Introduction and background It would be useful to use more specific references for the type of pain that this model is meant to be modelling. Materials and Methods Animals were randomly assigned to groups as stated in the Methods section Study Design Paragraph. Please state how animals were randomly allocated to group. Also, state whether animals were randomly assigned to analgesic treatment groups and how this was carried out. Results The data supports the claim that the model does develop pain-related behaviours that develop gradually and persist for months compared to control animals. However, should the comparison be to sham animals? Do the analgesic responses reflect human responses? All figures: For presentation of results in the figures I recommend the used of standard deviations not standard error of the mean 1 . Figure 5: The Sham animals also show an increase in pain behaviour from baseline and this should be indicated with asterisks. Figure 7-10: How many animals were tested in the analgesic drug experiments? This should be clearly stated in the results section and in the figure legend. Were the same animals used for each drug? If so, this should be clearly stated. The authors give a thorough and transparent description of their data and analysis choices. However, I recommend that a statistician assesses the statistical methods. For example, I question the use of the Fisher’s Protected Least Significant Difference test as this does not account for multiple comparisons. I also query the use of the Bonferroni-protected contrast because, as I understand it, this should only be used following a significant ANOVA result. Discussion Study limitations should be explored. For example, the use of only reflex behaviours to measure pain-related behaviours. The paragraph outlining the implications to the 3Rs should be changed as I do not believe that this model is a refinement of the use of animals in research. This paragraph should also be moved from the conclusions section. Although, it should be noted that in the future if it does provide a more reliable model of human neuropathic pain then it has the potential to reduce the number of animals used in models that are not clinically relevant. References 1. Lang T, Altman D: Basic statistical reporting for articles published in clinical medical journals: the SAMPL Guidelines. Science Editors' Handbook, European Association of Science Editors . 2013. Competing Interests: No competing interests were disclosed. I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above. Close READ LESS CITE CITE HOW TO CITE THIS REPORT Currie GL. Reviewer Report For: The refined biomimetic NeuroDigm GEL™ model of neuropathic pain in a mature rat [version 2; peer review: 2 approved, 1 approved with reservations] . F1000Research 2017, 5 :2516 ( https://doi.org/10.5256/f1000research.10281.r16966 ) The direct URL for this report is: https://f1000research.com/articles/5-2516/v1#referee-response-16966 NOTE: it is important to ensure the information in square brackets after the title is included in all citations of this article. COPY CITATION DETAILS Report a concern Author Response 04 May 2017 Mary Hannaman , NeuroDigm Corporation, Colorado Springs, USA 04 May 2017 Author Response Your perspective is appreciated and your concerns have been addressed. EPO pilot study power statistics have been added to the revision. The initial sample size was based on prior investigations. The ... Continue reading Your perspective is appreciated and your concerns have been addressed. EPO pilot study power statistics have been added to the revision. The initial sample size was based on prior investigations. The Supplemental S3 refinement chart we added depicts how the refinement of a scientific procedure (as referred to by NC3Rs) that limits tissue damage can reduce acute pain, eliminate paw dragging, limb deformities, and self-mutilation. If rodent refinements reduced or eliminated pain their potential as models could be lost. Your pertinent question about the type of pain the model represents is best answered simply. We strived to elicit the types of evoked pain behaviors referred to as allodynia and hyperalgesia (1) that may develop gradually in patients after soft tissue trauma. We were trying to mimic in this study the chronic pain sustained for years as seen in humans. Most investigations would not need to be months long and studies can be shortened to any time after post procedure day 23. However, the longer possible duration of this study can possibly reduce the number of animals used in future studies. There is no homogeneous “sham group” represented by the data that could be used as a control over time. After 3 months 5/8 shams developed pain behavior and there was no single sham animal that had intermediate behavior in the values represented by the graphs. We took the unusual step of presenting the sham data individually to be perfectly clear about what happened in that interesting group. We purposely did not include asterisks in Figure 5, because it would be misleading. The shams’ individual data in Figure 6 resembles the human response — not all humans get neuropathic pain after a soft tissue injury. The EPO pilot study also helps characterize the GEL model by showing the analgesic effect of a localized biologic, which has not been demonstrated in the current models. The second author (DAF) consulted on experimental design and data display and conducted the statistical analysis of the behavioral data. Aside from expertise in neurobiology and IACUC regulations, he has taught undergraduate statistics and published several articles (2— 6) on experimental design, simulation, and ANOVA. Regarding the standard deviation instead of standard error, this recommendation by Lang and Altman (7) is curious because they offer no rationale for it in their paper. Use of standard deviations allows estimation of standardized effect sizes, whereas use of standard errors allows estimation of inference (null hypothesis test or confidence interval). Those authors might have had in mind that the use of standard errors without indication of corresponding sample sizes would rule out the estimation of standardized effect sizes by subsequent readers or meta-analyses. That is not the case in our paper because we explicitly include estimates of standardized effect sizes in Table 1. Thus, there is no reason to prefer standard deviations over standard errors, and the latter assist in informal estimation of significance for the many contrasts that we did not explicitly test. Fisher's protected least significant differences (PLSD) and Bonferroni: Note that planned comparisons can always be tested, unlike post-hoc comparisons (data snooping). We tested only planned comparisons in this paper. We quote the recommendations of experts Milliken and Johnson (8): Conduct an F-test for equal means. If the F-statistic is significant at the 5% level, make any planned comparisons you wish to make by using the LSD method. This includes not only comparisons between pairs of means but also comparisons based on any selected contrasts of the i ’s. If one has equal sample sizes, the Waller-Duncan method can also be used. For data snooping and unplanned comparisons, use Scheffe’s method. If the F-statistic for equal means is not significant, the experimenter should still consider any individual comparisons that he or she had planned, but should do so using either the multivariate t-distribution method or Bonferroni’s method. The experimenter should not do any data snooping in this case. Since the F-test for equal means is nonsignificant, Scheffe’s procedure would not yield any significant differences anyway. Your insightful question “Do the analgesic responses reflect human responses?” highlights a crucial issue that cannot be accurately answered despite extensive discussion in the literature. Presently “pain” in patients and experimental rodents is assessed by different assays. With similar “pain assays” the validity of such translational comparisons can be improved. References 1. Baron R. Mechanisms of disease: neuropathic pain—a clinical perspective. Nature clinical practice Neurology. 2006 Feb 1;2(2):95-106. 2. Fitts DA. Misuse of ANOVA with cumulative intakes. Appetite. 2006 Jan 31;46(1):100-2. 3. Fitts DA. Improved stopping rules for the design of efficient small-sample experiments in biomedical and biobehavioral research. Behavior research methods. 2010 Feb 1;42(1):3-22. 4. Fitts DA. The variable-criteria sequential stopping rule: generality to unequal sample sizes, unequal variances, or to large ANOVAs. Behavior research methods. 2010 Nov 1;42(4):918-29. 5. Fitts DA. Ethics and animal numbers: informal analyses, uncertain sample sizes, inefficient replications, and type I errors. Journal of the American Association for Laboratory Animal Science. 2011 Jul 15;50(4):445-53. 6. Fitts DA. Minimizing animal numbers: the variable-criteria sequential stopping rule. Comparative medicine. 2011 Jun 15;61(3):206-18. 7. Lang T, Altman D: Basic statistical reporting for articles published in clinical medical journals: the SAMPL Guidelines. Science Editors' Handbook, European Association of Science Editors . 2013. 8. Milliken GA, Johnson DE. Analysis of messy data, Volume I: Designed experiments. Wadsworth. Inc. Belmont, California. 1984. Your perspective is appreciated and your concerns have been addressed. EPO pilot study power statistics have been added to the revision. The initial sample size was based on prior investigations. The Supplemental S3 refinement chart we added depicts how the refinement of a scientific procedure (as referred to by NC3Rs) that limits tissue damage can reduce acute pain, eliminate paw dragging, limb deformities, and self-mutilation. If rodent refinements reduced or eliminated pain their potential as models could be lost. Your pertinent question about the type of pain the model represents is best answered simply. We strived to elicit the types of evoked pain behaviors referred to as allodynia and hyperalgesia (1) that may develop gradually in patients after soft tissue trauma. We were trying to mimic in this study the chronic pain sustained for years as seen in humans. Most investigations would not need to be months long and studies can be shortened to any time after post procedure day 23. However, the longer possible duration of this study can possibly reduce the number of animals used in future studies. There is no homogeneous “sham group” represented by the data that could be used as a control over time. After 3 months 5/8 shams developed pain behavior and there was no single sham animal that had intermediate behavior in the values represented by the graphs. We took the unusual step of presenting the sham data individually to be perfectly clear about what happened in that interesting group. We purposely did not include asterisks in Figure 5, because it would be misleading. The shams’ individual data in Figure 6 resembles the human response — not all humans get neuropathic pain after a soft tissue injury. The EPO pilot study also helps characterize the GEL model by showing the analgesic effect of a localized biologic, which has not been demonstrated in the current models. The second author (DAF) consulted on experimental design and data display and conducted the statistical analysis of the behavioral data. Aside from expertise in neurobiology and IACUC regulations, he has taught undergraduate statistics and published several articles (2— 6) on experimental design, simulation, and ANOVA. Regarding the standard deviation instead of standard error, this recommendation by Lang and Altman (7) is curious because they offer no rationale for it in their paper. Use of standard deviations allows estimation of standardized effect sizes, whereas use of standard errors allows estimation of inference (null hypothesis test or confidence interval). Those authors might have had in mind that the use of standard errors without indication of corresponding sample sizes would rule out the estimation of standardized effect sizes by subsequent readers or meta-analyses. That is not the case in our paper because we explicitly include estimates of standardized effect sizes in Table 1. Thus, there is no reason to prefer standard deviations over standard errors, and the latter assist in informal estimation of significance for the many contrasts that we did not explicitly test. Fisher's protected least significant differences (PLSD) and Bonferroni: Note that planned comparisons can always be tested, unlike post-hoc comparisons (data snooping). We tested only planned comparisons in this paper. We quote the recommendations of experts Milliken and Johnson (8): Conduct an F-test for equal means. If the F-statistic is significant at the 5% level, make any planned comparisons you wish to make by using the LSD method. This includes not only comparisons between pairs of means but also comparisons based on any selected contrasts of the i ’s. If one has equal sample sizes, the Waller-Duncan method can also be used. For data snooping and unplanned comparisons, use Scheffe’s method. If the F-statistic for equal means is not significant, the experimenter should still consider any individual comparisons that he or she had planned, but should do so using either the multivariate t-distribution method or Bonferroni’s method. The experimenter should not do any data snooping in this case. Since the F-test for equal means is nonsignificant, Scheffe’s procedure would not yield any significant differences anyway. Your insightful question “Do the analgesic responses reflect human responses?” highlights a crucial issue that cannot be accurately answered despite extensive discussion in the literature. Presently “pain” in patients and experimental rodents is assessed by different assays. With similar “pain assays” the validity of such translational comparisons can be improved. References 1. Baron R. Mechanisms of disease: neuropathic pain—a clinical perspective. Nature clinical practice Neurology. 2006 Feb 1;2(2):95-106. 2. Fitts DA. Misuse of ANOVA with cumulative intakes. Appetite. 2006 Jan 31;46(1):100-2. 3. Fitts DA. Improved stopping rules for the design of efficient small-sample experiments in biomedical and biobehavioral research. Behavior research methods. 2010 Feb 1;42(1):3-22. 4. Fitts DA. The variable-criteria sequential stopping rule: generality to unequal sample sizes, unequal variances, or to large ANOVAs. Behavior research methods. 2010 Nov 1;42(4):918-29. 5. Fitts DA. Ethics and animal numbers: informal analyses, uncertain sample sizes, inefficient replications, and type I errors. Journal of the American Association for Laboratory Animal Science. 2011 Jul 15;50(4):445-53. 6. Fitts DA. Minimizing animal numbers: the variable-criteria sequential stopping rule. Comparative medicine. 2011 Jun 15;61(3):206-18. 7. Lang T, Altman D: Basic statistical reporting for articles published in clinical medical journals: the SAMPL Guidelines. Science Editors' Handbook, European Association of Science Editors . 2013. 8. Milliken GA, Johnson DE. Analysis of messy data, Volume I: Designed experiments. Wadsworth. Inc. Belmont, California. 1984. Competing Interests: Author is a principal of NeuroDigm Corporation. Close Report a concern Respond or Comment COMMENTS ON THIS REPORT Author Response 04 May 2017 Mary Hannaman , NeuroDigm Corporation, Colorado Springs, USA 04 May 2017 Author Response Your perspective is appreciated and your concerns have been addressed. EPO pilot study power statistics have been added to the revision. The initial sample size was based on prior investigations. The ... Continue reading Your perspective is appreciated and your concerns have been addressed. EPO pilot study power statistics have been added to the revision. The initial sample size was based on prior investigations. The Supplemental S3 refinement chart we added depicts how the refinement of a scientific procedure (as referred to by NC3Rs) that limits tissue damage can reduce acute pain, eliminate paw dragging, limb deformities, and self-mutilation. If rodent refinements reduced or eliminated pain their potential as models could be lost. Your pertinent question about the type of pain the model represents is best answered simply. We strived to elicit the types of evoked pain behaviors referred to as allodynia and hyperalgesia (1) that may develop gradually in patients after soft tissue trauma. We were trying to mimic in this study the chronic pain sustained for years as seen in humans. Most investigations would not need to be months long and studies can be shortened to any time after post procedure day 23. However, the longer possible duration of this study can possibly reduce the number of animals used in future studies. There is no homogeneous “sham group” represented by the data that could be used as a control over time. After 3 months 5/8 shams developed pain behavior and there was no single sham animal that had intermediate behavior in the values represented by the graphs. We took the unusual step of presenting the sham data individually to be perfectly clear about what happened in that interesting group. We purposely did not include asterisks in Figure 5, because it would be misleading. The shams’ individual data in Figure 6 resembles the human response — not all humans get neuropathic pain after a soft tissue injury. The EPO pilot study also helps characterize the GEL model by showing the analgesic effect of a localized biologic, which has not been demonstrated in the current models. The second author (DAF) consulted on experimental design and data display and conducted the statistical analysis of the behavioral data. Aside from expertise in neurobiology and IACUC regulations, he has taught undergraduate statistics and published several articles (2— 6) on experimental design, simulation, and ANOVA. Regarding the standard deviation instead of standard error, this recommendation by Lang and Altman (7) is curious because they offer no rationale for it in their paper. Use of standard deviations allows estimation of standardized effect sizes, whereas use of standard errors allows estimation of inference (null hypothesis test or confidence interval). Those authors might have had in mind that the use of standard errors without indication of corresponding sample sizes would rule out the estimation of standardized effect sizes by subsequent readers or meta-analyses. That is not the case in our paper because we explicitly include estimates of standardized effect sizes in Table 1. Thus, there is no reason to prefer standard deviations over standard errors, and the latter assist in informal estimation of significance for the many contrasts that we did not explicitly test. Fisher's protected least significant differences (PLSD) and Bonferroni: Note that planned comparisons can always be tested, unlike post-hoc comparisons (data snooping). We tested only planned comparisons in this paper. We quote the recommendations of experts Milliken and Johnson (8): Conduct an F-test for equal means. If the F-statistic is significant at the 5% level, make any planned comparisons you wish to make by using the LSD method. This includes not only comparisons between pairs of means but also comparisons based on any selected contrasts of the i ’s. If one has equal sample sizes, the Waller-Duncan method can also be used. For data snooping and unplanned comparisons, use Scheffe’s method. If the F-statistic for equal means is not significant, the experimenter should still consider any individual comparisons that he or she had planned, but should do so using either the multivariate t-distribution method or Bonferroni’s method. The experimenter should not do any data snooping in this case. Since the F-test for equal means is nonsignificant, Scheffe’s procedure would not yield any significant differences anyway. Your insightful question “Do the analgesic responses reflect human responses?” highlights a crucial issue that cannot be accurately answered despite extensive discussion in the literature. Presently “pain” in patients and experimental rodents is assessed by different assays. With similar “pain assays” the validity of such translational comparisons can be improved. References 1. Baron R. Mechanisms of disease: neuropathic pain—a clinical perspective. Nature clinical practice Neurology. 2006 Feb 1;2(2):95-106. 2. Fitts DA. Misuse of ANOVA with cumulative intakes. Appetite. 2006 Jan 31;46(1):100-2. 3. Fitts DA. Improved stopping rules for the design of efficient small-sample experiments in biomedical and biobehavioral research. Behavior research methods. 2010 Feb 1;42(1):3-22. 4. Fitts DA. The variable-criteria sequential stopping rule: generality to unequal sample sizes, unequal variances, or to large ANOVAs. Behavior research methods. 2010 Nov 1;42(4):918-29. 5. Fitts DA. Ethics and animal numbers: informal analyses, uncertain sample sizes, inefficient replications, and type I errors. Journal of the American Association for Laboratory Animal Science. 2011 Jul 15;50(4):445-53. 6. Fitts DA. Minimizing animal numbers: the variable-criteria sequential stopping rule. Comparative medicine. 2011 Jun 15;61(3):206-18. 7. Lang T, Altman D: Basic statistical reporting for articles published in clinical medical journals: the SAMPL Guidelines. Science Editors' Handbook, European Association of Science Editors . 2013. 8. Milliken GA, Johnson DE. Analysis of messy data, Volume I: Designed experiments. Wadsworth. Inc. Belmont, California. 1984. Your perspective is appreciated and your concerns have been addressed. EPO pilot study power statistics have been added to the revision. The initial sample size was based on prior investigations. The Supplemental S3 refinement chart we added depicts how the refinement of a scientific procedure (as referred to by NC3Rs) that limits tissue damage can reduce acute pain, eliminate paw dragging, limb deformities, and self-mutilation. If rodent refinements reduced or eliminated pain their potential as models could be lost. Your pertinent question about the type of pain the model represents is best answered simply. We strived to elicit the types of evoked pain behaviors referred to as allodynia and hyperalgesia (1) that may develop gradually in patients after soft tissue trauma. We were trying to mimic in this study the chronic pain sustained for years as seen in humans. Most investigations would not need to be months long and studies can be shortened to any time after post procedure day 23. However, the longer possible duration of this study can possibly reduce the number of animals used in future studies. There is no homogeneous “sham group” represented by the data that could be used as a control over time. After 3 months 5/8 shams developed pain behavior and there was no single sham animal that had intermediate behavior in the values represented by the graphs. We took the unusual step of presenting the sham data individually to be perfectly clear about what happened in that interesting group. We purposely did not include asterisks in Figure 5, because it would be misleading. The shams’ individual data in Figure 6 resembles the human response — not all humans get neuropathic pain after a soft tissue injury. The EPO pilot study also helps characterize the GEL model by showing the analgesic effect of a localized biologic, which has not been demonstrated in the current models. The second author (DAF) consulted on experimental design and data display and conducted the statistical analysis of the behavioral data. Aside from expertise in neurobiology and IACUC regulations, he has taught undergraduate statistics and published several articles (2— 6) on experimental design, simulation, and ANOVA. Regarding the standard deviation instead of standard error, this recommendation by Lang and Altman (7) is curious because they offer no rationale for it in their paper. Use of standard deviations allows estimation of standardized effect sizes, whereas use of standard errors allows estimation of inference (null hypothesis test or confidence interval). Those authors might have had in mind that the use of standard errors without indication of corresponding sample sizes would rule out the estimation of standardized effect sizes by subsequent readers or meta-analyses. That is not the case in our paper because we explicitly include estimates of standardized effect sizes in Table 1. Thus, there is no reason to prefer standard deviations over standard errors, and the latter assist in informal estimation of significance for the many contrasts that we did not explicitly test. Fisher's protected least significant differences (PLSD) and Bonferroni: Note that planned comparisons can always be tested, unlike post-hoc comparisons (data snooping). We tested only planned comparisons in this paper. We quote the recommendations of experts Milliken and Johnson (8): Conduct an F-test for equal means. If the F-statistic is significant at the 5% level, make any planned comparisons you wish to make by using the LSD method. This includes not only comparisons between pairs of means but also comparisons based on any selected contrasts of the i ’s. If one has equal sample sizes, the Waller-Duncan method can also be used. For data snooping and unplanned comparisons, use Scheffe’s method. If the F-statistic for equal means is not significant, the experimenter should still consider any individual comparisons that he or she had planned, but should do so using either the multivariate t-distribution method or Bonferroni’s method. The experimenter should not do any data snooping in this case. Since the F-test for equal means is nonsignificant, Scheffe’s procedure would not yield any significant differences anyway. Your insightful question “Do the analgesic responses reflect human responses?” highlights a crucial issue that cannot be accurately answered despite extensive discussion in the literature. Presently “pain” in patients and experimental rodents is assessed by different assays. With similar “pain assays” the validity of such translational comparisons can be improved. References 1. Baron R. Mechanisms of disease: neuropathic pain—a clinical perspective. Nature clinical practice Neurology. 2006 Feb 1;2(2):95-106. 2. Fitts DA. Misuse of ANOVA with cumulative intakes. Appetite. 2006 Jan 31;46(1):100-2. 3. Fitts DA. Improved stopping rules for the design of efficient small-sample experiments in biomedical and biobehavioral research. Behavior research methods. 2010 Feb 1;42(1):3-22. 4. Fitts DA. The variable-criteria sequential stopping rule: generality to unequal sample sizes, unequal variances, or to large ANOVAs. Behavior research methods. 2010 Nov 1;42(4):918-29. 5. Fitts DA. Ethics and animal numbers: informal analyses, uncertain sample sizes, inefficient replications, and type I errors. Journal of the American Association for Laboratory Animal Science. 2011 Jul 15;50(4):445-53. 6. Fitts DA. Minimizing animal numbers: the variable-criteria sequential stopping rule. Comparative medicine. 2011 Jun 15;61(3):206-18. 7. Lang T, Altman D: Basic statistical reporting for articles published in clinical medical journals: the SAMPL Guidelines. Science Editors' Handbook, European Association of Science Editors . 2013. 8. Milliken GA, Johnson DE. Analysis of messy data, Volume I: Designed experiments. Wadsworth. Inc. Belmont, California. 1984. Competing Interests: Author is a principal of NeuroDigm Corporation. Close Report a concern COMMENT ON THIS REPORT Views 0 Cite How to cite this report: Brines M. Reviewer Report For: The refined biomimetic NeuroDigm GEL™ model of neuropathic pain in a mature rat [version 2; peer review: 2 approved, 1 approved with reservations] . F1000Research 2017, 5 :2516 ( https://doi.org/10.5256/f1000research.10281.r17230 ) The direct URL for this report is: https://f1000research.com/articles/5-2516/v1#referee-response-17230 NOTE: it is important to ensure the information in square brackets after the title is included in this citation. Close Copy Citation Details Reviewer Report 14 Nov 2016 Michael Brines , Araim Pharmaceuticals Inc.,, Tarrytown, NY, USA Approved with Reservations VIEWS 0 https://doi.org/10.5256/f1000research.10281.r17230 This manuscript describes an interesting rodent model of chronic pain. The basic premise is that local injection of a mixture of biological materials typical of the extracellular matrix following tissue injury activates tissue repair processes which ultimately causes a constrictive ... Continue reading READ ALL 