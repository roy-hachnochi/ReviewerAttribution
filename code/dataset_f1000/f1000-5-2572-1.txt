In the manuscript titled “Sonification of hyperspectral fluorescence microscopy datasets”, Mysore, Velten and Eliceiri present the development of an “eye-to-ear” conversion plugin for Fiji. Modern imaging places a premium on extracting as much information as possible from images and much focus has been placed on increasing the dimensionality, and thus ability to segment and measure, of image data. These efforts have resulted in images containing 6 or more dimensions (x, y, z, Intensity, time, color, fluor lifetime, etc), making presentation and interpretation visually complex. In the case of spectral imaging, commercial instruments are fully capable of producing 32 channels in the color range (hyperspectral), further complicating the situation. Here, the authors present an innovative solution: a D to S conversion (digital to sound). The human eye is tuned to respond to a relatively narrow band in the electromagnetic spectrum, however to do so with relatively high resolution. On the otherhand, the human ear has a very high (~3 orders of magnitude) dynamic range combined with high resolution. As such, the ear is better suited to interpreting hyperspectral data. The authors make this case effectively with supportive calibration and experimental data. This is an exciting window (or tune?) into the future of data presentation. Below I make a few suggestions: The authors do an excellent job of explaining the biology of the eye, however the ear seems to be less well defined. What about the biology, mechanics, or innervation of the ear allows this dynamic range? Personally, I have always considered the ear a single dimensional detector; at any given moment, the ear interprets and reports a single piece of data. Is this the case or can the ear send multiple inputs to the audio processor in our brain? Can this concept be applied to non-spectral information? Have the authors tried to use it for simply portraying depth or time? In my experience there are only a limited number of people using spectral data when compared to depth and/or time. Minor comment: Page 3; what is “image UI”?