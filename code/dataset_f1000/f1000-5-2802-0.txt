This article provides useful survey data on aspects of instruction using the R programming language at Canadian Universities. The authors report intriguing data on the numbers of respondents who use R for teaching and research, the subject areas in which the respondents work, and their willingness to teach future classes using R. These data provide a useful glimpse of the adoption of R software in Canadian Universities, and the transparent inclusion of the survey and data makes this publication a valuable addition to the literature. My comments below are intended to provoke further critical analysis if possible. Although I am sympathetic to the authors’ opinions (as an instructor who uses R in my own research and teaching), I am not consistently convinced that these data support the authors’ conclusions, even though those are made somewhat tentatively. My skepticism comes from a few sources, as detailed below. I think most of my concerns could be addressed though a follow up survey and additional analyses. Much of the discussion is devoted to the argument that we need more teaching of R (especially in classes dedicated to the programming language itself, rather than its applications). I do not object to this assertion in principle (teaching with R has personally been a rewarding experience for me and most of my students), but the conclusion does not derive from the survey data, and the logic that underpins it is not always clear. The authors cite some pedagogical papers on the general importance of programming knowledge, but the relative value of programming per se (as opposed to its applications) for disciplines apart from computing science are not self-evident given the assumed cost to other portions of the curriculum. One could indeed use R markdown for lab report submissions, as the authors suggest on p.10, but I am not convinced that this would often be worth implementing if the main learning outcome sought is written communication skills. I think it would be useful if the authors could more clearly separate the discussion that derives directly from their survey findings from those that represent advocacy of a particular pedagogical opinion. As the authors acknowledge, there is a risk of positive bias in their survey because respondents unfamiliar with R may have been less likely to respond. The importance of the bias could be estimated through attempts to contact nonrespondents, and contrasts of the scores with the original surveys, and methods for computing estimates of response survey quality seem to be reasonably well established and (of course) have been developed for analysis with R 1 . Such an effort could help clarify the importance of biases in this study. For a paper about a language developed explicitly for conducting statistical analyses, the lack of statistics is quite jarring. The authors draw many conclusions about differences among categories of response based on apparent patterns, but it would be quite useful to know how much confidence we should place in the relative numbers of responses. Like the analyses of survey quality mentioned above, methods for conducting multinomial models and extracting multinomial CIs are readily available within R (e.g., see Villacorta 2012 ), and would allow the authors to both quantify uncertainty in their proportions and illustrate confidence limits for each response measure. Some of the comparisons suffer from a lack of context. For example, Fig. 1 concerns the relative provision of R courses to undergraduates vs graduate students, but this contrast is difficult to interpret without more information on the number of courses in total that are offered to graduates and undergraduates. Is the rate of provision higher at the graduate level, given the smaller number of total courses on offer? I wonder if the authors can hint at the answer by assessing numbers of courses in each category at a few institutions. In addition to a dissatisfying lack of measures of confidence in effects, the figures are not consistently laid out to permit effective consideration of the data. For example, in Figure 6, the key response variable is a scaled measure of willingness to teach R in future classes, but that variable appears on the x-axis instead of the y. Since the most meaningful contrast is between users and non-users of R, the authors could produce a plot that illustrates the numerical response scores in the two groups (e.g., in a strip chart) along with a measure of means and confidence limits: such a presentation would support the presumed difference much more persuasively, in my opinion, than the current layout. Minor comments: I spotted a few typographic errors, including the use of the word “preform” for perform on pp. 3 and 4, and “does’nt” on p. 10. The Education Board that Authored citation 19 is incorrectly attributed as if it were a single author, whereas there are 8 individuals listed as authors on the report who could be acknowledged. References 1. de Heij V, Schouten B, Shlomo N: RISQ manual: Tools in SAS and R for the computation of R-indicators and partial R-indicators. Representativity Indicators for Survey Quality . 2010. Competing Interests: No competing interests were disclosed. I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above. Close READ LESS CITE CITE HOW TO CITE THIS REPORT Bussiere LF. Reviewer Report For: Approaches to R education in Canadian universities [version 1; peer review: 1 approved, 2 approved with reservations] . F1000Research 2016, 5 :2802 ( https://doi.org/10.5256/f1000research.11021.r18125 ) The direct URL for this report is: https://f1000research.com/articles/5-2802/v1#referee-response-18125 NOTE: it is important to ensure the information in square brackets after the title is included in all citations of this article. COPY CITATION DETAILS Report a concern Respond or Comment COMMENT ON THIS REPORT Views 0 Cite How to cite this report: Gurarie E. Reviewer Report For: Approaches to R education in Canadian universities [version 1; peer review: 1 approved, 2 approved with reservations] . F1000Research 2016, 5 :2802 ( https://doi.org/10.5256/f1000research.11021.r18120 ) The direct URL for this report is: https://f1000research.com/articles/5-2802/v1#referee-response-18120 NOTE: it is important to ensure the information in square brackets after the title is included in this citation. Close Copy Citation Details Reviewer Report 14 Dec 2016 Eliezer Gurarie , School of Environmental and Forest Sciences, University of Washington, Seattle, WA, USA Approved with Reservations VIEWS 0 https://doi.org/10.5256/f1000research.11021.r18120 I feel odd reviewing this paper - since I have little technical expertise in assessing human survey-based studies. My interest in this topic is as a highly biased object of the study, specifically, as an enthusiastic user of R in ... Continue reading READ ALL 