Having read the revised paper it seems better, but I’m still somewhat puzzled about a few things. I am getting the feeling that the K-NN method is meant as a baseline control method since by definition K-NN looks at only the training set compounds close to the test set compounds, so there is an implicit selection of training set compounds, and this should have a similar effect as covariant shift. This is not explicitly said in the paper. The authors do not try sophisticated but more “standard” classification methods like random forest or SVM, and don’t say why not. Both myself and the other reviewer seem confused by Figure 1. The red line is supposed to be the importance weight. However, it implies that the highest weights are given in a region of descriptor space far away from both training and test sets. 