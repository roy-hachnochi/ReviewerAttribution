This review will focus a critical eye on three issues, integration with existing literature, survey methodology, and use of the Satisfaction with Life Scale (SWLS). The review then acknowledges some points of agreement and support for the authors and ultimately recommends significant revision for publication, with some reservations. The abstract begins with the implication that the public discourse about postdocs is not informed by empirical work. The implication that empirical work is missing is a red flag to me whenever I encounter it, not only when it is my own empirical work that is being overlooked. Yet I do believe that our paper (Miller Feldman, 2015) that uses the Science and Engineering PhD and Postdoc Survey (SEPPS) conducted by Sauermann and Roach to study dissatisfaction with postdoc appointments could have informed the design and interpretation of this study. So at the risk of being a caricature of reviewers who plug their own work, I will begin by pointing the authors toward this paper, which also contains a summary of prior research on postdoc satisfaction. The Scaffidi and Berman (2011) paper is also very relevant to the topic. I was pleased to see that the authors had cited Davis’s 2009 chapter analyzing the Sigma Xi survey of postdocs, as this has been some of the most influential empirical work on the postdoc experience. As a methodological step to avoid this type of disconnect from prior literature, I would recommend the practice of using Google Scholar’s “cited by” feature to look at the studies that have cited this chapter. It will connect the authors to even more recent and relevant empirical work. Further review of existing literature would also have been helpful to the authors in their use of the SWLS. Diener and colleagues have published a number of subsequent review articles (including but not limited to Diener Pavot 1993 and Pavot Diener 2008), but this study relies on the original 1985 paper. The review will now turn to issues of interpretation related to the survey data and measurement scales. Interpretation of the survey data was complicated by the absence of a correlation table. It was not entirely clear, but it appears that conclusions are drawn from correlations, rather than regression analyses that more carefully model the relationship to satisfaction by including control variables. I recommend the authors clearly explain the analyses performed and provide a correlation table. I have two concerns regarding the representativeness of the sample. First, the authors say the survey was distributed by postdoc associations to their members . Postdoc associations do not necessarily include all postdocs at an institution and often serve as agents of change, sometimes including formal unionization efforts. This is a limitation that would discourage me from drawing policy conclusions from the study. Postdoc association membership lists may overrepresent dissatisfied postdocs. Of course, it is also possible that at least some postdoc associations have a broader mailing list. It is even possible that not all postdoc associations distributed the survey at all. With only 29 associations, it seems likely it would be feasible to contact them to confirm distribution and to give some consideration to their mission statements. Second, in analyzing survey data, it is a questionable choice to include only complete cases. Various techniques for imputation allow the researchers to avoid discarding the valuable data from incomplete cases. The fact that age and gender were missing from over 20% of cases, while other variables were provided more completely, suggests that there may be some bias introduced by discarding missing data. Response bias also tends to overrepresent those with strong feelings and opinions. The likelihood for sample bias due to the reliance on postdoc associations is my main concern with the study as a whole. This cannot be remedied but can be acknowledged as an important limitation. Comparison of postdocs’ SWLS scores with early studies of relevant populations was complicated by the fact that the authors report the mean (4.47 on a 1-7 scale), while apparently other studies tend to report the total scale score (5-35). On page 2, the authors refer to 4 as the median, when 4 is more accurately described as the midpoint of the scale. Diener Pavot (1993) are careful to interpret findings relevant to their scale anchors. A mean of 4.47 indicates a neutral to slightly satisfied group. But taking into account confidence intervals, it is not clear to me that the satisfaction of postdocs is significantly worse than that found by Diener Pavot in 1993 for several groups of US college students. Given the cultural variation in reporting life satisfaction, the absence of nationality data also complicates interpretation of the scale (note the low satisfaction for Chinese students reported in the 1993 paper). Postdocs are a highly international group and nationality has been found to be relevant to satisfaction (Sabharwal Corley 2009). Figure 1 seemed especially problematic in terms of scale interpretation. This measurement seems to be on a different scale entirely, as it has a category 7, which would be impossible on a 1-7 scale. The authors should review literature about and applications of the SWLS to relevant populations more thoroughly and contextualize their findings in clear, comparable terms. Overall I did not find support for the claim that this survey showed surprisingly low levels of wellbeing. I’d like to conclude with a few points of agreement with prior research. For example, we also found that satisfaction does typically decline the longer someone is a postdoc (Miller Feldman 2015). It is also not surprising that people lost interest in pursuing tenure-track academic appointments. If they did not lose interest, the competition for the relatively few available positions would be even more fierce, with perhaps even more stark disappointment among those not selected. Yet, while this competition has intensified, it is by no means new. Like entertainment and athletics, scientific careers function as tournaments (Freeman et al. 2001). I agree with the authors’ recommendation that doctoral students and postdocs would benefit from more awareness of the structure of the scientific labor market. Prior research also supports the focus on improving the postdoc experience through interpersonal, lab-level interventions, rather than more tangible issues of pay and benefits (Miller Feldman 2015; Scaffidi Berman, 2011; Davis 2009). Research on postdoc satisfaction tends to identify the mentoring relationship and professional development as key to postdocs’ satisfaction. In summary, I have some fairly strong methodological reservations about this paper. As presented, the findings of dissatisfaction do not seem particularly strong. There are reasons to question the role of sample bias in selecting for more dissatisfied postdocs. However, I could support publication of a revised version that better contextualizes the paper with existing research, acknowledges the activist role of postdoc associations and resulting potential for bias, better examines the potential for nonresponse bias and missing data, and provides careful comparisons with other studies using the SWLS. Minor points For policy-relevant research, it is useful to report the time frame during which the data were collected. Supplementary File 1 is described as having been distributed among 190 postdocs. In fact, it was completed by 190 postdocs and it is unknown to how many the survey was distributed. The NSF Survey of Graduate Students and Postdoctorates in Science and Engineering could provide an estimate of the number of postdocs at these institutions. I do not usually use SPSS, so was not able to examine the data file. For what is probably a fairly manageable dataset like this, it would be helpful to provide a flat text file in a format like .csv. Both supplementary files appear to link to the survey, not the list of postdoc associations. Paragraph 1, “warranted” seems like an odd word choice here. 