SYNOPSIS: This overview deals with an enlarging key issue related to the reproducibility of published data in journals of all stripes, ranging from ‘high’ to ‘low’ impact quality. A ‘checkpoint’ process is proposed requiring authors to write a 5-year-post-publication ‘reflection’ on the previously published data. Failure to do so would place a ‘red flag’ beside references to that author’s work in subsequent databases and presumably also in subsequent manuscript reference sections quoting that work. The authors suggest a ‘simple’ yes/no checklist to determine whether the results of a paper have changed clinical or scientific practice. CRITIQUE This contribution is a well-written, thoughtful and concise overview of a deepening thorn in the side of published peer-reviewed data in the literature. The strength of the commentary is that the issue of long-term ‘accountability’ for those who publish the data is raised; and a ‘checkpoint’ solution is well described. The weakness in the overview is that the challenge of implementing the ‘simple questionnaire’ and the alternatives for failure of compliance are not dealt with in the text. For instance, one of the authors would have needed to respond to reflect on over 170 publications over the past 5 years. To determine an accurate answer about the subsequent reproducibility of the 170 findings or about the impact of the findings on clinical or basic science practice would represent a considerable challenge; and the request would be an invitation to side-step accuracy in favour of expediency to get the annoying fly off the desk. This issue is not dealt with in the text. Further, although author accountability is of prime importance, the suggested ‘solution’ would not surface the frustration of those e.g. other laboratories or even new trainees in the authors’ laboratories, who have difficulties repeating the published data. Those ‘negative’ findings, which are of immense importance, almost never see the light of day. The article does not deal with that key issue, which merits attention. SUMMARY AND RECOMMENDATION: This brief, well-written overview surfaces a key issue plaguing the scientific literature and offers a valuable process to enhance author accountability via a 5-year post-publication ‘reflection’ mechanism. That said, the above comments raise two issues that the authors may wish to deal with as they finalize their text. Thus, the possible outcomes of their approach (i.e. expected lack of compliance; or even worse, continued mis-representation of the data) could be dealt with and alternatives to poor outcomes for their process could be suggested. Further, a process that would enable the ‘reporting’ of lack of reproducibility from others in the field, with an opportunity for the authors to respond with ‘further reflections’ would enhance the process of accountability. As an example, this reviewer has had the opportunity to follow an enzyme isolation procedure exactly as described in a JBC manuscript; and the enzyme activity of the product was essentially as expected. That said, a biochemical sequencing of the enzyme product (NOT done in the previous JBC manuscript) showed that the enzyme was not at all the one claimed to be yielded by the published procedure. How would the ‘reflection’ process deal with that issue? One solution would be for the journal to be alerted as to the lack of reproducibility; and for the journal to insist on accountability from EACH AND EVERY ONE of those who have their names on the originally published article. The authors are encouraged to suggest an expanded ‘accountability’ process that would enhance the ‘reflection’ mechanism suggested and surface the lack of reproducibility by others of findings of published data. 