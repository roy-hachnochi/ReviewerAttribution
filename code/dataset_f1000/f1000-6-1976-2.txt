The authors present bcbioRNASeq, an R package for the QC and differential expression analysis of RNA-seq data. The package takes as input the output of the bcbio software, not presented in this work. bcbio is a community driven resource that handles the data processing of several high-throughput sequencing applications, ranging from variant calling to ChIP-seq and RNA-seq analyses. The bcbioRNASeq package focuses on RNA-seq. Overall, I enjoyed the article and I think it represents a nice resource for practitioners looking to perform standardized RNA-seq analyses of several datasets and for bcbio users that want to perform high-level statistical analyses after RNA-seq preprocessing. The article is well written and provides a reproducible example that walks the reader through the proposed pipelines. I am glad to report that (except for some minor issues reported below) I was able to fully reproduce the analysis. The following points will hopefully help the authors improve the manuscript. Currently, the package does not appear to be available through Bioconductor, but only through the authors' Github. Are the authors planning to submit it to Bioconductor? I definitely encourage them to do so, as a way to manage package versions and dependencies (see next point). If not, I would ask the authors to refer to bcbioRNASeq as an R package rather than a Bioconductor package. The authors do not specify the versions of the packages needed for their workflow to work. Although the DESCRIPTION file of the package provides such information, adding it to the manuscript would allow readers to reproduce the workflow example. This would be automatically taken care of if the package was part of a Bioconductor release. In addition, at the beginning of the paper, the authors load the packages "DESeq2" and "DEGreport". Aren't these packages in the Import: field of the DESCRIPTION file of bcbioRNASeq? S4 object. Is it really needed to store all the normalized data in the S4 object? This could lead to a huge object when the analysis is run on hundreds of samples. Since scaling normalization is very fast wouldn’t it be better to compute normalized data on the fly and only store the raw and tpm data computed by tximport and featureCounts? On a related note, wouldn’t it be better for the authors to store the featureCounts data in an additional element of the assays() slot and provide coercion methods from their object to the DESeqDataSet and tximport objects? Is it really needed to store both tximport results in the assays slot and in the bcbio slot? Overall, I have the feeling that the object is needlessly big and this could lead to a big memory footprint. Are the plots based on raw or normalized data? If the latter, which normalization / transformation is used by default? How does the user change it? Interpretation of the plots. Although the authors describe the plots in generic terms, it would be useful to explain them more specifically referring to the actual example analysis. For instance, which of the three transformation of Figure 3 is best for the example data? Is Figure 1F a typical pattern or does it uncover something unusual with the data? Same for Figure 7. A better metric to highlight the difference in distribution among samples (Figure 2) is the Relative Log Expression (RLE) plot. The authors might want to include such plot to their already excellent array of QC plots. What to do if the data fail the QC step? The authors present all their QC plots but then move on by simply stating "Once the QC is complete and the dataset looks good [...]". What if the data do not look good? It would be good to advice on what to do (just as a discussion perhaps). E.g., there could be outlying samples to be removed or batch effects to be accounted for in the model. Minor issues: The last sentence of the first paragraph of the Introduction seems to indicate that the R package actually runs the QC tools, while these are run in bcbio and the results are loaded in the R package for exploration. First chunk of R code (page 4 of the PDF version of the paper): at my first read I was wondering how to get the data to run this command. It should be made clearer that this is only meant to show the syntax and is not part of the runnable example. The link to the bcb.rda file is broken. `normalized - counts(dds, "normalized") ` This line doesn’t work. Did the author mean normalized=TRUE? `tpm - tpm(txi) ` This line doesn’t work. Did the author mean `tpm - counts(dds, normalized=“tpm”)`? Please describe writeCounts(). Please consider removing the "+" in the R chunks (e.g., at page 13 of the PDF) so that readers could run the code by copying and pasting into an R session. In statistics, ICA is often used to refer to Independent Component Analysis, so the authors may want to avoid this acronym for the correlation analysis to avoid confusion. In my RStudio session the plotPCACovariates() plot did not work (I couldn't see any points but just a gray background). YAML parameters for the Functional Analysis Rmarkdown: I believe that the line "res" should be "resFile". 