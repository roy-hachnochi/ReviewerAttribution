An initial observation as regards my review is that I am unfamiliar with the background to this story and I have reviewed this paper only. The authors make a number of claims regarding facts that could probably be checked by reading some of the references. I have not done this. My comments are limited to the internal logic of the paper only. Whether or not one agrees with the conclusions, this is an interesting investigation. I have some reservations as regards emphasis in the conclusions, which I shall explain in due course, but first I shall explain why statisticians with my background may have a slightly different point of view to the authors. Since the time in which I worked in the pharmaceutical industry (1987-1995), I have been interested in drug regulatory science. An attitude that (rightly or wrongly) is accepted as being the norm in both sides of the regularity divide is that evidence of efficacy for one drug in a class cannot (usually) be used as evidence of efficacy of another. In fact, so strong is this point of view that when it is sought to use the proof of efficacy of one formulation for another, proof of equivalence is required. Thus, not only is it the case that different molecules cannot be regarded as having the same efficacy, this carries over to doses and formulations. Some, no doubt, will see this as a conspiracy to inhibit generic competition. However, during my own time in drug development I twice worked on alternative formulations (that is to say developed by the innovator company) that had to be abandoned. In one case a clinical trial of the new formulation revealed it had one quarter the potency of the existing formulation 1 . This ‘no pooling of products’ attitude also holds for ‘ proving’ safety. For different formulation ‘proof’ of equivalence would be required and for different molecules usually a whole new programme. (Biosimilars might be a controversial exception.) However, regulators do generally consider that observed safety problems in one molecule in a class create a potential concern. The FDA’s attitude as regards development of treatments in diabetes, partly as a response to Nissen and Wolski’s meta-analysis of rosiglitazone, is a case in point 2 . Thus, there is a general aversion in drug-development and regulation, not necessarily shared by the evidence-based medicine movement, to pooling different molecules in a meta-analysis. Nevertheless, I consider that such pooling is legitimate for one purpose, namely that of testing the hypothesis that no drug in among those pooled has the effect being studied. If this is adopted as a null hypothesis and a fixed effect analysis suggests the null hypothesis should be rejected, then the hypothesis to assert becomes the hypothesis that at least one drug in the class has an effect. (See my paper on overstating evidence 3 p3. ) Further investigations are then necessary to determine what the practical implications of this are, but asserting the alternative hypothesis that all drugs have an effect is clearly not warranted. In fact, I can put it cynically like this. We seem to live in an era in which everyone believes in personalised medicine (thus in patient by treatment interaction ) but we are unconcerned about the differences between the main effects of treatment. However, a further consequence of my time in the pharmaceutical industry, is that I share a general mistrust of investigator led-trials (with some notable exceptions). The fact that previously, raw data from pharmaceutical trials were not shared with the wider public, has been the subject of much criticism. Nevertheless, such trials were examined by the regulator and this, in my opinion, has done much to improve the quality of pharmaceutical industry trials. Without such external scrutiny the danger is that independent trials may suffer in quality. I now come to my specific comments. It is clear from the authors’ paper that in the meta-analysis different drugs are pooled. This implies that one explanation that should not be dismissed on the basis of the statistical analysis alone , is that the effects vary from treatment to treatment in the class. To be fair to the authors, they do discuss this in more than one place but I feel that they do not appreciate fully the reservations that apply generally to pooling drugs. Again, to be fair, they do provide the extremely helpful table 2, which provides an analysis by table. It would be nice to see, just to complete the picture, if there is a connected network, what a network meta-analysis would show. (If there is not a connected network then this must be that the problem with the different experimental treatments also applies to the controls.) For example, this would permit formal comparison of different drugs. Again, it should be noted that the authors do include what might be regarded as a sort of network analysis, however, all other treatments are lumped together and this suffers from a problem discussed in point 4 below. I am not suggesting that the authors need to do this analysis (it could a be task for future work), I am just suggesting that the fact that this has not been done is a limitation that needs to be reflected in the discussion. By the same token, this means that it would be highly debatable anyway, irrespective of any particular doubts about the reliability of the DECREASE I IV trials, to use these as proof of efficacy of beta-blockade generally. Again, to be fair to the authors, they do suggest that more trials are needed. However, if the data from the DECREASE I IV trials have not been audited, then in my opinion nobody is obliged to accept the results anyway. Checkability is the standard by which claims should be judged. I have some reservations regarding the use of the one degree of freedom chi-square tests in step 1. It should be appreciated that the analysis is one that is strictly speaking only valid if pre-specified without any access to results. It is not an analysis that is valid when comparing observed extreme results with others 4 . I did not understand the argument in the last paragraph of Step 3. This is probably just due to my being obtuse. The robustness of the results and the implication of the results, if true, seemed to me to get mixed up. However, these comments do not alter my opinion that this is an interesting paper. 