This paper presents a new Shiny application for analyses of qPCR data to facilitate comparison of methods. This software is important for the community and well suited to publication in F1000Research . Major comments Some details of the software are hard to follow from the manuscript below (e.g., which methods are implemented, what benchmark datasets, etc). These are detailed in minor comments below, and must be fixed for readability of the manuscript. The authors may wish to add a table listing each of the methods and the quality thresholds that they yield. Use cases should report results from applying the method, not merely the datasets used for analysis. The manuscript should describe the range of possible analyses that can be performed with miRcomp-Shiny, expanding upon the “output section”. The annotations and help on the software available from https://laurenkemperman.shinyapps.io/mircomp/ require improvement for greater usability. Some examples are listed below: Dataset descriptions describes the methods employed, but does not indicate which datasets are used. The platform seems limited to analysis of the miRcomp data. The software does not appear to enable input of new datasets which would be critical to its utility. The format of files for qc and ct elements for custom analyses are not specified. There is no ability to export processed datasets and/or assess the quality of specific miRNAs from the preprocessing implemented in this application. Minor comments The Implementation subsection of the Methods should expand the sentence “Currently, six of the most widely-used algorithms to estimate miRNA expression and sample quality are included in the miRcomp-Shiny app” to clarify precisely which six algorithms are implemented and include citations to those methods. It should also clarify whether these 6 algorithms are representative of all in the miRcomp R package or a subset of the methods implemented in that package. “The benchmark data” referenced in the Methodology and quality selection threshold should be defined. Which datasets are included as benchmarks? How are they selected? It is unclear what variables the “quality thresholds” in the Methodology and quality section threshold section reference. The subsection “Comparison of novel algorithms…” should edit the sentence “Another use case is comparison of a new method to an existing method.” to read “Another use case is comparison of a data table with results from a new method to the existing methods implemented in the miRcomp-Shiny app.” The sentence “We have already begun encouraging people to use the package, and hope that readers will do the same.” Should be cut. The summary should place this tool in context of others in the literature and discuss its limitations / future work. 