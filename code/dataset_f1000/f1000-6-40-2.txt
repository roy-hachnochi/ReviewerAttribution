The article describes an predominantly explorative analysis of the capabilities of a machine-learning based texture analysis of fetal MR images for the purpose of extracting information of brain structure (ROI labeling/segmentation) with a (semi-)automatic procedure. My background is in neuroimaging data analysis, including the application of machine-learning algorithms on such data. Consequently, I cannot provide an expert opinion on the suitability of the proposed analysis strategies for diagnosing brain development abnormalities, and I will focus on the technical aspects of the procedure and its description in the article. In my opinion, the present structure of the manuscript, and chosen balance of the level of detail with which the research is motivated vs. its methodological details are described, are suboptimal for communicating the implications of these findings. In the following I summarize aspects that I consider critical: Objective and conclusions It is not clear to me what the exact objective of this research was. How good does ROI classification have to be in order to improve the status quo? Are the developed methods feasible enough (computational demands, ability to obtain suitable raw data, ...) to be employed in clinical applications? What exactly is not possible with available solution (quote "Sadly, they are primarily designed for pre-loaded applications but not much else"). It would be very helpful, if the author would provide a concrete example of the segmentation problem they are trying to solve. This could be a figure showing actual data. Figures 2-5 do not provide this information. It is unclear whether those show a schematic depiction of the problem, are actual empirical results -- this uncertainty is compounded by the very short figure captions. Provided information on methods is insufficient I would like to refer to this report http://www.humanbrainmapping.org/COBIDASreport for guidelines on what to report for MRI studies in general. In particular, there is no information provided on how the MR images were obtained, this includes missing information on the type of MR sequence, its parameters, vendor of the equipment, etc. There is no information on the nature of the MR image preprocessing. One of the issues with fetal MRI is the impact of unavoidable motion of the fetus during the scan. This aspect is not touched upon in the manuscript. Analysis description assumes familiarity with the MaZda package. Here is an example: "360 parameters were extracted with MaZda (histogram: 9; co-occurrence matrix: 220; run-length matrix: 20; gradient matrix: 5; auto-regression: 5; Haar wavelet: 28; geometry: 73). Parameters’ names are provided in the appendix at the end of this manuscript." Dataset 7 contains a plain list of names such as "GeoUg" that are uninterpretable without familiarity with the MaZda package (which in turn only runs on outdated windows machine (98,2000,XP, according to the website), and source code is not available). Structure of manuscript Especially the methods section does not contain typical sections, such as "MRI acquisition", "Participants", etc. Instead, it has "Advance notice to readers" that states that it is impossible to provide an introduction to machine learning. While that may or may not be true, I consider it problematic that the KBS is only described at a conceptual level, while there is extensive space devoted to the development history of MaZda, which seems irrelevant in the context of this study. (Note that the statement: "ANN is a self-organizing algorithm" is not true in its generality) The heading levels seem to be off at times. "Computer vision" is a subsection of "Clinical trial registration". In general the section heading should be more indicative of the content. The is "Customization" which reports on adjustments in the original procedure, but also on how files were renamed. The discussion has a section "Constraints, limitations, and assumptions" which essentially restates that data acquisitions took several years. The authors should reconsider the components of the manuscript. What is presented as "datasets" are actually Excel tables with text content in their cells that are pretty much tables that should go into the manuscript. Proprietary formats are inappropriate for sharing data. Additionally data types of shared data should focus on re-use, i.e. numerical values of result statistics should be shared as such, and not embedded in textual descriptions. Citations The author often cite several publication in a single context. It was frequently difficult for me to see why particular choices were relevant. For example, in the context of "Due to administrative and logistic delay as well as finding volunteers and expensive cost and availability of MRI, it took us nearly five years to collect the magnetic resonance (MR) samples." Stipp H: Using neuroscience to improve ad impact: How new research tools can advance cultural marketing. Journal of Cultural Marketing Strategy. 2016; 1(2):193–202. and a news item on "Portable MRI developed at Los Alamos".