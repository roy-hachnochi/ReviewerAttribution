We read the manuscript by Jansen et al. titled “ De novo whole-genome assembly of a wild type yeast isolate using Nanopore sequencing” with great interest. Authors describe their strategy to sequence and assemble a yeast strain using different methodologies: a short read strategy with Illumina reads alone and two hybrid approaches, the first one combining both short and long reads for the assembly and the second using long reads for the assembly and short reads for the correction of the consensus. In general, we think that this is a well put together study that reflects the current standard approaches for assembling genomes with both short and long reads. However, we have some questions/remarks that we would like the authors to answer. It seems that the high level of polymorphism complicate the de novo assembly. If some regions are heterozygous, it should lead to a higher than expected assembly size. We think the authors should describe in more details the Illumina-only assembly especially the cumulative size (add a column in Table 1). As the error rate is low, with a high level of SNPs, both (Is the DDNA#1 isolate is a diploid yeast?) haplotypes should be segregated. On the contrary, the assembly length of the nanopore-only assemblies seems to be near the expected size (12Mb), does it mean that the error rate prevent to distinguish haplotypes? We think the authors should discuss in more details how haplotypes are resolved in their different assemblies. The whole dataset (reads + final assembly) should be submitted in public repository to ensure full reproducibility. Paragraph Illumina and MinION de novo genome assembly, line 38. Contigs were polished using the Pilon tool but line 7 of the same paragraph, authors indicate that the Spades assembly that was generated from Illumina reads alone was highly fragmented possibly due to a high level of SNPs in the DDNA#1 isolate. I think that to verify if the Pilon correction didn’t do more harm than good, authors could run the Busco tool ( http://busco.ezlab.org/ ) on the assemblies, or annotate genes, before and after correction to verify if it didn’t introduce errors in the consensus due to heterogeneous input reads. Paragraph Illumina and MinION de novo genome assembly, lines 14-15 it is said that the cumulative size of reads that was given as input to Canu was 2.05 Gb and that the corrected reads cumulative output size was equal to 389 Mb. I think that by default Canu only corrects 30X of the input read set (controlled by the corOutCoverage parameter) and since it is relatively close to 30-fold coverage of a yeast genome, I was wondering if authors leaved this parameter as default or if they moved up the limit and it could only correct around 30X of coverage. If this parameter was changed, I think it would be a good idea to indicate it. Authors should add a table that contains standard metrics about the sequencing data (nanopore and illumina): number of reads, cumulative size, coverage, average read length… Paragraph Full genome comparison, lines 12-15 it is said that the Nucmer’s ouput was filtered with the delta-filter software; please add the parameters used to filter out alignments. Moreover, if the yeast genomes used for the comparison are highly variable the nucmer software is not the best suited; maybe lastz ( https://github.com/lastz/lastz ) should better perform. The smartdenovo assembler has been successfully applied to yeast genomes ( https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5466710/ ), it would be interesting to compare their results with a smartdenovo assembly. 