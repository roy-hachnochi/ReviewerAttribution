This paper describes the implementation of a new structural variant caller, called TIDDIT, that uses multiple forms of evidence to call structural variants (deletions, duplications, inversions, and translocations) in whole genome sequencing experiments. In addition to structural variant calling, TIDDIT includes database functionality that helps reduce errors and makes it adaptable to diverse applications (e.g. rare and de novo variant detection). Structural variant calling is an area of research that is in strong need for more reliable and sensitive bioinformatics methods. TIDDIT has the potential to be a valuable open source tool and, overall, we think that the method warrants publication but some further refinement is necessary. We hope that the authors will address the following major and minor comments: Major Comments: The authors list the current problems in the field as computational costs, non-standard output formats, and limited support for different sequencing platforms/library types. We don’t believe they have adequately described the tools they compare against with respect to these limitations. For example, both CNVnator and Manta have reasonable computational costs (2 and 3 core hours respectively), while Manta outputs VCF and does not list any platform/library type as a known limitation of their tool. A better description of how their work solves these limitations compared to other tools is required. Alternatively, they could shift focus towards the novelty of the database functionality. Generally, there is sufficient information provided for interpretation. However, there are some cases where further explanations are required. First, Manta is compared against for both the simulated data and NA12878 but is subsequently dropped from analysis of HG002 with no explanation. The authors should provide an explanation for this either in the text or as a footnote to the figures. Second, there is no description of the clustering method selected for the evaluation of database functionality (overlap based and DBSCAN clustering). The two clustering methods are described only from a technical stand point without providing details on how selection would affect the output or what use cases might be appropriate for each method. While the results generally support the conclusions made, the language used tends to overstate the differences between the tested methods: “TIDDIT is consistently the caller with the highest sensitivity”, “The high sensitivity of TIDDIT is coupled with extremely high precision”, “Despite being one of the most sensitive tools, it is also one of the most precise tools”. For example, while it is true that TIDDIT is the caller with highest sensitivity in the simulated datasets (table 1), the margin of victory is often quite low (only 0.01 in deletions and duplications – with lower precision than Manta, the next most sensitive caller). The authors should adjust the language used in the paper to provide a more truthful and honest description of the real performance of the tool as reported in the tables. Significant better performance is indeed achieved for simulated translocations but the improvements on the other classes of variants seem to be limited. We found the description for resolving the chain-like pattern of overlaps in the “overlap based clustering” to be quite confusing and hard to follow as currently described in the paper. The authors should state more clearly the problem. Is this a specific issue that has not been properly addressed by the community so far? Also, it is usually helpful to explain some of the complexity in interval analysis by including figures that elucidate the details of the process. Minor Comments: The methods used to generate the simulated data is described well enough, however, in this case making the simulated data sets available would also have been practical and would facilitate reproducing the results independently. The code is easily installed and provides sufficient documentation via the help options to get started with using the tool. Simulated structural variants seem to be created at random locations, however real variants tend to happen in a non-random fashion along the genome, in particular around repetitive sequences. It is important to emphasize in the paper the limitations of the simulated data, which may also explain partially why sensitivity on real data is significantly worse than in the simulated experiment. The caption for Figure 2 seems particularly long for such a simple figure and many of the details given in the figure caption would be better placed in the main text. Equations in the paper should be numbered. On the equation on page 3, the variable W is used to indicate the number of consecutive (base pair) positions used to halt the construction of a set. This value seems to play a significant role in partitioning the genome to identify structural variants. However, there is no information on what value is used and whether it is a user parameter. On page 6: “These calls are recognized by searching for variants [were - where] the regions of the first read and its mate overlap, or where the regions of the primary and secondary alignment overlap.” The authors report TIDDIT’s system requirements to be only 2 hours using a single CPU and 2 GB of RAM. However, these numbers are uninformative without reporting also the amount of data (e.g., sequence coverage, number of reads, etc.) that was used to test the tool. 