The work described represents the first in a number of expected publications from a long running and important effort to build an integrated “e-Laboratory” for ecosystems modelling. The ambition of this k-LAB is to support the automatic assembly of scientific workflows over data and models, which in turn requires that inputs and outputs are compatible. The ARIES project web site gives some indication of the ambition and the driving application of work reported – more so than the paper. This paper chiefly sets out to describe the semantic principles and methods to support the required interoperability (dubbed “FAIR+”) through systematic semantic descriptions of observable phenomena, the observations made on the observables and the context of these observations. The majority of the paper is given over to the philosophy underpinnings of these semantics and the presentation of a bespoke language and its support software developed by the authors to support the expression of the semantics. Thus the main thrust of the paper is The fundamental arguments behind the development of an ontology for the systematic representation of observable phenomena (“specifying observable semantics”) suitable for ecoservices modelling across different domains and different contexts (notably scales) using this ontology to make observations about data and models (or “informational artifacts”) through annotations (“specifying observation semantics”) The presentation of the k.IM language of the authors’ invention to express the ontology and annotations with bespoke support software. that these annotations serve to support model input-output compatibility to support the automatic assembly of scientific workflows to answer questions posed using this (and other?) ontologies Each of these points is interesting and worthwhile, most notably the development of a semantics observables that can transcend the difficulties of scales. The final point – demonstrating interoperability through compatible observations – is the least well demonstrated in the paper. The semantics of observations is an important topic and has long challenged ontologists and those working in the fields of data annotation. The paper presents valuable insights into the challenges and thought processes in the development of the authors’ phenomenon-based semantic infrastructure and makes a case for why interoperability of observations is paramount for ecosystem modelling. The notion of defining a “worldview” is a useful one. The tiers of users chimes with experiences and expectations reported in the biosemantics literature. The authors are also well aware of the limitations of their approach as discussed in section 3. The k.IM language is interesting, and it is more than plausible that one would want a language to disguise OWL2: though claims to its ease of readability and its compatibility with OWL2 are not really demonstrated. It’s a very dense paper that packs a lot in and requires several readings. Part of the challenge of the paper is to describe the semantics coherently and completely enough to be convincing whilst leaving examples of how the semantics are used to other papers. It partially succeeds. The paper’s presentation is also often frustrating. Nonetheless this is stimulating and valuable work and a useful contribution to the semantics of observables and observations. Suggestions for improvements: Ontologies, semantics, whatever you like to call them, are for a purpose. The authors note the success of domain ontologies is because of their purpose. However, very little information is given on the purpose of the semantics of observations: the application, the nature of the questions, data and models, whether the data to be interoperated is public data or privately annotated or the nature of compatibility that is being sought. Section 2.6 and some hints in section 1.2 are the only hints we have towards the driver of the work – that is input-output compatibility. Many readers will not know what socio-ecological modelling is. A much better description, all in one place with an example from the beginning would be beneficial. It is not clear what is even meant by a model – the annotation example in section 2.5 suggests it is a tiff file. An example that will exercise compatibility across scales would be ideal. A clear description – with example - of the application of the enterprise would make it much easier to judge the value of the method and to judge the claims to interoperability made in the abstract and introduction. The salinity example in section 2.3 is the most compelling, as an example of how all the work of the semantics could be put to use and it’s a pity this wasn’t developed further in favour of a shorter treatment of the metaphysics of the semantics of observables. There is a tendency to introduce key points and terminology almost as asides as one goes along which makes it much harder to digest than it should be. For example: Inherency for qualities is an important concept and is frequently referred to but is not specifically defined. Configuration is briefly introduced as an aside example – does the configuration Terrain render the need to state that Elevation is within Earth:Terrestrial earth: Region redundant as Elevation is im:Height of earth:Terrain? The whole of section 2.2 is a drip-feed of new keywords and terms that makes it a slog to work out from the examples what the semantics and syntax of the k.IM language actually are. The software is not amenable to the uninitiated – there are few readmes and the documentation seems to be entirely in a password-guarded wiki. Table 1 gives some words, but definitions of “is”, “as”, “described”, “requires”, “has children” etc are not given. Tables 1 and 2 should have an example for each entry. A complete definition of the full syntax of the language is needed at least in supplementary materials The resultant ontology of observables is not available or referenced as far as I am aware. Granted that the semantics as defined by the language are expressed through the language: nevertheless it is not clear what the “common phenomenology” referenced in section 2.5 ended up as. What other ontologies are imported? We discover that quality is imported from the BFO ontology as an aside on page 13. In section 1.1 the authors do a good job of discussing various classes of ontology and their roles, but then drop any further references. Tables 1 and 2 need to do a better job of the provenance of terms. If the paper is aimed at ontologists (as one might expect) then more detail is needed in the description of the final ontology. Several times the authors’ mention that the descriptions compile to OWL 2.0. It would have been instructive to see one such compilation or to have an example as a supplementary material. Claims to compatibility with OWL2 are not really demonstrated. Is the ontology of observables available? Figure 1 gives the intuition that the authors hope for but perhaps doesn’t stand up to close scrutiny. Coarse grained spatial scale and temporal scale as continuant subject? Are all subjects coarse grained? The section on identities is well written and clear – “bridging authorities” have been attempted for example http://www.bridgedb.org/ and to some extent identifiers.org. Scientific lenses to support multiple views over linked chemistry data . Batchelor C, et al In The Semantic Web – ISWC 2014, Lecture Notes in Computer Science Volume 8796, 2014, 98-113 sets out the notion of linksets used in the Open PHACTS linked data platform for pharmacological data Other related work has a few gaps. The notion of ontological patterns and languages, some of which sit on top of OWL, has has been addressed in the literature. OPPL (the Ontology Pre-Processor Language) dates from 2010 ( http://oppl2.sourceforge.net/documentation.html ) and more recently tawny-owl (https://github.com/phillord/tawny-owl); both promote the notion of Ontology Patterns, which is inherent in the k.IM approach. Webulous takes a spreadsheet approach to ontology patterns rather than a language based one (http://www.ebi.ac.uk/spot/webulous/). Given that the k.IM language is effectively constraining Tier3 developers to certain patterns, this literature seems relevant. There is also the ontology annotation literature: examples include Zooma ( http://www.ebi.ac.uk/spot/zooma/ ) and DOMEO ( https://doi.org/10.1186/2041-1480-3-S1-S1 ) the latter of which uses the W3C Open Annotation Data Model. The notion of automated workflows using ontological annotations on inputs and outputs has also had some past attention. A well known example is the WINGS system: A Semantic Framework for Automatic Generation of Computational Workflows Using Distributed Data and Component Catalogs. Gil, et al Journal of Experimental and Theoretical Artificial Intelligence , 2011. http://dx.doi.org/10.1080/0952813X.2010.490962 