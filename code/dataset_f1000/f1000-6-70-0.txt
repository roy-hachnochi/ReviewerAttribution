Metagenomics has a great potential to influence our understanding of the complex ecology of biotopes, including marine waters. Despite the impressive speed of generating sequence data, the analyses pipelines are not as well developed and standardized. This article describes a comparison between two analysis pipelines and how they perform on different types of sequence data. The main methodological difference between the two pipe-lines tested is if the anaysis is done on the read-level (EMG) or at the contig-level (META-pipe). This will of course have a major influence on the results obtained, which is in essence what this study aims to outline. The manuscript also has a link to a nice webinar that explains parts of the background, technical details, challenges and some of the results. Major critique/comments: Why a specific marine metagenomics pipeline? Why could not this service be generic - independent on where the organisms live (marine, soil, stomach, flowers, etc....). This issue is addressed in the webinar, but not in the paper, e.g. marine samples/sequences are taxonomically complex and with really high genetic/sequence diversity. There might be more reasons. These reasons for a specific marine pipeline should be outlined in 1-2 sentences in the paper. Why picking unpublished data for the test? Anything specifically general with this data? Or could there be very specific biases and technical problems with this data? This should be outlined and described. They should also consider using some already published data for their comparison. In addition, the data analysed is based on comparably long-read Illumina reads - 250nt and 300nt. Plenty of metagenomics data has been, and will be, collected using more standard length reads (≈ 125nt). Please discuss, e.g. in the conclusion part, to what extent this selection of example data could have had an impact on the obtained results. In the Conclusion section they state: " While there are differences in the respective approaches, EMG and META-pipe provide comparable results. " But do they really show similar results? There appear to exist huge differences between the two programs that are also highlighted earlier in the text: p.6, rc, " While META-pipe was able to predict 6584 16S rRNA sequences, EMG predicted 4339 in the “Muddy” dataset (Figure 2)." p.6, rc, " In the “Muddy” dataset, EMG classified 2500 sequences (58%), while META-pipe was able to classify 6119 (93%)." p.8, lc, " EMG predict 11 572 617 CDSs (from 12 103 194 merged reads), while META-pipe predicts a total of 47 434 CDSs (from 25 581 assembled contigs 500 bp), which accounts for 0.4% compared to EMG. p.8, rc, " EMG provided a total of 28 942 422 accumulated GO-slim annotations for the predicted CDSs, while META-pipe only provided 565 125 accumulated annotations, which accounts for 0.2% compared to EMG." I think there statement about "comparable results" should be modified and differences also highlighted in the Conclusion. Finally, should one recommend that both pipelines are used in analyses before publication, and that results are being reported? And if so, what about other pipelines? How do they see that this challenge (which is a great problem in the comparison of results between studies using different analysis pipelines) should be handled in the future? Minor comments: Abstract In the last sentence of the abstract it says: "In this paper, we summarize some of the results from the ELIXIR pilot action “Marine metagenomics – towards user centric services”. Shouldn't this be the same as in the title? Page 3, left column (lc), line 7 I am not sure I see why replication would be hard given the information in publications - databases are not per see a guarantee for higher transparancy in information handling. Even if the access to the data might be easier. The statement should be modified. Or do they mean "results" and not "analyses" are hard to replicate? p.3, lc, l.15 Please provide a short overview of the types of metagenomics pipeline that are available at this stage. Please explain to the reader why EMG and META-pipe were selected for comparison? Anything that make this comparison particularly valid? p.4, lc, l.3 preform - perform p.4, rc, l.18 Give arguments for why Kmer = 31 was selected. Are there reasons to believe the results would have been different if another Kmer had been used? p.4, right column (rc), l.4 from bottom Please explain "biomes". p.6, lc, l.33 They state that META-pipe is reluctant to classify on species level. Can one explain to the reader why that is? p.6, lc, l.35 Be more specific - how was "better" defined? Table 2 Just to be sure - do they mean prokaryotic + eukaryotic? Table 2 Why can't EMG do eukaryotes? Figure 4 What do we really learn from this figure? Figure 5 How have the annotations been sorted? p.9, lc, l.3 to - the p.10, lc, l.10 from bottom They talk about gold standard tools. But these might differ dependent on the data - technical problems; community complexity; lengths of reads; .... Can they be a bit more specific for how they see that this "golden standard" can be reached? 