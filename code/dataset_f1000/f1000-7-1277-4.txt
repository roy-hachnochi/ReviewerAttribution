This study asks when the intrinsic biophysical properties of neurons do or do not affect their spiking responses to synaptic inputs. I denote the main claims and results of the paper as I,II,and III below, each of which is discussed individually thereafter. I. The author begins by noting that, in the presence of strong synchronous inputs, essentially all neurons are driven to quickly spike, regardless of their intrinsic properties. In the presence of less-synchronous inputs, differences in intrinsic properties do lead to noticeable changes in spiking outputs. This is (presumably) because differences in integration time, and excitability (effective spiking threshold) determine how much input is needed to get the cell to spike, but sufficiently strong synchronous inputs always suffice to generate spikes. This is a neat observation, somewhat obvious in hindsight, but nevertheless made me glad to read the paper. II. Next, they investigate how different network structures (quantified by dispersion of the graph's out-degree distribution) affect the synchrony in the inputs to individual neurons: networks with high dispersion (e.g., small numbers of critical "hubs" in the network) lead to higher synchrony. Thus, in those networks, the neurons' intrinsic properties are less influential than in networks with lower dispersion. III. Finally, the authors speculate that, because neuromodulators can change effective connectivity, they could switch the network between different graph structures, thereby either enabling, or disabling, the influences of neurons' intrinsic properties. In that way, the network can "multiplex" between operational modes, on of which (the asynchronous one) is more affected by neurons' intrinsic plasticity, and thus more affected by memory and experience. Below, I summarize first the relation to prior studies for each claim (I-III), and then comment on some technical and presentation issues that, to me, hinder somewhat the readability of the paper. My hope is that addressing these concerns will help the author to increase the impact of their work. Comments on relation to other studies: Result I . This is a neat observation. It is somewhat foreshadowed by some older work by Salinas and Sejnowski 1 , 2 , showing that synchronous inputs are good at driving spikes in basically any neuron model. It would be useful to differentiate the findings of this paper from their older work. Result II . Closely related results were obtained in a pair of studies by Yu Hu, James Trousdale, and colleagues 3 , 4 . There, they computed the correlation structure (closely related to the author's synchrony measure) in networks with different connectivity motifs, using a neat analytical approach involving motif cumulants. It would be worthwhile (again) differentiating the results here from that prior work, so that readers know what's new and significant about this paper vs. the prior state of the field. Result III . I'm puzzled by the claim that the network topology is strongly affected by neuromodulators (which is the key to the switching property that's discussed through the paper). While I understand that neuromodulators can strengthen or weaken synapses, that mechanism will change the weights within the graph describing network connectivity, but not change the underlying unweighted graph describing which neurons are connected to each other (regardless of the strength of that connection). To change the network topology, the neuromodulators would need to either a) add new synapses (or "unsilence" previously silenced synapses) selectively to some neurons, or b) remove (or completely silence) synapses selectively from some neurons. I think that, in order for the author to make claims about neuromodulators changing network topology, they should include some discussion (ideally based on the experimental literature) of when and how neuromodulators actually change network topology. This literature could of course exist: there's lots that I don't know about neuromodulators. And in that case, I think the author's claims would be much strengthened by referencing and discussing it. Comments on presentation and specific technical issues: Methods, 3rd paragraph. Why only focus on modulators affecting slow A-type K channels? Are those the most important ones? The ones most affected by common neuromodulators? Which neuromodulators are those? Methods, 4th paragraph. It would help me if you would describe explicitly the method used to generate either correlated or uncorrelated synaptic input traces. For example, do these incoming spike trains (generating the synaptic inputs) come from a process like SIP or MIP? And specifically, how were the "correlation factors" quantified and manipulated? Similar to (2) it would help to describe explicitly the synapse model used. For example, are the synapses conductance based (e.g., convolve incoming spike trains with a double exponential to get conductance traces)? I assume not, given that in Figs. 1-6, the same synaptic current trace is shown for all neurons. If the synapses were conductance-based, the differences in membrane potentials of those neurons would lead to differences in synaptic currents. The definition of the synchronization is fine to me but doesn't seem to match the description in the preceding paragraph. Specifically, the formula doesn't seem to "count the number of other neurons which fire in a 10ms window. . . " so much as "count the number of spikes emitted by each other neuron in a 10 ms window". I'd describe the rewiring process in the "graph properties" section of the Methods and not the "Definitions" section. That way, when you introduce the dispersion \sigma, you can explain the process used to manipulate it in your simulations. The figures generally could use much more annotation, to help the readers parse what all the different curves mean. For example, in Figs. 1 and 2, I'd color code the curves (distributions) in panel B, and have those same colors used for the different spike trains in panel A, so that readers know which distribution goes with which spike train goes with which model. The same idea could be applied to the other figures: help the reader out so that, at a quick glance (which is how people read papers now) they can tell what's what and what the main point is. Similarly, in Fig. 11, I'd label the color bar, so that people know what variable the colors are describing. The formula for density on p. 6 (bottom left) seems incorrect, as d=K/(NxN-1). That would be K/(N^2 -1), whereas I think you mean K/[Nx(N-1)]. P. 6, upper right, description of stimulating the graph by driving 10 excitatory neurons. How was this done? Did you inject current into those model neurons? If so, how much? Some consistency between the network sizes in the simulations would help a lot. Specificlaly, in Fig. 10, you study a 1924 neuron network, whereas Fig. 9 uses 1800 neurons. This leave the interpretation muddier than it needs to be: readers might wonder whether some of the differences could be attributed to changes in network size, and not just to changes in connectivity. In general, I'd suggest keeping all but one key variable constant, so that the comparisons can be made as cleanly as possible. 