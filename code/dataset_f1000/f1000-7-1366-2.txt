The manuscript by Weirick et al. introduces a tool-suite to calculate differential RNA editing. The interest towards RNA editing is rapidly growing and, thus, similar tools to improve the investigation of RNA editing in different experimental conditions are demanding. DRETools include some functions to mainly post-process results from RNAEditor, developed in the same research group. Even though they can be applied to results from other tools after an ad hoc parsing. Calculations are based on the definition of EPK (editing per kilobase), in turn, based on the overall editing concept introduced by Tan et al. 2017. The overall editing is simply calculated as the total number of reads with G at all known editing positions as compared to all reads covering the position. In other terms, this metric is a global editing frequency per sample. Authors multiply the overall editing by 1000 in order to improve the readability because in same cases very low numbers may appear. Although authors show that EPK values are useful over the raw count of editing sites, the properties of EPK are not well investigated. The number of As and Gs is dependent on filters used to detect editing and the quantity of reads generated by sequencing. Base quality is also an additional factor to consider. Iâ€™m not completely sure if EPK can take into account the number of reads per sample. I suggest to perform further investigations calculating global EPK in samples belonging to the same tissue. For example, authors could use GTEx RNAseq from three or four tissues and at least 10 experiments per tissue. Other authors proposed similar indices to detect editing activity in a sample. For example, Paz-Yaacov introduced the Alu editing index, a robust measure that can be calculated also on other additional genomic properties (recoding sites, conserved sites and so on). This index has been successfully used in several cases and authors need to perform appropriate comparisons. Regarding statistical tests used to detect differential editing, authors implement a linear model and the t-test. In figure 1 (panels E to H), p-values distributions are shown and great differences seem to appear. Authors should discuss the reason why of these observed discrepancies. I suggest authors to check the use of non parametric tests since they could be robust in case of small samples or when users cannot easily establish if normality and other assumptions are encountered. Additionally, the tool does not take into account the correction for multiple testing. So it needs to be implemented. In humans, RNA editing has different properties depending on affected genomic regions. For example, Alu editing is different from recoding editing. Is there a way to take such properties into account? Finally, DRETools features should better described in the manuscript and details about input and output files should be included in the wiki pages. Some experimental validations are required to corroborate tool results. In my opinion DRETools are useful but major improvement is deeply needed. 