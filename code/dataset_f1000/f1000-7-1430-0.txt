Unfortunately the authors did not provide a point to point response to my critique, and also addressed only some of the issues I raised: My criticism regarding version 1: Group sizes of 5 are exceedingly low, but the sentence ‘Whilst this study may have been slightly underpowered in terms of animal numbers, actively pursuing significance with higher numbers would be ethically questionable, and against the principles of reduction and refinement.’ is absurd and unscientific. In fact, underpowered studies are unethical, as pointed out by Cressey D . An informal, post hoc power calculation on their data set reveals that they may have achieved only 10-20 % power (instead of 80 or 95%). This is particularly worrisome, as they report a null result, so false negatives are a major concern. The study is lacking a justification of the sample sizes, and Type II error considerations. What are the effect sizes the study could have possibly detected? Partly resolved in version 2: A priori power analysis using sucrose preference testing data from our own publications on models of stress and depression, where the effect is substantial26, results in a Cohen’s d of 2.5. With a suggested power of 0.95 this gives a minimum samples size of 5. True, but a cohen’s d is an absurdly high es! using a d of 2,5 one could justify to conduct studies in preclinical neuroscience with 3 animals, and clinical studies with 10 patients, to always find null effects as the targeted es was not reached (but the study appropriately powered). “For example, studying latency to immobility at 24 hours (where differences are likely to be most stark in the post-stroke brain) results in a suggested sample size of 161 animals to give a significant difference. Even in tests where the trend could potentially be seen, such as sucrose preference, the number of animals required to show a significant change was 40. Powering up pilot studies for negative results is an ongoing discussion amongst preclinical researchers and ethical review boards. Overall, this exploratory data provides citable evidence that there is no overt depression-like phenotype in the acute phase of the distal MCAO model. The aim of providing this data is to inform those wishing to investigate depression-like behaviors post-stroke in rodents should consider using alternative models.” I am a big supporter of the publication of null results. but I am afraid that the authors of this study are not doing a good service to this idea. The argument they basically use is: following our apriori sample size calculation to make a meaningful statement we would have needed forbiddingly high animal numbers. I agree but the consequence of this cannot be to then conclude that using too few animals is the alternative. Small studies on animals that do not lead to useful evidence are unethical. given the apriori sample size calculation a sensible conclusion would have been to either try to find a model with lower variance; or to abort the experimental project. a systematic review of the existing literature would have been much more helpful, as such a review could have exposed the gross lack of power and low internal and external validity of the available studies. the authors instead replicate many of the problems of the already existing literature. My criticism regarding version 1: In general, the test statistics of this study don’t make a lot of sense. Although they are formally correct, in the absence of the definition of one primary outcome, and the fact that they performed at least 12 ANOVAs (for which they did not correct), as well as given the exploratory character of the study, test statistics should be avoided, and the focus should be on effect sizes and variance. This brings me to another problem: The authors use SEMs (a measure of precision, not of the spread of the data) and they use bar graphs, instead of dot plots (individual data points) and true measures of variance to illustrate their data. Thank you for eliminating bar graphs and using dot plots; but why do you insist on SEMs when a measure of the spread of the data is needed and not one for the precision of the measurement? My criticism regarding version 1: The authors do not mention how many animals went into the study (ARRIVE guidelines), they only mention group sizes (in the figures). Only downloading the full data set reveals that there obviously was no attrition, although there are unexplained missing data points. Not resolved in version 2 My criticism regarding version 1: External validity I: Left sided occlusion only! Kronenberg et al , in a mouse model of transient proximal occlusion demonstrated that left, but not right, middle cerebral artery occlusion leads to chronic ‘Depression-Like’ behavior, which was reversed by serotonin reuptake inhibition. This article, as well as a number of other relevant publications pertinent to the subject of modeling of PSD in rodents, is not cited. Although Gammelstrup Andersen used left sided occlusion, it at least demonstrates the potential of lateralization of behavioural symptoms in rodents. Not resolved in version 2 My criticism regarding version 1: External validity II: Only male mice are studied, and of an age range and without comorbidities. This does not reflect the cohort of patients which are at risk for stroke and PSD. Not resolved in version 2 My criticism regarding version 1: The title of the study ‘Distal middle cerebral artery occlusion does not result in depression-like behaviors’ is imprecise and should contain at least the species, but ideally more information on the model. I suggest: An exploratory investigation of ‘depression-like’ behaviours in a model of left-sided distal middle cerebral artery occlusion in young, male C57B6 mice.