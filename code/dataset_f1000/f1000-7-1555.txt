

    <!DOCTYPE html>
<html class="">

        
<head>
    <title>Recent advances in understanding the auditory... | F1000Research</title>
    <meta charset="utf-8">
    <!--<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>-->
    <!--<meta lang="$locale">-->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="9-QVycOO2_ob3Z9QzRmXv2CF08A9oyYXqWyTiVdKPlU" />
    <!-- This is commented out to fix display problems on mobile devices.
    We may use it again once we implement a responsive design that supports native device resolutions.
    <meta name="viewport" content="width=device-width"> -->

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <link rel="alternate" title="Recent articles published in F1000Research" href="/rss" type="application/rss+xml">
            <link rel="alternate" type="application/pdf" title="PDF" href="https://f1000research.com/articles/7-1555/pdf"/>
        <link rel="canonical" href="https://f1000research.com/articles/7-1555" />
    
            <meta name="description" content="Read the original article in full on F1000Research: Recent advances in understanding the auditory cortex" />
    
            <meta name="og:title" content="F1000Research Article: Recent advances in understanding the auditory cortex.">
            <meta name="og:description" content="Read the latest article version by Andrew J. King, Sundeep Teki, Ben D.B. Willmore, at F1000Research.">
            <meta name="og:image" content="/img/sharing/og_research.png">
            <meta name="version-id" content="16995">
            <meta name="article-id" content="15580">
            <meta name="dc.title" content="Recent advances in understanding the auditory cortex">
            <meta name="dc.description" content="Our ability to make sense of the auditory world results from neural processing that begins in the ear, goes through multiple subcortical areas, and continues in the cortex. The specific contribution of the auditory cortex to this chain of processing is far from understood. Although many of the properties of neurons in the auditory cortex resemble those of subcortical neurons, they show somewhat more complex selectivity for sound features, which is likely to be important for the analysis of natural sounds, such as speech, in real-life listening conditions. Furthermore, recent work has shown that auditory cortical processing is highly context-dependent, integrates auditory inputs with other sensory and motor signals, depends on experience, and is shaped by cognitive demands, such as attention. Thus, in addition to being the locus for more complex sound selectivity, the auditory cortex is increasingly understood to be an integral part of the network of brain regions responsible for prediction, auditory perceptual decision-making, and learning. In this review, we focus on three key areas that are contributing to this understanding: the sound features that are preferentially represented by cortical neurons, the spatial organization of those preferences, and the cognitive roles of the auditory cortex.">
            <meta name="dc.subject" content="auditory cortex, receptive field, model, map, cognition, plasticity">
            <meta name="dc.creator" content="King, Andrew J.">
            <meta name="dc.creator" content="Teki, Sundeep">
            <meta name="dc.creator" content="Willmore, Ben D.B.">
            <meta name="dc.date" content="2018/09/26">
            <meta name="dc.identifier" content="doi:10.12688/f1000research.15580.1">
            <meta name="dc.source" content="F1000Research 2018 7:1555">
            <meta name="dc.format" content="text/html">
            <meta name="dc.language" content="en">
            <meta name="dc.publisher" content="F1000 Research Limited">
            <meta name="dc.rights" content="https://creativecommons.org/licenses/by/3.0/igo/">
            <meta name="dc.type" content="text">
            <meta name="prism.keyword" content="auditory cortex">
            <meta name="prism.keyword" content="receptive field">
            <meta name="prism.keyword" content="model">
            <meta name="prism.keyword" content="map">
            <meta name="prism.keyword" content="cognition">
            <meta name="prism.keyword" content="plasticity">
            <meta name="prism.publication.Name" content="F1000Research">
            <meta name="prism.publicationDate" content="2018/09/26">
            <meta name="prism.volume" content="7">
            <meta name="prism.number" content="1555">
            <meta name="prism.versionIdentifier" content="1">
            <meta name="prism.doi" content="10.12688/f1000research.15580.1">
            <meta name="prism.url" content="https://f1000research.com/articles/7-1555">
            <meta name="citation_title" content="Recent advances in understanding the auditory cortex">
            <meta name="citation_abstract" content="Our ability to make sense of the auditory world results from neural processing that begins in the ear, goes through multiple subcortical areas, and continues in the cortex. The specific contribution of the auditory cortex to this chain of processing is far from understood. Although many of the properties of neurons in the auditory cortex resemble those of subcortical neurons, they show somewhat more complex selectivity for sound features, which is likely to be important for the analysis of natural sounds, such as speech, in real-life listening conditions. Furthermore, recent work has shown that auditory cortical processing is highly context-dependent, integrates auditory inputs with other sensory and motor signals, depends on experience, and is shaped by cognitive demands, such as attention. Thus, in addition to being the locus for more complex sound selectivity, the auditory cortex is increasingly understood to be an integral part of the network of brain regions responsible for prediction, auditory perceptual decision-making, and learning. In this review, we focus on three key areas that are contributing to this understanding: the sound features that are preferentially represented by cortical neurons, the spatial organization of those preferences, and the cognitive roles of the auditory cortex.">
            <meta name="citation_description" content="Our ability to make sense of the auditory world results from neural processing that begins in the ear, goes through multiple subcortical areas, and continues in the cortex. The specific contribution of the auditory cortex to this chain of processing is far from understood. Although many of the properties of neurons in the auditory cortex resemble those of subcortical neurons, they show somewhat more complex selectivity for sound features, which is likely to be important for the analysis of natural sounds, such as speech, in real-life listening conditions. Furthermore, recent work has shown that auditory cortical processing is highly context-dependent, integrates auditory inputs with other sensory and motor signals, depends on experience, and is shaped by cognitive demands, such as attention. Thus, in addition to being the locus for more complex sound selectivity, the auditory cortex is increasingly understood to be an integral part of the network of brain regions responsible for prediction, auditory perceptual decision-making, and learning. In this review, we focus on three key areas that are contributing to this understanding: the sound features that are preferentially represented by cortical neurons, the spatial organization of those preferences, and the cognitive roles of the auditory cortex.">
            <meta name="citation_keywords" content="auditory cortex, receptive field, model, map, cognition, plasticity">
            <meta name="citation_journal_title" content="F1000Research">
            <meta name="citation_author" content="Andrew J. King">
            <meta name="citation_author_institution" content="Department of Physiology, Anatomy &amp; Genetics, University of Oxford, Oxford, OX1 3PT, UK">
            <meta name="citation_author" content="Sundeep Teki">
            <meta name="citation_author_institution" content="Department of Physiology, Anatomy &amp; Genetics, University of Oxford, Oxford, OX1 3PT, UK">
            <meta name="citation_author" content="Ben D.B. Willmore">
            <meta name="citation_author_institution" content="Department of Physiology, Anatomy &amp; Genetics, University of Oxford, Oxford, OX1 3PT, UK">
            <meta name="citation_publication_date" content="2018/09/26">
            <meta name="citation_volume" content="7">
            <meta name="citation_publication_number" content="1555">
            <meta name="citation_version_number" content="1">
            <meta name="citation_doi" content="10.12688/f1000research.15580.1">
            <meta name="citation_firstpage" content="1555">
            <meta name="citation_pdf_url" content="https://f1000research.com/articles/7-1555/v1/pdf">
    

    
    <link href="/img/favicon-research.ico" rel="shortcut icon" type="image/ico">
    <link href="/img/favicon-research.ico" rel="icon" type="image/ico">

        <link rel="stylesheet" href="/1597255280893/css/mdl/material-design-lite.css" type="text/css" media="all" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/MaterialDesign-Webfont/2.2.43/css/materialdesignicons.min.css" />

        
            
    <link rel="stylesheet" href="/1597255280893/css/F1000Research.css" type="text/css" media="all" />
    <link rel="stylesheet" href="/css/F1000ResearchFontIcons/F1000ResearchFontIcons.css" type="text/css" media="all" />
    <link rel="stylesheet" href="/css/F1000ResearchFontIcons/animation.css" type="text/css" media="all" />

        <!--[if IE 7]><link rel="stylesheet" href="/css/F1000ResearchFontIcons/F1000ResearchFontIcons-ie7.css" media="all" /><![endif]-->

                    <script>dataLayer = [];</script>
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-54Z2SBK');</script>
        <!-- End Google Tag Manager -->
    
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.1/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="/js/vendor/jquery-1.8.1.min.js"><\/script>')</script>
    <script src="/1597255280893/js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>
    <script src="/1597255280893/js/shared_scripts/sticky.js"></script>
    <script src="/1597255280893/js/shared_scripts/helpers.js"></script>
    <script src="/1597255280893/js/shared_scripts/menu.js"></script>
    <script src="/1597255280893/js/shared_scripts/navbar.js"></script>
    <script src="/1597255280893/js/shared_scripts/platforms.js"></script>
    <script src="/1597255280893/js/shared_scripts/object-polyfills.js"></script>
            <script src="/1597255280893/js/vendor/lodash.min.js"></script>
        <script>CKEDITOR_BASEPATH='https://f1000research.com/js/ckeditor/'</script>
    <script src="https://f1000researchdata.s3-eu-west-1.amazonaws.com/js/plugins.js"></script>
    <script src="/1597255280893/js/shared_scripts/helpers.js"></script>
    <script src="/1597255280893/js/app/research.js"></script>
    <script>window.reactTheme = 'research';</script>
    <script src="/1597255280893/js/public/bundle.js"></script>

    <script src="/1597255280893/js/app/research.ui.js"></script>
    <script src="/1597255280893/js/app/login.js"></script>
    <script src="/1597255280893/js/app/main.js"></script>
    <script src="/1597255280893/js/app/js-date-format.min.js"></script>
    <script src="/1597255280893/js/app/search.js"></script>
    <script src="/1597255280893/js/app/cookies_warning.js"></script>
    <script src="/1597255280893/js/mdl/mdl.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script src="https://f1000researchdata.s3-eu-west-1.amazonaws.com/js/ckeditor.js"></script>
            <script src="/js/ckeditor/adapters/jquery.js"></script>
                <script src="/js/article/article_scrolling_module.js"></script>
            <script src="/js/article/article_stats.js"></script>
            <script src="/js/article/article.js"></script>
            <script src="/js/shared_scripts/referee_timeline_pagination.js"></script>
            <script src="/js/app/text_editor_controller.js"></script>
            <script src="//s7.addthis.com/js/250/addthis_widget.js#pubid=ra-503e5e99593dc42c"></script>
            <script src="/js/article/article_metrics.js"></script>
        
                                                                            <script>
            if (window.location.hash == '#_=_'){
                window.location = window.location.href.split('#')[0]
            }
        </script>

                    
        
    <!-- pixelId: 1641728616063202 :: assetPixelId: 6034867600215 :: funderPixelId:  -->

            <!-- Facebook pixel code (merged with EP GTM code) -->
        <script>
            !function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function()

            {n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}
            ;if(!f._fbq)f._fbq=n;
            n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
            t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
            document,'script','https://connect.facebook.net/en_US/fbevents.js');

            fbq('init', '1641728616063202');

            
            fbq('track', "PixelInitialized", {});
        </script>

        <noscript><img height="1" width="1" style="display:none"
            src="https://www.facebook.com/tr?id=1641728616063202&noscript=1&amp;ev=PixelInitialized"
        /></noscript>
        <!-- End Facebook Pixel Code -->
    
                <script>
            (function(h,o,t,j,a,r){
                h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
                h._hjSettings={hjid:917825,hjsv:6};
                a=o.getElementsByTagName('head')[0];
                r=o.createElement('script');r.async=1;
                r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
                a.appendChild(r);
            })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
        </script>
    
</head>
<body  class="o-page-container no-js p-article o-layout-reset   ">

    
                            <!-- Google Tag Manager (noscript) -->
        <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-54Z2SBK"
        height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
        <!-- End Google Tag Manager (noscript) -->
    
        
    <div class="o-page">

        <div id="notify-container"></div>
        <div id="pageWarning"></div>
        <div id="pageMessage"></div>
        <div id="pageFooterMessage"></div>

                                <div id="f1r-ga-data" data-name="f1r-ga-data" class="f1r-ga-data"
                data-user-registered="false"
                data-user-module=""
                data-current-path=""
                data-location=""
                data-website="F1000Research"
                data-websiteDisplayName="F1000Research">
            </div>
        
                
        
        <div class="header-wrapper   js-navbar-space ">
                            


    










        
                            
    
            



<nav class="c-navbar js-navbar js-mini-nav js-sticky c-navbar--js-sticky c-navbar--userSite c-navbar__platform-bgcolor  c-navbar--bg-f1000research ">

    <div class="c-navbar__content">

                                <div class="c-navbar__extras">
            <div class="o-wrapper">
                <div class="o-actions o-actions--middle c-navbar__extras-row">
                    <div class="o-actions__primary">
                        
                                            </div>
                                    </div>
            </div>
        </div>

        <div class="o-wrapper t-inverted js-sticky-start">

            <div class="c-navbar__branding-row">
                <div class="c-navbar__row">


                                        
                    <div class="c-navbar__primary u-mr--2">

                                                                                                                                                                                                    <a href="/" class="c-navbar__branding u-ib u-middle"   data-test-id="nav_branding"  >
                                <img class="u-ib u-middle" src="/img/research/F1000Research_white_solid.svg" alt="F1000Research">
                            </a>
                                            </div>

                    <div class="c-navbar__secondary c-navbar__row">


                                                
                                                    <form action="/search" class="-navbar__secondary u-mr--2 c-search-form js-search-form u-hide u-show@navbar">
                                <label for="searchInput" class="c-search-form__label _mdl-layout">
                                    <input name="q" type="search" class="c-search-form__input" id="searchInput" placeholder="Search">
                                    <button type="submit" class="c-search-form__submit mdl-button mdl-js-button mdl-button--icon"><i class="material-icons">search</i></button>
                                </label>
                            </form>
                        
                                                
                                                    <div class="c-navbar__primary u-hide u-show@navbar">
                                <div class="_mdl-layout c-navbar__cta">
                                    <a class="mdl-button mdl-js-button mdl-button--raised mdl-button--no-shadow mdl-button--multi-line mdl-js-ripple-effect mdl-button--inverted c-navbar__submit" href="/for-authors/publish-your-research"   data-test-id="nav_submit_research"  ><i class="material-icons">file_upload</i>Submit your research</a>
                                </div>
                            </div>
                        

                                                
                        <span class="u-hide@navbar _mdl-layout u-nowrap">

                                                            <button type="button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon c-navbar__toggle c-navbar__toggle--menu js-navbar-toggle" data-focus="#navbar_mob_search_input" data-toggle="navbarMenu" data-target="navbarMenu" aria-controls="navbarMenu" aria-expanded="false" aria-label="Toggle navigation"   data-test-id="nav_menu_search_mob"  ><i class="material-icons">search</i></button>
                            
                                                            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-button--multi-line c-navbar__toggle c-navbar__toggle--menu js-navbar-toggle" type="button" data-toggle="navbarMenu" data-target="navbarMenu" aria-controls="navbarMenu" aria-expanded="false" aria-label="Toggle navigation"   data-test-id="nav_menu_toggle_mob"  >
                                    <i class="material-icons c-navbar__toggle-open">menu</i>
                                    <i class="material-icons c-navbar__toggle-close">close</i>
                                </button>
                                                    </span>
                    </div>

                </div>
            </div>

                        
                            <div class="c-navbar__menu-row js-navbar-block is-collapsed" id="navbarMenu">

                                                                                                                                                
                                                                    
                                                                    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                            

                                                                
                                                                                                                                                                                                                                
                                            
                    <div class="c-navbar__menu-row-content">

                                                                            <div class="u-hide@navbar c-navbar__menu-bar-spacing">
                                <form action="/search" class="c-search-form js-search-form">
                                    <label for="navbar_mob_search_input" class="c-search-form__label _mdl-layout">
                                        <input id="navbar_mob_search_input" name="q" type="search" class="c-search-form__input" placeholder="Search">
                                        <button type="submit" class="c-search-form__submit mdl-button mdl-js-button mdl-button--icon"><i class="material-icons">search</i></button>
                                    </label>
                                </form>
                            </div>
                        
                        <div class="o-actions o-actions--middle">

                            <div class="o-actions__primary">

                                                                
    <ul class="c-menubar c-navbar__menu-bar js-main-menu"   id="main-menu"   role="menubar" aria-label="Main Navigation"  data-menu-group="navbar" >

        
            
                                                                
                                
                                
                                    <li role="none"
                        data-index="0"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/browse/articles" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="0"
                              data-test-id="nav_browse"                              >Browse</a>

                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="1"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/gateways" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="-1"
                              data-test-id="nav_gatewaysViewAndBrowse"                              >Gateways & Collections</a>

                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="2"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="-1"
                              data-test-id="nav_for-authors"                              >How to Publish</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="How to Publish">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_submit-manuscript"                      href="/for-authors/publish-your-research"
                    role="menuitem"
                    tabindex="0">Submit your Research</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-submissions"                      href="/for-authors/my-submissions"
                    role="menuitem"
                    tabindex="-1">My Submissions</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-guidelines"                      href="/for-authors/article-guidelines"
                    role="menuitem"
                    tabindex="-1">Article Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-guidelines-new-versions"                      href="/for-authors/article-guidelines-new-versions"
                    role="menuitem"
                    tabindex="-1">Article Guidelines (New Versions)</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_data-guidelines"                      href="/for-authors/data-guidelines"
                    role="menuitem"
                    tabindex="-1">Data Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_asset-guidelines"                      href="/for-authors/posters-and-slides-guidelines"
                    role="menuitem"
                    tabindex="-1">Posters and Slides Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_document-guidelines"                      href="/for-authors/document-guidelines"
                    role="menuitem"
                    tabindex="-1">Document Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-processing-charges"                      href="/for-authors/article-processing-charges"
                    role="menuitem"
                    tabindex="-1">Article Processing Charges</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_finding-referees"                      href="/for-authors/tips-for-finding-referees"
                    role="menuitem"
                    tabindex="-1">Finding Article Reviewers</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="3"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="-1"
                              data-test-id="nav_about-contact"                              >About</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="About">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_about-page"                      href="/about"
                    role="menuitem"
                    tabindex="0">How it Works</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_referee-guidelines"                      href="/for-referees/guidelines"
                    role="menuitem"
                    tabindex="-1">For Reviewers</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_advisoryPanel"                      href="/advisors"
                    role="menuitem"
                    tabindex="-1">Our Advisors</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_policy-page"                      href="/about/policies"
                    role="menuitem"
                    tabindex="-1">Policies</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_glossary-page"                      href="/glossary"
                    role="menuitem"
                    tabindex="-1">Glossary</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_faqs-page"                      href="/faqs"
                    role="menuitem"
                    tabindex="-1">FAQs</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              u-hide u-show@navbar"
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      u-hide u-show@navbar"
                                          data-test-id="nav_for-developers"                      href="/developers"
                    role="menuitem"
                    tabindex="-1">For Developers</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_newsroom-page"                      href="/newsroom"
                    role="menuitem"
                    tabindex="-1">Newsroom</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_contact-page"                      href="/contact"
                    role="menuitem"
                    tabindex="-1">Contact</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="4"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="https://blog.f1000.com/blogs/f1000research/" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                             target="_blank"                                                         tabindex="-1"
                              data-test-id="nav_blog"                              >Blog</a>

                                            </li>
                
            
        
    </ul>



                            </div>

                            <div class="o-actions__secondary">

                                                                
    <ul class="c-menubar c-navbar__menu-bar js-main-menu"   id="secondary-items"   role="menubar" aria-label="My Account"  data-menu-group="navbar" >

        
            
                                                                
                                
                                
                                    <li role="none"
                        data-index="0"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="0"
                              data-test-id="nav_my-research"                              >My Research</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="My Research">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-submissions"                      href="/login?originalPath=/my/submissions"
                    role="menuitem"
                    tabindex="0">Submissions</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-email-alerts"                      href="/login?originalPath=/my/email-alerts"
                    role="menuitem"
                    tabindex="-1">Content and Tracking Alerts</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-user-details"                      href="/login?originalPath=/my/user-details"
                    role="menuitem"
                    tabindex="-1">My Details</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="1"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/login?originalPath=/articles/7-1555.html" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="-1"
                              data-test-id="nav_sign-in"                              >Sign In</a>

                                            </li>
                
            
        
    </ul>



                            </div>

                                                                                        <div class="_mdl-layout c-navbar__cta u-hide@navbar c-navbar__menu-bar-spacing">
                                    <a class="mdl-button mdl-js-button mdl-button--raised mdl-button--multi-line mdl-button--no-shadow mdl-js-ripple-effect mdl-button--inverted c-navbar__submit" href="/for-authors/publish-your-research"   data-test-id="nav_submit_research_mob"  ><i class="material-icons">file_upload</i>Submit your research</a>
                                </div>
                                                    </div>

                    </div>

                </div>
            
        </div>

    </div>

</nav>
                    </div>

        <div class="content-wrapper o-page__main row ">
            <div id="highlight-area" class="content ">
                





<div id=article-metadata class=hidden> <input type=hidden name=versionId value=16995 /> <input type=hidden id=articleId name=articleId value=15580 /> <input type=hidden id=xmlUrl value="/articles/7-1555/v1/xml"/> <input type=hidden id=xmlFileName value="-7-1555-v1.xml"> <input type=hidden id=article_uuid value=8a8fb5c8-0d07-4778-9896-5f526a15f5db /> <input type=hidden id=referer value=""/> <input type=hidden id=meta-article-title value="Recent advances in understanding the auditory cortex"/> <input type=hidden id=workspace-export-url value="https://sciwheel.com/work/api/import/external?doi=10.12688/f1000research.15580.1"/> <input type=hidden id=versionDoi value="10.12688/f1000research.15580.1"/> <input type=hidden id=usePmcStats value=true /> </div> <main class="o-wrapper p-article__wrapper js-wrapper"> <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "ScholarlyArticle",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://f1000research.com/articles/7-1555"
  },
  "headline": "Recent advances in understanding the auditory cortex",
  "datePublished": "2018-09-26T11:13:45",
  "dateModified": "2018-09-26T11:13:45",
  "author": [
    {
      "@type": "Person",
      "name": "Andrew J. King"
    },    {
      "@type": "Person",
      "name": "Sundeep Teki"
    },    {
      "@type": "Person",
      "name": "Ben D.B. Willmore"
    }  ],
  "publisher": {
    "@type": "Organization",
    "name": "F1000Research",
    "logo": {
      "@type": "ImageObject",
      "url": "https://f1000research.com/img/AMP/F1000Research_image.png",
      "height": 480,
      "width": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://f1000research.com/img/AMP/F1000Research_image.png",
    "height": 1200,
    "width": 150
  },
  "description": "Our ability to make sense of the auditory world results from neural processing that begins in the ear, goes through multiple subcortical areas, and continues in the cortex. The specific contribution of the auditory cortex to this chain of processing is far from understood. Although many of the properties of neurons in the auditory cortex resemble those of subcortical neurons, they show somewhat more complex selectivity for sound features, which is likely to be important for the analysis of natural sounds, such as speech, in real-life listening conditions. Furthermore, recent work has shown that auditory cortical processing is highly context-dependent, integrates auditory inputs with other sensory and motor signals, depends on experience, and is shaped by cognitive demands, such as attention. Thus, in addition to being the locus for more complex sound selectivity, the auditory cortex is increasingly understood to be an integral part of the network of brain regions responsible for prediction, auditory perceptual decision-making, and learning. In this review, we focus on three key areas that are contributing to this understanding: the sound features that are preferentially represented by cortical neurons, the spatial organization of those preferences, and the cognitive roles of the auditory cortex."
}
</script> <div class="o-layout o-layout--right-gutter"> <div id=article_secondary-column class="p-article__main o-layout__item u-font-size--legal u-2/3@article not-expanded "> <div class=float-left> <script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BreadcrumbList",
    "itemListElement": [
              {
          "@type": "ListItem",
          "position": "1",
          "item": {
            "@id": "https://f1000research.com/",
            "name": "Home"
          }
        },              {
          "@type": "ListItem",
          "position": "2",
          "item": {
            "@id": "https://f1000research.com/browse/articles",
            "name": "Browse"
          }
        },              {
          "@type": "ListItem",
          "position": "3",
          "item": {
            "@id": "https://f1000research.com/articles/7-1555.html",
            "name": "Recent advances in understanding the auditory cortex"
          }
        }          ]
  }
  </script> <div class="breadcrumbs js-breadcrumbs"> <a href="/" class=f1r-standard-link>Home</a> <span class=item_separator></span> <a href="/browse/articles" class=f1r-standard-link>Browse</a> <span class=item_separator></span> Recent advances in understanding the auditory cortex </div> </div> <div class="article-badges-container u-mb--2"> <div class=crossmark-new> <script src="https://crossmark-cdn.crossref.org/widget/v2.0/widget.js"></script> <a data-target=crossmark><img height=30 width=150 src="https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg"/></a> </div> <div id=crossmark-dialog style="display: none;" title=""> <iframe id=crossmark-dialog-frame frameborder=0></iframe> </div> <div class=clearfix></div> </div> <div class=article-interaction-container> <div id=main-article-count-box class=article-count-box> <div class="article-metrics-wrapper metrics-icon-wrapper" data-version-id=16995 data-id=15580 data-downloads="" data-views="" data-scholar="10.12688/f1000research.15580.1" data-recommended="" data-doi="10.12688/f1000research.15580.1" data-f1r-ga-helper="Article Page Metrics (Desktop)"> <span class="metrics-on-browse article-metrics-icon f1r-icon icon-89_metrics"></span> <div class="count-title article-metrics-text">ALL Metrics</div> <div class=js-article-metrics-container></div> </div> <div> <div class=count-delimiter></div> <div title="Total views from F1000Research and PubMed Central"> <div class="count-container view-count js-views-count">-</div> <div class=count-title><span class="count-title-icon count-title-views-icon"></span>Views</div> </div> <div class=download-counts hidden> <div class=count-delimiter></div> <div title="Total downloads from F1000Research and PubMed Central"> <div class="count-container js-downloads-count"></div> <div class=count-title><span class="count-title-icon f1r-icon icon-76_download_file"></span>Downloads</div> </div> </div> </div> </div> <div id=main-article-interaction-box class="article-interaction-box has-control-tab"> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-102_download_pdf"></span> <a href="https://f1000research.com/articles/7-1555/v1/pdf?article_uuid=8a8fb5c8-0d07-4778-9896-5f526a15f5db" title="Download PDF" class="button-link download pdf-download-helper" target=_blank>Get PDF</a> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-103_download_xml"></span> <a id=download-xml href="#" class="button-link download" title="Download XML">Get XML</a> </div> </div> <div class="article-interaction-info article-page"> <div class="cite-article-popup-wrapper article-page-interaction-box"> <div class="article-interaction-button cite-article-button" title="Cite this article" data-windowref=cite-article-popup-15580-1> <span class="f1r-icon icon-82_quote"></span> <a href="#" class="button-link cite-article-popup-link" title="Cite Article">Cite</a> </div> <div id=cite-article-popup-15580-1 class="popup-window-wrapper is-hidden"> <div class=cite-popup-background></div> <div class="popup-window top-popup cite-this-article-box research-layout"> <div class="popup-window-title small cite-title">How to cite this article</div> <span id=cite-article-text-15580-1 data-test-id=copy-citation_text> <span class="article-title-and-info in-popup">King AJ, Teki S and Willmore BDB. Recent advances in understanding the auditory cortex [version 1; peer review: 2 approved]</span>. <i>F1000Research</i> 2018, <b>7</b>(F1000 Faculty Rev):1555 (<a class=new-orange href="https://doi.org/10.12688/f1000research.15580.1" target=_blank>https://doi.org/10.12688/f1000research.15580.1</a>) </span> <div class="popup-window-title small margin-top-20 margin-bottom-20 note"> <strong>NOTE:</strong> it is important to ensure the information in square brackets after the title is included in all citations of this article. </div> <div class=float-right> <button class="secondary no-fill orange-text-and-border margin-right-20 close-cite-popup uppercase">Close</button> <button id=copy-citation-details class="secondary orange copy-cite-article-version uppercase js-clipboard" title="Copy the current citation details to the clipboard." data-clipboard-target="#cite-article-text-15580-1" data-test-id=copy-citation_button>Copy Citation Details</button> </div> </div> </div> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-76_download_file"></span> <a id=export-citation href="#" class="button-link download" title="Export Citation">Export</a> </div> <div class="modal-window-wrapper is-hidden"> <div id=export-citation-popup class="modal-window padding-20"> <div class=modal-window-close-button></div> <div class=modal-window-title>Export Citation</div> <div class=modal-window-row> <div> <input type=radio name=export-citation-option value=WORKSPACE /> <span class=radio-label>Sciwheel</span> </div> <div> <input type=radio name=export-citation-option value=ENDNOTE /> <span class=radio-label>EndNote</span> </div> <div> <input type=radio name=export-citation-option value=REF_MANAGER /> <span class=radio-label>Ref. Manager</span> </div> <div> <input type=radio name=export-citation-option value=BIBTEX /> <span class=radio-label>Bibtex</span> </div> <div> <input type=radio name=export-citation-option value=PROCITE /> <span class=radio-label>ProCite</span> </div> <div> <input type=radio name=export-citation-option value=SENTE /> <span class=radio-label>Sente</span> </div> </div> <div class=modal-window-footer> <button class=general-white-orange-button id=export-citation-submit>EXPORT</button> </div> <div class=default-error style="display: none;">Select a format first</div> </div> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-90_track"></span> <a class="button-link track-article" data-article-id=15580 id=track-article-signin-15580 title="Receive updates on new activity such as publication of new versions, peer reviews or author responses." href="/login?originalPath=/trackArticle/15580?target=/articles/7-1555.html">Track</a> </div> </div> <div class="article-interaction-info article-page"> <div class="article-interaction-button email-article"> <span class="f1r-icon icon-6_email"></span> <a href="#" class=button-link title="Email this article">Email</a> </div> <div class="email-article-version-container small-tooltip _chrome-fix"> <div class=close-icon><span class="f1r-icon icon-3_close_big"></span></div> <script src='https://www.recaptcha.net/recaptcha/api.js'></script> <form class="recommend-version-form research-layout"> <p>All fields are required.</p> <input name=versionId type=hidden value=16995 /> <input name=articleId type=hidden value=15580 /> <input name=senderName class="form-input-field reg-form" value="" type=text placeholder="Your name"/> <input name=senderEmail class="form-input-field reg-form margin-top" value="" type=text placeholder="Your email address"/> <textarea name=recipientEmails class="form-textarea-field ninetynine-percent-wide margin-top no-resize" placeholder="Recipient email address(es) (comma delimited)"></textarea> <input class="form-input-field reg-form margin-top" name=subject type=text value="Interesting article on F1000Research" placeholder=Subject /> <textarea name=message class="form-textarea-field reg-form margin-top no-resize">I thought this article from F1000Research (https://f1000research.com) would be of interest to you.</textarea> <div class="g-recaptcha margin-top" data-sitekey=6LcHqxoUAAAAANP3_0TzpGG6qFvl4DhbUcuRzw7W></div> <input value="" name=captcha type=hidden /> <p>A full article citation will be automatically included.</p> <p><img class="ticker-email-article-details hidden" src="/img/ticker.gif" alt=loading /></p> <button class="secondary orange margin-bottom" data-test-id=version_share_email_send>SEND EMAIL</button> <div class="orange-message margin-bottom is-hidden" data-test-id=version_share_email_message></div> </form> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-34_share"></span> <a href="#" class="button-link last addthis_button share-article" title="Share this article">Share</a> </div> </div> </div> <div id=article-interaction-control-tab class=article-interaction-control-tab> <div id=hide-article-interaction class=article-interaction-control title="Hide Toolbox">&#9644;</div> <div id=show-article-interaction class="article-interaction-control open" title="Show Toolbox">&#10010;</div> </div> </div> <div class="article-header-information article-page"> <div class="f1r-article-mobile article-heading-bar"></div> <div class="article-type article-display">Review </div> <div class="article-title-and-info article-view highlighted-article" id=anchor-title> <h1>Recent advances in understanding the auditory cortex</h1><span class=other-info> [version 1; peer review: 2 approved]</span> </div> <div class=article-subtitle></div> <div class=f1r-article-desk> <div class="authors _mdl-layout"><span class=""><a href="mailto:andrew.king@dpag.ox.ac.uk" title="Send email" class="cauthor research-layout"><span class='f1r-icon icon-6_email orange'></span><span>Andrew J. King</span></a><a href="https://orcid.org/0000-0001-5180-7179" target=_blank id=author-orcid-0><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=author-orcid-0><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0001-5180-7179</div>,&nbsp;</span><span class="">Sundeep Teki<a href="https://orcid.org/0000-0002-7951-6581" target=_blank id=author-orcid-1><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=author-orcid-1><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0002-7951-6581</div>,&nbsp;</span><span class="">Ben D.B. Willmore<a href="https://orcid.org/0000-0002-2969-7572" target=_blank id=author-orcid-2><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=author-orcid-2><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0002-2969-7572</div></span></div> </div> <div class=f1r-article-mobile> <div class="authors _mdl-layout"><span class=""><a href="mailto:andrew.king@dpag.ox.ac.uk" title="Send email" class="cauthor research-layout"><span class='f1r-icon icon-6_email orange'></span><span>Andrew J. King</span></a><a href="http://orcid.org/0000-0001-5180-7179" target=_blank id=mauthor-orcid-0><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=mauthor-orcid-0><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0001-5180-7179</div>,&nbsp;</span><span class="">Sundeep Teki<a href="http://orcid.org/0000-0002-7951-6581" target=_blank id=mauthor-orcid-1><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=mauthor-orcid-1><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0002-7951-6581</div>,&nbsp;</span><span class="">Ben D.B. Willmore<a href="http://orcid.org/0000-0002-2969-7572" target=_blank id=mauthor-orcid-2><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=mauthor-orcid-2><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0002-2969-7572</div></span></div> </div> <div class=f1r-article-mobile> <div class=article-pubinfo-mobile> PUBLISHED 26 Sep 2018 </div> </div> <span class=Z3988 title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;rft_id=info:doi/10.12688%2Ff1000research.15580.1"></span> <div class=f1r-article-desk> <div class="contracted-details first"> <a href="#" class="contracted-details-label author-affiliations"><span class=contracted></span>Author details</a> <a href="#" class=section-title>Author details</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details affiliations is-hidden"> Department of Physiology, Anatomy &amp; Genetics, University of Oxford, Oxford, OX1 3PT, UK<br/> <p> <div class=margin-bottom> Andrew J. King <br/> <span>Roles: </span> Conceptualization, Funding Acquisition, Writing  Original Draft Preparation, Writing  Review & Editing </div> <div class=margin-bottom> Sundeep Teki <br/> <span>Roles: </span> Conceptualization, Funding Acquisition, Writing  Original Draft Preparation </div> <div class=margin-bottom> Ben D.B. Willmore <br/> <span>Roles: </span> Conceptualization, Writing  Original Draft Preparation, Writing  Review & Editing </div> </p> </div> </div> </div> <div class=f1r-article-mobile> <div class="article-page-section-box margin-bottom-40 research-layout"> <span class=box-title> <span class="f1r-icon icon-85_peer_review"></span> OPEN PEER REVIEW </span> <button class="tertiary grey float-right" data-scrollto=article-reports>DETAILS</button> <div class="status-row referee-reports-container"> REVIEWER STATUS <span class=status-icons> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved data-refInfo=23534-38455></span> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved data-refInfo=39296-38454></span> </span> </div> </div> </div> </div> <h2 class="article-headings article-page-abstract" id=anchor-abstract> <span class="f1r-article-mobile-inline abstract-heading-border"></span> Abstract </h2> <div class="article-abstract article-page-general-text-mobile research-layout"> <div class="abstract-text is-expanded"> Our ability to make sense of the auditory world results from neural processing that begins in the ear, goes through multiple subcortical areas, and continues in the cortex. The specific contribution of the auditory cortex to this chain of processing is far from understood. Although many of the properties of neurons in the auditory cortex resemble those of subcortical neurons, they show somewhat more complex selectivity for sound features, which is likely to be important for the analysis of natural sounds, such as speech, in real-life listening conditions. Furthermore, recent work has shown that auditory cortical processing is highly context-dependent, integrates auditory inputs with other sensory and motor signals, depends on experience, and is shaped by cognitive demands, such as attention. Thus, in addition to being the locus for more complex sound selectivity, the auditory cortex is increasingly understood to be an integral part of the network of brain regions responsible for prediction, auditory perceptual decision-making, and learning. In this review, we focus on three key areas that are contributing to this understanding: the sound features that are preferentially represented by cortical neurons, the spatial organization of those preferences, and the cognitive roles of the auditory cortex. </div> <div class=abstract-for-mobile> <div class="margin-top-30 padding-bottom-30 research-layout is-centered"> <button class="primary orange-text white-bg bigger-text abstract-expand-button-mobile with-border show" style="display: none;"> READ ALL <span class="f1r-icon icon-14_more_small orange vmiddle big"></span> </button> <button class="primary orange-text white-bg bigger-text abstract-expand-button-mobile with-border hide"> READ LESS <span class="f1r-icon icon-10_less_small orange vmiddle big"></span> </button> </div> </div> </div> <div class=clearfix></div> <div class="article-context no-divider"> <div class="article-abstract article-page-general-text-mobile research-layout generated-article-body"> <h2 class=main-title>Keywords</h2> <p class="u-mb--0 u-pb--2"> auditory cortex, receptive field, model, map, cognition, plasticity </p> </div> </div> <div class=article-information> <span class="info-separation padding-bottom"> <div id=corresponding-author-icon class="email-icon float-left"> <span class="f1r-icon icon-6_email orange"></span> <div id=corresponding-author-window class="margin-top-20 popup-window-wrapper is-hidden"> <div class="popup-window corresponding-authors-popup"> <div class=corresponding-author-container> <div class="popup-window-title small">Corresponding Author(s)</div> <div class=authors> Andrew J. King (<a href="mailto:andrew.king@dpag.ox.ac.uk">andrew.king@dpag.ox.ac.uk</a>) </div> </div> <div class="margin-top margin-bottom float-left"> <button id=close-popup-window class=general-white-orange-button>Close</button> </div> </div> </div> </div> <span class="icon-text float-left" data-test-id=box-corresponding-author> <b>Corresponding author:</b> Andrew J. King </span> <div class=clearfix></div> </span> <span class="info-separation padding-bottom competing-interests-display"> <span class=competing-interests-title>Competing interests:</span> No competing interests were disclosed. </span> <div class="info-separation padding-bottom grant-information-display"> <span class=grant-information-title>Grant information:</span> Our research is supported by Wellcome grants WT108369/Z/2015/Z (AK and BW) and WT106084/Z/14/Z (ST). <br/> <i>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</i> </div> <span class="f1r-article-desk info-separation padding-bottom"> <span class="copywrite-icon float-left"> <span class="f1r-icon icon-100_open_access"></span> </span> <span class="icon-text float-left" data-test-id=box-copyright-text> <b>Copyright:</b>&nbsp;  2018 King AJ <em>et al</em>. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/" target=_blank data-test-id=box-licence-link>Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. </span> <div class=clearfix></div> </span> <span class="info-separation padding-bottom" data-test-id=box-how-to-cite> <b>How to cite:</b> <span class="article-title-and-info in-article-box"> King AJ, Teki S and Willmore BDB. Recent advances in understanding the auditory cortex [version 1; peer review: 2 approved]</span>. <i>F1000Research</i> 2018, <b>7</b>(F1000 Faculty Rev):1555 (<a href="https://doi.org/10.12688/f1000research.15580.1" target=_blank>https://doi.org/10.12688/f1000research.15580.1</a>) </span> <span class=info-separation data-test-id=box-first-published><b>First published:</b> 26 Sep 2018, <b>7</b>(F1000 Faculty Rev):1555 (<a href="https://doi.org/10.12688/f1000research.15580.1" target=_blank>https://doi.org/10.12688/f1000research.15580.1</a>)</span> <span class=info-separation data-test-id=box-latest-published><b>Latest published:</b> 26 Sep 2018, <b>7</b>(F1000 Faculty Rev):1555 (<a href="https://doi.org/10.12688/f1000research.15580.1" target=_blank>https://doi.org/10.12688/f1000research.15580.1</a>)</span> </div> <div class=clearfix></div> <div id=article-context class=article-context> <div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e170>Introduction</h2><p class="" id=d9874e173>Our seemingly effortless ability to localize, distinguish, and recognize a vast array of natural sounds, including speech and music, results from the neural processing that begins in the inner ear and continues through a complex sequence of subcortical and cortical brain areas. Many aspects of hearingsuch as computation of the cues that enable sound sources to be localized or their pitch to be extractedrely on the processing that takes place in the brainstem and other subcortical structures. It is widely thought to be the case, however, that the auditory cortex plays a critical role in the perception of complex sounds. Although this partly reflects the emergence of response properties, such as sensitivity to combinations of sound features, it is striking how similar many of the properties of neurons in the primary auditory cortex (A1) are to those of subcortical neurons<sup><a href="#ref-1">1</a></sup>. Equally important is the growing realization that auditory cortical processing, in particular, is highly context-dependent and integrates auditory (and other sensory) inputs with information about an individuals current internal state, including their arousal level, focus of attention, and motor planning, as well as their past experience<sup><a href="#ref-2">2</a></sup>. The auditory cortex is therefore an integral part of the network of brain regions responsible for generating meaning from sounds, auditory perceptual decision-making, and learning.</p><p class="" id=d9874e184>In this review, we focus on three key areas of auditory cortical processing where there has been progress in the last few years. First, we consider what sound features A1 neurons represent, highlighting recent attempts to improve receptive field models that can predict the responses of neurons to natural sounds. Second, we examine the distribution of those stimulus preferences within A1 and across the hierarchy of auditory cortical areas, focusing on the extent to which this conforms to canonical principles of columnar organization and functional specialization that are the hallmark of visual and somatosensory processing. Finally, we look at the cognitive role of auditory cortex, highlighting its involvement in prediction, learning, and decision making.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e190>Spectrotemporal receptive fields</h2><p class="" id=d9874e193>The tuning properties of sensory neurons are defined by their receptive fields, which describe the stimulus features to which they are most responsive. Reflecting the spectral analysis that begins in the inner ear, auditory neurons are most commonly characterized by their sensitivity to sound frequency. The spectrotemporal receptive field<sup><a href="#ref-3">3</a>,<a href="#ref-4">4</a></sup> (STRF) is the dominant computational tool for characterizing the responses of auditory neurons. Most widely used as part of a linear-nonlinear (LN) model, an STRF comprises a set of coefficients that describe how the response of the neuron at each moment in time can be modelled as a linear weighted sum of the recent history of the stimulus power in different spectral channels. Owing to their simplicity, STRFs can be reliably estimated by using randomly chosen structured stimuli, such as ripples<sup><a href="#ref-5">5</a><a href="#ref-7">7</a></sup>, and relatively small amounts of data. They can then be used, in combination with a static output nonlinearity, to describe and predict neural responses to arbitrary sounds<sup><a href="#ref-8">8</a></sup>, making them invaluable tools in understanding the computational roles of single neurons and whole neuronal populations. However, STRFs do not accurately capture the full complexity of the behavior of auditory neurons; for example, multiple studies have shown that there are differences between STRFs estimated by using standard synthetic stimuli and those estimated by using natural sounds<sup><a href="#ref-9">9</a><a href="#ref-11">11</a></sup>, suggesting that these models systematically fail to fully describe neural responses to complex stimuli.</p><div class=section><a name=d9874e221 class=n-a></a><h3 class=section-title>Multiple stimulus dimensions</h3><p class="" id=d9874e226>Standard STRF models contain a single receptive fieldone set of spectrotemporal weighting coefficients that describes a single time-varying spectral pattern to which the neuron is sensitive. There is no reason, however, to believe that the spectrotemporal selectivity of auditory neurons is so simple. Artificial neural networks are built on the principle that arbitrarily complex computations can be constructed from simple neuron-like computing elements, and cortical neurons are likely to have similarly complex selectivity based on nonlinear combination of the responses of afferent neurons with simpler selectivity. Capturing this complexity requires STRF models that nonlinearly combine the responses of neurons to multiple stimulus dimensions.</p><p class="" id=d9874e229>With a maximally informative dimensions approach, it has been found that multiple stimulus dimensions are required to describe the responses of neurons in A1<sup><a href="#ref-12">12</a>,<a href="#ref-13">13</a></sup>, whereas a similar approach requires only a single dimension to describe most neurons in the inferior colliculus (IC) in the midbrain<sup><a href="#ref-14">14</a></sup>. This suggests that neuronal complexity is higher in the cortex and that this complexity can be captured by nonlinear combination of the responses of multiple simpler units, a finding that also applies to high-level neurons in songbirds<sup><a href="#ref-15">15</a>,<a href="#ref-16">16</a></sup>. Two recent articles have successfully shown that neural networks are an effective way to model these interactions. Harper <i>et al</i>.<sup><a href="#ref-17">17</a></sup> used a two-layer perceptron to describe the behavior of neurons in ferret auditory cortex, and Kozlov and Gentner<sup><a href="#ref-16">16</a></sup> used a similar network to describe high-level auditory neurons in the starling. To achieve this, both studies used neural networks of intermediate complexity, thus avoiding an explosion in the number of parameters that must be fitted. They also used careful regularizationwhere the model is optimized subject to a penalty on parameter values. Regularization effectively reduces the number of parameters that must be fitted, meaning that models can be fitted accurately using smaller datasets<sup><a href="#ref-18">18</a></sup>. This approach enabled both studies to show that auditory neurons can be better described by a model which takes into account the tuning of multiple afferent neurons (hidden units), suggesting that the selectivity of individual neurons is the result of a combination of information about multiple stimulus dimensions.</p><p class="" id=d9874e266>Other studies using synthetic stimuli also indicate that cortical neurons integrate different sound features, including frequency, spectral bandwidth, level, amplitude modulation over time, and spatial location<sup><a href="#ref-19">19</a>,<a href="#ref-20">20</a></sup>. By using an online optimization procedure (see earlier work by deCharms <i>et al</i>.<sup><a href="#ref-21">21</a></sup>) to dynamically generate sounds that varied along these dimensions, the authors of these studies were able to efficiently search stimulus space and constrain their model within a few minutes of stimulus presentation. They also found that individual neurons multiplex information about multiple stimulus dimensions and that neuronal responses to multidimensional stimuli could not be predicted simply from responses to low-dimensional stimuli.</p><p class="" id=d9874e283>Taken together, these studies suggest that the successor of the STRF will be a model that allows multiple STRF-like elements to be combined in nonlinear ways. The development of such models will require large datasets that include neuronal responses to complex, natural stimuli.</p></div><div class=section><a name=d9874e287 class=n-a></a><h3 class=section-title>Dynamic changes in tuning</h3><p class="" id=d9874e292>Static multidimensional models capture complex selectivity for the recent spectral structure of sounds. However, several studies have highlighted the importance of dynamic changes in the response properties of auditory cortical neurons<sup><a href="#ref-22">22</a><a href="#ref-26">26</a></sup>. Most real-life soundscapes are characterized by constant changes in the statistics of the sounds that reach the ears. Neurons rapidly adapt to stimulus statisticsfor example, stimulus probability, contrast, and correlation structureand adjust their sensitivity in response to behavioral requirements<sup><a href="#ref-27">27</a><a href="#ref-29">29</a></sup>. This can produce representations that are invariant to some changes in sound features and robustly selective for other features<sup><a href="#ref-30">30</a></sup>.</p><p class="" id=d9874e313>Several authors have incorporated such adaptation by adding a nonlinear input stage to the standard LN model<sup><a href="#ref-25">25</a>,<a href="#ref-31">31</a><a href="#ref-33">33</a></sup>. Willmore <i>et al</i>.<sup><a href="#ref-33">33</a></sup> explicitly incorporated the behavior of afferent neurons into a model of A1 spectrotemporal tuning. In both the auditory nerve<sup><a href="#ref-34">34</a></sup> and IC<sup><a href="#ref-35">35</a></sup>, dynamic coding occurs in the form of adaptation to mean sound level. When the mean sound level is high, neurons shift their dynamic ranges upwards, so that neuronal responses are relatively invariant to changes in background level. Because these structures are precursors of the auditory cortex, it makes sense to incorporate IC adaptation into the input stage of a model of auditory cortex and Willmore <i>et al</i>.<sup><a href="#ref-33">33</a></sup> found that this improved the performance of their model of cortical neurons.</p><p class="" id=d9874e349>Neurons in the A1 of the ferret show compensatory adaptation to sound contrast (that is, the variance of the sound level distribution)<sup><a href="#ref-24">24</a>,<a href="#ref-36">36</a></sup>. When the contrast of the input to a given neuron is high, the gain of the neuron is reduced, thereby making it relatively insensitive to changes in sound level. When the contrast of the input is low, the gain of the neuron rises, increasing its sensitivity. This adaptive coding therefore tends to compensate for changes in sound contrast. Adaptation to the mean and variance of sound level is specifically beneficial for the representation of dynamic sounds against a background of constant noise. If the noise is statistically stationary (that is, the mean and variance are fixed), then the effect of adaptation is to minimize the responses of cortical neurons to the background. Thus, the neuronal responses depend mainly on the dynamic foreground sound and are relatively invariant to its contrast. This enables cortical neurons to represent complex sounds using a code that is relatively robust to the presence of background noise. Similar noise robustness has been shown independently in the songbird<sup><a href="#ref-37">37</a></sup> and in decoding studies applied to populations of mammalian cortical neural responses<sup><a href="#ref-30">30</a>,<a href="#ref-38">38</a></sup>.</p></div><div class=section><a name=d9874e371 class=n-a></a><h3 class=section-title>Normative models</h3><p class="" id=d9874e376>To fully understand how sounds are represented by neurons in the auditory cortex, we need to ask why this particular representation has been selected, whether by evolution or by developmental processes. One approach to addressing this question is to build normative computational models. Normative models embody certain constraints that are hypothesized to be important for determining the neural representation. By building normative models and comparing their representations with real physiological representations, it is possible to test hypotheses about which constraints determine the structure of the neural codes used in the brain. For example, Olshausen and Field<sup><a href="#ref-39">39</a></sup> built a neural network and trained it to produce a sparse, generative representation of natural visual scenes. Once trained, the networks units exhibited receptive fields with many similarities to those found in neurons in the primary visual cortex (V1), suggesting that V1 itself may be optimized to produce sparse representations of natural visual scenes.</p><p class="" id=d9874e383>Carlson <i>et al</i>.<sup><a href="#ref-40">40</a></sup> trained a neural network so that it produced a sparse, generative representation of natural auditory stimuli. They found that the model learned STRFs whose spectral structure resembled that of real neurons in the auditory system, suggesting that the auditory system may be optimized for sparse representation. Carlin and Elhilali<sup><a href="#ref-41">41</a></sup> showed that optimizing model neural responses to produce a code based on sustained firing rates also revealed feature preferences similar to those of auditory neurons. Recently, Singer <i>et al</i>.<sup><a href="#ref-42">42</a></sup> observed that the temporal structure of the STRFs in sparse coding models (which generally have envelopes that are symmetrical in time) is very different from those of real neurons in both V1 and A1, where neurons are typically most selective for recent stimulation and have envelopes that decay into the past. These authors trained networks to predict the immediate future of either natural visual or auditory stimuli and found that the networks developed receptive fields that closely matched those of real visual and auditory cortical neurons, including their asymmetric temporal envelopes (<a href="#f1">Figure 1</a>). This suggests that neurons in these areas may be optimized to predict the immediate future of sensory stimulation. Such a representation may be advantageous for acting efficiently in the world using neurons, which introduce inevitable delays in information transmission.</p><a name=f1 class=n-a></a><div class="fig panel clearfix"><a target=_blank href="https://f1000researchdata.s3.amazonaws.com/manuscripts/16995/a41b1d72-156f-4d23-bdec-2ce19a620287_figure1.gif"><img alt="a41b1d72-156f-4d23-bdec-2ce19a620287_figure1.gif" src="https://f1000researchdata.s3.amazonaws.com/manuscripts/16995/a41b1d72-156f-4d23-bdec-2ce19a620287_figure1.gif"></a><div class=caption><h3>Figure 1. Neuronal selectivity in the auditory cortex is optimized to represent sound features in the recent sensory past that best predict immediate future inputs.</h3><p id=d9874e418>A feedforward artificial neural network was trained to predict the immediate future of natural sounds (represented as cochleagrams describing the spectral content over time) from their recent past. This temporal prediction model developed spectrotemporal receptive fields that closely matched those of real auditory cortical neurons. A similar correspondence was found between the receptive fields produced when the model was trained to predict the next few video frames in clips of natural scenes and the receptive field properties of neurons in primary visual cortex. Model nomenclature: <i>s<sub>j</sub></i>, hidden unit output; <i>u<sub>i</sub></i>, inputthe past; <i>v<sub>k</sub></i>, target outputthe true future; <span class=inline-formula><math display=inline id=M1 overflow=scroll><mrow><msub><mrow><mover><mi>v</mi><mo>^</mo></mover></mrow><mrow><mi>k</mi></mrow></msub></mrow></math></span>, outputthe predicted future; <i>w<sub>ji</sub></i>, input weights (analogous to cortical receptive fields); <i>w<sub>kj</sub></i>, output weights. Reprinted from Singer <i>et al</i>.<sup><a href="#ref-42">42</a></sup>.</p></div></div><p class="" id=d9874e472>As discussed above, STRFs do not provide a complete description of the stimulus preferences of auditory neurons. It is therefore important to extend the normative approach into more complex models in order to generate hypotheses about what nonlinear combinations of features we might expect to find in the auditory system. To address this question, Mynarski and McDermott<sup><a href="#ref-43">43</a></sup> trained a hierarchical, generative neural network to represent natural sounds and found that some units in the second layer of the model developed sensitivity to combinations of elementary sound features but that others developed opponency between sound features. By providing insights into how different parameters interact to determine their response properties, these modelling approaches can generate testable hypotheses about the possible roles played by auditory neurons at different levels of the processing hierarchy.</p></div></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e483>Origin of auditory cortical tuning properties</h2><p class="" id=d9874e486>The receptive field properties of auditory cortical neurons are derived from their ascending thalamic inputs and are shaped by recurrent synaptic interactions between excitatory neurons as well as by local inhibitory inputs. The importance of ascending inputs in determining the functional organization of the auditory pathway is illustrated by the presence of tonotopic maps at each processing level, which have their origin in the decomposition of sounds into their individual frequencies along the length of the cochlea in the inner ear. The presence of tonotopic maps in the cortex can be demonstrated by using a variety of methods, including the use of functional brain imaging in humans<sup><a href="#ref-44">44</a></sup>. However, this is a relatively coarse approach and the much finer spatial resolution provided by <i>in vivo</i> two-photon calcium imaging suggests that the spatial organization varies across the layers of A1 and that frequency tuning in the main thalamorecipient layer 4 is more homogenous than in the upper cortical layers<sup><a href="#ref-45">45</a></sup>. Whilst this laminar transformation is consistent with a possible integration of inputs in the superficial layers, which might contribute to the emergence of sensitivity to multiple sound features, it turns out that the thalamic input map to A1 is surprisingly imprecise<sup><a href="#ref-46">46</a></sup>. The significance of this for the generation of cortical response properties remains to be investigated, but heterogeneity in the frequency selectivity of ascending inputs might provide a substrate for the contextual modulation of cortical response properties.</p><p class="" id=d9874e504>In the last few years, progress has been made in determining how the local circuitry of excitatory and inhibitory neurons contributes to auditory cortical response properties<sup><a href="#ref-47">47</a><a href="#ref-50">50</a></sup>. For example, both parvalbumin-expressing and somatostatin-expressing inhibitory interneurons in layers 2/3 have been implicated in regulating the frequency selectivity of A1 neurons<sup><a href="#ref-48">48</a>,<a href="#ref-50">50</a></sup>, while manipulating the activity of parvalbumin-expressing neurons, the most common type of cortical interneuron, has been shown to alter the behavioral performance of mice on tasks that rely on their ability to discriminate different sound frequencies<sup><a href="#ref-49">49</a></sup>. Furthermore, local inhibitory interneurons are involved in mediating the way A1 responses change according to the recent history of stimulation<sup><a href="#ref-51">51</a><a href="#ref-54">54</a></sup>, and it is likely that dynamic interactions between different cell types are responsible for much of the context-dependent modulation that characterizes the way sounds are processed in the auditory cortex. Thus, in addition to being present at subcortical levels, adaptive coding of auditory information can arise <i>de novo</i> from local circuit interactions in the cortex.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e538>Beyond tonotopy</h2><p class="" id=d9874e541>A tonotopic representation is defined by a systematic variation in the frequency selectivity of the neurons from low to high values. A long-standing and controversial question regarding the functional organization of A1 and other brain areas that contain frequency maps is how neuronal sensitivity to other stimulus features is represented across the isofrequency axes. In the visual cortex of carnivores and primates, neuronal preferences for different stimulus featuresorientation, spatial frequency and eye of stimulationare overlaid so that they are all represented at each location within a two-dimensional map of the visual field<sup><a href="#ref-55">55</a></sup>. In a similar vein, functional magnetic resonance imaging (fMRI) studies in humans<sup><a href="#ref-56">56</a></sup> and macaque monkeys<sup><a href="#ref-57">57</a></sup> have revealed that core auditory fields, including A1, contain a gradient in sensitivity to the rate of amplitude modulation, which is arranged orthogonally to the tonotopic map. In other words, a temporal map seems to exist within the cortical representation of each sound frequency.</p><p class="" id=d9874e556>By contrast, analysis of the activity of large samples of neurons within the upper layers of mouse auditory cortex has failed to provide evidence for such topography. Instead, neurons displaying similar frequency tuning bandwidth<sup><a href="#ref-58">58</a></sup>, preferred sound level<sup><a href="#ref-58">58</a></sup>, and sensitivity to changes in sound level<sup><a href="#ref-59">59</a></sup> or to differences in level between the ears<sup><a href="#ref-60">60</a></sup>an important cue to localizing sound sourcesform intermingled clusters across the auditory cortex. Within the isofrequency domain, clearer evidence for segregated processing modules with distinct spectral integration properties or preferences for other sound features has been obtained in monkeys<sup><a href="#ref-61">61</a></sup> and cats<sup><a href="#ref-62">62</a></sup>. It therefore remains possible that the more diffuse spatial arrangement observed in mice may be a general property of sensory cortex in this species<sup><a href="#ref-63">63</a></sup> or more generally of animals with relatively small brains. Although multiple, interleaved processing modules for behaviorally relevant sound features may exist to varying degrees in different species, our understanding of how they map onto the tonotopic organization of A1 or other auditory areas is far from complete.</p><p class="" id=d9874e588>Vertical clustering of neurons with similar tuning properties also represents a potentially important aspect of the functional organization of the cerebral cortex. Compared with other sensory systems, there has been less focus on the columnar organization of auditory cortex. As previously mentioned, there is evidence for layer-specific differences in the frequency representation in auditory cortex<sup><a href="#ref-45">45</a></sup> and this has been shown to extend to other response properties<sup><a href="#ref-64">64</a>,<a href="#ref-65">65</a></sup>. At the same time, ensemble activity within putative cortical columns may play a role in representing auditory information<sup><a href="#ref-66">66</a>,<a href="#ref-67">67</a></sup>.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e612>Representing sound features in multiple cortical areas</h2><p class="" id=d9874e615>As with other sensory modalities, the auditory cortex is subdivided into a number of separate areas, which can be distinguished on the basis of their connections, response properties, and (to some extent) the auditory perceptual deficits that result from localized damage. That these areas are organized hierarchically is clearly illustrated by neuroimaging evidence in humans for the involvement of sequential cortical regions in transforming the spectral features of speech into its semantic content<sup><a href="#ref-68">68</a>,<a href="#ref-69">69</a></sup>. Furthermore, by training a neural network model on speech and music tasks, Kell <i>et al</i>.<sup><a href="#ref-70">70</a></sup> found that the best performing model architecture separated speech and music into separate pathways, in keeping with fMRI responses in human non-A1<sup><a href="#ref-71">71</a></sup>. Neuroimaging evidence in monkeys also suggests that analysis of auditory motion may involve different pathways from those engaged during the processing of static spatial information<sup><a href="#ref-72">72</a></sup>. In both human and non-human primates, the concept of distinct ventral and dorsal processing streams is widely accepted. These were initially assigned to what and where functions, respectively, but their precise functions, and the extent to which they interact, continue to be debated<sup><a href="#ref-73">73</a><a href="#ref-76">76</a></sup>.</p><p class="" id=d9874e648>Evidence for a division of labor among the multiple areas that comprise the auditory cortex extends to other species, as illustrated, for example, by the finding that anatomically segregated regions of mouse auditory cortex can be distinguished by differences in the frequency selectivity of the neurons and in their sensitivity to frequency-modulated sweeps<sup><a href="#ref-77">77</a></sup>. Nevertheless, the question of whether a particular aspect of auditory perception is localized to one or more of those areas is, in some ways, ill posed. Given the extensive subcortical processing that takes place and the growing evidence for multidimensional receptive field properties in early cortical areas<sup><a href="#ref-19">19</a>,<a href="#ref-20">20</a>,<a href="#ref-78">78</a></sup>, it is likely that neurons convey information about multiple sound attributes. Indeed, recent neuroimaging studies have demonstrated widespread areas of activation in response to variations in spatial<sup><a href="#ref-79">79</a></sup> or non-spatial<sup><a href="#ref-80">80</a></sup> parameters, adding to earlier electrophysiological recordings which indicated that sensitivity to pitch, timbre, and location is distributed across several cortical areas<sup><a href="#ref-81">81</a></sup>.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e681>Decoding auditory cortical activity</h2><p class="" id=d9874e684>Even where different sound features are apparently encoded by the same cortical regions, differences in the evoked activity patterns may enable them to be distinguished. For example, auditory cortical neurons can unambiguously represent more than one stimulus parameter by independently modulating their spike rates within distinct time windows<sup><a href="#ref-78">78</a></sup>. Furthermore, a recent fMRI study demonstrated that although variations in pitch or timbretwo key aspects of sound identityactivate largely overlapping cortical areas, they can be distinguished by using multivoxel pattern analysis<sup><a href="#ref-80">80</a></sup>. Studies like these hint at how the brain might solve the problem of perceptual invariancerecognizing, for example, the melody of a familiar tune even when it is played on different musical instruments irrespective of where they are located.</p><p class="" id=d9874e695>This type of approach is part of a growing trend to investigate the decoding or reconstruction of sound features from the measured responses of populations of neurons (or other multidimensional measures of brain activity, such as fMRI voxel responses<sup><a href="#ref-82">82</a></sup> or electroencephalography signals). Indeed, Yildiz <i>et al</i>.<sup><a href="#ref-83">83</a></sup> found that a normative decoding model of auditory cortex described neuronal response dynamics better than some classic encoding models that define the relationship between the stimulus and the neural response. It is therefore possible that the responses of populations of cortical neurons can be more accurately understood in terms of decoding rather than encoding.</p><p class="" id=d9874e709>The application of decoding techniques has provided valuable insights into how neural representations change under different sensory conditions, such as in the presence of background noise<sup><a href="#ref-30">30</a>,<a href="#ref-38">38</a>,<a href="#ref-84">84</a>,<a href="#ref-85">85</a></sup>, or when specific stimuli are selectively attended<sup><a href="#ref-86">86</a><a href="#ref-89">89</a></sup>. They can also help to identify the size of the neural populations within the cortex from which auditory information needs to be read out in order to account for behavior<sup><a href="#ref-90">90</a><a href="#ref-92">92</a></sup> and the way in which stimulus features are represented there. For example, evidence from electrophysiological<sup><a href="#ref-93">93</a>,<a href="#ref-94">94</a></sup>, two-photon calcium imaging<sup><a href="#ref-60">60</a></sup> and fMRI<sup><a href="#ref-95">95</a>,<a href="#ref-96">96</a></sup> studies is all consistent with an opponent-channel model in which the location of sounds in the horizontal plane, at least based on interaural level differences, is decoded from the relative activity of contralaterally and ipsilaterally tuned neurons within each hemisphere. Furthermore, based on the accuracy with which spectrotemporal modulations in a range of natural sounds could be reconstructed from high-resolution fMRI signals, Santoro <i>et al</i>.<sup><a href="#ref-97">97</a></sup> concluded that even early stages of the human auditory cortex may be optimized for processing speech and voices.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e768>Auditory scene analysis</h2><p class="" id=d9874e771>Separating a sound source of interest from a dynamic mixture of potentially competing sounds is a fundamental function of the auditory system. In order to perceptually isolate a sound source as a distinct auditory object<sup><a href="#ref-98">98</a></sup>, its constituent acoustic features like pitch, timbre, intensity, and location need to be individually analyzed and then grouped together to form a coherent perceptual representation. Although neural computations underlying scene analysis have been demonstrated at different subcortical levels<sup><a href="#ref-99">99</a><a href="#ref-101">101</a></sup>, the cortex is the hub where stimulus-driven feature segregation and top-down attentional selection mechanisms converge<sup><a href="#ref-102">102</a></sup>. Indeed, several recent studies suggest a critical role for the auditory cortex in forming stable perceptual representations based on grouping and segregation of spectral, spatial, and temporal regularities in the acoustic environment<sup><a href="#ref-103">103</a><a href="#ref-115">115</a></sup>.</p><p class="" id=d9874e796>Whilst cortical spike-based accounts of auditory segregation of narrowband signals rely on mechanisms of tonotopicity, adaptation, and forward suppression<sup><a href="#ref-116">116</a></sup>, recent work has highlighted the importance of temporal coherence<sup><a href="#ref-113">113</a>,<a href="#ref-117">117</a><a href="#ref-119">119</a></sup> and oscillatory sampling<sup><a href="#ref-120">120</a><a href="#ref-122">122</a></sup> in driving dynamic segregation of attended broadband stimuli. Results from human electro-corticography experiments suggest that low-level auditory cortex encodes spectrotemporal features of selectively attended speech<sup><a href="#ref-86">86</a>,<a href="#ref-87">87</a></sup>. Speech representations derived from high-gamma (75- to 150-Hz) local field potential activity in non-A1 of subjects listening to two speakers talking simultaneously are dominated by the spectrotemporal features of whichever speaker attention is drawn to<sup><a href="#ref-86">86</a></sup>. Moreover, the attention-modulated responses were found to predict the accuracy with which target words were correctly detected in the two-speaker speech mixture, revealing a neural correlate of cocktail party listening<sup><a href="#ref-86">86</a></sup>. Attentional modulation of the representation of multiple speech sources increases along the cortical hierarchy<sup><a href="#ref-114">114</a></sup>, and a similar finding has been reported for the emergence of task-dependent spectrotemporal tuning in neurons in ferret cortex<sup><a href="#ref-123">123</a></sup>.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e847>Prediction</h2><p class="" id=d9874e850>The predictability of sounds plays an important role in processing natural sound sequences like speech and music<sup><a href="#ref-124">124</a></sup>. A prominent generative model of perception is based on the concept of predictive coding; that is, the brain learns to minimize the prediction error between internal predictions of sensory input and the external sensory input<sup><a href="#ref-125">125</a>,<a href="#ref-126">126</a></sup>. This model has been successfully applied to explain the encoding of pitch in a hierarchical fashion in distributed areas of the auditory cortex<sup><a href="#ref-127">127</a></sup>. Furthermore, distinct oscillatory signatures for the key variables of predictive coding models, including surprise, prediction error, prediction change, and prediction precision, have all been demonstrated in the auditory cortex<sup><a href="#ref-128">128</a></sup>. Most of the work in this area at the level of individual neurons has focused on stimulus-specific adaptation, a phenomenon in which particular sounds elicit stronger responses when they are rarely encountered than when they are common<sup><a href="#ref-22">22</a></sup>. Recent work has indicated that A1 neurons exhibit deviance or surprise sensitivity<sup><a href="#ref-129">129</a></sup> and encode prediction error<sup><a href="#ref-124">124</a></sup> and that prediction error signals increase along the auditory pathway<sup><a href="#ref-130">130</a></sup>. Furthermore, the auditory cortex encodes predictions for not only what kind of sensory event is to occur but also when it may occur<sup><a href="#ref-131">131</a></sup>.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e896>Behavioral engagement and auditory decision-making</h2><p class="" id=d9874e899>Further evidence for dynamic processing in the auditory cortex has been obtained from studies demonstrating that engagement in auditory tasks modulates both spontaneous<sup><a href="#ref-132">132</a>,<a href="#ref-133">133</a></sup> and sound-evoked<sup><a href="#ref-92">92</a>,<a href="#ref-133">133</a><a href="#ref-135">135</a></sup> activity, as well as correlations between the activity of different neurons<sup><a href="#ref-92">92</a>,<a href="#ref-136">136</a></sup>, in ways that enhance behavioral performance. Furthermore, changes in task reward structure can alter A1 responses to otherwise identical sounds<sup><a href="#ref-28">28</a></sup>, and other studies suggest that the auditory cortex is part of the network of brain regions involved in maintaining perceptual representations during memory-based tasks<sup><a href="#ref-137">137</a>,<a href="#ref-138">138</a></sup>. Although the source of these modulatory signals is not yet fully understood, accumulating evidence suggests the involvement of top-down inputs from areas such as the parietal and frontal cortices<sup><a href="#ref-88">88</a>,<a href="#ref-139">139</a><a href="#ref-141">141</a></sup> as well as the neuromodulatory systems discussed in the next section. In addition, inputs from motor cortex have been shown to suppress both spontaneous and evoked activity in the auditory cortex during movement<sup><a href="#ref-142">142</a>,<a href="#ref-143">143</a></sup>.</p><p class="" id=d9874e955>The notion of the auditory cortex as a high-level cognitive processor is also supported by investigations into perceptual decision-making. Traditionally, decision making is a function that has been attributed to parietal and frontal cortex in association with subcortical structures like the basal ganglia. However, recent work suggests that the auditory cortex not only encodes physical attributes of task-relevant stimuli but also represents behavioral choice and decision-related signals<sup><a href="#ref-92">92</a>,<a href="#ref-144">144</a><a href="#ref-146">146</a></sup>. Tsunada <i>et al</i>.<sup><a href="#ref-147">147</a></sup> provided direct evidence for a role for auditory cortex in decision making: they found that micro-stimulation of the anterolateral but not the mediolateral belt region of the macaque auditory cortex biased behavioral responses toward the choice associated with the preferred sound frequency of the neurons at the site of stimulation.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e978>The auditory cortex and learning</h2><p class="" id=d9874e981>An ability to learn and remember features in complex acoustic scenes is crucial for adaptive behavior, and plasticity of sound processing in the auditory cortex is an integral part of the circuitry responsible for these essential functions. Robust learning often occurs without conscious awareness and persists for a long time. Agus <i>et al</i>.<sup><a href="#ref-148">148</a></sup> demonstrated that human participants can rapidly learn to detect a particular token of repeated white noise and remember the same pattern for weeks<sup><a href="#ref-149">149</a></sup> in a completely unsupervised fashion. Functional brain imaging experiments have implicated the auditory cortex as well as the hippocampus in encoding memory representations for such complex scenes. The underlying mechanisms of this rapid formation of robust acoustic memories are not clear, but recent psychoacoustical experiments suggest a computation based on encoding summary statistics<sup><a href="#ref-150">150</a></sup>.</p><p class="" id=d9874e999>Recognition of structure in complex sequences based on passive exposure is also imperative for acquiring knowledge of the various rules manifest in speech and language<sup><a href="#ref-151">151</a></sup>. Electrophysiological recordings from songbird forebrain areas that correspond to the mammalian auditory cortex have revealed evidence for statistical learning, expressed as a decrease in the spike rate for familiar versus novel sequences<sup><a href="#ref-152">152</a></sup>. Following passive learning with sequences of nonsense speech sounds that contained an artificial grammar structure, exposure to violations in this sequence activated homologous cortical areas<sup><a href="#ref-153">153</a></sup> and modulated hierarchically nested low-frequency phase and high-gamma amplitude coupling in the auditory cortex in a very similar way in humans and monkeys<sup><a href="#ref-154">154</a></sup>. Interestingly, this form of oscillatory coupling is thought to underlie speech processing in the human auditory cortex<sup><a href="#ref-155">155</a></sup>, suggesting that it may represent an evolutionarily conserved strategy for analyzing sound sequences.</p><p class="" id=d9874e1022>Not all learning, however, occurs without supervision, and reinforcement in the form of reward or punishment is also key for successful learning outcomes. As in other sensory modalities, training can produce improvements in auditory detection and discrimination abilities, including linguistic and musical abilities<sup><a href="#ref-156">156</a></sup>. A number of studies have reported that auditory perceptual learning is associated with changes in the stimulus-encoding response properties of A1 neurons<sup><a href="#ref-157">157</a></sup>. This often entails an expansion in the representation of the stimuli on which subjects are trained, and the extent of the representational plasticity is thought to encode both the behavioral importance of these stimuli and the strength of the associative memory<sup><a href="#ref-158">158</a></sup>. Nevertheless, there have been few attempts to show that A1 plasticity is required for auditory perceptual learning. Indeed, training-induced changes in the functional organization of A1 have been found to disappear over time, even though improvements in behavioral performance are retained<sup><a href="#ref-159">159</a>,<a href="#ref-160">160</a></sup>. However, a recent study in which gerbils were trained on an amplitude-modulation detection task found both a close correlation between the magnitude and time course of cortical and behavioral plasticity and that inactivation of the auditory cortex reduced learning without affecting detection thresholds<sup><a href="#ref-161">161</a></sup>. Cortical inactivation has also been shown to impair training-dependent adaptation to altered spatial cues resulting from plugging of one ear<sup><a href="#ref-162">162</a></sup>. This is consistent with physiological evidence that the encoding of different spatial cues in the auditory cortex is experience-dependent, changing in ways that can explain the recovery of localization accuracy following exposure to abnormal inputs<sup><a href="#ref-94">94</a>,<a href="#ref-163">163</a>,<a href="#ref-164">164</a></sup>.</p><p class="" id=d9874e1063>The alterations in cortical response properties that accompany perceptual learning are likely driven by top-down inputs that determine which stimulus features to attend to<sup><a href="#ref-165">165</a></sup>. Several neuromodulatory systems, including the cholinergic basal forebrain<sup><a href="#ref-166">166</a>,<a href="#ref-167">167</a></sup> and the noradrenergic locus coeruleus<sup><a href="#ref-168">168</a>,<a href="#ref-169">169</a></sup>, play an important role in auditory processing and plasticity and appear to provide reinforcement signals and information about behavioral context to auditory cortex. It has recently been shown that cholinergic inputs primarily target inhibitory interneurons in the auditory cortex<sup><a href="#ref-170">170</a>,<a href="#ref-171">171</a></sup>, which suggests a possible basis by which the balance of cortical excitation and inhibition is transiently altered during learning<sup><a href="#ref-172">172</a></sup>.</p><p class="" id=d9874e1096>Although its involvement in learning is probably one of the most important functions of the auditory cortex, there is growing evidence for a specific role for its outputs to other brain areas. For instance, selective strengthening of auditory corticostriatal synapses has been observed over the course of learning an auditory discrimination task<sup><a href="#ref-173">173</a></sup>, while the integrity of A1 neurons that project to the IC is required for adaptation to hearing loss in one ear<sup><a href="#ref-174">174</a></sup>. Indeed, it is likely that descending corticofugal pathways play a more general role in auditory learning<sup><a href="#ref-175">175</a>,<a href="#ref-176">176</a></sup> as well as other aspects of auditory perception and behavior<sup><a href="#ref-177">177</a><a href="#ref-180">180</a></sup>.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d9874e1124>Conclusions</h2><p class="" id=d9874e1127>The studies outlined in this article show how neurons in the auditory cortex encode sounds in ways that are directly relevant to behavior. Auditory cortical processing depends not only on the sounds themselves but also on the individuals internal state, such as the level of arousal, and the sensory and behavioral context in which sounds are detected. Therefore, to understand how cortical neurons process specific sound features, we have to consider the complexity of the auditory scene and the presence of other sensory cues as well as factors such as motor activity, experience, and attention. Indeed, the auditory cortex seems to play a particularly important role in learning and in constructing memory-dependent perceptual representations of the auditory world.</p><p class="" id=d9874e1130>We are now beginning to understand the computations performed by auditory cortical neurons as well as the role of long-range inputs and local cortical circuits, including the participation of specific cell types, in those computations. Research over the last few years has also provided insights into the way information flows within and between different auditory cortical areas as well as the complex interplay between the auditory cortex and other brain areas. In particular, through its extensive network of descending projections, cortical activity can influence almost every subcortical processing stage in the auditory pathway, but we are only beginning to understand how those pathways contribute to auditory function. Further progress in this field will require the application of coordinated computational and experimental approaches, including the increased use of methods for measuring, manipulating, and decoding activity patterns from populations of neurons.</p></div><div id=article1-back class=generated-article-footer><div class=back-section><a name=d9874e1 class=n-a></a><h2 class=main-title id=d10321>Grant information</h2><p>Our research is supported by Wellcome grants WT108369/Z/2015/Z (AK and BW) and WT106084/Z/14/Z (ST).</p><p> <i>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</i> </p></div><div class=back-section><a name=d9874e1137 class=n-a></a><span class="research-layout prime-recommended-wrapper reference-heading"><span class="f1r-icon icon-79_faculty_recommended_badge red vmiddle default-cursor"></span><span class="prime-red big">F1000 recommended</span></span><h2 class=main-title id=d10993>References</h2><div class="section ref-list"><a name=d9874e1137 class=n-a></a><ul><li><a name=ref-1 class=n-a></a><span class=label>1. </span>&nbsp;<span class=citation><a name=d9874e1144 class=n-a></a>King AJ, Nelken I: Unraveling the principles of auditory cortical processing: Can we learn from the visual system? <i>Nat Neurosci.</i> 2009; <b>12</b>(6): 698701. <a target=xrefwindow id=d9874e1152 href="http://www.ncbi.nlm.nih.gov/pubmed/19471268">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1155 href="http://dx.doi.org/10.1038/nn.2308">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1158 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3657701">Free Full Text </a></span></li><li><a name=ref-2 class=n-a></a><span class=label>2. </span>&nbsp;<span class=citation><a name=d9874e1167 class=n-a></a>Kuchibhotla K, Bathellier B: Neural encoding of sensory and behavioral complexity in the auditory cortex. <i>Curr Opin Neurobiol.</i> 2018; <b>52</b>: 6571. <a target=xrefwindow id=d9874e1175 href="http://www.ncbi.nlm.nih.gov/pubmed/29709885">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1178 href="http://dx.doi.org/10.1016/j.conb.2018.04.002">Publisher Full Text </a></span></li><li><a name=ref-3 class=n-a></a><span class=label>3. </span>&nbsp;<span class=citation><a name=d9874e1187 class=n-a></a>de Boer R, Kuyper P: Triggered correlation. <i>IEEE Trans Biomed Eng.</i> 1968; <b>15</b>(3): 16979. <a target=xrefwindow id=d9874e1195 href="http://www.ncbi.nlm.nih.gov/pubmed/5667803">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1198 href="http://dx.doi.org/10.1109/TBME.1968.4502561">Publisher Full Text </a></span></li><li><a name=ref-4 class=n-a></a><span class=label>4. </span>&nbsp;<span class=citation><a name=d9874e1207 class=n-a></a>Aertsen AM, Johannesma PI: The spectro-temporal receptive field. A functional characteristic of auditory neurons. <i>Biol Cybern.</i> 1981; <b>42</b>(2): 13343. <a target=xrefwindow id=d9874e1215 href="http://www.ncbi.nlm.nih.gov/pubmed/7326288">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1218 href="http://dx.doi.org/10.1007/BF00336731">Publisher Full Text </a></span></li><li><a name=ref-5 class=n-a></a><span class=label>5. </span>&nbsp;<span class=citation><a name=d9874e1227 class=n-a></a>Schreiner CE, Calhoun BM: Spectral envelope coding in cat primary auditory cortex: Properties of ripple transfer functions. <i>Aud Neurosci.</i> 1994; <b>1</b>: 3961. <a target=xrefwindow id=d9874e1235 href="https://www.mechanicsofhearing.org/mohdl/pdfs/AN/Schreiner-Calhoun-AudNeurosci-1994.pdf">Reference Source</a></span></li><li><a name=ref-6 class=n-a></a><span class=label>6. </span>&nbsp;<span class=citation><a name=d9874e1245 class=n-a></a>Shamma SA, Versnel H, Kowalski N: Ripple analysis in the ferret primary auditory cortex. I. Response characteristics of single units to sinusoidally rippled spectra. <i>Aud Neurosci.</i> 1995; <b>1</b>: 233254. <a target=xrefwindow id=d9874e1253 href="https://www.mechanicsofhearing.org/mohdl/pdfs/AN/Shamma-etal-AudNeurosci-1995.pdf">Reference Source</a></span></li><li><a name=ref-7 class=n-a></a><span class=label>7. </span>&nbsp;<span class=citation><a name=d9874e1262 class=n-a></a>Shamma SA: Auditory cortical representation of complex acoustic spectra as inferred from the ripple analysis method. <i>Netw Comput Neural Syst.</i> 2009; <b>7</b>(3): 43976. <a target=xrefwindow id=d9874e1270 href="http://dx.doi.org/10.1088/0954-898X_7_3_001">Publisher Full Text </a></span></li><li><a name=ref-8 class=n-a></a><span class=label>8. </span>&nbsp;<span class=citation><a name=d9874e1279 class=n-a></a>Shamma SA, Versnel H: Ripple analysis in the ferret primary auditory cortex. II. Prediction of unit responses to arbitrary spectral profiles. <i>Aud Neurosci.</i> 1995; <b>1</b>: 255270. <a target=xrefwindow id=d9874e1287 href="https://www.mechanicsofhearing.org/mohdl/pdfs/AN/Shamma-Versnel-AudNeurosci-1995.pdf">Reference Source</a></span></li><li><a name=ref-9 class=n-a></a><span class=label>9. </span>&nbsp;<span class=citation><a name=d9874e1296 class=n-a></a>Theunissen FE, Sen K, Doupe AJ: Spectral-temporal receptive fields of nonlinear auditory neurons obtained using natural sounds. <i>J Neurosci.</i> 2000; <b>20</b>(6): 231531. <a target=xrefwindow id=d9874e1304 href="http://www.ncbi.nlm.nih.gov/pubmed/10704507">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1307 href="http://dx.doi.org/10.1523/JNEUROSCI.20-06-02315.2000">Publisher Full Text </a></span></li><li><a name=ref-10 class=n-a></a><span class=label>10. </span>&nbsp;<span class=citation><a name=d9874e1316 class=n-a></a>Woolley SM, Fremouw TE, Hsu A, <i> et al.</i>: Tuning for spectro-temporal modulations as a mechanism for auditory discrimination of natural sounds. <i>Nat Neurosci.</i> 2005; <b>8</b>(10): 13719. <a target=xrefwindow id=d9874e1327 href="http://www.ncbi.nlm.nih.gov/pubmed/16136039">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1330 href="http://dx.doi.org/10.1038/nn1536">Publisher Full Text </a></span></li><li><a name=ref-11 class=n-a></a><span class=label>11. </span>&nbsp;<span class=citation><a name=d9874e1339 class=n-a></a>Nagel KI, Doupe AJ: Organizing principles of spectro-temporal encoding in the avian primary auditory area field L. <i>Neuron.</i> 2008; <b>58</b>(6): 93855. <a target=xrefwindow id=d9874e1347 href="http://www.ncbi.nlm.nih.gov/pubmed/18579083">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1350 href="http://dx.doi.org/10.1016/j.neuron.2008.04.028">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1353 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2547416">Free Full Text </a></span></li><li><a name=ref-12 class=n-a></a><span class=label>12. </span>&nbsp;<span class=citation><a name=d9874e1363 class=n-a></a>Sharpee T, Rust NC, Bialek W: Analyzing neural responses to natural signals: maximally informative dimensions. <i>Neural Comput.</i> 2004; <b>16</b>(2): 22350. <a target=xrefwindow id=d9874e1371 href="http://www.ncbi.nlm.nih.gov/pubmed/15006095">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1374 href="http://dx.doi.org/10.1162/089976604322742010">Publisher Full Text </a></span></li><li><a name=ref-13 class=n-a></a><span class=label>13. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727798564"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e1383 class=n-a></a>Atencio CA, Sharpee TO: Multidimensional receptive field processing by cat primary auditory cortical neurons. <i>Neuroscience.</i> 2017; <b>359</b>: 13041. <a target=xrefwindow id=d9874e1391 href="http://www.ncbi.nlm.nih.gov/pubmed/28694174">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1394 href="http://dx.doi.org/10.1016/j.neuroscience.2017.07.003">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1397 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5600511">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727798564">F1000 Recommendation</a></span></li><li><a name=ref-14 class=n-a></a><span class=label>14. </span>&nbsp;<span class=citation><a name=d9874e1410 class=n-a></a>Atencio CA, Sharpee TO, Schreiner CE: Receptive field dimensionality increases from the auditory midbrain to cortex. <i>J Neurophysiol.</i> 2012; <b>107</b>(10): 2594603. <a target=xrefwindow id=d9874e1418 href="http://www.ncbi.nlm.nih.gov/pubmed/22323634">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1421 href="http://dx.doi.org/10.1152/jn.01025.2011">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1424 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3362274">Free Full Text </a></span></li><li><a name=ref-15 class=n-a></a><span class=label>15. </span>&nbsp;<span class=citation><a name=d9874e1433 class=n-a></a>Kozlov AS, Gentner TQ: Central auditory neurons display flexible feature recombination functions. <i>J Neurophysiol.</i> 2014; <b>111</b>(6): 11839. <a target=xrefwindow id=d9874e1441 href="http://www.ncbi.nlm.nih.gov/pubmed/24353301">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1444 href="http://dx.doi.org/10.1152/jn.00637.2013">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1447 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3949310">Free Full Text </a></span></li><li><a name=ref-16 class=n-a></a><span class=label>16. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/726086971"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e1456 class=n-a></a>Kozlov AS, Gentner TQ: Central auditory neurons have composite receptive fields. <i>Proc Natl Acad Sci U S A.</i> 2016; <b>113</b>(5): 14416. <a target=xrefwindow id=d9874e1464 href="http://www.ncbi.nlm.nih.gov/pubmed/26787894">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1467 href="http://dx.doi.org/10.1073/pnas.1506903113">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1470 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4747712">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/726086971">F1000 Recommendation</a></span></li><li><a name=ref-17 class=n-a></a><span class=label>17. </span>&nbsp;<span class=citation><a name=d9874e1483 class=n-a></a>Harper NS, Schoppe O, Willmore BD, <i> et al.</i>: Network Receptive Field Modeling Reveals Extensive Integration and Multi-feature Selectivity in Auditory Cortical Neurons. <i>PLoS Comput Biol.</i> 2016; <b>12</b>(11): e1005113. <a target=xrefwindow id=d9874e1494 href="http://www.ncbi.nlm.nih.gov/pubmed/27835647">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1497 href="http://dx.doi.org/10.1371/journal.pcbi.1005113">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1501 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5105998">Free Full Text </a></span></li><li><a name=ref-18 class=n-a></a><span class=label>18. </span>&nbsp;<span class=citation><a name=d9874e1511 class=n-a></a>David SV, Mesgarani N, Shamma SA: Estimating sparse spectro-temporal receptive fields with natural stimuli. <i>Network.</i> 2007; <b>18</b>(3): 191212. <a target=xrefwindow id=d9874e1519 href="http://www.ncbi.nlm.nih.gov/pubmed/17852750">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1522 href="http://dx.doi.org/10.1080/09548980701609235">Publisher Full Text </a></span></li><li><a name=ref-19 class=n-a></a><span class=label>19. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/718478351"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e1531 class=n-a></a>Chambers AR, Hancock KE, Sen K, <i> et al.</i>: Online stimulus optimization rapidly reveals multidimensional selectivity in auditory cortical neurons. <i>J Neurosci.</i> 2014; <b>34</b>(27): 896375. <a target=xrefwindow id=d9874e1542 href="http://www.ncbi.nlm.nih.gov/pubmed/24990917">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1545 href="http://dx.doi.org/10.1523/JNEUROSCI.0260-14.2014">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1549 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4078078">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/718478351">F1000 Recommendation</a></span></li><li><a name=ref-20 class=n-a></a><span class=label>20. </span>&nbsp;<span class=citation><a name=d9874e1562 class=n-a></a>Sloas DC, Zhuo R, Xue H, <i> et al.</i>: Interactions across Multiple Stimulus Dimensions in Primary Auditory Cortex. <i>eNeuro.</i> 2016; <b>3</b>(4): pii: ENEURO.0124-16.2016. <a target=xrefwindow id=d9874e1573 href="http://www.ncbi.nlm.nih.gov/pubmed/27622211">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1576 href="http://dx.doi.org/10.1523/ENEURO.0124-16.2016">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1580 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5008244">Free Full Text </a></span></li><li><a name=ref-21 class=n-a></a><span class=label>21. </span>&nbsp;<span class=citation><a name=d9874e1589 class=n-a></a>deCharms RC, Blake DT, Merzenich MM: Optimizing sound features for cortical neurons. <i>Science.</i> 1998; <b>280</b>(5368): 143943. <a target=xrefwindow id=d9874e1597 href="http://www.ncbi.nlm.nih.gov/pubmed/9603734">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1600 href="http://dx.doi.org/10.1126/science.280.5368.1439">Publisher Full Text </a></span></li><li><a name=ref-22 class=n-a></a><span class=label>22. </span>&nbsp;<span class=citation><a name=d9874e1609 class=n-a></a>Ulanovsky N, Las L, Nelken I: Processing of low-probability sounds by cortical neurons. <i>Nat Neurosci.</i> 2003; <b>6</b>(4): 3918. <a target=xrefwindow id=d9874e1617 href="http://www.ncbi.nlm.nih.gov/pubmed/12652303">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1620 href="http://dx.doi.org/10.1038/nn1032">Publisher Full Text </a></span></li><li><a name=ref-23 class=n-a></a><span class=label>23. </span>&nbsp;<span class=citation><a name=d9874e1629 class=n-a></a>Schneider DM, Woolley SM: Extra-classical tuning predicts stimulus-dependent receptive fields in auditory neurons. <i>J Neurosci.</i> 2011; <b>31</b>(33): 1186778. <a target=xrefwindow id=d9874e1637 href="http://www.ncbi.nlm.nih.gov/pubmed/21849547">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1640 href="http://dx.doi.org/10.1523/JNEUROSCI.5790-10.2011">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1643 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3164972">Free Full Text </a></span></li><li><a name=ref-24 class=n-a></a><span class=label>24. </span>&nbsp;<span class=citation><a name=d9874e1653 class=n-a></a>Rabinowitz NC, Willmore BD, Schnupp JW, <i> et al.</i>: Contrast gain control in auditory cortex. <i>Neuron.</i> 2011; <b>70</b>(6): 117891. <a target=xrefwindow id=d9874e1664 href="http://www.ncbi.nlm.nih.gov/pubmed/21689603">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1667 href="http://dx.doi.org/10.1016/j.neuron.2011.04.030">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1671 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3133688">Free Full Text </a></span></li><li><a name=ref-25 class=n-a></a><span class=label>25. </span>&nbsp;<span class=citation><a name=d9874e1680 class=n-a></a>David SV, Shamma SA: Integration over multiple timescales in primary auditory cortex. <i>J Neurosci.</i> 2013; <b>33</b>(49): 1915466. <a target=xrefwindow id=d9874e1688 href="http://www.ncbi.nlm.nih.gov/pubmed/24305812">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1691 href="http://dx.doi.org/10.1523/JNEUROSCI.2270-13.2013">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1694 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3850039">Free Full Text </a></span></li><li><a name=ref-26 class=n-a></a><span class=label>26. </span>&nbsp;<span class=citation><a name=d9874e1703 class=n-a></a>Williamson RS, Ahrens MB, Linden JF, <i> et al.</i>: Input-Specific Gain Modulation by Local Sensory Context Shapes Cortical and Thalamic Responses to Complex Sounds. <i>Neuron.</i> 2016; <b>91</b>(2): 46781. <a target=xrefwindow id=d9874e1714 href="http://www.ncbi.nlm.nih.gov/pubmed/27346532">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1717 href="http://dx.doi.org/10.1016/j.neuron.2016.05.041">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1721 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4961224">Free Full Text </a></span></li><li><a name=ref-27 class=n-a></a><span class=label>27. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/1016670"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e1730 class=n-a></a>Fritz J, Shamma S, Elhilali M, <i> et al.</i>: Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex. <i>Nat Neurosci.</i> 2003; <b>6</b>(11): 121623. <a target=xrefwindow id=d9874e1741 href="http://www.ncbi.nlm.nih.gov/pubmed/14583754">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1744 href="http://dx.doi.org/10.1038/nn1141">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/1016670">F1000 Recommendation</a></span></li><li><a name=ref-28 class=n-a></a><span class=label>28. </span>&nbsp;<span class=citation><a name=d9874e1757 class=n-a></a>David SV, Fritz JB, Shamma SA: Task reward structure shapes rapid receptive field plasticity in auditory cortex. <i>Proc Natl Acad Sci U S A.</i> 2012; <b>109</b>(6): 21449. <a target=xrefwindow id=d9874e1765 href="http://www.ncbi.nlm.nih.gov/pubmed/22308415">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1768 href="http://dx.doi.org/10.1073/pnas.1117717109">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1771 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3277538">Free Full Text </a></span></li><li><a name=ref-29 class=n-a></a><span class=label>29. </span>&nbsp;<span class=citation><a name=d9874e1780 class=n-a></a>David SV: Incorporating behavioral and sensory context into spectro-temporal models of auditory encoding. <i>Hear Res.</i> 2018; <b>360</b>: 10723. <a target=xrefwindow id=d9874e1788 href="http://www.ncbi.nlm.nih.gov/pubmed/29331232">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1791 href="http://dx.doi.org/10.1016/j.heares.2017.12.021">Publisher Full Text </a></span></li><li><a name=ref-30 class=n-a></a><span class=label>30. </span>&nbsp;<span class=citation><a name=d9874e1801 class=n-a></a>Rabinowitz NC, Willmore BD, King AJ, <i> et al.</i>: Constructing noise-invariant representations of sound in the auditory pathway. <i>PLoS Biol.</i> 2013; <b>11</b>(11): e1001710. <a target=xrefwindow id=d9874e1812 href="http://www.ncbi.nlm.nih.gov/pubmed/24265596">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1815 href="http://dx.doi.org/10.1371/journal.pbio.1001710">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1819 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3825667">Free Full Text </a></span></li><li><a name=ref-31 class=n-a></a><span class=label>31. </span>&nbsp;<span class=citation><a name=d9874e1828 class=n-a></a>Ahrens MB, Linden JF, Sahani M: Nonlinearities and contextual influences in auditory cortical responses modeled with multilinear spectrotemporal methods. <i>J Neurosci.</i> 2008; <b>28</b>(8): 192942. <a target=xrefwindow id=d9874e1836 href="http://www.ncbi.nlm.nih.gov/pubmed/18287509">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1839 href="http://dx.doi.org/10.1523/JNEUROSCI.3377-07.2008">Publisher Full Text </a></span></li><li><a name=ref-32 class=n-a></a><span class=label>32. </span>&nbsp;<span class=citation><a name=d9874e1848 class=n-a></a>David SV, Mesgarani N, Fritz JB, <i> et al.</i>: Rapid synaptic depression explains nonlinear modulation of spectro-temporal tuning in primary auditory cortex by natural stimuli. <i>J Neurosci.</i> 2009; <b>29</b>(11): 337486. <a target=xrefwindow id=d9874e1859 href="http://www.ncbi.nlm.nih.gov/pubmed/19295144">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1862 href="http://dx.doi.org/10.1523/JNEUROSCI.5249-08.2009">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1866 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2774136">Free Full Text </a></span></li><li><a name=ref-33 class=n-a></a><span class=label>33. </span>&nbsp;<span class=citation><a name=d9874e1875 class=n-a></a>Willmore BD, Schoppe O, King AJ, <i> et al.</i>: Incorporating Midbrain Adaptation to Mean Sound Level Improves Models of Auditory Cortical Processing. <i>J Neurosci.</i> 2016; <b>36</b>(2): 2809. <a target=xrefwindow id=d9874e1886 href="http://www.ncbi.nlm.nih.gov/pubmed/26758822">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1889 href="http://dx.doi.org/10.1523/JNEUROSCI.2441-15.2016">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1893 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4710761">Free Full Text </a></span></li><li><a name=ref-34 class=n-a></a><span class=label>34. </span>&nbsp;<span class=citation><a name=d9874e1902 class=n-a></a>Wen B, Wang GI, Dean I, <i> et al.</i>: Dynamic range adaptation to sound level statistics in the auditory nerve. <i>J Neurosci.</i> 2009; <b>29</b>(44): 13797808. <a target=xrefwindow id=d9874e1913 href="http://www.ncbi.nlm.nih.gov/pubmed/19889991">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1916 href="http://dx.doi.org/10.1523/JNEUROSCI.5610-08.2009">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1920 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2774902">Free Full Text </a></span></li><li><a name=ref-35 class=n-a></a><span class=label>35. </span>&nbsp;<span class=citation><a name=d9874e1929 class=n-a></a>Dean I, Harper NS, McAlpine D: Neural population coding of sound level adapts to stimulus statistics. <i>Nat Neurosci.</i> 2005; <b>8</b>(12): 16849. <a target=xrefwindow id=d9874e1937 href="http://www.ncbi.nlm.nih.gov/pubmed/16286934">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1940 href="http://dx.doi.org/10.1038/nn1541">Publisher Full Text </a></span></li><li><a name=ref-36 class=n-a></a><span class=label>36. </span>&nbsp;<span class=citation><a name=d9874e1950 class=n-a></a>Rabinowitz NC, Willmore BD, Schnupp JW, <i> et al.</i>: Spectrotemporal contrast kernels for neurons in primary auditory cortex. <i>J Neurosci.</i> 2012; <b>32</b>(33): 1127184. <a target=xrefwindow id=d9874e1961 href="http://www.ncbi.nlm.nih.gov/pubmed/22895711">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1964 href="http://dx.doi.org/10.1523/JNEUROSCI.1715-12.2012">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1968 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3542625">Free Full Text </a></span></li><li><a name=ref-37 class=n-a></a><span class=label>37. </span>&nbsp;<span class=citation><a name=d9874e1977 class=n-a></a>Moore RC, Lee T, Theunissen FE: Noise-invariant neurons in the avian auditory cortex: Hearing the song in noise. <i>PLoS Comput Biol.</i> 2013; <b>9</b>(3): e1002942. <a target=xrefwindow id=d9874e1985 href="http://www.ncbi.nlm.nih.gov/pubmed/23505354">PubMed Abstract </a> | <a target=xrefwindow id=d9874e1988 href="http://dx.doi.org/10.1371/journal.pcbi.1002942">Publisher Full Text </a> | <a target=xrefwindow id=d9874e1991 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3591274">Free Full Text </a></span></li><li><a name=ref-38 class=n-a></a><span class=label>38. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/718357968"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2000 class=n-a></a>Mesgarani N, David SV, Fritz JB, <i> et al.</i>: Mechanisms of noise robust representation of speech in primary auditory cortex. <i>Proc Natl Acad Sci U S A.</i> 2014; <b>111</b>(18): 67927. <a target=xrefwindow id=d9874e2011 href="http://www.ncbi.nlm.nih.gov/pubmed/24753585">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2014 href="http://dx.doi.org/10.1073/pnas.1318017111">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2018 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4020083">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/718357968">F1000 Recommendation</a></span></li><li><a name=ref-39 class=n-a></a><span class=label>39. </span>&nbsp;<span class=citation><a name=d9874e2031 class=n-a></a>Olshausen BA, Field DJ: Emergence of simple-cell receptive field properties by learning a sparse code for natural images. <i>Nature.</i> 1996; <b>381</b>(6583): 6079. <a target=xrefwindow id=d9874e2039 href="http://www.ncbi.nlm.nih.gov/pubmed/8637596">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2042 href="http://dx.doi.org/10.1038/381607a0">Publisher Full Text </a></span></li><li><a name=ref-40 class=n-a></a><span class=label>40. </span>&nbsp;<span class=citation><a name=d9874e2051 class=n-a></a>Carlson NL, Ming VL, DeWeese MR: Sparse codes for speech predict spectrotemporal receptive fields in the inferior colliculus. <i>PLoS Comput Biol.</i> 2012; <b>8</b>(7): e1002594. <a target=xrefwindow id=d9874e2059 href="http://www.ncbi.nlm.nih.gov/pubmed/22807665">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2062 href="http://dx.doi.org/10.1371/journal.pcbi.1002594">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2065 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3395612">Free Full Text </a></span></li><li><a name=ref-41 class=n-a></a><span class=label>41. </span>&nbsp;<span class=citation><a name=d9874e2074 class=n-a></a>Carlin MA, Elhilali M: Sustained firing of model central auditory neurons yields a discriminative spectro-temporal representation for natural sounds. <i>PLoS Comput Biol.</i> 2013; <b>9</b>(3): e1002982. <a target=xrefwindow id=d9874e2082 href="http://www.ncbi.nlm.nih.gov/pubmed/23555217">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2085 href="http://dx.doi.org/10.1371/journal.pcbi.1002982">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2088 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3610626">Free Full Text </a></span></li><li><a name=ref-42 class=n-a></a><span class=label>42. </span>&nbsp;<span class=citation><a name=d9874e2098 class=n-a></a>Singer Y, Teramoto Y, Willmore BD, <i> et al.</i>: Sensory cortex is optimized for prediction of future input. <i>eLife.</i> 2018; <b>7</b>: pii: e31557. <a target=xrefwindow id=d9874e2109 href="http://www.ncbi.nlm.nih.gov/pubmed/29911971">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2112 href="http://dx.doi.org/10.7554/eLife.31557">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2116 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6108826">Free Full Text </a></span></li><li><a name=ref-43 class=n-a></a><span class=label>43. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/732249609"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2125 class=n-a></a>Mynarski W, McDermott JH: Learning Midlevel Auditory Codes from Natural Sound Statistics. <i>Neural Comput.</i> 2018; <b>30</b>(3): 63169. <a target=xrefwindow id=d9874e2133 href="http://www.ncbi.nlm.nih.gov/pubmed/29220308">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2136 href="http://dx.doi.org/10.1162/neco_a_01048">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/732249609">F1000 Recommendation</a></span></li><li><a name=ref-44 class=n-a></a><span class=label>44. </span>&nbsp;<span class=citation><a name=d9874e2149 class=n-a></a>Saenz M, Langers DR: Tonotopic mapping of human auditory cortex. <i>Hear Res.</i> 2014; <b>307</b>: 4252. <a target=xrefwindow id=d9874e2157 href="http://www.ncbi.nlm.nih.gov/pubmed/23916753">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2160 href="http://dx.doi.org/10.1016/j.heares.2013.07.016">Publisher Full Text </a></span></li><li><a name=ref-45 class=n-a></a><span class=label>45. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/717973204"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2169 class=n-a></a>Winkowski DE, Kanold PO: Laminar transformation of frequency organization in auditory cortex. <i>J Neurosci.</i> 2013; <b>33</b>(4): 1498508. <a target=xrefwindow id=d9874e2177 href="http://www.ncbi.nlm.nih.gov/pubmed/23345224">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2180 href="http://dx.doi.org/10.1523/JNEUROSCI.3101-12.2013">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2183 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3783029">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/717973204">F1000 Recommendation</a></span></li><li><a name=ref-46 class=n-a></a><span class=label>46. </span>&nbsp;<span class=citation><a name=d9874e2196 class=n-a></a>Vasquez-Lopez SA, Weissenberger Y, Lohse M, <i> et al.</i>: Thalamic input to auditory cortex is locally heterogeneous but globally tonotopic. <i>eLife.</i> 2017; <b>6</b>: pii: e25141. <a target=xrefwindow id=d9874e2207 href="http://www.ncbi.nlm.nih.gov/pubmed/28891466">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2210 href="http://dx.doi.org/10.7554/eLife.25141">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2214 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5614559">Free Full Text </a></span></li><li><a name=ref-47 class=n-a></a><span class=label>47. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/9037956"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2223 class=n-a></a>Oviedo HV, Bureau I, Svoboda K, <i> et al.</i>: The functional asymmetry of auditory cortex is reflected in the organization of local cortical circuits. <i>Nat Neurosci.</i> 2010; <b>13</b>(11): 141320. <a target=xrefwindow id=d9874e2234 href="http://www.ncbi.nlm.nih.gov/pubmed/20953193">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2237 href="http://dx.doi.org/10.1038/nn.2659">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2241 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3140463">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/9037956">F1000 Recommendation</a></span></li><li><a name=ref-48 class=n-a></a><span class=label>48. </span>&nbsp;<span class=citation><a name=d9874e2255 class=n-a></a>Li LY, Ji XY, Liang F, <i> et al.</i>: A feedforward inhibitory circuit mediates lateral refinement of sensory representation in upper layer 2/3 of mouse primary auditory cortex. <i>J Neurosci.</i> 2014; <b>34</b>(41): 1367083. <a target=xrefwindow id=d9874e2266 href="http://www.ncbi.nlm.nih.gov/pubmed/25297094">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2269 href="http://dx.doi.org/10.1523/JNEUROSCI.1516-14.2014">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2273 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4188965">Free Full Text </a></span></li><li><a name=ref-49 class=n-a></a><span class=label>49. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/725979854"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2282 class=n-a></a>Aizenberg M, Mwilambwe-Tshilobo L, Briguglio JJ, <i> et al.</i>: Bidirectional Regulation of Innate and Learned Behaviors That Rely on Frequency Discrimination by Cortical Inhibitory Neurons. <i>PLoS Biol.</i> 2015; <b>13</b>(12): e1002308. <a target=xrefwindow id=d9874e2293 href="http://www.ncbi.nlm.nih.gov/pubmed/26629746">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2296 href="http://dx.doi.org/10.1371/journal.pbio.1002308">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2300 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4668086">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/725979854">F1000 Recommendation</a></span></li><li><a name=ref-50 class=n-a></a><span class=label>50. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727795772"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2313 class=n-a></a>Kato HK, Asinof SK, Isaacson JS: Network-Level Control of Frequency Tuning in Auditory Cortex. <i>Neuron.</i> 2017; <b>95</b>(2): 412423.e4. <a target=xrefwindow id=d9874e2321 href="http://www.ncbi.nlm.nih.gov/pubmed/28689982">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2324 href="http://dx.doi.org/10.1016/j.neuron.2017.06.019">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2327 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5705232">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727795772">F1000 Recommendation</a></span></li><li><a name=ref-51 class=n-a></a><span class=label>51. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/725780377"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2340 class=n-a></a>Chen IW, Helmchen F, Ltcke H: Specific Early and Late Oddball-Evoked Responses in Excitatory and Inhibitory Neurons of Mouse Auditory Cortex. <i>J Neurosci.</i> 2015; <b>35</b>(36): 1256073. <a target=xrefwindow id=d9874e2348 href="http://www.ncbi.nlm.nih.gov/pubmed/26354921">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2351 href="http://dx.doi.org/10.1523/JNEUROSCI.2240-15.2015">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/725780377">F1000 Recommendation</a></span></li><li><a name=ref-52 class=n-a></a><span class=label>52. </span>&nbsp;<span class=citation><a name=d9874e2364 class=n-a></a>Natan RG, Briguglio JJ, Mwilambwe-Tshilobo L, <i> et al.</i>: Complementary control of sensory adaptation by two types of cortical interneurons. <i>eLife.</i> 2015; <b>4</b>: pii: e09868. <a target=xrefwindow id=d9874e2375 href="http://www.ncbi.nlm.nih.gov/pubmed/26460542">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2378 href="http://dx.doi.org/10.7554/eLife.09868">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2382 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4641469">Free Full Text </a></span></li><li><a name=ref-53 class=n-a></a><span class=label>53. </span>&nbsp;<span class=citation><a name=d9874e2391 class=n-a></a>Natan RG, Rao W, Geffen MN: Cortical Interneurons Differentially Shape Frequency Tuning following Adaptation. <i>Cell Rep.</i> 2017; <b>21</b>(4): 87890. <a target=xrefwindow id=d9874e2399 href="http://www.ncbi.nlm.nih.gov/pubmed/29069595">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2402 href="http://dx.doi.org/10.1016/j.celrep.2017.10.012">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2405 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5830304">Free Full Text </a></span></li><li><a name=ref-54 class=n-a></a><span class=label>54. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727841010"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2415 class=n-a></a>Phillips EAK, Schreiner CE, Hasenstaub AR: Cortical Interneurons Differentially Regulate the Effects of Acoustic Context. <i>Cell Rep.</i> 2017; <b>20</b>(4): 7718. <a target=xrefwindow id=d9874e2423 href="http://www.ncbi.nlm.nih.gov/pubmed/28746863">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2426 href="http://dx.doi.org/10.1016/j.celrep.2017.07.001">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2429 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5714710">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727841010">F1000 Recommendation</a></span></li><li><a name=ref-55 class=n-a></a><span class=label>55. </span>&nbsp;<span class=citation><a name=d9874e2442 class=n-a></a>Hbener M, Shoham D, Grinvald A, <i> et al.</i>: Spatial relationships among three columnar systems in cat area 17. <i>J Neurosci.</i> 1997; <b>17</b>(23): 927084. <a target=xrefwindow id=d9874e2453 href="http://www.ncbi.nlm.nih.gov/pubmed/9364073">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2456 href="http://dx.doi.org/10.1523/JNEUROSCI.17-23-09270.1997">Publisher Full Text </a></span></li><li><a name=ref-56 class=n-a></a><span class=label>56. </span>&nbsp;<span class=citation><a name=d9874e2465 class=n-a></a>Barton B, Venezia JH, Saberi K, <i> et al.</i>: Orthogonal acoustic dimensions define auditory field maps in human cortex. <i>Proc Natl Acad Sci U S A.</i> 2012; <b>109</b>(50): 2073843. <a target=xrefwindow id=d9874e2476 href="http://www.ncbi.nlm.nih.gov/pubmed/23188798">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2479 href="http://dx.doi.org/10.1073/pnas.1213381109">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2483 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3528571">Free Full Text </a></span></li><li><a name=ref-57 class=n-a></a><span class=label>57. </span>&nbsp;<span class=citation><a name=d9874e2492 class=n-a></a>Baumann S, Joly O, Rees A, <i> et al.</i>: The topography of frequency and time representation in primate auditory cortices. <i>eLife.</i> 2015; <b>4</b>: e03256. <a target=xrefwindow id=d9874e2503 href="http://www.ncbi.nlm.nih.gov/pubmed/25590651">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2506 href="http://dx.doi.org/10.7554/eLife.03256">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2510 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4398946">Free Full Text </a></span></li><li><a name=ref-58 class=n-a></a><span class=label>58. </span>&nbsp;<span class=citation><a name=d9874e2519 class=n-a></a>Bandyopadhyay S, Shamma SA, Kanold PO: Dichotomy of functional organization in the mouse auditory cortex. <i>Nat Neurosci.</i> 2010; <b>13</b>(3): 3618. <a target=xrefwindow id=d9874e2527 href="http://www.ncbi.nlm.nih.gov/pubmed/20118924">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2530 href="http://dx.doi.org/10.1038/nn.2490">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2533 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2866453">Free Full Text </a></span></li><li><a name=ref-59 class=n-a></a><span class=label>59. </span>&nbsp;<span class=citation><a name=d9874e2542 class=n-a></a>Deneux T, Kempf A, Daret A, <i> et al.</i>: Temporal asymmetries in auditory coding and perception reflect multi-layered nonlinearities. <i>Nat Commun.</i> 2016; <b>7</b>: 12682. <a target=xrefwindow id=d9874e2553 href="http://www.ncbi.nlm.nih.gov/pubmed/27580932">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2556 href="http://dx.doi.org/10.1038/ncomms12682">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2560 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5025791">Free Full Text </a></span></li><li><a name=ref-60 class=n-a></a><span class=label>60. </span>&nbsp;<span class=citation><a name=d9874e2570 class=n-a></a>Panniello M, King AJ, Dahmen JC, <i> et al.</i>: Local and Global Spatial Organization of Interaural Level Difference and Frequency Preferences in Auditory Cortex. <i>Cereb Cortex.</i> 2018; <b>28</b>(1): 35069. <a target=xrefwindow id=d9874e2581 href="http://www.ncbi.nlm.nih.gov/pubmed/29136122">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2584 href="http://dx.doi.org/10.1093/cercor/bhx295">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2588 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5991210">Free Full Text </a></span></li><li><a name=ref-61 class=n-a></a><span class=label>61. </span>&nbsp;<span class=citation><a name=d9874e2597 class=n-a></a>Recanzone GH, Schreiner CE, Sutter ML, <i> et al.</i>: Functional organization of spectral receptive fields in the primary auditory cortex of the owl monkey. <i>J Comp Neurol.</i> 1999; <b>415</b>(4): 46081. <a target=xrefwindow id=d9874e2608 href="http://www.ncbi.nlm.nih.gov/pubmed/10570456">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2611 href="http://dx.doi.org/10.1002/(SICI)1096-9861(19991227)415:4%3C460::AID-CNE4%3E3.0.CO;2-F">Publisher Full Text </a></span></li><li><a name=ref-62 class=n-a></a><span class=label>62. </span>&nbsp;<span class=citation><a name=d9874e2620 class=n-a></a>Atencio CA, Schreiner CE: Spectrotemporal processing in spectral tuning modules of cat primary auditory cortex. <i>PLoS One.</i> 2012; <b>7</b>(2): e31537. <a target=xrefwindow id=d9874e2628 href="http://www.ncbi.nlm.nih.gov/pubmed/22384036">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2631 href="http://dx.doi.org/10.1371/journal.pone.0031537">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2634 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3288040">Free Full Text </a></span></li><li><a name=ref-63 class=n-a></a><span class=label>63. </span>&nbsp;<span class=citation><a name=d9874e2643 class=n-a></a>Ringach DL, Mineault PJ, Tring E, <i> et al.</i>: Spatial clustering of tuning in mouse primary visual cortex. <i>Nat Commun.</i> 2016; <b>7</b>: 12270. <a target=xrefwindow id=d9874e2654 href="http://www.ncbi.nlm.nih.gov/pubmed/27481398">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2657 href="http://dx.doi.org/10.1038/ncomms12270">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2661 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4974656">Free Full Text </a></span></li><li><a name=ref-64 class=n-a></a><span class=label>64. </span>&nbsp;<span class=citation><a name=d9874e2670 class=n-a></a>Atencio CA, Schreiner CE: Laminar diversity of dynamic sound processing in cat primary auditory cortex. <i>J Neurophysiol.</i> 2010; <b>103</b>(1): 192205. <a target=xrefwindow id=d9874e2678 href="http://www.ncbi.nlm.nih.gov/pubmed/19864440">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2681 href="http://dx.doi.org/10.1152/jn.00624.2009">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2684 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2807218">Free Full Text </a></span></li><li><a name=ref-65 class=n-a></a><span class=label>65. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/732665006"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2693 class=n-a></a>Morrill RJ, Hasenstaub AR: Visual Information Present in Infragranular Layers of Mouse Auditory Cortex. <i>J Neurosci.</i> 2018; <b>38</b>(11): 285462. <a target=xrefwindow id=d9874e2701 href="http://www.ncbi.nlm.nih.gov/pubmed/29440554">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2704 href="http://dx.doi.org/10.1523/JNEUROSCI.3102-17.2018">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2707 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5852663">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/732665006">F1000 Recommendation</a></span></li><li><a name=ref-66 class=n-a></a><span class=label>66. </span>&nbsp;<span class=citation><a name=d9874e2721 class=n-a></a>Schaefer MK, Kssl M, Hechavarra JC: Laminar differences in response to simple and spectro-temporally complex sounds in the primary auditory cortex of ketamine-anesthetized gerbils. <i>PLoS One.</i> 2017; <b>12</b>(8): e0182514. <a target=xrefwindow id=d9874e2729 href="http://www.ncbi.nlm.nih.gov/pubmed/28771568">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2732 href="http://dx.doi.org/10.1371/journal.pone.0182514">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2735 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5542772">Free Full Text </a></span></li><li><a name=ref-67 class=n-a></a><span class=label>67. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/733386955"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2744 class=n-a></a>See JZ, Atencio CA, Sohal VS, <i> et al.</i>: Coordinated neuronal ensembles in primary auditory cortical columns. <i>eLife.</i> 2018; <b>7</b>: pii: e35587. <a target=xrefwindow id=d9874e2755 href="http://www.ncbi.nlm.nih.gov/pubmed/29869986">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2758 href="http://dx.doi.org/10.7554/eLife.35587">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2762 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6017807">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/733386955">F1000 Recommendation</a></span></li><li><a name=ref-68 class=n-a></a><span class=label>68. </span>&nbsp;<span class=citation><a name=d9874e2775 class=n-a></a>Overath T, McDermott JH, Zarate JM, <i> et al.</i>: The cortical analysis of speech-specific temporal structure revealed by responses to sound quilts. <i>Nat Neurosci.</i> 2015; <b>18</b>(6): 90311. <a target=xrefwindow id=d9874e2786 href="http://www.ncbi.nlm.nih.gov/pubmed/25984889">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2789 href="http://dx.doi.org/10.1038/nn.4021">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2793 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4769593">Free Full Text </a></span></li><li><a name=ref-69 class=n-a></a><span class=label>69. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727692323"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2802 class=n-a></a>de Heer WA, Huth AG, Griffiths TL, <i> et al.</i>: The Hierarchical Cortical Organization of Human Speech Processing. <i>J Neurosci.</i> 2017; <b>37</b>(27): 653957. <a target=xrefwindow id=d9874e2813 href="http://www.ncbi.nlm.nih.gov/pubmed/28588065">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2816 href="http://dx.doi.org/10.1523/JNEUROSCI.3267-16.2017">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2820 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5511884">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727692323">F1000 Recommendation</a></span></li><li><a name=ref-70 class=n-a></a><span class=label>70. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/733077121"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2833 class=n-a></a>Kell AJE, Yamins DLK, Shook EN, <i> et al.</i>: A Task-Optimized Neural Network Replicates Human Auditory Behavior, Predicts Brain Responses, and Reveals a Cortical Processing Hierarchy. <i>Neuron.</i> 2018; <b>98</b>(3): 630644.e16. <a target=xrefwindow id=d9874e2844 href="http://www.ncbi.nlm.nih.gov/pubmed/29681533">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2847 href="http://dx.doi.org/10.1016/j.neuron.2018.03.044">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/733077121">F1000 Recommendation</a></span></li><li><a name=ref-71 class=n-a></a><span class=label>71. </span>&nbsp;<span class=citation><a name=d9874e2860 class=n-a></a>Norman-Haignere S, Kanwisher NG, McDermott JH: Distinct Cortical Pathways for Music and Speech Revealed by Hypothesis-Free Voxel Decomposition. <i>Neuron.</i> 2015; <b>88</b>(6): 128196. <a target=xrefwindow id=d9874e2868 href="http://www.ncbi.nlm.nih.gov/pubmed/26687225">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2871 href="http://dx.doi.org/10.1016/j.neuron.2015.11.035">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2874 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4740977">Free Full Text </a></span></li><li><a name=ref-72 class=n-a></a><span class=label>72. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727582754"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e2884 class=n-a></a>Poirier C, Baumann S, Dheerendra P, <i> et al.</i>: Auditory motion-specific mechanisms in the primate brain. <i>PLoS Biol.</i> 2017; <b>15</b>(5): e2001379. <a target=xrefwindow id=d9874e2895 href="http://www.ncbi.nlm.nih.gov/pubmed/28472038">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2898 href="http://dx.doi.org/10.1371/journal.pbio.2001379">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2902 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5417421">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727582754">F1000 Recommendation</a></span></li><li><a name=ref-73 class=n-a></a><span class=label>73. </span>&nbsp;<span class=citation><a name=d9874e2915 class=n-a></a>Cohen YE, Bennur S, Christison-Lagay K, <i> et al.</i>: Functional Organization of the Ventral Auditory Pathway. <i>Adv Exp Med Biol.</i> 2016; <b>894</b>: 3818. <a target=xrefwindow id=d9874e2926 href="http://www.ncbi.nlm.nih.gov/pubmed/27080679">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2929 href="http://dx.doi.org/10.1007/978-3-319-25474-6_40">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2933 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5444378">Free Full Text </a></span></li><li><a name=ref-74 class=n-a></a><span class=label>74. </span>&nbsp;<span class=citation><a name=d9874e2942 class=n-a></a>Albouy P, Weiss A, Baillet S, <i> et al.</i>: Selective Entrainment of Theta Oscillations in the Dorsal Stream Causally Enhances Auditory Working Memory Performance. <i>Neuron.</i> 2017; <b>94</b>(1): 193206.e5. <a target=xrefwindow id=d9874e2953 href="http://www.ncbi.nlm.nih.gov/pubmed/28343866">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2956 href="http://dx.doi.org/10.1016/j.neuron.2017.03.015">Publisher Full Text </a></span></li><li><a name=ref-75 class=n-a></a><span class=label>75. </span>&nbsp;<span class=citation><a name=d9874e2965 class=n-a></a>Da Costa S, Clarke S, Crottaz-Herbette S: Keeping track of sound objects in space: The contribution of early-stage auditory areas. <i>Hear Res.</i> 2018; <b>366</b>: 1731. <a target=xrefwindow id=d9874e2973 href="http://www.ncbi.nlm.nih.gov/pubmed/29643021">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2976 href="http://dx.doi.org/10.1016/j.heares.2018.03.027">Publisher Full Text </a></span></li><li><a name=ref-76 class=n-a></a><span class=label>76. </span>&nbsp;<span class=citation><a name=d9874e2985 class=n-a></a>Rauschecker JP: Where, When, and How: Are they all sensorimotor? Towards a unified view of the dorsal pathway in vision and audition. <i>Cortex.</i> 2018; <b>98</b>: 2628. <a target=xrefwindow id=d9874e2993 href="http://www.ncbi.nlm.nih.gov/pubmed/29183630">PubMed Abstract </a> | <a target=xrefwindow id=d9874e2996 href="http://dx.doi.org/10.1016/j.cortex.2017.10.020">Publisher Full Text </a> | <a target=xrefwindow id=d9874e2999 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5771843">Free Full Text </a></span></li><li><a name=ref-77 class=n-a></a><span class=label>77. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727143403"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3008 class=n-a></a>Issa JB, Haeffele BD, Young ED, <i> et al.</i>: Multiscale mapping of frequency sweep rate in mouse auditory cortex. <i>Hear Res.</i> 2017; <b>344</b>: 20722. <a target=xrefwindow id=d9874e3019 href="http://www.ncbi.nlm.nih.gov/pubmed/28011084">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3022 href="http://dx.doi.org/10.1016/j.heares.2016.11.018">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3026 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5240629">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727143403">F1000 Recommendation</a></span></li><li><a name=ref-78 class=n-a></a><span class=label>78. </span>&nbsp;<span class=citation><a name=d9874e3040 class=n-a></a>Walker KM, Bizley JK, King AJ, <i> et al.</i>: Multiplexed and robust representations of sound features in auditory cortex. <i>J Neurosci.</i> 2011; <b>31</b>(41): 1456576. <a target=xrefwindow id=d9874e3051 href="http://www.ncbi.nlm.nih.gov/pubmed/21994373">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3054 href="http://dx.doi.org/10.1523/JNEUROSCI.2074-11.2011">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3058 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3272412">Free Full Text </a></span></li><li><a name=ref-79 class=n-a></a><span class=label>79. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727301648"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3067 class=n-a></a>Ortiz-Rios M, Azevedo FAC, Kumierek P, <i> et al.</i>: Widespread and Opponent fMRI Signals Represent Sound Location in Macaque Auditory Cortex. <i>Neuron.</i> 2017; <b>93</b>(4): 971983.e4. <a target=xrefwindow id=d9874e3078 href="http://www.ncbi.nlm.nih.gov/pubmed/28190642">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3081 href="http://dx.doi.org/10.1016/j.neuron.2017.01.013">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3085 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5757378">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727301648">F1000 Recommendation</a></span></li><li><a name=ref-80 class=n-a></a><span class=label>80. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727146552"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3098 class=n-a></a>Allen EJ, Burton PC, Olman CA, <i> et al.</i>: Representations of Pitch and Timbre Variation in Human Auditory Cortex. <i>J Neurosci.</i> 2017; <b>37</b>(5): 128493. <a target=xrefwindow id=d9874e3109 href="http://www.ncbi.nlm.nih.gov/pubmed/28025255">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3112 href="http://dx.doi.org/10.1523/JNEUROSCI.2336-16.2016">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3116 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5296797">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727146552">F1000 Recommendation</a></span></li><li><a name=ref-81 class=n-a></a><span class=label>81. </span>&nbsp;<span class=citation><a name=d9874e3129 class=n-a></a>Bizley JK, Walker KM, Silverman BW, <i> et al.</i>: Interdependent encoding of pitch, timbre, and spatial location in auditory cortex. <i>J Neurosci.</i> 2009; <b>29</b>(7): 206475. <a target=xrefwindow id=d9874e3140 href="http://www.ncbi.nlm.nih.gov/pubmed/19228960">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3143 href="http://dx.doi.org/10.1523/JNEUROSCI.4755-08.2009">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3147 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2663390">Free Full Text </a></span></li><li><a name=ref-82 class=n-a></a><span class=label>82. </span>&nbsp;<span class=citation><a name=d9874e3156 class=n-a></a>Pasley BN, David SV, Mesgarani N, <i> et al.</i>: Reconstructing speech from human auditory cortex. <i>PLoS Biol.</i> 2012; <b>10</b>(1): e1001251. <a target=xrefwindow id=d9874e3167 href="http://www.ncbi.nlm.nih.gov/pubmed/22303281">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3170 href="http://dx.doi.org/10.1371/journal.pbio.1001251">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3174 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3269422">Free Full Text </a></span></li><li><a name=ref-83 class=n-a></a><span class=label>83. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727086041"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3183 class=n-a></a>Yildiz IB, Mesgarani N, Deneve S: Predictive Ensemble Decoding of Acoustical Features Explains Context-Dependent Receptive Fields. <i>J Neurosci.</i> 2016; <b>36</b>(49): 1233850. <a target=xrefwindow id=d9874e3191 href="http://www.ncbi.nlm.nih.gov/pubmed/27927954">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3194 href="http://dx.doi.org/10.1523/JNEUROSCI.4648-15.2016">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3197 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5148225">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727086041">F1000 Recommendation</a></span></li><li><a name=ref-84 class=n-a></a><span class=label>84. </span>&nbsp;<span class=citation><a name=d9874e3211 class=n-a></a>Christison-Lagay KL, Bennur S, Cohen YE: Contribution of spiking activity in the primary auditory cortex to detection in noise. <i>J Neurophysiol.</i> 2017; <b>118</b>(6): 311831. <a target=xrefwindow id=d9874e3219 href="http://www.ncbi.nlm.nih.gov/pubmed/28855294">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3222 href="http://dx.doi.org/10.1152/jn.00521.2017">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3225 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5814708">Free Full Text </a></span></li><li><a name=ref-85 class=n-a></a><span class=label>85. </span>&nbsp;<span class=citation><a name=d9874e3234 class=n-a></a>Malone BJ, Heiser MA, Beitel RE, <i> et al.</i>: Background noise exerts diverse effects on the cortical encoding of foreground sounds. <i>J Neurophysiol.</i> 2017; <b>118</b>(2): 103454. <a target=xrefwindow id=d9874e3245 href="http://www.ncbi.nlm.nih.gov/pubmed/28490644">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3248 href="http://dx.doi.org/10.1152/jn.00152.2017">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3252 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5547268">Free Full Text </a></span></li><li><a name=ref-86 class=n-a></a><span class=label>86. </span>&nbsp;<span class=citation><a name=d9874e3261 class=n-a></a>Mesgarani N, Chang EF: Selective cortical representation of attended speaker in multi-talker speech perception. <i>Nature.</i> 2012; <b>485</b>(7397): 2336. <a target=xrefwindow id=d9874e3269 href="http://www.ncbi.nlm.nih.gov/pubmed/22522927">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3272 href="http://dx.doi.org/10.1038/nature11020">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3275 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3870007">Free Full Text </a></span></li><li><a name=ref-87 class=n-a></a><span class=label>87. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/718018777"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3284 class=n-a></a>Zion Golumbic EM, Ding N, Bickel S, <i> et al.</i>: Mechanisms underlying selective neuronal tracking of attended speech at a "cocktail party". <i>Neuron.</i> 2013; <b>77</b>(5): 98091. <a target=xrefwindow id=d9874e3295 href="http://www.ncbi.nlm.nih.gov/pubmed/23473326">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3298 href="http://dx.doi.org/10.1016/j.neuron.2012.12.037">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3302 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3891478">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/718018777">F1000 Recommendation</a></span></li><li><a name=ref-88 class=n-a></a><span class=label>88. </span>&nbsp;<span class=citation><a name=d9874e3315 class=n-a></a>Rodgers CC, DeWeese MR: Neural correlates of task switching in prefrontal cortex and primary auditory cortex in a novel stimulus selection task for rodents. <i>Neuron.</i> 2014; <b>82</b>(5): 115770. <a target=xrefwindow id=d9874e3323 href="http://www.ncbi.nlm.nih.gov/pubmed/24908492">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3326 href="http://dx.doi.org/10.1016/j.neuron.2014.04.031">Publisher Full Text </a></span></li><li><a name=ref-89 class=n-a></a><span class=label>89. </span>&nbsp;<span class=citation><a name=d9874e3335 class=n-a></a>Fuglsang SA, Dau T, Hjortkjr J: Noise-robust cortical tracking of attended speech in real-world acoustic scenes. <i>Neuroimage.</i> 2017; <b>156</b>: 43544. <a target=xrefwindow id=d9874e3343 href="http://www.ncbi.nlm.nih.gov/pubmed/28412441">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3346 href="http://dx.doi.org/10.1016/j.neuroimage.2017.04.026">Publisher Full Text </a></span></li><li><a name=ref-90 class=n-a></a><span class=label>90. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/722583732"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3356 class=n-a></a>Bathellier B, Ushakova L, Rumpel S: Discrete neocortical dynamics predict behavioral categorization of sounds. <i>Neuron.</i> 2012; <b>76</b>(2): 43549. <a target=xrefwindow id=d9874e3364 href="http://www.ncbi.nlm.nih.gov/pubmed/23083744">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3367 href="http://dx.doi.org/10.1016/j.neuron.2012.07.008">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/722583732">F1000 Recommendation</a></span></li><li><a name=ref-91 class=n-a></a><span class=label>91. </span>&nbsp;<span class=citation><a name=d9874e3380 class=n-a></a>Ince RA, Panzeri S, Kayser C: Neural codes formed by small and temporally precise populations in auditory cortex. <i>J Neurosci.</i> 2013; <b>33</b>(46): 1827787. <a target=xrefwindow id=d9874e3388 href="http://www.ncbi.nlm.nih.gov/pubmed/24227737">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3391 href="http://dx.doi.org/10.1523/JNEUROSCI.2631-13.2013">Publisher Full Text </a></span></li><li><a name=ref-92 class=n-a></a><span class=label>92. </span>&nbsp;<span class=citation><a name=d9874e3400 class=n-a></a>Francis NA, Winkowski DE, Sheikhattar A, <i> et al.</i>: Small Networks Encode Decision-Making in Primary Auditory Cortex. <i>Neuron.</i> 2018; <b>97</b>(4): 885897.e6. <a target=xrefwindow id=d9874e3411 href="http://www.ncbi.nlm.nih.gov/pubmed/29398362">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3414 href="http://dx.doi.org/10.1016/j.neuron.2018.01.019">Publisher Full Text </a></span></li><li><a name=ref-93 class=n-a></a><span class=label>93. </span>&nbsp;<span class=citation><a name=d9874e3423 class=n-a></a>Stecker GC, Harrington IA, Middlebrooks JC: Location coding by opponent neural populations in the auditory cortex. <i>PLoS Biol.</i> 2005; <b>3</b>(3): e78. <a target=xrefwindow id=d9874e3431 href="http://www.ncbi.nlm.nih.gov/pubmed/15736980">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3434 href="http://dx.doi.org/10.1371/journal.pbio.0030078">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3437 href="http://www.ncbi.nlm.nih.gov/pmc/articles/1044834">Free Full Text </a></span></li><li><a name=ref-94 class=n-a></a><span class=label>94. </span>&nbsp;<span class=citation><a name=d9874e3446 class=n-a></a>Keating P, Dahmen JC, King AJ: Complementary adaptive processes contribute to the developmental plasticity of spatial hearing. <i>Nat Neurosci.</i> 2015; <b>18</b>(2): 1857. <a target=xrefwindow id=d9874e3454 href="http://www.ncbi.nlm.nih.gov/pubmed/25581359">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3457 href="http://dx.doi.org/10.1038/nn.3914">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3460 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4338598">Free Full Text </a></span></li><li><a name=ref-95 class=n-a></a><span class=label>95. </span>&nbsp;<span class=citation><a name=d9874e3469 class=n-a></a>Derey K, Valente G, de Gelder B, <i> et al.</i>: Opponent Coding of Sound Location (Azimuth) in Planum Temporale is Robust to Sound-Level Variations. <i>Cereb Cortex.</i> 2016; <b>26</b>(1): 45064. <a target=xrefwindow id=d9874e3480 href="http://www.ncbi.nlm.nih.gov/pubmed/26545618">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3483 href="http://dx.doi.org/10.1093/cercor/bhv269">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3487 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4677988">Free Full Text </a></span></li><li><a name=ref-96 class=n-a></a><span class=label>96. </span>&nbsp;<span class=citation><a name=d9874e3497 class=n-a></a>McLaughlin SA, Higgins NC, Stecker GC: Tuning to Binaural Cues in Human Auditory Cortex. <i>J Assoc Res Otolaryngol.</i> 2016; <b>17</b>(1): 3753. <a target=xrefwindow id=d9874e3505 href="http://www.ncbi.nlm.nih.gov/pubmed/26466943">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3508 href="http://dx.doi.org/10.1007/s10162-015-0546-4">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3511 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4722015">Free Full Text </a></span></li><li><a name=ref-97 class=n-a></a><span class=label>97. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727531524"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3520 class=n-a></a>Santoro R, Moerel M, De Martino F, <i> et al.</i>: Reconstructing the spectrotemporal modulations of real-life sounds from fMRI response patterns. <i>Proc Natl Acad Sci U S A.</i> 2017; <b>114</b>(18): 4799804. <a target=xrefwindow id=d9874e3531 href="http://www.ncbi.nlm.nih.gov/pubmed/28420788">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3534 href="http://dx.doi.org/10.1073/pnas.1617622114">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3538 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5422795">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727531524">F1000 Recommendation</a></span></li><li><a name=ref-98 class=n-a></a><span class=label>98. </span>&nbsp;<span class=citation><a name=d9874e3551 class=n-a></a>Griffiths TD, Warren JD: What is an auditory object? <i>Nat Rev Neurosci.</i> 2004; <b>5</b>(11): 88792. <a target=xrefwindow id=d9874e3559 href="http://www.ncbi.nlm.nih.gov/pubmed/15496866">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3562 href="http://dx.doi.org/10.1038/nrn1538">Publisher Full Text </a></span></li><li><a name=ref-99 class=n-a></a><span class=label>99. </span>&nbsp;<span class=citation><a name=d9874e3571 class=n-a></a>Pressnitzer D, Sayles M, Micheyl C, <i> et al.</i>: Perceptual organization of sound begins in the auditory periphery. <i>Curr Biol.</i> 2008; <b>18</b>(15): 11248. <a target=xrefwindow id=d9874e3582 href="http://www.ncbi.nlm.nih.gov/pubmed/18656355">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3585 href="http://dx.doi.org/10.1016/j.cub.2008.06.053">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3589 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2559912">Free Full Text </a></span></li><li><a name=ref-100 class=n-a></a><span class=label>100. </span>&nbsp;<span class=citation><a name=d9874e3598 class=n-a></a>Kondo HM, Kashino M: Involvement of the thalamocortical loop in the spontaneous switching of percepts in auditory streaming. <i>J Neurosci.</i> 2009; <b>29</b>(40): 12695701. <a target=xrefwindow id=d9874e3606 href="http://www.ncbi.nlm.nih.gov/pubmed/19812344">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3609 href="http://dx.doi.org/10.1523/JNEUROSCI.1549-09.2009">Publisher Full Text </a></span></li><li><a name=ref-101 class=n-a></a><span class=label>101. </span>&nbsp;<span class=citation><a name=d9874e3618 class=n-a></a>Yao JD, Bremen P, Middlebrooks JC: Emergence of Spatial Stream Segregation in the Ascending Auditory Pathway. <i>J Neurosci.</i> 2015; <b>35</b>(49): 16199212. <a target=xrefwindow id=d9874e3626 href="http://www.ncbi.nlm.nih.gov/pubmed/26658870">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3629 href="http://dx.doi.org/10.1523/JNEUROSCI.3116-15.2015">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3632 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4682785">Free Full Text </a></span></li><li><a name=ref-102 class=n-a></a><span class=label>102. </span>&nbsp;<span class=citation><a name=d9874e3642 class=n-a></a>Shamma SA, Elhilali M, Micheyl C: Temporal coherence and attention in auditory scene analysis. <i>Trends Neurosci.</i> 2011; <b>34</b>(3): 11423. <a target=xrefwindow id=d9874e3650 href="http://www.ncbi.nlm.nih.gov/pubmed/21196054">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3653 href="http://dx.doi.org/10.1016/j.tins.2010.11.002">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3656 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3073558">Free Full Text </a></span></li><li><a name=ref-103 class=n-a></a><span class=label>103. </span>&nbsp;<span class=citation><a name=d9874e3665 class=n-a></a>Ding N, Simon JZ: Emergence of neural encoding of auditory objects while listening to competing speakers. <i>Proc Natl Acad Sci U S A.</i> 2012; <b>109</b>(29): 118549. <a target=xrefwindow id=d9874e3673 href="http://www.ncbi.nlm.nih.gov/pubmed/22753470">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3676 href="http://dx.doi.org/10.1073/pnas.1205381109">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3679 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3406818">Free Full Text </a></span></li><li><a name=ref-104 class=n-a></a><span class=label>104. </span>&nbsp;<span class=citation><a name=d9874e3688 class=n-a></a>Middlebrooks JC, Bremen P: Spatial stream segregation by auditory cortical neurons. <i>J Neurosci.</i> 2013; <b>33</b>(27): 109861001. <a target=xrefwindow id=d9874e3696 href="http://www.ncbi.nlm.nih.gov/pubmed/23825404">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3699 href="http://dx.doi.org/10.1523/JNEUROSCI.1065-13.2013">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3702 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3718378">Free Full Text </a></span></li><li><a name=ref-105 class=n-a></a><span class=label>105. </span>&nbsp;<span class=citation><a name=d9874e3711 class=n-a></a>Fishman YI, Steinschneider M, Micheyl C, <i> et al.</i>: Neural representation of concurrent harmonic sounds in monkey primary auditory cortex: Implications for models of auditory scene analysis. <i>J Neurosci.</i> 2014; <b>34</b>(37): 1242543. <a target=xrefwindow id=d9874e3722 href="http://www.ncbi.nlm.nih.gov/pubmed/25209282">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3725 href="http://dx.doi.org/10.1523/JNEUROSCI.0025-14.2014">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3729 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4160777">Free Full Text </a></span></li><li><a name=ref-106 class=n-a></a><span class=label>106. </span>&nbsp;<span class=citation><a name=d9874e3738 class=n-a></a>Fishman YI, Micheyl C, Steinschneider M: Neural Representation of Concurrent Vowels in Macaque Primary Auditory Cortex. <i>eNeuro.</i> 2016; <b>3</b>(3): pii: ENEURO.0071-16.2016. <a target=xrefwindow id=d9874e3746 href="http://www.ncbi.nlm.nih.gov/pubmed/27294198">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3749 href="http://dx.doi.org/10.1523/ENEURO.0071-16.2016">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3752 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4901243">Free Full Text </a></span></li><li><a name=ref-107 class=n-a></a><span class=label>107. </span>&nbsp;<span class=citation><a name=d9874e3761 class=n-a></a>Christison-Lagay KL, Gifford AM, Cohen YE: Neural correlates of auditory scene analysis and perception. <i>Int J Psychophysiol.</i> 2015; <b>95</b>(2): 23845. <a target=xrefwindow id=d9874e3769 href="http://www.ncbi.nlm.nih.gov/pubmed/24681354">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3772 href="http://dx.doi.org/10.1016/j.ijpsycho.2014.03.004">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3775 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4176604">Free Full Text </a></span></li><li><a name=ref-108 class=n-a></a><span class=label>108. </span>&nbsp;<span class=citation><a name=d9874e3785 class=n-a></a>Riecke L, Sack AT, Schroeder CE: Endogenous Delta/Theta Sound-Brain Phase Entrainment Accelerates the Buildup of Auditory Streaming. <i>Curr Biol.</i> 2015; <b>25</b>(24): 3196201. <a target=xrefwindow id=d9874e3793 href="http://www.ncbi.nlm.nih.gov/pubmed/26628008">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3796 href="http://dx.doi.org/10.1016/j.cub.2015.10.045">Publisher Full Text </a></span></li><li><a name=ref-109 class=n-a></a><span class=label>109. </span>&nbsp;<span class=citation><a name=d9874e3805 class=n-a></a>Teki S, Griffiths TD: Brain Bases of Working Memory for Time Intervals in Rhythmic Sequences. <i>Front Neurosci.</i> 2016; <b>10</b>: 239. <a target=xrefwindow id=d9874e3813 href="http://www.ncbi.nlm.nih.gov/pubmed/27313506">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3816 href="http://dx.doi.org/10.3389/fnins.2016.00239">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3819 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4888525">Free Full Text </a></span></li><li><a name=ref-110 class=n-a></a><span class=label>110. </span>&nbsp;<span class=citation><a name=d9874e3828 class=n-a></a>Teki S, Barascud N, Picard S, <i> et al.</i>: Neural Correlates of Auditory Figure-Ground Segregation Based on Temporal Coherence. <i>Cereb Cortex.</i> 2016; <b>26</b>(9): 366980. <a target=xrefwindow id=d9874e3839 href="http://www.ncbi.nlm.nih.gov/pubmed/27325682">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3842 href="http://dx.doi.org/10.1093/cercor/bhw173">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3846 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5004755">Free Full Text </a></span></li><li><a name=ref-111 class=n-a></a><span class=label>111. </span>&nbsp;<span class=citation><a name=d9874e3855 class=n-a></a>Tth B, Kocsis Z, Hden GP, <i> et al.</i>: EEG signatures accompanying auditory figure-ground segregation. <i>NeuroImage.</i> 2016; <b>141</b>: 10819. <a target=xrefwindow id=d9874e3866 href="http://www.ncbi.nlm.nih.gov/pubmed/27421185">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3869 href="http://dx.doi.org/10.1016/j.neuroimage.2016.07.028">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3873 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5656226">Free Full Text </a></span></li><li><a name=ref-112 class=n-a></a><span class=label>112. </span>&nbsp;<span class=citation><a name=d9874e3882 class=n-a></a>Alain C, Arsenault JS, Garami L, <i> et al.</i>: Neural Correlates of Speech Segregation Based on Formant Frequencies of Adjacent Vowels. <i>Sci Rep.</i> 2017; <b>7</b>: 40790. <a target=xrefwindow id=d9874e3893 href="http://www.ncbi.nlm.nih.gov/pubmed/28102300">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3896 href="http://dx.doi.org/10.1038/srep40790">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3900 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5244401">Free Full Text </a></span></li><li><a name=ref-113 class=n-a></a><span class=label>113. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727169686"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3909 class=n-a></a>Lu K, Xu Y, Yin P, <i> et al.</i>: Temporal coherence structure rapidly shapes neuronal interactions. <i>Nat Commun.</i> 2017; <b>8</b>: 13900. <a target=xrefwindow id=d9874e3920 href="http://www.ncbi.nlm.nih.gov/pubmed/28054545">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3923 href="http://dx.doi.org/10.1038/ncomms13900">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3927 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5228385">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727169686">F1000 Recommendation</a></span></li><li><a name=ref-114 class=n-a></a><span class=label>114. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/728776814"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3941 class=n-a></a>Puvvada KC, Simon JZ: Cortical Representations of Speech in a Multitalker Auditory Scene. <i>J Neurosci.</i> 2017; <b>37</b>(38): 918996. <a target=xrefwindow id=d9874e3949 href="http://www.ncbi.nlm.nih.gov/pubmed/28821680">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3952 href="http://dx.doi.org/10.1523/JNEUROSCI.0938-17.2017">Publisher Full Text </a> | <a target=xrefwindow id=d9874e3955 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5607465">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/728776814">F1000 Recommendation</a></span></li><li><a name=ref-115 class=n-a></a><span class=label>115. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/733152936"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e3968 class=n-a></a>Shiell MM, Hausfeld L, Formisano E: Activity in Human Auditory Cortex Represents Spatial Separation Between Concurrent Sounds. <i>J Neurosci.</i> 2018; <b>38</b>(21): 497784. <a target=xrefwindow id=d9874e3976 href="http://www.ncbi.nlm.nih.gov/pubmed/29712782">PubMed Abstract </a> | <a target=xrefwindow id=d9874e3979 href="http://dx.doi.org/10.1523/JNEUROSCI.3323-17.2018">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/733152936">F1000 Recommendation</a></span></li><li><a name=ref-116 class=n-a></a><span class=label>116. </span>&nbsp;<span class=citation><a name=d9874e3992 class=n-a></a>Fishman YI, Steinschneider M: Formation of auditory streams. In <i>The Oxford Handbook of Auditory Science: The Auditory Brain.</i> 215246 (Oxford University Press, 2010). <a target=xrefwindow id=d9874e3997 href="https://books.google.co.in/books?id=Kyq65C3ygGAC&amp;pg=PA215">Reference Source</a></span></li><li><a name=ref-117 class=n-a></a><span class=label>117. </span>&nbsp;<span class=citation><a name=d9874e4006 class=n-a></a>Teki S, Chait M, Kumar S, <i> et al.</i>: Segregation of complex acoustic scenes based on temporal coherence. <i>eLife.</i> 2013; <b>2</b>: e00699. <a target=xrefwindow id=d9874e4017 href="http://www.ncbi.nlm.nih.gov/pubmed/23898398">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4020 href="http://dx.doi.org/10.7554/eLife.00699">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4024 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3721234">Free Full Text </a></span></li><li><a name=ref-118 class=n-a></a><span class=label>118. </span>&nbsp;<span class=citation><a name=d9874e4033 class=n-a></a>Krishnan L, Elhilali M, Shamma S: Segregating complex sound sources through temporal coherence. <i>PLoS Comput Biol.</i> 2014; <b>10</b>(12): e1003985. <a target=xrefwindow id=d9874e4041 href="http://www.ncbi.nlm.nih.gov/pubmed/25521593">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4044 href="http://dx.doi.org/10.1371/journal.pcbi.1003985">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4047 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4270434">Free Full Text </a></span></li><li><a name=ref-119 class=n-a></a><span class=label>119. </span>&nbsp;<span class=citation><a name=d9874e4056 class=n-a></a>O'Sullivan JA, Power AJ, Mesgarani N, <i> et al.</i>: Attentional Selection in a Cocktail Party Environment Can Be Decoded from Single-Trial EEG. <i>Cereb Cortex.</i> 2015; <b>25</b>(7): 1697706. <a target=xrefwindow id=d9874e4067 href="http://www.ncbi.nlm.nih.gov/pubmed/24429136">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4070 href="http://dx.doi.org/10.1093/cercor/bht355">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4074 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4481604">Free Full Text </a></span></li><li><a name=ref-120 class=n-a></a><span class=label>120. </span>&nbsp;<span class=citation><a name=d9874e4084 class=n-a></a>Lakatos P, Musacchia G, O'Connel MN, <i> et al.</i>: The spectrotemporal filter mechanism of auditory selective attention. <i>Neuron.</i> 2013; <b>77</b>(4): 75061. <a target=xrefwindow id=d9874e4095 href="http://www.ncbi.nlm.nih.gov/pubmed/23439126">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4098 href="http://dx.doi.org/10.1016/j.neuron.2012.11.034">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4102 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3583016">Free Full Text </a></span></li><li><a name=ref-121 class=n-a></a><span class=label>121. </span>&nbsp;<span class=citation><a name=d9874e4111 class=n-a></a>VanRullen R, Zoefel B, Ilhan B: On the cyclic nature of perception in vision versus audition. <i>Philos Trans R Soc Lond B Biol Sci.</i> 2014; <b>369</b>(1641): 20130214. <a target=xrefwindow id=d9874e4119 href="http://www.ncbi.nlm.nih.gov/pubmed/24639585">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4122 href="http://dx.doi.org/10.1098/rstb.2013.0214">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4125 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3965168">Free Full Text </a></span></li><li><a name=ref-122 class=n-a></a><span class=label>122. </span>&nbsp;<span class=citation><a name=d9874e4134 class=n-a></a>Morillon B, Schroeder CE: Neuronal oscillations as a mechanistic substrate of auditory temporal prediction. <i>Ann N Y Acad Sci.</i> 2015; <b>1337</b>: 2631. <a target=xrefwindow id=d9874e4142 href="http://www.ncbi.nlm.nih.gov/pubmed/25773613">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4145 href="http://dx.doi.org/10.1111/nyas.12629">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4148 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4363099">Free Full Text </a></span></li><li><a name=ref-123 class=n-a></a><span class=label>123. </span>&nbsp;<span class=citation><a name=d9874e4157 class=n-a></a>Atiani S, David SV, Elgueda D, <i> et al.</i>: Emergent selectivity for task-relevant stimuli in higher-order auditory cortex. <i>Neuron.</i> 2014; <b>82</b>(2): 48699. <a target=xrefwindow id=d9874e4168 href="http://www.ncbi.nlm.nih.gov/pubmed/24742467">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4171 href="http://dx.doi.org/10.1016/j.neuron.2014.02.029">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4175 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4048815">Free Full Text </a></span></li><li><a name=ref-124 class=n-a></a><span class=label>124. </span>&nbsp;<span class=citation><a name=d9874e4184 class=n-a></a>Rubin J, Ulanovsky N, Nelken I, <i> et al.</i>: The Representation of Prediction Error in Auditory Cortex. <i>PLoS Comput Biol.</i> 2016; <b>12</b>(8): e1005058. <a target=xrefwindow id=d9874e4195 href="http://www.ncbi.nlm.nih.gov/pubmed/27490251">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4198 href="http://dx.doi.org/10.1371/journal.pcbi.1005058">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4202 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4973877">Free Full Text </a></span></li><li><a name=ref-125 class=n-a></a><span class=label>125. </span>&nbsp;<span class=citation><a name=d9874e4211 class=n-a></a>Rao RP, Ballard DH: Predictive coding in the visual cortex: A functional interpretation of some extra-classical receptive-field effects. <i>Nat Neurosci.</i> 1999; <b>2</b>(1): 7987. <a target=xrefwindow id=d9874e4219 href="http://www.ncbi.nlm.nih.gov/pubmed/10195184">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4222 href="http://dx.doi.org/10.1038/4580">Publisher Full Text </a></span></li><li><a name=ref-126 class=n-a></a><span class=label>126. </span>&nbsp;<span class=citation><a name=d9874e4232 class=n-a></a>Friston K: A theory of cortical responses. <i>Philos Trans R Soc Lond B Biol Sci.</i> 2005; <b>360</b>(1456): 81536. <a target=xrefwindow id=d9874e4240 href="http://www.ncbi.nlm.nih.gov/pubmed/15937014">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4243 href="http://dx.doi.org/10.1098/rstb.2005.1622">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4246 href="http://www.ncbi.nlm.nih.gov/pmc/articles/1569488">Free Full Text </a></span></li><li><a name=ref-127 class=n-a></a><span class=label>127. </span>&nbsp;<span class=citation><a name=d9874e4255 class=n-a></a>Kumar S, Sedley W, Nourski KV, <i> et al.</i>: Predictive coding and pitch processing in the auditory cortex. <i>J Cogn Neurosci.</i> 2011; <b>23</b>(10): 308494. <a target=xrefwindow id=d9874e4266 href="http://www.ncbi.nlm.nih.gov/pubmed/21452943">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4269 href="http://dx.doi.org/10.1162/jocn_a_00021">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4273 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3821983">Free Full Text </a></span></li><li><a name=ref-128 class=n-a></a><span class=label>128. </span>&nbsp;<span class=citation><a name=d9874e4282 class=n-a></a>Sedley W, Gander PE, Kumar S, <i> et al.</i>: Neural signatures of perceptual inference. <i>eLife.</i> 2016; <b>5</b>: e11476. <a target=xrefwindow id=d9874e4293 href="http://www.ncbi.nlm.nih.gov/pubmed/26949254">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4296 href="http://dx.doi.org/10.7554/eLife.11476">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4300 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4841773">Free Full Text </a></span></li><li><a name=ref-129 class=n-a></a><span class=label>129. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/733394309"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e4309 class=n-a></a>Polterovich A, Jankowski MM, Nelken I: Deviance sensitivity in the auditory cortex of freely moving rats. <i>PLoS One.</i> 2018; <b>13</b>(6): e0197678. <a target=xrefwindow id=d9874e4317 href="http://www.ncbi.nlm.nih.gov/pubmed/29874246">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4320 href="http://dx.doi.org/10.1371/journal.pone.0197678">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4323 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5991388">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/733394309">F1000 Recommendation</a></span></li><li><a name=ref-130 class=n-a></a><span class=label>130. </span>&nbsp;<span class=citation><a name=d9874e4336 class=n-a></a>Parras GG, Nieto-Diego J, Carbajal GV, <i> et al.</i>: Neurons along the auditory pathway exhibit a hierarchical organization of prediction error. <i>Nat Commun.</i> 2017; <b>8</b>(1): 2148. <a target=xrefwindow id=d9874e4347 href="http://www.ncbi.nlm.nih.gov/pubmed/29247159">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4350 href="http://dx.doi.org/10.1038/s41467-017-02038-6">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4354 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5732270">Free Full Text </a></span></li><li><a name=ref-131 class=n-a></a><span class=label>131. </span>&nbsp;<span class=citation><a name=d9874e4363 class=n-a></a>Jaramillo S, Zador AM: The auditory cortex mediates the perceptual effects of acoustic temporal expectation. <i>Nat Neurosci.</i> 2011; <b>14</b>(2): 24651. <a target=xrefwindow id=d9874e4371 href="http://www.ncbi.nlm.nih.gov/pubmed/21170056">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4374 href="http://dx.doi.org/10.1038/nn.2688">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4377 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3152437">Free Full Text </a></span></li><li><a name=ref-132 class=n-a></a><span class=label>132. </span>&nbsp;<span class=citation><a name=d9874e4387 class=n-a></a>Buran BN, von Trapp G, Sanes DH: Behaviorally gated reduction of spontaneous discharge can improve detection thresholds in auditory cortex. <i>J Neurosci.</i> 2014; <b>34</b>(11): 407681. <a target=xrefwindow id=d9874e4395 href="http://www.ncbi.nlm.nih.gov/pubmed/24623785">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4398 href="http://dx.doi.org/10.1523/JNEUROSCI.4825-13.2014">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4401 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3951702">Free Full Text </a></span></li><li><a name=ref-133 class=n-a></a><span class=label>133. </span>&nbsp;<span class=citation><a name=d9874e4410 class=n-a></a>Carcea I, Insanally MN, Froemke RC: Dynamics of auditory cortical activity during behavioural engagement and auditory perception. <i>Nat Commun.</i> 2017; <b>8</b>: 14412. <a target=xrefwindow id=d9874e4418 href="http://www.ncbi.nlm.nih.gov/pubmed/28176787">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4421 href="http://dx.doi.org/10.1038/ncomms14412">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4424 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5309852">Free Full Text </a></span></li><li><a name=ref-134 class=n-a></a><span class=label>134. </span>&nbsp;<span class=citation><a name=d9874e4433 class=n-a></a>Niwa M, Johnson JS, O'Connor KN, <i> et al.</i>: Active engagement improves primary auditory cortical neurons' ability to discriminate temporal modulation. <i>J Neurosci.</i> 2012; <b>32</b>(27): 932334. <a target=xrefwindow id=d9874e4444 href="http://www.ncbi.nlm.nih.gov/pubmed/22764239">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4447 href="http://dx.doi.org/10.1523/JNEUROSCI.5832-11.2012">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4451 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3410753">Free Full Text </a></span></li><li><a name=ref-135 class=n-a></a><span class=label>135. </span>&nbsp;<span class=citation><a name=d9874e4460 class=n-a></a>von Trapp G, Buran BN, Sen K, <i> et al.</i>: A Decline in Response Variability Improves Neural Signal Detection during Auditory Task Performance. <i>J Neurosci.</i> 2016; <b>36</b>(43): 11097106. <a target=xrefwindow id=d9874e4471 href="http://www.ncbi.nlm.nih.gov/pubmed/27798189">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4474 href="http://dx.doi.org/10.1523/JNEUROSCI.1302-16.2016">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4478 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5098844">Free Full Text </a></span></li><li><a name=ref-136 class=n-a></a><span class=label>136. </span>&nbsp;<span class=citation><a name=d9874e4487 class=n-a></a>Downer JD, Niwa M, Sutter ML: Task engagement selectively modulates neural correlations in primary auditory cortex. <i>J Neurosci.</i> 2015; <b>35</b>(19): 756574. <a target=xrefwindow id=d9874e4495 href="http://www.ncbi.nlm.nih.gov/pubmed/25972181">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4498 href="http://dx.doi.org/10.1523/JNEUROSCI.4094-14.2015">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4501 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4429156">Free Full Text </a></span></li><li><a name=ref-137 class=n-a></a><span class=label>137. </span>&nbsp;<span class=citation><a name=d9874e4510 class=n-a></a>Huang Y, Matysiak A, Heil P, <i> et al.</i>: Persistent neural activity in auditory cortex is related to auditory working memory in humans and nonhuman primates. <i>eLife.</i> 2016; <b>5</b>: pii: e15441. <a target=xrefwindow id=d9874e4521 href="http://www.ncbi.nlm.nih.gov/pubmed/27438411">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4524 href="http://dx.doi.org/10.7554/eLife.15441">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4528 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4974052">Free Full Text </a></span></li><li><a name=ref-138 class=n-a></a><span class=label>138. </span>&nbsp;<span class=citation><a name=d9874e4538 class=n-a></a>Kumar S, Joseph S, Gander PE, <i> et al.</i>: A Brain System for Auditory Working Memory. <i>J Neurosci.</i> 2016; <b>36</b>(16): 4492505. <a target=xrefwindow id=d9874e4549 href="http://www.ncbi.nlm.nih.gov/pubmed/27098693">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4552 href="http://dx.doi.org/10.1523/JNEUROSCI.4341-14.2016">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4556 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4837683">Free Full Text </a></span></li><li><a name=ref-139 class=n-a></a><span class=label>139. </span>&nbsp;<span class=citation><a name=d9874e4565 class=n-a></a>Cusack R: The intraparietal sulcus and perceptual organization. <i>J Cogn Neurosci.</i> 2005; <b>17</b>(4): 64151. <a target=xrefwindow id=d9874e4573 href="http://www.ncbi.nlm.nih.gov/pubmed/15829084">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4576 href="http://dx.doi.org/10.1162/0898929053467541">Publisher Full Text </a></span></li><li><a name=ref-140 class=n-a></a><span class=label>140. </span>&nbsp;<span class=citation><a name=d9874e4585 class=n-a></a>Teki S, Chait M, Kumar S, <i> et al.</i>: Brain bases for auditory stimulus-driven figure-ground segregation. <i>J Neurosci.</i> 2011; <b>31</b>(1): 16471. <a target=xrefwindow id=d9874e4596 href="http://www.ncbi.nlm.nih.gov/pubmed/21209201">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4599 href="http://dx.doi.org/10.1523/JNEUROSCI.3788-10.2011">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4603 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3059575">Free Full Text </a></span></li><li><a name=ref-141 class=n-a></a><span class=label>141. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727191757"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e4612 class=n-a></a>Winkowski DE, Nagode DA, Donaldson KJ, <i> et al.</i>: Orbitofrontal Cortex Neurons Respond to Sound and Activate Primary Auditory Cortex Neurons. <i>Cereb Cortex.</i> 2018; <b>28</b>(3): 86879. <a target=xrefwindow id=d9874e4623 href="http://www.ncbi.nlm.nih.gov/pubmed/28069762">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4626 href="http://dx.doi.org/10.1093/cercor/bhw409">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4630 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6059099">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727191757">F1000 Recommendation</a></span></li><li><a name=ref-142 class=n-a></a><span class=label>142. </span>&nbsp;<span class=citation><a name=d9874e4643 class=n-a></a>Schneider DM, Nelson A, Mooney R: A synaptic and circuit basis for corollary discharge in the auditory cortex. <i>Nature.</i> 2014; <b>513</b>(7517): 18994. <a target=xrefwindow id=d9874e4651 href="http://www.ncbi.nlm.nih.gov/pubmed/25162524">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4654 href="http://dx.doi.org/10.1038/nature13724">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4657 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4248668">Free Full Text </a></span></li><li><a name=ref-143 class=n-a></a><span class=label>143. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/718356637"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e4666 class=n-a></a>Zhou M, Liang F, Xiong XR, <i> et al.</i>: Scaling down of balanced excitation and inhibition by active behavioral states in auditory cortex. <i>Nat Neurosci.</i> 2014; <b>17</b>(6): 84150. <a target=xrefwindow id=d9874e4677 href="http://www.ncbi.nlm.nih.gov/pubmed/24747575">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4680 href="http://dx.doi.org/10.1038/nn.3701">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4684 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4108079">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/718356637">F1000 Recommendation</a></span></li><li><a name=ref-144 class=n-a></a><span class=label>144. </span>&nbsp;<span class=citation><a name=d9874e4698 class=n-a></a>Niwa M, Johnson JS, O'Connor KN, <i> et al.</i>: Activity related to perceptual judgment and action in primary auditory cortex. <i>J Neurosci.</i> 2012; <b>32</b>(9): 3193210. <a target=xrefwindow id=d9874e4709 href="http://www.ncbi.nlm.nih.gov/pubmed/22378891">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4712 href="http://dx.doi.org/10.1523/JNEUROSCI.0767-11.2012">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4716 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3572866">Free Full Text </a></span></li><li><a name=ref-145 class=n-a></a><span class=label>145. </span>&nbsp;<span class=citation><a name=d9874e4725 class=n-a></a>Bizley JK, Walker KM, Nodal FR, <i> et al.</i>: Auditory cortex represents both pitch judgments and the corresponding acoustic cues. <i>Curr Biol.</i> 2013; <b>23</b>(7): 6205. <a target=xrefwindow id=d9874e4736 href="http://www.ncbi.nlm.nih.gov/pubmed/23523247">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4739 href="http://dx.doi.org/10.1016/j.cub.2013.03.003">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4743 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3696731">Free Full Text </a></span></li><li><a name=ref-146 class=n-a></a><span class=label>146. </span>&nbsp;<span class=citation><a name=d9874e4752 class=n-a></a>Runyan CA, Piasini E, Panzeri S, <i> et al.</i>: Distinct timescales of population coding across cortex. <i>Nature.</i> 2017; <b>548</b>(7665): 926. <a target=xrefwindow id=d9874e4763 href="http://www.ncbi.nlm.nih.gov/pubmed/28723889">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4766 href="http://dx.doi.org/10.1038/nature23020">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4770 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5859334">Free Full Text </a></span></li><li><a name=ref-147 class=n-a></a><span class=label>147. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/726008792"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e4779 class=n-a></a>Tsunada J, Liu AS, Gold JI, <i> et al.</i>: Causal contribution of primate auditory cortex to auditory perceptual decision-making. <i>Nat Neurosci.</i> 2016; <b>19</b>(1): 13542. <a target=xrefwindow id=d9874e4790 href="http://www.ncbi.nlm.nih.gov/pubmed/26656644">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4793 href="http://dx.doi.org/10.1038/nn.4195">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4797 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4696881">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/726008792">F1000 Recommendation</a></span></li><li><a name=ref-148 class=n-a></a><span class=label>148. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/3665962"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e4810 class=n-a></a>Agus TR, Thorpe SJ, Pressnitzer D: Rapid formation of robust auditory memories: Insights from noise. <i>Neuron.</i> 2010; <b>66</b>(4): 6108. <a target=xrefwindow id=d9874e4818 href="http://www.ncbi.nlm.nih.gov/pubmed/20510864">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4821 href="http://dx.doi.org/10.1016/j.neuron.2010.04.014">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/3665962">F1000 Recommendation</a></span></li><li><a name=ref-149 class=n-a></a><span class=label>149. </span>&nbsp;<span class=citation><a name=d9874e4834 class=n-a></a>Viswanathan J, Rmy F, Bacon-Mac N, <i> et al.</i>: Long Term Memory for Noise: Evidence of Robust Encoding of Very Short Temporal Acoustic Patterns. <i>Front Neurosci.</i> 2016; <b>10</b>: 490. <a target=xrefwindow id=d9874e4845 href="http://www.ncbi.nlm.nih.gov/pubmed/27932941">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4848 href="http://dx.doi.org/10.3389/fnins.2016.00490">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4852 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5121232">Free Full Text </a></span></li><li><a name=ref-150 class=n-a></a><span class=label>150. </span>&nbsp;<span class=citation><a name=d9874e4862 class=n-a></a>McDermott JH, Schemitsch M, Simoncelli EP: Summary statistics in auditory perception. <i>Nat Neurosci.</i> 2013; <b>16</b>(4): 4938. <a target=xrefwindow id=d9874e4870 href="http://www.ncbi.nlm.nih.gov/pubmed/23434915">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4873 href="http://dx.doi.org/10.1038/nn.3347">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4876 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4143328">Free Full Text </a></span></li><li><a name=ref-151 class=n-a></a><span class=label>151. </span>&nbsp;<span class=citation><a name=d9874e4885 class=n-a></a>Yaron A, Hershenhoren I, Nelken I: Sensitivity to complex statistical regularities in rat auditory cortex. <i>Neuron.</i> 2012; <b>76</b>(3): 60315. <a target=xrefwindow id=d9874e4893 href="http://www.ncbi.nlm.nih.gov/pubmed/23141071">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4896 href="http://dx.doi.org/10.1016/j.neuron.2012.08.025">Publisher Full Text </a></span></li><li><a name=ref-152 class=n-a></a><span class=label>152. </span>&nbsp;<span class=citation><a name=d9874e4905 class=n-a></a>Lu K, Vicario DS: Statistical learning of recurring sound patterns encodes auditory objects in songbird forebrain. <i>Proc Natl Acad Sci U S A.</i> 2014; <b>111</b>(40): 145538. <a target=xrefwindow id=d9874e4913 href="http://www.ncbi.nlm.nih.gov/pubmed/25246563">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4916 href="http://dx.doi.org/10.1073/pnas.1412109111">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4919 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4210023">Free Full Text </a></span></li><li><a name=ref-153 class=n-a></a><span class=label>153. </span>&nbsp;<span class=citation><a name=d9874e4928 class=n-a></a>Wilson B, Kikuchi Y, Sun L, <i> et al.</i>: Auditory sequence processing reveals evolutionarily conserved regions of frontal cortex in macaques and humans. <i>Nat Commun.</i> 2015; <b>6</b>: 8901. <a target=xrefwindow id=d9874e4939 href="http://www.ncbi.nlm.nih.gov/pubmed/26573340">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4942 href="http://dx.doi.org/10.1038/ncomms9901">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4946 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4660034">Free Full Text </a></span></li><li><a name=ref-154 class=n-a></a><span class=label>154. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727550670"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e4955 class=n-a></a>Kikuchi Y, Attaheri A, Wilson B, <i> et al.</i>: Sequence learning modulates neural responses and oscillatory coupling in human and monkey auditory cortex. <i>PLoS Biol.</i> 2017; <b>15</b>(4): e2000219. <a target=xrefwindow id=d9874e4966 href="http://www.ncbi.nlm.nih.gov/pubmed/28441393">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4969 href="http://dx.doi.org/10.1371/journal.pbio.2000219">Publisher Full Text </a> | <a target=xrefwindow id=d9874e4973 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5404755">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727550670">F1000 Recommendation</a></span></li><li><a name=ref-155 class=n-a></a><span class=label>155. </span>&nbsp;<span class=citation><a name=d9874e4986 class=n-a></a>Giraud AL, Poeppel D: Cortical oscillations and speech processing: emerging computational principles and operations. <i>Nat Neurosci.</i> 2012; <b>15</b>(4): 5117. <a target=xrefwindow id=d9874e4994 href="http://www.ncbi.nlm.nih.gov/pubmed/22426255">PubMed Abstract </a> | <a target=xrefwindow id=d9874e4997 href="http://dx.doi.org/10.1038/nn.3063">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5000 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4461038">Free Full Text </a></span></li><li><a name=ref-156 class=n-a></a><span class=label>156. </span>&nbsp;<span class=citation><a name=d9874e5010 class=n-a></a>White EJ, Hutka SA, Williams LJ, <i> et al.</i>: Learning, neural plasticity and sensitive periods: implications for language acquisition, music training and transfer across the lifespan. <i>Front Syst Neurosci.</i> 2013; <b>7</b>: 90. <a target=xrefwindow id=d9874e5021 href="http://www.ncbi.nlm.nih.gov/pubmed/24312022">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5024 href="http://dx.doi.org/10.3389/fnsys.2013.00090">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5028 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3834520">Free Full Text </a></span></li><li><a name=ref-157 class=n-a></a><span class=label>157. </span>&nbsp;<span class=citation><a name=d9874e5037 class=n-a></a>Irvine DRF: Plasticity in the auditory system. <i>Hear Res.</i> 2018; <b>362</b>: 6173. <a target=xrefwindow id=d9874e5045 href="http://www.ncbi.nlm.nih.gov/pubmed/29126650">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5048 href="http://dx.doi.org/10.1016/j.heares.2017.10.011">Publisher Full Text </a></span></li><li><a name=ref-158 class=n-a></a><span class=label>158. </span>&nbsp;<span class=citation><a name=d9874e5057 class=n-a></a>Bieszczad KM, Weinberger NM: Representational gain in cortical area underlies increase of memory strength. <i>Proc Natl Acad Sci U S A.</i> 2010; <b>107</b>(8): 37938. <a target=xrefwindow id=d9874e5065 href="http://www.ncbi.nlm.nih.gov/pubmed/20133679">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5068 href="http://dx.doi.org/10.1073/pnas.1000159107">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5071 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2840533">Free Full Text </a></span></li><li><a name=ref-159 class=n-a></a><span class=label>159. </span>&nbsp;<span class=citation><a name=d9874e5080 class=n-a></a>Reed A, Riley J, Carraway R, <i> et al.</i>: Cortical map plasticity improves learning but is not necessary for improved performance. <i>Neuron.</i> 2011; <b>70</b>(1): 12131. <a target=xrefwindow id=d9874e5091 href="http://www.ncbi.nlm.nih.gov/pubmed/21482361">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5094 href="http://dx.doi.org/10.1016/j.neuron.2011.02.038">Publisher Full Text </a></span></li><li><a name=ref-160 class=n-a></a><span class=label>160. </span>&nbsp;<span class=citation><a name=d9874e5103 class=n-a></a>Elias GA, Bieszczad KM, Weinberger NM: Learning strategy refinement reverses early sensory cortical map expansion but not behavior: Support for a theory of directed cortical substrates of learning and memory. <i>Neurobiol Learn Mem.</i> 2015; <b>126</b>: 3955. <a target=xrefwindow id=d9874e5111 href="http://www.ncbi.nlm.nih.gov/pubmed/26596700">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5114 href="http://dx.doi.org/10.1016/j.nlm.2015.10.006">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5117 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4674018">Free Full Text </a></span></li><li><a name=ref-161 class=n-a></a><span class=label>161. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/729805043"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e5126 class=n-a></a>Caras ML, Sanes DH: Top-down modulation of sensory cortex gates perceptual learning. <i>Proc Natl Acad Sci U S A.</i> 2017; <b>114</b>(37): 99727. <a target=xrefwindow id=d9874e5134 href="http://www.ncbi.nlm.nih.gov/pubmed/28847938">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5137 href="http://dx.doi.org/10.1073/pnas.1712305114">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5140 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5604044">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/729805043">F1000 Recommendation</a></span></li><li><a name=ref-162 class=n-a></a><span class=label>162. </span>&nbsp;<span class=citation><a name=d9874e5154 class=n-a></a>Nodal FR, Bajo VM, King AJ: Plasticity of spatial hearing: behavioural effects of cortical inactivation. <i>J Physiol.</i> 2012; <b>590</b>(16): 396586. <a target=xrefwindow id=d9874e5162 href="http://www.ncbi.nlm.nih.gov/pubmed/22547635">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5165 href="http://dx.doi.org/10.1113/jphysiol.2011.222828">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5168 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3464400">Free Full Text </a></span></li><li><a name=ref-163 class=n-a></a><span class=label>163. </span>&nbsp;<span class=citation><a name=d9874e5177 class=n-a></a>Keating P, Dahmen JC, King AJ: Context-specific reweighting of auditory spatial cues following altered experience during development. <i>Curr Biol.</i> 2013; <b>23</b>(14): 12919. <a target=xrefwindow id=d9874e5185 href="http://www.ncbi.nlm.nih.gov/pubmed/23810532">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5188 href="http://dx.doi.org/10.1016/j.cub.2013.05.045">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5191 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3722484">Free Full Text </a></span></li><li><a name=ref-164 class=n-a></a><span class=label>164. </span>&nbsp;<span class=citation><a name=d9874e5200 class=n-a></a>Trapeau R, Schnwiesner M: The Encoding of Sound Source Elevation in the Human Auditory Cortex. <i>J Neurosci.</i> 2018; <b>38</b>(13): 325264. <a target=xrefwindow id=d9874e5208 href="http://www.ncbi.nlm.nih.gov/pubmed/29507148">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5211 href="http://dx.doi.org/10.1523/JNEUROSCI.2530-17.2018">Publisher Full Text </a></span></li><li><a name=ref-165 class=n-a></a><span class=label>165. </span>&nbsp;<span class=citation><a name=d9874e5220 class=n-a></a>Polley DB, Steinberg EE, Merzenich MM: Perceptual learning directs auditory cortical map reorganization through top-down influences. <i>J Neurosci.</i> 2006; <b>26</b>(18): 497082. <a target=xrefwindow id=d9874e5228 href="http://www.ncbi.nlm.nih.gov/pubmed/16672673">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5231 href="http://dx.doi.org/10.1523/JNEUROSCI.3771-05.2006">Publisher Full Text </a></span></li><li><a name=ref-166 class=n-a></a><span class=label>166. </span>&nbsp;<span class=citation><a name=d9874e5240 class=n-a></a>Froemke RC, Carcea I, Barker AJ, <i> et al.</i>: Long-term modification of cortical synapses improves sensory perception. <i>Nat Neurosci.</i> 2013; <b>16</b>(1): 7988. <a target=xrefwindow id=d9874e5251 href="http://www.ncbi.nlm.nih.gov/pubmed/23178974">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5254 href="http://dx.doi.org/10.1038/nn.3274">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5258 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3711827">Free Full Text </a></span></li><li><a name=ref-167 class=n-a></a><span class=label>167. </span>&nbsp;<span class=citation><a name=d9874e5267 class=n-a></a>Leach ND, Nodal FR, Cordery PM, <i> et al.</i>: Cortical cholinergic input is required for normal auditory perception and experience-dependent plasticity in adult ferrets. <i>J Neurosci.</i> 2013; <b>33</b>(15): 665971. <a target=xrefwindow id=d9874e5278 href="http://www.ncbi.nlm.nih.gov/pubmed/23575862">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5281 href="http://dx.doi.org/10.1523/JNEUROSCI.5039-12.2013">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5285 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3682393">Free Full Text </a></span></li><li><a name=ref-168 class=n-a></a><span class=label>168. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/725736296"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e5295 class=n-a></a>Martins AR, Froemke RC: Coordinated forms of noradrenergic plasticity in the locus coeruleus and primary auditory cortex. <i>Nat Neurosci.</i> 2015; <b>18</b>(10): 148392. <a target=xrefwindow id=d9874e5303 href="http://www.ncbi.nlm.nih.gov/pubmed/26301326">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5306 href="http://dx.doi.org/10.1038/nn.4090">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5309 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4583810">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/725736296">F1000 Recommendation</a></span></li><li><a name=ref-169 class=n-a></a><span class=label>169. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/733375063"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e5322 class=n-a></a>Glennon E, Carcea I, Martins ARO, <i> et al.</i>: Locus coeruleus activation accelerates perceptual learning. <i>Brain Res.</i> 2018; pii: S0006-8993(18)30324-X <a target=xrefwindow id=d9874e5330 href="http://www.ncbi.nlm.nih.gov/pubmed/29859972">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5333 href="http://dx.doi.org/10.1016/j.brainres.2018.05.048">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/733375063">F1000 Recommendation</a></span></li><li><a name=ref-170 class=n-a></a><span class=label>170. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/726314067"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e5346 class=n-a></a>Nelson A, Mooney R: The Basal Forebrain and Motor Cortex Provide Convergent yet Distinct Movement-Related Inputs to the Auditory Cortex. <i>Neuron.</i> 2016; <b>90</b>(3): 63548. <a target=xrefwindow id=d9874e5354 href="http://www.ncbi.nlm.nih.gov/pubmed/27112494">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5357 href="http://dx.doi.org/10.1016/j.neuron.2016.03.031">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5360 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4866808">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/726314067">F1000 Recommendation</a></span></li><li><a name=ref-171 class=n-a></a><span class=label>171. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/726906588"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e5373 class=n-a></a>Kuchibhotla KV, Gill JV, Lindsay GW, <i> et al.</i>: Parallel processing by cortical inhibition enables context-dependent behavior. <i>Nat Neurosci.</i> 2017; <b>20</b>(1): 6271. <a target=xrefwindow id=d9874e5384 href="http://www.ncbi.nlm.nih.gov/pubmed/27798631">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5387 href="http://dx.doi.org/10.1038/nn.4436">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5391 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5191967">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/726906588">F1000 Recommendation</a></span></li><li><a name=ref-172 class=n-a></a><span class=label>172. </span>&nbsp;<span class=citation><a name=d9874e5404 class=n-a></a>Carcea I, Froemke RC: Cortical plasticity, excitatory-inhibitory balance, and sensory perception. <i>Prog Brain Res.</i> 2013; <b>207</b>: 6590. <a target=xrefwindow id=d9874e5412 href="http://www.ncbi.nlm.nih.gov/pubmed/24309251">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5415 href="http://dx.doi.org/10.1016/B978-0-444-63327-9.00003-5">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5418 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4300113">Free Full Text </a></span></li><li><a name=ref-173 class=n-a></a><span class=label>173. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/725373740"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e5427 class=n-a></a>Xiong Q, Znamenskiy P, Zador AM: Selective corticostriatal plasticity during acquisition of an auditory discrimination task. <i>Nature.</i> 2015; <b>521</b>(7552): 34851. <a target=xrefwindow id=d9874e5435 href="http://www.ncbi.nlm.nih.gov/pubmed/25731173">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5438 href="http://dx.doi.org/10.1038/nature14225">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5441 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4454418">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/725373740">F1000 Recommendation</a></span></li><li><a name=ref-174 class=n-a></a><span class=label>174. </span>&nbsp;<span class=citation><a name=d9874e5455 class=n-a></a>Bajo VM, Nodal FR, Moore DR, <i> et al.</i>: The descending corticocollicular pathway mediates learning-induced auditory plasticity. <i>Nat Neurosci.</i> 2010; <b>13</b>(2): 25360. <a target=xrefwindow id=d9874e5466 href="http://www.ncbi.nlm.nih.gov/pubmed/20037578">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5469 href="http://dx.doi.org/10.1038/nn.2466">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5473 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3634157">Free Full Text </a></span></li><li><a name=ref-175 class=n-a></a><span class=label>175. </span>&nbsp;<span class=citation><a name=d9874e5482 class=n-a></a>Kraus N, White-Schwoch T: Unraveling the Biology of Auditory Learning: A Cognitive-Sensorimotor-Reward Framework. <i>Trends Cogn Sci.</i> 2015; <b>19</b>(11): 64254. <a target=xrefwindow id=d9874e5490 href="http://www.ncbi.nlm.nih.gov/pubmed/26454481">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5493 href="http://dx.doi.org/10.1016/j.tics.2015.08.017">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5496 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4754986">Free Full Text </a></span></li><li><a name=ref-176 class=n-a></a><span class=label>176. </span>&nbsp;<span class=citation><a name=d9874e5505 class=n-a></a>Bidelman GM, Schneider AD, Heitzmann VR, <i> et al.</i>: Musicianship enhances ipsilateral and contralateral efferent gain control to the cochlea. <i>Hear Res.</i> 2017; <b>344</b>: 27583. <a target=xrefwindow id=d9874e5516 href="http://www.ncbi.nlm.nih.gov/pubmed/27964936">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5519 href="http://dx.doi.org/10.1016/j.heares.2016.12.001">Publisher Full Text </a></span></li><li><a name=ref-177 class=n-a></a><span class=label>177. </span>&nbsp;<span class=citation><a name=d9874e5528 class=n-a></a>Xiong XR, Liang F, Zingg B, <i> et al.</i>: Auditory cortex controls sound-driven innate defense behaviour through corticofugal projections to inferior colliculus. <i>Nat Commun.</i> 2015; <b>6</b>: 7224. <a target=xrefwindow id=d9874e5539 href="http://www.ncbi.nlm.nih.gov/pubmed/26068082">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5542 href="http://dx.doi.org/10.1038/ncomms8224">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5546 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4467028">Free Full Text </a></span></li><li><a name=ref-178 class=n-a></a><span class=label>178. </span>&nbsp;<span class=citation><a name=d9874e5555 class=n-a></a>Robinson BL, Harper NS, McAlpine D: Meta-adaptation in the auditory midbrain under cortical influence. <i>Nat Commun.</i> 2016; <b>7</b>: 13442. <a target=xrefwindow id=d9874e5563 href="http://www.ncbi.nlm.nih.gov/pubmed/27883088">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5566 href="http://dx.doi.org/10.1038/ncomms13442">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5569 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5123015">Free Full Text </a></span></li><li><a name=ref-179 class=n-a></a><span class=label>179. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727730643"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d9874e5578 class=n-a></a>Guo W, Clause AR, Barth-Maron A, <i> et al.</i>: A Corticothalamic Circuit for Dynamic Switching between Feature Detection and Discrimination. <i>Neuron.</i> 2017; <b>95</b>(1): 180194.e5. <a target=xrefwindow id=d9874e5589 href="http://www.ncbi.nlm.nih.gov/pubmed/28625486">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5592 href="http://dx.doi.org/10.1016/j.neuron.2017.05.019">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5596 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5568886">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727730643">F1000 Recommendation</a></span></li><li><a name=ref-180 class=n-a></a><span class=label>180. </span>&nbsp;<span class=citation><a name=d9874e5610 class=n-a></a>Homma NY, Happel MFK, Nodal FR, <i> et al.</i>: A Role for Auditory Corticothalamic Feedback in the Perception of Complex Sounds. <i>J Neurosci.</i> 2017; <b>37</b>(25): 614961. <a target=xrefwindow id=d9874e5621 href="http://www.ncbi.nlm.nih.gov/pubmed/28559384">PubMed Abstract </a> | <a target=xrefwindow id=d9874e5624 href="http://dx.doi.org/10.1523/JNEUROSCI.0397-17.2017">Publisher Full Text </a> | <a target=xrefwindow id=d9874e5628 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5481946">Free Full Text </a></span></li></ul></div></div></div> </div> <div id=article-comments class="article-comments padding-bottom-20"> <div class=current-article-comment-section> <h2 class=main-title name=add-new-comment id=add-new-comment> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-104_comments size30"></span> </span> <span class=f1r-article-desk-inline>Comments on this article</span> <span class=f1r-article-mobile-inline>Comments (0)</span> <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> </div> <div class="f1r-article-desk-inline referee-report-info-box referee-report-version-box"> Version 1 </div> <div class="f1r-article-mobile research-layout mobile-version-info padding-top-30"> <span class=mversion>VERSION 1</span> <span class=details>PUBLISHED 26 Sep 2018</span> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div class="f1r-article-mobile research-layout margin-top-20 is-centered"> <a href="/login?originalPath=/articles/7-1555.html&scrollTo=add-new-comment" class=register-report-comment-button data-test-id=add-comment_mob> <button class="primary orange extra-padding comment-on-this-report">ADD YOUR COMMENT</button> </a> </div> <a href="/login?originalPath=/articles/7-1555.html&scrollTo=add-new-comment" class="f1r-article-desk register-report-comment-button" data-test-id=add-comment> <span class=contracted></span>Comment </a> </div> <div class="f1r-article-mobile margin-bottom-30"> <div class=contracted-details> <a href="#" class="contracted-details-label author-affiliations"><span class=contracted></span>Author details</a> <a href="#" class=section-title>Author details</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details affiliations is-hidden"> Department of Physiology, Anatomy &amp; Genetics, University of Oxford, Oxford, OX1 3PT, UK<br/> <p> <div class=margin-bottom> Andrew J. King <br/> <span>Roles: </span> Conceptualization, Funding Acquisition, Writing  Original Draft Preparation, Writing  Review & Editing </div> <div class=margin-bottom> Sundeep Teki <br/> <span>Roles: </span> Conceptualization, Funding Acquisition, Writing  Original Draft Preparation </div> <div class=margin-bottom> Ben D.B. Willmore <br/> <span>Roles: </span> Conceptualization, Writing  Original Draft Preparation, Writing  Review & Editing </div> </p> </div> </div> <div class=contracted-details> <a href="#" class=section-title>Article Versions (1)</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details grant-information article-page is-hidden"> <div> <a href="https://f1000research.com/articles/7-1555/v1" title="Open version 1 of this article." class="" gahelper=1>version 1</a> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div> Published: 26 Sep 2018, 7:1555 </div> <div class=""><a href="https://doi.org/10.12688/f1000research.15580.1">https://doi.org/10.12688/f1000research.15580.1</a></div> </div> </div> <div class=contracted-details> <a href="#" class=section-title> <span class="f1r-icon icon-100_open_access"></span> Copyright </a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details grant-information article-page is-hidden">  2018 King AJ <em>et al</em>. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/" target=_blank data-test-id=box-licence-link>Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. </div> </div> <div class="padding-top-30 research-layout"> <div class=article-toolbox-wrapper-mobile> <div class=article-tools-icon-mobile data-section=download> <span class="f1r-icon icon-76_download_file white"></span> </div> <div class="article-tools-icon-mobile mobile-metrics article-metrics-wrapper metrics-icon-wrapper" data-section=metrics data-version-id=16995 data-id=15580 data-downloads="" data-views="" data-scholar="10.12688/f1000research.15580.1" data-recommended="" data-f1r-ga-helper="Article Page Metrics (Mobile)"> <span class="f1r-icon icon-89_metrics white"></span> </div> <div class=article-tools-divider-mobile></div> <div class=article-tools-icon-mobile data-section=cite> <span class="f1r-icon icon-82_quote white"></span> </div> <div class="article-tools-icon-mobile " data-section=track> <span class="f1r-icon icon-90_track white"></span> </div> <div class=article-tools-divider-mobile></div> <div class=article-tools-icon-mobile data-section=share> <span class="f1r-icon icon-34_share white"></span> </div> <span class=article-toolbox-stretch></span> </div> <div class=article-toolbox-content-mobile> <div class="toolbox-section download"> <div class=toolbox-section-heading>Download</div> <div class=toolbox-section-content> <a href="https://f1000research.com/articles/7-1555/v1/pdf?article_uuid=8a8fb5c8-0d07-4778-9896-5f526a15f5db" title="Download PDF" class="no-decoration pdf-download-helper"> <span class="f1r-icon icon-102_download_pdf toolbox-section-icon"></span> </a> <div class=toolbox-section-option-divider>&nbsp;</div> <a id=mobile-download-xml class=no-decoration href="#" title="Download XML"> <span class="f1r-icon icon-103_download_xml toolbox-section-icon"></span> </a> </div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>Export To</div> <div class=toolbox-section-content> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=WORKSPACE>Sciwheel</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=BIBTEX>Bibtex</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=ENDNOTE>EndNote</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=PROCITE>ProCite</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=REF_MANAGER>Ref. Manager (RIS)</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=SENTE>Sente</button> </div> </div> <div class="toolbox-section metrics"> <div class="toolbox-section-heading no-top-border">metrics</div> <div class="toolbox-section-divider toolbox-section-divider--no-height"></div> <div class=article-metrics-pageinfo> <div class=c-article-metrics-table> <table class=c-article-metrics-table__table> <thead> <tr> <th></th> <th><span class=c-article-metrics-table__heading>Views</span></th> <th><span class=c-article-metrics-table__heading>Downloads</span></th> </tr> </thead> <tbody> <tr> <th class=c-article-metrics-table__row-heading><span class="c-article-metrics-table__platform u-platform--" data-test-id=metrics_platform_name_mob>F1000Research</span></th> <td class="c-article-metrics-table__value js-article-views-count" data-test-id=metrics_platform_views_mob>-</td> <td class="c-article-metrics-table__value js-article-downloads-count" data-test-id=metrics_platform_downloads_mob>-</td> </tr> <tr> <th class=c-article-metrics-table__row-heading> <span class="u-ib u-middle c-article-metrics-table__pmc" data-test-id=metrics_pmc_name_mob>PubMed Central</span> <div class="c-block-tip c-block-tip--centered c-article-metrics-table__tooltip c-block-tip--md-padding c-block-tip--small-arrow u-ib u-middle"> <button type=button class="u-black--medium u-black--high@hover u-ib u-middle c-button--icon c-button--text c-block-tip__toggle"><i class="material-icons c-button--icon__icon">info_outline</i></button> <div class=c-block-tip__content>Data from PMC are received and updated monthly.</div> </div> </th> <td class="c-article-metrics-table__value js-pmc-views-count" data-test-id=metrics_pmc_views_mob>-</td> <td class="c-article-metrics-table__value js-pmc-downloads-count" data-test-id=metrics_pmc_downloads_mob>-</td> </tr> </tbody> </table> </div> </div> <span class=metrics-citations-container> <div class=toolbox-section-divider></div> <div class="toolbox-section-heading u-mb--1">Citations</div> <div> <div class=toolbox-section-colsplit> <div class=citations-scopus-logo> <a href="" target=_blank class="is-hidden metrics-citation-icon" title="View full citation details at www.scopus.com"><i class="material-icons scopus-icon">open_in_new</i></a> </div> <div class="toolbox-section-count scopus"> <a href='' class='scopus-citation-link is-hidden' target=_blank title='View full citation details at www.scopus.com'>0</a> </div> </div> <div class=toolbox-section-colsplit> <div class="citations-pubmed-logo f1000research"> <a href="" target=_blank class="is-hidden metrics-citation-icon f1000research" title="View full citation details"><i class="material-icons scopus-icon">open_in_new</i></a> </div> <div class="toolbox-section-count pubmed"> <a href='' class='pubmed-citation-link is-hidden' target=_blank title='View full citation details'>0</a> </div> </div> <div class=toolbox-section-divider></div> <div class=toolbox-section-content> <div class="citations-scholar-logo f1000research"> <a href="" target=_blank class="is-hidden metrics-citation-icon google-scholar f1000research" title="View full citation details" data-scholar="10.12688/f1000research.15580.1"><i class="material-icons scopus-icon">open_in_new</i></a> </div> </div> </div> </span> <span class=metrics-details-container> <div class=toolbox-section-divider></div> <div class="toolbox-section-content altmetric-section"> <div class=altmetrics-image></div> <div class=altmetrics-more-link> <a href="" target=_blank class=f1r-standard-link>SEE MORE DETAILS</a> </div> <div class=altmetric-mobile-column-counts></div> <div class=altmetric-mobile-column-readers></div> <div class=toolbox-section-divider></div> </div> </span> </div> <div class="toolbox-section cite"> <div class="toolbox-section-heading no-top-border">CITE</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>how to cite this article</div> <div id=citation-copy-mobile class="toolbox-section-content text-content heading9 small" data-test-id=mob_copy-citation_text> King AJ, Teki S and Willmore BDB. Recent advances in understanding the auditory cortex [version 1; peer review: 2 approved] <i>F1000Research</i> 2018, <b>7</b>(F1000 Faculty Rev):1555 (<a href="https://doi.org/10.12688/f1000research.15580.1" target=_blank>https://doi.org/10.12688/f1000research.15580.1</a>) </div> <div class=toolbox-section-divider></div> <div class="toolbox-section-content text-content heading9 small"> NOTE: <em>it is important to ensure the information in <b>square brackets after the title</b> is included in all citations of this article.</em> </div> <div class=toolbox-section-content> <button class="primary orange extra-padding copy-cite-article-mobile js-clipboard" data-clipboard-target="#citation-copy-mobile" title="Copy the current citation details." data-test-id=mob_copy-citation_button-mob>COPY CITATION DETAILS</button> </div> </div> <div class="toolbox-section track"> <div class="toolbox-section-heading no-top-border">track</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>receive updates on this article</div> <div class="toolbox-section-content padding-left-20 padding-right-20 heading9 small"> Track an article to receive email alerts on any updates to this article. </div> <div class=toolbox-section-content> <a data-article-id=15580 id=mobile-track-article-signin-15580 title="Receive updates on new activity such as publication of new versions, peer reviews or author responses." href="/login?originalPath=/trackArticle/15580?target=/articles/7-1555.html"> <button class="primary orange extra-padding"> TRACK THIS ARTICLE </button> </a> </div> </div> <div class="toolbox-section share"> <div class="toolbox-section-heading no-top-border">Share</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-content> <a target=_blank class="f1r-shares-icon-square f1r-shares-email" title="Email this article"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-twitter" title="Share on Twitter"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-facebook" title="Share on Facebook"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-linkedin" title="Share on LinkedIn"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-reddit" title="Share on Reddit"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-mendelay" title="Share on Mendeley"></a> <div class="email-article-wrapper email-article-version-container"> <div class=toolbox-section-divider></div> <script src='https://www.recaptcha.net/recaptcha/api.js'></script> <form class="recommend-version-form-mobile research-layout"> <p>All fields are required.</p> <input name=versionId type=hidden value=16995 /> <input name=articleId type=hidden value=15580 /> <input name=senderName class="form-input-field reg-form" value="" type=text placeholder="Your name"/> <input name=senderEmail class="form-input-field reg-form margin-top" value="" type=text placeholder="Your email address"/> <textarea name=recipientEmails class="form-textarea-field ninetynine-percent-wide margin-top no-resize" placeholder="Recipient email address(es) (comma delimited)"></textarea> <input class="form-input-field reg-form margin-top" name=subject type=text value="Interesting article on F1000Research" placeholder=Subject /> <textarea name=message class="form-textarea-field reg-form margin-top no-resize">I thought this article from F1000Research (https://f1000research.com) would be of interest to you.</textarea> <div class="g-recaptcha margin-top" data-sitekey=6LcHqxoUAAAAANP3_0TzpGG6qFvl4DhbUcuRzw7W></div> <input value="" name=captcha type=hidden /> <p>A full article citation will be automatically included.</p> <p><img class="ticker-email-article-details hidden" src="/img/ticker.gif" alt=loading /></p> <button class="secondary orange margin-bottom" data-test-id=version_share_email_send>SEND EMAIL</button> <div class="orange-message margin-bottom is-hidden" data-test-id=version_share_email_message></div> </form> </div> </div> </div> </div> </div> <a name=article-reports></a> <div id=article-reports class="u-mt--3 reports-comments no-divider"> <div class="current-referee-status current-referee-status--faculty "> <h2 class=main-title id=current-referee-status> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-85_peer_review size30"></span> </span> Open Peer Review <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> <a name=current-referee-status></a> <div class=current-referee-status__content name=add-new-report-comment id=add-new-report-comment> Current Reviewer Status: <span class="research-layout f1r-article-desk-inline"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-mobile float-right"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-desk-inline"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-mobile float-right"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-mobile"> <div class=mobile-ref-status-help> Key to Reviewer Statuses <span class=referee-status-pointer></span> <span class="view-control float-right">VIEW</span> <span class="view-control float-right is-hidden">HIDE</span> <div class=mobile-ref-status-help-content> <div class="cf margin-top"> <span class="f1r-icon icon-86_approved status-green smaller float-left margin-bottom-40 margin-right" title=Approved></span> <span class=title>Approved</span>The paper is scientifically sound in its current form and only minor, if any, improvements are suggested </div> <div class="cf margin-top"> <span class="f1r-icon icon-87_approved_reservations status-green smaller float-left margin-bottom-40 margin-right" title="Approved with Reservations"></span> <span class=title>Approved with reservations</span> A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </div> <div class="cf margin-top"> <span class="f1r-icon icon-88_not_approved status-red small float-left margin-bottom-30 margin-right" title="Not Approved"></span> <span class=title>Not approved</span>Fundamental flaws in the paper seriously undermine the findings and conclusions </div> </div> </div> </span> <div class=editorial-note> <h5 class=editorial-note__title>Editorial Note on the Review Process</h5> <p class=editorial-note__text><a href="/browse/faculty-reviews">Faculty Reviews</a> are review articles written by the prestigious Members of <a href="https://facultyopinions.com/prime/home">Faculty Opinions</a>. The articles are commissioned and peer reviewed before publication to ensure that the final, published version is comprehensive and accessible. The reviewers who approved the final version are listed with their names and affiliations.</p> </div> <div class=approved-referee> <h4 class=approved-referee__title>Reviewers who approved this article</h4> <ol class=approved-referee__list> <li class="approved-referee__list-item "> <span class=approved-referee__co-referee> <strong>Christoph Schreiner</strong>, UCSF Center for Integrative Neuroscience, University of California San Francisco, USA </span> <span class=approved-referee__competing-list> <strong>Competing interests:</strong> No competing interests were declared. (for version 1) <br> </span> </li> <li class="approved-referee__list-item margin-top-20"> <span class=approved-referee__co-referee> <strong>Shihab Shamma</strong>, Department of Electrical & Computer Engineering, University of Maryland, USA; The Institute for Systems Research, University of Maryland, USA </span> <span class=approved-referee__competing-list> <strong>Competing interests:</strong> No competing interests were declared. (for version 1) <br> </span> </li> </ol> </div> </div> </div> </div> <div class="f1r-article-mobile research-layout"> <div class="mobile-sections-divider before-comments"></div> </div> <div id=article-comments class="article-comments padding-bottom-20"> <div class=current-article-comment-section> <h2 class=main-title name=add-new-comment id=add-new-comment> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-104_comments size30"></span> </span> <span class=f1r-article-desk-inline>Comments on this article</span> <span class=f1r-article-mobile-inline>Comments (0)</span> <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> </div> <div class="f1r-article-desk-inline referee-report-info-box referee-report-version-box"> Version 1 </div> <div class="f1r-article-mobile research-layout mobile-version-info padding-top-30"> <span class=mversion>VERSION 1</span> <span class=details>PUBLISHED 26 Sep 2018</span> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div class="f1r-article-mobile research-layout margin-top-20 is-centered"> <a href="/login?originalPath=/articles/7-1555.html&scrollTo=add-new-comment" class=register-report-comment-button data-test-id=add-comment_mob> <button class="primary orange extra-padding comment-on-this-report">ADD YOUR COMMENT</button> </a> </div> <a href="/login?originalPath=/articles/7-1555.html&scrollTo=add-new-comment" class="f1r-article-desk register-report-comment-button" data-test-id=add-comment> <span class=contracted></span>Comment </a> </div> </div> </div> <div id=article_main-column class="p-article__sidebar o-layout__item u-1/3 not-expanded js-article-sidebar"> <div class="o-tab p-article__column-toggle-container"> <button class="c-tab c-tab--left js-column-toggle p-article__column-toggle not-expanded " type=button data-target-main=article_main-column data-target-secondary=article_secondary-column><i class="c-tab__icon material-icons u-hide@expanded">keyboard_arrow_left</i><i class="c-tab__icon material-icons u-show@expanded">keyboard_arrow_right</i></button> </div> <div class=p-article__sidebar-content> <div class="p-article__sidebar-scroller js-article-sidebar-scroller"> <section class="p-article__sidebar-view js-article-sidebar-view js-article-sidebar-main u-pt u-pb--8" data-view=peer-review> <div class="o-layout o-layout--flush"> <div class="o-layout__item u-pl"> <h3 class="u-mt--0 u-mb--2 t-h3 u-weight--md u-pl" data-test-id=article_sidebar_heading>Open Peer Review</h3> </div> <div class=o-layout__item> <section class=""> <div class="p-article__sidebar-highlight u-mb--2 u-pr--1"> <div class="o-actions o-actions--middle"> <div class=o-actions__primary> <h4 class="u-mt--0 u-mb--0 u-ib u-middle t-h4 u-weight--md u-mr--1/2">Reviewer Status</h4> <div class="c-referee-status__icons u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--approved " title=Approved #data-refInfo=23534-38455></i> <i class="c-icn--f1r-icon c-icn--approved " title=Approved #data-refInfo=39296-38454></i> </div> </div> <div class="o-actions__secondary _mdl-layout"> <div class="c-block-tip p-article__sidebar-tooltip c-block-tip--below c-block-tip--small-arrow c-block-tip--sm-padding"> <button type=button class="c-button c-button--icon c-button--text c-block-tip__toggle"><i class="material-icons c-button--icon__icon">info_outline</i></button> <div class=c-block-tip__content> <p class="t-body u-mt--0 u-mb--0"><em class=u-weight--md>Alongside their report, reviewers assign a status to the article:</em></p> <dl class=c-definitions> <dt class="c-definitions__term u-upper t-control u-weight--md u-black--high"><span class="u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--approved " title=Approved #data-refInfo=""></i> </span> <span class="u-middle u-ib u-ml--1/2">Approved</span></dt> <dd class="c-definitions__description t-caption">The paper is scientifically sound in its current form and only minor, if any, improvements are suggested</dd> <dt class="c-definitions__term u-upper t-control u-weight--md u-black--high"><span class="u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--reservations" title="Approved with Reservations" #data-refInfo=""></i> </span> <span class="u-middle u-ib u-ml--1/2">Approved with reservations</span></dt> <dd class="c-definitions__description t-caption"> A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </dd> <dt class="c-definitions__term u-upper t-control u-weight--md u-black--high"><span class="u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--not-approved " title="Not Approved" #data-refInfo=""></i> </span> <span class="u-middle u-ib u-ml--1/2">Not approved</span></dt> <dd class="c-definitions__description t-caption">Fundamental flaws in the paper seriously undermine the findings and conclusions</dd> </dl> </div> </div> </div> </div> </div> <div class="o-layout__item u-mb--1"><h4 class="u-mt--0 u-mb--0 u-ib u-middle t-h4 u-weight--md">Reviewer Reports</h4></div> <table class="c-report-timeline u-mb--2"> <thead class=c-report-timeline__headings> <tr> <th></th> <th class="u-pb--1/2" colspan=2><em class="t-body u-weight--rg">Invited Reviewers</em></th> </tr> <tr class=c-report-timeline__headings-row> <th></th> <th class="c-report-timeline__headings-version p-article__color--dark">1</th> <th class="c-report-timeline__headings-version p-article__color--dark">2</th> </tr> </thead> <tbody> <tr class="c-report-timeline__row c-report-timeline__row--selected "> <th class=c-report-timeline__version> <a data-test-id=sidebar_timeline_v1_version href="https://f1000research.com/articles/7-1555/v1">Version 1</a><br/> <span class=p-article__color--dark> <span data-test-id=sidebar_timeline_v1_date class=c-report-timeline__date>26 Sep 18</span> </span> </th> <td class="c-report-timeline__report c-report-timeline__cell "> <i class="c-icn--f1r-icon c-icn--approved small" title=Approved #data-refInfo=""></i> </td> <td class="c-report-timeline__report c-report-timeline__cell "> <i class="c-icn--f1r-icon c-icn--approved small" title=Approved #data-refInfo=""></i> </td> </tr> </tbody> </table> <div class=o-layout__item> <hr class="c-hr c-hr--low u-mb--2"> </div> </section> </div> <div class=o-layout__item> <div class="u-pl u-pr"> <p class="t-body u-mt--0 u-mb--2"><a href="/browse/faculty-reviews">Faculty Reviews</a> are review articles written by the prestigious Members of <a href="https://facultyopinions.com/prime/home" target=_blank class=in-text-link>Faculty Opinions</a>. The articles are commissioned and peer reviewed before publication to ensure that the final, published version is comprehensive and accessible. The reviewers who approved the final version are listed with their names and affiliations.</p> <ol class="p-article__faculty-referee-list t-caption"> <li> <p class=" u-mt--0 u-mb--1/2"><strong>Christoph Schreiner</strong>, UCSF Center for Integrative Neuroscience, University of California San Francisco, USA </p> <div class="c-read-more js-read-more " data-lines=3> <div class="c-read-more__content js-read-more-content "> <p class="u-mt--0 u-mb--0 p-article__color--light"> <strong class=u-weight--md>Competing interests:</strong> No competing interests were declared. </p> </div> <a href="#" class="c-read-more__toggle js-read-more-toggle t-caption"> <span class=c-read-more__expand>View more</span> <span class=c-read-more__contract>View less</span> </a> </div> </li> <li> <p class=" u-mt--0 u-mb--1/2"><strong>Shihab Shamma</strong>, Department of Electrical & Computer Engineering, University of Maryland, USA; The Institute for Systems Research, University of Maryland, USA </p> <div class="c-read-more js-read-more " data-lines=3> <div class="c-read-more__content js-read-more-content "> <p class="u-mt--0 u-mb--0 p-article__color--light"> <strong class=u-weight--md>Competing interests:</strong> No competing interests were declared. </p> </div> <a href="#" class="c-read-more__toggle js-read-more-toggle t-caption"> <span class=c-read-more__expand>View more</span> <span class=c-read-more__contract>View less</span> </a> </div> </li> </ol> </div> </div> <section class="o-layout__item u-pl"> <div class=u-pl> <hr class="c-hr c-hr--low c-hr--md u-mb--3"> <h4 class="t-h3 u-weight--md u-mt--0 u-mb--2">Comments on this article</h4> <div class=u-mb--4> <p class="u-mt--0 u-mb--1 t-h4"><a class=p-article__color--light href="#article-comments">All Comments</a><span class=" u-ib u-ml--1/2 p-article__color--light">(0)</span></p> <a class=t-h4 href="/login?originalPath=/articles/7-1555.html&scrollTo=add-new-comment" data-test-id=add-comment>Add a comment</a> </div> <hr class="c-hr c-hr--low c-hr--md u-mb--4"> <div class="research-layout f1r-article-desk"> <div class="heading6 c-ribbon-wrapper c-ribbon-wrapper--etoc f1000research "> <div class=c-ribbon-wrapper__body>Sign up for content alerts</div> </div> </div> <div class="research-layout sidebar-sign-up-form f1r-article-desk u-mb--4 "> <form class=js-email-alert-signup action="#" method=POST data-email=tocAlertWeekly> <input type=hidden name=isUserLoggedIn class=js-email-alert-signup-logged-in value=N /> <input type=hidden name=userId class=js-email-alert-signup-user-id value=""/> <input type=hidden name=frequency class=js-email-alert-signup-frequency value=WEEKLY /> <div class="o-actions o-actions--middle"> <div class=o-actions__primary> <input type=email name=emailAddress class="form-input-field js-email-alert-signup-address u-1/1 u-bb" required=required placeholder=Email /> </div> <div class=o-actions__secondary> <div class="_mdl-layout u-ml--1/2"> <button class="mdl-button mdl-js-button mdl-button--colored mdl-button--small mdl-button--filled js-email-alert-signup-submit">Sign Up</button> </div> </div> </div> </form> <div id=sidebar-sign-up-message class="section-text js-email-alert-signup-msg is-hidden">You are now signed up to receive this alert</div> </div> <section class=js-terms-container> <hr class="c-hr c-hr--low c-hr--md u-mb--3"> <h4 class="t-h3 u-weight--md u-mt--0 u-mb--1">Browse by related subjects</h4> <div class="article-subcontainer article-subcontainer--sidebar"> <ul class=js-terms-list></ul> </div> </section> </div> </section> </div> </section> </div> <script src="/js/shared_scripts/modal-dialogue.js"></script> <script src="/js/shared_scripts/read-more.js"></script> <script src="/js/article/article-router.js"></script> <script src="/js/article/article-sidebar.js"></script> <script src="/js/referee/new/referee_helpers.js"></script> <script src="/js/article/article-column-toggle.js"></script> </div> </div> </div> </main> <input type=hidden id=_articleVersionUrl value="https://f1000research.com/articles/7-1555/v1/"> <div class=research-help id=about-referee-status> <div class="research-layout research-help-content about-referee-status"> <span class="close-research-help dark-cross" title=Close></span> Alongside their report, reviewers assign a status to the article: <div class="cf research-help-row"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> <span class=research-help-text>Approved - the paper is scientifically sound in its current form and only minor, if any, improvements are suggested</span> </div> <div class="cf research-help-row"> <span class="f1r-icon icon-87_approved_reservations status-green smaller" title="Approved with Reservations"></span> <span class=research-help-text>Approved with reservations - A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </span> </div> <div class="cf research-help-row"> <span class="f1r-icon icon-88_not_approved status-red small" title="Not Approved"></span> <span class=research-help-text>Not approved - fundamental flaws in the paper seriously undermine the findings and conclusions</span> </div> </div> </div> <div id=datasets-info class=is-hidden> </div> <div class=article-interactive-content-container style="display: none;"> <a name=f-template class=n-a></a> <div class="interactive-content-wrapper padding-20"> <img src="" class=interactive-content-image title="Open the interactive image display"> <div class=interactive-content-title></div> <div class=interactive-content-text></div> <div class="f1r-article-desk interactive-content-ribbon" data-interactive-content-type=R-Script> <div class=interactive-content-label>Adjust parameters to alter display</div> <div class=interactive-content-button></div> </div> <div class="f1r-article-mobile mobile-interactive-note"> View on desktop for interactive features <img src="/img/icon/interactive_content.png" class="float-right margin-right-40"/> </div> <div class=clearfix></div> </div> </div> <div id=article-interactive-omero-container class=article-interactive-omero-container style="display: none;"> <div class=interactive-content-wrapper> <div class="interactive-omero-button omero-content" title="Open the interactive content window." data-interactive-content-type=Omero></div> <div class=has-interactive-content-image> <span class=box-arrow></span> <span class=box-middle>Includes Interactive Elements</span> <span class=box-end></span> </div> <div class="fig panel clearfix" style="margin: 0; padding-bottom: 20px;"> <a name=templatelink class=n-a></a> <a target=_blank href="" class=link-for-omero-image> <img src="" class=interactive-omero-image title="Open the image display window."> </a> <div class=caption> <div class=interactive-content-title></div> <div class=interactive-content-text></div> </div> <div class="is-hidden omero-image-list"></div> </div> <div class="f1r-article-mobile mobile-interactive-note omero"> View on desktop for interactive features <img src="/img/icon/interactive_content.png" class="float-right margin-right-40"/> </div> <div class=clearfix></div> </div> </div> <div class="add-comment-container shadow-box is-hidden" id=save-comment-container> <span id=save-comment-text class=intro-text>Edit comment</span> <textarea id=new-comment name=new-comment class="global-textarea comment margin-bottom margin-top"></textarea> <p><strong>Competing Interests</strong></p> <textarea id=new-competing-interests name=competing-interests class="global-textarea competing-interests margin-bottom check-xss"></textarea> <div class=clearfix></div> <button id=cancelComment type=button class="general-white-orange-button float-right no-background-button margin-left"> Cancel </button> <button id=save-comment-button commentId="" type=button class="general-white-orange-button float-right"> Save </button> <div class=clearfix></div> <div class="green-message margin-top is-hidden comment-is-saved">The comment has been saved.</div> <div class="red-message margin-top is-hidden comment-not-added">An error has occurred. Please try again.</div> <div class="red-message margin-top is-hidden comment-enter-text ucf">Your must enter a comment.</div> <div class="red-message margin-top is-hidden comment-references-error references">References error.</div> </div> <div class="modal-window-wrapper is-hidden"> <div id=conflicts-interests class="modal-window padding-20"> <div class=modal-window__content> <h2 class=h2-title>Competing Interests Policy</h2> <p> Provide sufficient details of any financial or non-financial competing interests to enable users to assess whether your comments might lead a reasonable person to question your impartiality. Consider the following examples, but note that this is not an exhaustive list: </p> <div class=heading5>Examples of 'Non-Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>Within the past 4 years, you have held joint grants, published or collaborated with any of the authors of the selected paper.</li> <li class=standard-padding>You have a close personal relationship (e.g. parent, spouse, sibling, or domestic partner) with any of the authors.</li> <li class=standard-padding>You are a close professional associate of any of the authors (e.g. scientific mentor, recent student).</li> <li class=standard-padding>You work at the same institute as any of the authors.</li> <li class=standard-padding>You hope/expect to benefit (e.g. favour or employment) as a result of your submission.</li> <li class=standard-padding>You are an Editor for the journal in which the article is published.</li> </ol> <div class="heading5 padding-top">Examples of 'Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>You expect to receive, or in the past 4 years have received, any of the following from any commercial organisation that may gain financially from your submission: a salary, fees, funding, reimbursements.</li> <li class=standard-padding>You expect to receive, or in the past 4 years have received, shared grant support or other funding with any of the authors.</li> <li class=standard-padding>You hold, or are currently applying for, any patents or significant stocks/shares relating to the subject matter of the paper you are commenting on.</li> </ol> </div> <div class="f1r-article-mobile research-layout"> <span class=modal-window-close-button></span> </div> </div> </div> <div class="o-modal c-email-alert-popup js-email-alert-popup is-hidden"> <div class="o-modal__body js-modal-body c-email-alert-popup__inner"> <h3 class=c-email-alert-popup__title>Stay Updated</h3> <p class=c-email-alert-popup__sub>Sign up for content alerts and receive a weekly or monthly email with all newly published articles</p> <p><a href="/register?originalPath=" class="c-email-alert-popup__lnk c-email-alert-popup__button js-email-alert-popup-action">Register with F1000Research</a></p> <p>Already registered? <a href="/login?originalPath=" class="c-email-alert-popup__lnk js-email-alert-popup-action">Sign in</a></p> <p class=c-email-alert-popup__footer><a class="c-email-alert-popup__lnk js-email-alert-popup-cancel" href="#">Not now, thanks</a></p> </div> </div> <div id=addCommentModal role=dialog aria-labelledby=addCommentModal_title aria-describedby=addCommentModal_description> <div class="c-modal js-modal is-closed p-article__add-comment-modal c-modal--xlarge js-article-comment-modal c-modal--scroll "> <aside class="c-modal__content u-black--high o-box u-pb--0 u-bg--2 c-modal--scroll-always "> <div class=c-modal__close> <button type=button class="c-button c-button--icon c-button--medium c-button--full@hover js-modal__close"><i class="c-button--icon__icon material-icons">close</i></button> </div> <div id=addCommentModal_description class="c-modal__description js-modal__content t-h4 u-mt--0 u-mb--2 u-black--medium"> <div class="js-add-comment-container t-caption u-black--high"> <div class=u-weight--bd>PLEASE NOTE</div> <div class=u-mt--1> <span class="red u-weight--bd">If you are an AUTHOR of this article,</span> please check that you signed in with the account associated with this article otherwise we cannot automatically identify your role as an author and your comment will be labelled as a &ldquo;User Comment&rdquo;. </div> <div class=u-mt--1> <span class="red u-weight--bd">If you are a REVIEWER of this article,</span> please check that you have signed in with the account associated with this article and then go to your <a href="/my/referee">account</a> to submit your report, please do not post your review here. </div> <div class="u-mt--1 u-mb--1"> If you do not have access to your original account, please <a href="mailto:research@f1000.com">contact us</a>. </div> <p class=no-top-margin>All commenters must hold a formal affiliation as per our <a href="/about/policies#commentspolicy" target=_blank>Policies</a>. The information that you give us will be displayed next to your comment.</p> <p>User comments must be in English, comprehensible and relevant to the article under discussion. We reserve the right to remove any comments that we consider to be inappropriate, offensive or otherwise in breach of the <a href="/about/legal/usercommenttermsandconditions" target=_blank>User Comment Terms and Conditions</a>. Commenters must not use a comment for personal attacks. When criticisms of the article are based on unpublished data, the data should be made available.</p> <div class="comments-note margin-bottom" id=accept-user-comments> <input class=js-add-comment-accept-terms type=checkbox id=acceptedTermsAndConditions name=acceptedTermsAndConditions> I accept the <a href="/about/legal/usercommenttermsandconditions" target=_blank> User Comment Terms and Conditions</a> <span class=required>&nbsp;</span> </div> <div class="default-error margin-top is-hidden comment-accept-conditions utac">Please confirm that you accept the User Comment Terms and Conditions.</div> <div class="research-layout registration-form u-mb--2"> <div class="u-mb--1 u-mt--2"> <strong>Affiliation</strong> </div> <div class=form-field> <input type=text name=institution class="form-input-field check-xss js-add-comment-institution" placeholder="Organization *" autocomplete=off /> <div class="default-error margin-top is-hidden comment-enter-institution institution">Please enter your organisation.</div> </div> <div class=form-field> <input type=text name=place class="form-input-field check-xss js-add-comment-place" placeholder=Place> </div> <div class=form-field> <div class="form-input-wrapper hundred-percent-wide"> <div class="new-select-standard-wrapper half-width inline-display heading10"> <select name=countryId id=country class="form-select-menu smaller js-add-comment-country"> <option value=-1>Country*</option> <option value=840>USA</option> <option value=826>UK</option> <option value=124>Canada</option> <option value=156>China</option> <option value=250>France</option> <option value=276>Germany</option> <optgroup label=-----------------------------------------------></optgroup> <option value=4>Afghanistan</option> <option value=248>Aland Islands</option> <option value=8>Albania</option> <option value=12>Algeria</option> <option value=16>American Samoa</option> <option value=20>Andorra</option> <option value=24>Angola</option> <option value=660>Anguilla</option> <option value=10>Antarctica</option> <option value=28>Antigua and Barbuda</option> <option value=32>Argentina</option> <option value=51>Armenia</option> <option value=533>Aruba</option> <option value=36>Australia</option> <option value=40>Austria</option> <option value=31>Azerbaijan</option> <option value=44>Bahamas</option> <option value=48>Bahrain</option> <option value=50>Bangladesh</option> <option value=52>Barbados</option> <option value=112>Belarus</option> <option value=56>Belgium</option> <option value=84>Belize</option> <option value=204>Benin</option> <option value=60>Bermuda</option> <option value=64>Bhutan</option> <option value=68>Bolivia</option> <option value=70>Bosnia and Herzegovina</option> <option value=72>Botswana</option> <option value=74>Bouvet Island</option> <option value=76>Brazil</option> <option value=86>British Indian Ocean Territory</option> <option value=92>British Virgin Islands</option> <option value=96>Brunei</option> <option value=100>Bulgaria</option> <option value=854>Burkina Faso</option> <option value=108>Burundi</option> <option value=116>Cambodia</option> <option value=120>Cameroon</option> <option value=124>Canada</option> <option value=132>Cape Verde</option> <option value=136>Cayman Islands</option> <option value=140>Central African Republic</option> <option value=148>Chad</option> <option value=152>Chile</option> <option value=156>China</option> <option value=162>Christmas Island</option> <option value=166>Cocos (Keeling) Islands</option> <option value=170>Colombia</option> <option value=174>Comoros</option> <option value=178>Congo</option> <option value=184>Cook Islands</option> <option value=188>Costa Rica</option> <option value=384>Cote d'Ivoire</option> <option value=191>Croatia</option> <option value=192>Cuba</option> <option value=196>Cyprus</option> <option value=203>Czech Republic</option> <option value=180>Democratic Republic of the Congo</option> <option value=208>Denmark</option> <option value=262>Djibouti</option> <option value=212>Dominica</option> <option value=214>Dominican Republic</option> <option value=218>Ecuador</option> <option value=818>Egypt</option> <option value=222>El Salvador</option> <option value=226>Equatorial Guinea</option> <option value=232>Eritrea</option> <option value=233>Estonia</option> <option value=231>Ethiopia</option> <option value=238>Falkland Islands</option> <option value=234>Faroe Islands</option> <option value=583>Federated States of Micronesia</option> <option value=242>Fiji</option> <option value=246>Finland</option> <option value=250>France</option> <option value=254>French Guiana</option> <option value=258>French Polynesia</option> <option value=260>French Southern Territories</option> <option value=266>Gabon</option> <option value=268>Georgia</option> <option value=276>Germany</option> <option value=288>Ghana</option> <option value=292>Gibraltar</option> <option value=300>Greece</option> <option value=304>Greenland</option> <option value=308>Grenada</option> <option value=312>Guadeloupe</option> <option value=316>Guam</option> <option value=320>Guatemala</option> <option value=831>Guernsey</option> <option value=324>Guinea</option> <option value=624>Guinea-Bissau</option> <option value=328>Guyana</option> <option value=332>Haiti</option> <option value=334>Heard Island and Mcdonald Islands</option> <option value=336>Holy See (Vatican City State)</option> <option value=340>Honduras</option> <option value=344>Hong Kong</option> <option value=348>Hungary</option> <option value=352>Iceland</option> <option value=356>India</option> <option value=360>Indonesia</option> <option value=364>Iran</option> <option value=368>Iraq</option> <option value=372>Ireland</option> <option value=376>Israel</option> <option value=380>Italy</option> <option value=388>Jamaica</option> <option value=392>Japan</option> <option value=832>Jersey</option> <option value=400>Jordan</option> <option value=398>Kazakhstan</option> <option value=404>Kenya</option> <option value=296>Kiribati</option> <option value=901>Kosovo (Serbia and Montenegro)</option> <option value=414>Kuwait</option> <option value=417>Kyrgyzstan</option> <option value=418>Lao People's Democratic Republic</option> <option value=428>Latvia</option> <option value=422>Lebanon</option> <option value=426>Lesotho</option> <option value=430>Liberia</option> <option value=434>Libya</option> <option value=438>Liechtenstein</option> <option value=440>Lithuania</option> <option value=442>Luxembourg</option> <option value=446>Macao</option> <option value=807>Macedonia</option> <option value=450>Madagascar</option> <option value=454>Malawi</option> <option value=458>Malaysia</option> <option value=462>Maldives</option> <option value=466>Mali</option> <option value=470>Malta</option> <option value=584>Marshall Islands</option> <option value=474>Martinique</option> <option value=478>Mauritania</option> <option value=480>Mauritius</option> <option value=175>Mayotte</option> <option value=484>Mexico</option> <option value=581>Minor Outlying Islands of the United States</option> <option value=498>Moldova</option> <option value=492>Monaco</option> <option value=496>Mongolia</option> <option value=499>Montenegro</option> <option value=500>Montserrat</option> <option value=504>Morocco</option> <option value=508>Mozambique</option> <option value=104>Myanmar</option> <option value=516>Namibia</option> <option value=520>Nauru</option> <option value=524>Nepal</option> <option value=530>Netherlands Antilles</option> <option value=540>New Caledonia</option> <option value=554>New Zealand</option> <option value=558>Nicaragua</option> <option value=562>Niger</option> <option value=566>Nigeria</option> <option value=570>Niue</option> <option value=574>Norfolk Island</option> <option value=580>Northern Mariana Islands</option> <option value=408>North Korea</option> <option value=578>Norway</option> <option value=512>Oman</option> <option value=586>Pakistan</option> <option value=585>Palau</option> <option value=275>Palestinian Territory</option> <option value=591>Panama</option> <option value=598>Papua New Guinea</option> <option value=600>Paraguay</option> <option value=604>Peru</option> <option value=608>Philippines</option> <option value=612>Pitcairn</option> <option value=616>Poland</option> <option value=620>Portugal</option> <option value=630>Puerto Rico</option> <option value=634>Qatar</option> <option value=638>Reunion</option> <option value=642>Romania</option> <option value=643>Russian Federation</option> <option value=646>Rwanda</option> <option value=654>Saint Helena</option> <option value=659>Saint Kitts and Nevis</option> <option value=662>Saint Lucia</option> <option value=666>Saint Pierre and Miquelon</option> <option value=670>Saint Vincent and the Grenadines</option> <option value=882>Samoa</option> <option value=674>San Marino</option> <option value=678>Sao Tome and Principe</option> <option value=682>Saudi Arabia</option> <option value=686>Senegal</option> <option value=688>Serbia</option> <option value=690>Seychelles</option> <option value=694>Sierra Leone</option> <option value=702>Singapore</option> <option value=703>Slovakia</option> <option value=705>Slovenia</option> <option value=90>Solomon Islands</option> <option value=706>Somalia</option> <option value=710>South Africa</option> <option value=239>South Georgia and the South Sandwich Is</option> <option value=410>South Korea</option> <option value=724>Spain</option> <option value=144>Sri Lanka</option> <option value=736>Sudan</option> <option value=740>Suriname</option> <option value=744>Svalbard and Jan Mayen</option> <option value=748>Swaziland</option> <option value=752>Sweden</option> <option value=756>Switzerland</option> <option value=760>Syria</option> <option value=158>Taiwan</option> <option value=762>Tajikistan</option> <option value=834>Tanzania</option> <option value=764>Thailand</option> <option value=270>The Gambia</option> <option value=528>The Netherlands</option> <option value=626>Timor-Leste</option> <option value=768>Togo</option> <option value=772>Tokelau</option> <option value=776>Tonga</option> <option value=780>Trinidad and Tobago</option> <option value=788>Tunisia</option> <option value=792>Turkey</option> <option value=795>Turkmenistan</option> <option value=796>Turks and Caicos Islands</option> <option value=798>Tuvalu</option> <option value=800>Uganda</option> <option value=826>UK</option> <option value=804>Ukraine</option> <option value=784>United Arab Emirates</option> <option value=850>United States Virgin Islands</option> <option value=858>Uruguay</option> <option value=840>USA</option> <option value=860>Uzbekistan</option> <option value=548>Vanuatu</option> <option value=862>Venezuela</option> <option value=704>Vietnam</option> <option value=876>Wallis and Futuna</option> <option value=905>West Bank and Gaza Strip</option> <option value=732>Western Sahara</option> <option value=887>Yemen</option> <option value=894>Zambia</option> <option value=716>Zimbabwe</option> </select> </div> </div> <div class="default-error margin-top is-hidden comment-enter-country country">Please select your country.</div> </div> </div> <textarea data-test-id=article_add-comment_comment name=new-comment class="js-add-comment-comment comment margin-bottom margin-top"></textarea> <div class="default-error margin-top comment-enter-text comment-error is-hidden ">You must enter a comment.</div> <label class="comments-note u-mt--2 u-mb--2" for=competingInterests_1> <div class="u-mb--1 u-mt--2"><strong data-test-id=article_report-add-comment_competing-interests-title>Competing Interests</strong></div> <p class="u-mb--2 u-mt--0" data-test-id=article_report-add-comment_competing-interests-description>Please disclose any <a href="#article-competing-intersts-policy" class=js-modal-competing-intersts-toggle>competing interests</a> that might be construed to influence your judgment of the article's or peer review report's validity or importance.</p> </label> <div id=article-competing-intersts-policy class=js-article-competing-interests-policy style="display: none;"> <h2 class="h2-title u-mt--0 u-pt--0">Competing Interests Policy</h2> <p> Provide sufficient details of any financial or non-financial competing interests to enable users to assess whether your comments might lead a reasonable person to question your impartiality. Consider the following examples, but note that this is not an exhaustive list: </p> <div class=heading5>Examples of 'Non-Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>Within the past 4 years, you have held joint grants, published or collaborated with any of the authors of the selected paper.</li> <li class=standard-padding>You have a close personal relationship (e.g. parent, spouse, sibling, or domestic partner) with any of the authors.</li> <li class=standard-padding>You are a close professional associate of any of the authors (e.g. scientific mentor, recent student).</li> <li class=standard-padding>You work at the same institute as any of the authors.</li> <li class=standard-padding>You hope/expect to benefit (e.g. favour or employment) as a result of your submission.</li> <li class=standard-padding>You are an Editor for the journal in which the article is published.</li> </ol> <div class="heading5 padding-top">Examples of 'Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>You expect to receive, or in the past 4 years have received, any of the following from any commercial organisation that may gain financially from your submission: a salary, fees, funding, reimbursements.</li> <li class=standard-padding>You expect to receive, or in the past 4 years have received, shared grant support or other funding with any of the authors.</li> <li class=standard-padding>You hold, or are currently applying for, any patents or significant stocks/shares relating to the subject matter of the paper you are commenting on.</li> </ol> </div> <div id=competingInterests_1 class="c-inline-editor js-inline-editor js-form_input u-bb--all u-mb--2 js-comment-competing-interests" data-name=competing-interests data-rows=3> <textarea id=competingInterests_1_input name=competing-interests placeholder="&nbsp;" required=false class="u-hide-visually js-inline-editor_input" tabindex=-1></textarea> <div class="c-inline-editor__editor js-inline-editor_editor o-box c-box o-box--tiny u-bg--11" data-target=competingInterests_1_input role=textbox required=false data-placeholder="&nbsp;" contenteditable=true></div> <span class="c-inline-editor__error js-inline-editor-message">Please state your competing interests</span> </div> <div data-test-id=article_add-comment_saved class="green-message comments is-hidden comment-is-saved">The comment has been saved.</div> <div data-test-id=article_add-comment_error class="default-error comments is-hidden comment-not-added">An error has occurred. Please try again.</div> <div class=clearfix></div> <div class=js-hook></div> </div> <div class="c-modal__extra-message js-modal__extra-message t-h4 u-black--medium"></div></div> <div class="c-modal__actions o-box__actions"> <a href="#" data-test-id=article_add-comment_cancel class="c-button c-button--full js-modal__close c-button--secondary">Cancel</a> <a href="#" data-test-id=article_add-comment_post class="c-button c-button--full js-modal__confirm c-button--primary">Post</a> </div> </aside> </div> </div> <style>
                .at-icon-wrapper {
        background-size: 100% !important;
    }
</style> <script src="/js/namespace.js"></script> <script src="/js/constants.js"></script> <script src="/js/utilities.js"></script> <script src="/js/article/alert-signup.js"></script> <script type='text/javascript'>
    var lTitle = "Recent advances in understanding the auditory...".replace("'", '');
    var linkedInUrl = "http://www.linkedin.com/shareArticle?url=https://f1000research.com/articles/7-1555/v1" + "&title=" + encodeURIComponent(lTitle) + "&summary=" + encodeURIComponent('Read the article by ');

    var deliciousUrl = "https://del.icio.us/post?url=https://f1000research.com/articles/7-1555/v1&title=" + encodeURIComponent(lTitle);

    var redditUrl = "http://reddit.com/submit?url=https://f1000research.com/articles/7-1555/v1" + "&title=" + encodeURIComponent(lTitle);

            linkedInUrl += encodeURIComponent('King AJ et al.');
    
    var offsetTop = /chrome/i.test( navigator.userAgent ) ? 4 : -10; 
    var addthis_config = {
            ui_offset_top: offsetTop,
                                    services_compact : "facebook,twitter,www.linkedin.com,www.mendeley.com,reddit.com",
            services_expanded : "facebook,twitter,www.linkedin.com,www.mendeley.com,reddit.com",
            services_custom : [
                {
                    name: "LinkedIn",
                    url:  linkedInUrl,
                    icon:"/img/icon/at_linkedin.svg"
                },
                {
                    name: "Mendeley",
                    url:  "http://www.mendeley.com/import/?url=https://f1000research.com/articles/7-1555/v1/mendeley",
                    icon:"/img/icon/at_mendeley.svg"
                },
                {
                    name: "Reddit",
                    url:  redditUrl,
                    icon:"/img/icon/at_reddit.svg"
                },
            ]
        };


    var addthis_share = {
            url: "https://f1000research.com/articles/7-1555",
            templates : {
                twitter : "Recent advances in understanding the auditory cortex. King AJ et al., published by " + 
               "@F1000Research"
       + ", https://f1000research.com/articles/7-1555/v1"
            }
        };

    if (typeof(addthis) != "undefined"){
        addthis.addEventListener('addthis.ready', checkCount);
        addthis.addEventListener('addthis.menu.share', checkCount);
    }

        $(".f1r-shares-twitter").attr("href", "https://twitter.com/intent/tweet?text=" + addthis_share.templates.twitter);
    $(".f1r-shares-facebook").attr("href", "https://www.facebook.com/sharer/sharer.php?u=" + addthis_share.url);
    $(".f1r-shares-linkedin").attr("href", addthis_config.services_custom[0].url);
    $(".f1r-shares-reddit").attr("href", addthis_config.services_custom[2].url);
    $(".f1r-shares-mendelay").attr("href", addthis_config.services_custom[1].url);

    function checkCount(){
        setTimeout(function(){
            $(".addthis_button_expanded").each(function(){
                var count = $(this).text();
                if (count !== "" && count != "0")
                    $(this).removeClass("is-hidden");
                else
                    $(this).addClass("is-hidden");
            });
        }, 1000);
    }
</script> <div id=citeReportModal role=dialog aria-labelledby=citeReportModal_title aria-describedby=citeReportModal_description> <div class="c-modal js-modal is-closed c-modal--large js-cite-report-modal "> <aside class="c-modal__content u-black--high o-box u-pb--0 u-black--high "> <div class=c-modal__close> <button type=button class="c-button c-button--icon c-button--medium c-button--full@hover js-modal__close"><i class="c-button--icon__icon material-icons">close</i></button> </div> <h1 id=citeReportModal_title class="c-modal__title t-h3 u-mt--0 u-mb--2 u-weight--md">How to cite this report</h1> <div id=citeReportModal_description class="c-modal__description js-modal__content t-h4 u-mt--0 u-mb--2 u-black--medium"> <div id="" class=js-report-citation-container>{{reportCitation}}</div> <div class="c-modal__extra-message js-modal__extra-message t-h4 u-black--medium"></div></div> <div class="c-modal__actions o-box__actions"> <a href="#" class="c-button c-button--full js-modal__close c-button--secondary">Cancel</a> <a href="#" title="Copy the current citation details to the clipboard." data-clipboard-target="#referee-report-citation" data-test-id=report_copy-citation_button class="c-button c-button--full js-modal__confirm c-button--primary js-clipboard c-mini-tooltip--above">Copy Citation Details</a> </div> </aside> </div> </div> <script src="/js/referee/new/referee_validators.js"></script> <script src="/js/referee/new/referee_helpers.js"></script> <script src="/js/referee/new/referee_checkbox-input.js"></script> <script src="/js/referee/new/referee_inline-editor.js"></script> <script type="text/javascript">
    $(function(){
        var gaCat = "F1000Research";
        if (gaCat === "") {
            gaCat = $("body").hasClass("wellcome-brand") ? "Wellcome Open Research" : "F1000Research";
        }
        GAHelper.track({category: gaCat, action: "Article Page: Recent advances in understanding the auditory cortex", label: "pageviews"});
        GAHelper.track({category: gaCat, action: "Article Type: Review", label: "Article Page"});
        $(".f1r-article-desk .collection-image").each(function (idx, el) {
            var whatChannel = $(el).find("a").attr("href"),
                channelName = $.trim($(el).parent().find(".collection-detail a").text()),
                gaRef = "(ID: " + whatChannel.replace("/collections/", "") + ") " + channelName;
            GAHelper.track({category: 'ChannelStats', action: "Article Page: Recent advances in understanding the auditory cortex", label: gaRef});
        });
    });
</script> <script>
    $(function(){R.ui.buttonDropdowns('.dropdown-for-downloads');});
    $(function(){R.ui.toolbarDropdowns('.toolbar-dropdown-for-downloads');});
</script> <script src="/js/article/track_article.js" type="text/javascript"></script> <script type="text/javascript">
    $.get("/articles/acj/15580/16995")
</script> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script type="text/javascript" src="/js/app/messenger.js"></script> <script type="text/javascript" src="/js/article/article_mobiles.js"></script> <script src="/js/vendor/clipboard.min.js"></script> <script src="/js/shared_scripts/modal-dialogue.js"></script> <script src="/js/shared_scripts/clipboard.js"></script> <script src="/js/article/thesaurus-terms-display.js"></script> <script>
    new F1000.Clipboard();
    new F1000.ThesaurusTermsDisplay("faculty-reviews", "article", "16995");
</script> <script>
    $(document).ready(function() {
        $( "#frame1" ).on('load', function() {
            var mydiv = $(this).contents().find("div");
            var h     = mydiv.height();
            console.log(h)
        });

        
        var tooltipLivingFigure = jQuery(".interactive-living-figure-label .icon-more-info"),
            titleLivingFigure = tooltipLivingFigure.attr("title");
        tooltipLivingFigure.simpletip({
            fixed: true,
            position: ["-115", "30"],
            baseClass: 'small-tooltip',
            content:titleLivingFigure + "<div class='tooltip-arrow'></div>"
        });
        tooltipLivingFigure.removeAttr("title");

        $("body").on("click", ".cite-living-figure", function(e) {
            e.preventDefault();
            var ref = $(this).attr("data-ref");
            $(this).closest(".living-figure-list-container").find("#" + ref).fadeIn(200);
        });
        $("body").on("click", ".close-cite-living-figure", function(e) {
            e.preventDefault();
            $(this).closest(".popup-window-wrapper").fadeOut(200);
        });

                $(document).on("mouseup", function(e) {
            var metricsContainer = $(".article-metrics-popover-wrapper");
            if (!metricsContainer.is(e.target) && metricsContainer.has(e.target).length === 0) {
                $(".article-metrics-close-button").click();
            }
        });

        var articleId = $('#articleId').val();

        if($("#main-article-count-box").attachArticleMetrics) {
            $("#main-article-count-box").attachArticleMetrics(articleId, {
                articleMetricsView: true
            });
        }
    });

    var figshareWidget = $(".new_figshare_widget");
    if (figshareWidget.length > 0) {
        window.figshare.load("f1000", function(Widget) {
            // Select a tag/tags defined in your page. In this tag we will place the widget.
            _.map(figshareWidget, function(el){
                var widget = new Widget({
                    articleId: $(el).attr("figshare_articleId")
                    //height:300 // this is the height of the viewer part. [Default: 550]
                });
                widget.initialize(); // initialize the widget
                widget.mount(el); // mount it in a tag that's on your page
                // this will save the widget on the global scope for later use from
                // your JS scripts. This line is optional.
                //window.widget = widget;
            });
        });
    }
</script>

<script>
    $(document).ready(function () {

        
        var reportIds = {
                           "38454": 0,
                           "38455": 0,
                    };

        $(".referee-response-container,.js-referee-report").each(function(index, el) {
            var reportId = $(el).attr("data-reportid"),
                reportCount = reportIds[reportId] || 0;
            $(el).find(".comments-count-container,.js-referee-report-views").html(reportCount);
        });

        var uuidInput = $("#article_uuid"),
            oldUUId = uuidInput.val(),
            newUUId = "f85a0856-0242-4aa2-bf06-1862e96a1786";
        uuidInput.val(newUUId);

        $("a[href*='article_uuid=']").each(function(index, el) {
            var newHref = $(el).attr("href").replace(oldUUId, newUUId);
            $(el).attr("href", newHref);
        });

    });
</script>              </div>
        </div>

        
            
            <div class="o-page__footer sticky-email-wrapper">
                
                

                


<footer class="c-footer t-inverted">

    <div class="o-wrapper">
        <div class="o-layout">


                        
            <div class="o-layout__item u-mb--3">
                <div class="c-branding c-branding--research">
                    <img src="/img/research/F1000Research_white.svg" alt="F1000Research">
                </div>
            </div>


                        
            <div class="o-layout__item u-1/3@md u-mb--3">

                <span class="c-hr c-hr--thick c-hr--low u-mb--2"></span>

                <p class="t-h3 u-mt--0 u-mb--0">An innovative open access publishing platform offering rapid publication and open peer review, whilst supporting data deposition and sharing.</p>

            </div>


                        
            <div class="o-layout__item u-2/3@md">

                <span class="c-hr c-hr--thick c-hr--low u-mb--2"></span>

                <div class="o-layout">
                    <nav class="c-footer__nav">

                            <div class="o-layout__item u-3/5@sm u-mb--3">


                                <div class="o-columns o-columns--2">

                                                                            <a href="/browse/articles" class="t-body c-footer__nav-item "      >Browse</a>
                                                                            <a href="/gateways" class="t-body c-footer__nav-item "      >Gateways</a>
                                                                            <a href="/collections" class="t-body c-footer__nav-item "      >Collections</a>
                                                                            <a href="/about" class="t-body c-footer__nav-item "      >How it Works</a>
                                                                            <a href="https://blog.f1000.com/blogs/f1000research/" class="t-body c-footer__nav-item "      >Blog</a>
                                                                            <a href="/contact" class="t-body c-footer__nav-item "      >Contact</a>
                                                                            <a href="/developers" class="t-body c-footer__nav-item u-hide u-show@navbar"      >For Developers</a>
                                                                            <a href="/published/rss" class="t-body c-footer__nav-item "   title="RSS feed of published articles"     >RSS</a>
                                    
                                </div>

                            </div>

                            <div class="o-layout__item u-2/5@sm u-center u-right@sm u-mb--3">

                                <div class="u-hide u-show@lg">
                                    <div class="_mdl-layout">
                                        <a class="mdl-button mdl-js-button mdl-button--inverted mdl-button--no-shadow mdl-js-ripple-effect mdl-button--outline" href="/for-authors/publish-your-research"   data-test-id="footer_submit_research"  >Submit Your Research</a>
                                    </div>
                                </div>

                            </div>

                    </nav>
                </div>

            </div>

            <div class="o-layout__item u-mb--2">
                <div class="c-footer__share">
                        <div class="c-footer__share">
        <span class="c-footer__share-icon" title="Open Access">
            <span class="f1r-icon icon-100_open_access license-icon"></span>
        </span>

        <a class="c-footer__share-icon" href="//creativecommons.org/licenses" target="_blank" title="Creative Commons License CC-BY">
            <span class="f1r-icon icon-116_cc license-icon license-icon-cc"></span>
            <span class="f1r-icon icon-117_ccby license-icon license-icon-cc"></span>
        </a>

        <a class="c-footer__share-icon" href="//creativecommons.org/about/cc0" target="_blank" title="Creative Commons License CC0">
            <span class="f1r-icon icon-118_cco license-icon"></span>
        </a>

    </div>
                </div>
            </div>


                        
            <div class="o-layout__item u-1/3@md u-mb--3">

                <span class="c-hr c-hr--low u-mb--3"></span>

                <p class="c-footer__social u-mt--0 u-mb--0 u-white--low-med">Follow us
                    <a href="https://www.facebook.com/F1000" target="_blank" class="c-footer__social-icon f1r-icon icon-55_footer_facebook"></a>
                    <a href="https://twitter.com/#!/F1000Research" target="_blank" class="c-footer__social-icon f1r-icon icon-56_footer_twitter"></a>
                    <a href="http://www.youtube.com/user/F1000research" target="_blank" class="c-footer__social-icon f1r-icon icon-57_footer_youtube"></a></p>

            </div>


                        
            <div class="o-layout__item u-2/3@md u-right@md">

                <span class="c-hr c-hr--low u-mb--3"></span>

                <p class="t-caption u-white--low-med">&copy; 2012-2020 F1000 Research Ltd. ISSN 2046-1402 | <a href="/about/legal" class="copyrightLegal">Legal</a> | Partner of <a target="_blank" href="http://www.who.int/hinari/en/">HINARI</a>  &bull; <a target="_blank" href="http://crossref.org/">CrossRef</a> &bull; <a target="_blank" href="http://about.orcid.org/">ORCID</a> &bull; <a target="_blank" href="http://www.fairsharing.org">FAIRSharing</a></p>

            </div>
        </div>
    </div>

</footer>            </div>
        
    </div>

            <div class="js-cookie-spacer"></div>
        <div class="cookie-warning">
            <div class="instruction">The F1000Research website uses cookies. By continuing to browse the site, you are agreeing to our use of cookies. <a class="js-scroll-to" href="/about/legal/privacypolicy#use-of-cookies" data-scroll-target="#use-of-cookies">Find out more &raquo;</a></div>
            <div class="close-button"></div>
        </div>
    
    <script>
                    R.templateTests.simpleTemplate = R.template('<p class="$variable.one">$text</p><p class="${variable.two}">$text</p><p class="$!variable.three">$text</p><p class="$!{variable.four}">$text</p><p class="${selector}.five">$text</p>');
            R.templateTests.runTests();
        
        var F1000platform = new F1000.Platform({
            name: "f1000research",
            displayName: "F1000Research",
            hostName: "f1000research.com",
            id: "1",
            editorialEmail: "research@f1000.com",
            infoEmail: "info@f1000.com",
            usePmcStats: true
        });

                    $(function(){R.ui.dropdowns('.dropdown-for-authors, .dropdown-for-about, .dropdown-for-myresearch');});
            // $(function(){R.ui.dropdowns('.dropdown-for-referees');});

            $(document).ready(function () {
                if ($(".cookie-warning").is(":visible")) {
                    $(".sticky").css("margin-bottom", "35px");
                    $(".devices").addClass("devices-and-cookie-warning");
                }
                $(".cookie-warning .close-button").click(function (e) {
                    $(".devices").removeClass("devices-and-cookie-warning");
                    $(".sticky").css("margin-bottom", "0");
                });

                $("#tweeter-feed .tweet-message").each(function (i, message) {
                    var self = $(message);
                    self.html(linkify(self.html()));
                });

                $(".partner").on("mouseenter mouseleave", function() {
                    $(this).find(".gray-scale, .colour").toggleClass("is-hidden");
                });
            });
        
    </script>

            
<div class="sign-in-popup">
	<!-- <a href="#" class="sign-in shadow">Sign in <span class="sign-in-image-active"></span></a> -->
	<a href="#" class="sign-in ${locale}">Sign In <span class="arrow-closed sign-in-arrow-padding arrow-opened"></span></a>
	<div class="sign-in-form">

            <form action="https://f1000research.com/j_spring_oauth_security_check" id="googleOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/7-1555.html"/>
                            <input id="google-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-google" name="system" type="hidden" value="GOOGLE"/>
    </form>
            <form action="https://f1000research.com/j_spring_oauth_security_check" id="facebookOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/7-1555.html"/>
                            <input id="facebook-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-fb" name="system" type="hidden" value="FACEBOOK"/>
    </form>
            <form action="https://f1000research.com/j_spring_oauth_security_check" id="orcidOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/7-1555.html"/>
                            <input id="orcid-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-orcid" name="system" type="hidden" value="ORCID"/>
    </form>
		<form id="sign-in-form" class="login-container" action="https://f1000research.com/login" method="post" name="f">
           <div id="sign-in-form-gfb-popup"></div>

                                                            <input class="target-field" type="hidden" name="target" value="/articles/7-1555.html"/>
                            			<input type="text" name="username" id="signin-email-box" class="sign-in-input" placeholder="Email address" autocomplete="email">
			<input type="password" name="password" id="signin-password-box" class="sign-in-input" placeholder="Password" autocomplete="current-password">
			<div class="sign-in-remember">
                <div class="checkbox-wrapper">
    				<input type="checkbox" id="remember-me" name="remember_me" class="checkbox is-hidden">
                </div>
                <span class="checkbox-label">Remember me</span>
			</div>
			<a href="#" class="sign-in-link" id="forgot-password-link">Forgotten your password?</a>
			<div class="sign-in-button-container margin-top margin-left-20 margin-bottom">
				<button type="submit" id="sign-in-button" class="sign-in-buttons general-white-orange-button">Sign In</button>
				<button type="button" id="sign-in-cancel" class="sign-in-buttons sign-in-cancel-button margin-left">Cancel</button>
				<div class="clearfix"></div>
			</div>
			<div class="sign-in-error">Email or password not correct. Please try again</div>
			<div class="sign-in-loading">Please wait...</div>
		</form>
		<div class="forgot-password-container">
			
<script type="text/javascript">
	$(function(){
		// Note: All the setup needs to run against a name attribute and *not* the id due the clonish
		// nature of facebox...
		$("a[id=googleSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("GOOGLE");
            $("form[id=oAuthForm]").submit();
        });
        $("a[id=facebookSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("FACEBOOK");
            $("form[id=oAuthForm]").submit();
        });
        $("a[id=orcidSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("ORCID");
            $("form[id=oAuthForm]").submit();
        });
	});
</script>

<span class="text first">
	If you've forgotten your password, please enter your email address below and we'll send you instructions on how to reset your password.
    <p>The email address should be the one you originally registered with F1000.</p>
</span>
<input name="email" class="sign-in-input" id="email-forgot-password" type="text" placeholder="Email address">
<div class="forgot-password-email-error">
	Email address not valid, please try again
</div>
<div class="forgot-password-google-email-error">
    <p>You registered with F1000 via Google, so we cannot reset your password.</p>
	<p>To sign in, please click <a href="#" id="googleSignInButton">here</a>.</p>
    <p>If you still need help with your Google account password, please click <a href="https://www.google.com/accounts/recovery">here</a>.</p>
</div>
<div class="forgot-password-facebook-email-error">
    <p>You registered with F1000 via Facebook, so we cannot reset your password.</p>
    <p>To sign in, please click <a href="#" id="facebookSignInButton">here</a>.</p>
	<p>If you still need help with your Facebook account password, please click <a href="https://www.facebook.com/recover/initiate">here</a>.</p>
</div>
<div class="clearfix"></div>
<div class="forgot-password-captcha-error">
	Code not correct, please try again
</div>
<div class="clearfix"></div>
<div class="sign-in-button-container margin-left-20 margin-bottom">
	<button type="button" id="sign-in-reset-password" class="sign-in-buttons general-white-orange-button">Reset password</button>
	<button type="button" id="forgot-password-cancel" class="sign-in-buttons sign-in-cancel-button margin-left">Cancel</button>
	<div class="clearfix"></div>
</div>
<span class="text last">
	<a href="mailto:">Email us</a> for further assistance.
</span>
<form action="https://f1000research.com/j_spring_oauth_security_check" id="oAuthForm" method="post" target="_top">
                        <input class="target-field" type="hidden" name="target" value="/articles/7-1555.html"/>
                <input id="oAuthSystem" name="system" type="hidden"/>
</form>
			<div class="forgot-password-server-error">Server error, please try again.</div>
			<div class="sign-in-success">
                <p>We have sent an email to <span id="email-value"></span>, please follow the instructions to reset your password.</p>
                <p>If you don't receive this email, please check your spam filters and/or contact .</p>
            </div>
			<div class="sign-in-loading">Please wait...</div>
		</div>

		<div class="sign-in-form-register-section">
			<div class="sign-in-button-container margin-left-20 margin-bottom">
				<a href="/register" title="Register"><button type="button" id="sign-in-register-button" class="sign-in-buttons general-white-orange-button">Register</button></a>
				<div class="clearfix"></div>
			</div>
		</div>

	</div>
</div>

<script type="text/javascript">
$(document).ready(function () {

    signIn.createSignInAsRow($("#sign-in-form-gfb-popup"));

    $(".target-field").each(function () {
        var uris = $(this).val().split("/");
        if (uris.pop() === "login") {
        	$(this).val(uris.toString().replace(",","/"));
        }
    });
});
</script>
        <div id="templateOverlay" class="is-hidden" hidden="hidden">
  <div class="o-overlay js-overlay is-hidden" hidden="hidden"></div>
</div>

<div id="templateExternalMessages" class="is-hidden" hidden="hidden">
  <div class="o-modal o-modal--auto@md js-external-messages is-hidden" hidden="hidden">
    <div class="o-modal__body">
      <section class="c-console">
        <div class="_mdl-layout c-console__bdy js-external-messages-body"></div>
        <footer class="_mdl-layout c-console__ftr o-flex o-flex--reverse js-external-messages-footer">
          <button type="button" class="mdl-button mdl-js-button mdl-button--raised mdl-button--colored c-console__btn js-external-messages-close" data-action="maintenance-close">I Understand</button>
        </footer>
      </section>
    </div>
  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.1/moment.min.js"></script>

<script src="/js/namespace.js"></script>
<script src="/js/constants.js"></script>
<script src="/js/utilities.js"></script>

<script>
                  F1000.ExtenalMaintenanceItems = [
    {
      start: '2018-12-10T14:21:00Z',
      end: '2018-12-13T16:00:00Z',
      msg: 'This site will be down for a short time on XX December. It is advisable not to start any submissions on that day or you may lose your work unless you save regularly.',
      cookieName: 'outage23122018',
      editor: false,
    }
  ];
</script>

<script src="/js/shared_scripts/cookie-helper.js"></script>
<script src="/js/shared_scripts/mdl-helper.js"></script>

<script src="/js/app/external-maintenance.js"></script>

                <script type="text/javascript">
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-5646075-11', 'auto');
            ga('require', 'displayfeatures');
            ga('send', 'pageview');
        </script>
        
                <script type="text/javascript" src="/js/app/research.analytics.js"></script>

        <!-- Start of HubSpot Embed Code -->
        <script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/4475190.js"></script>
        <!-- End of HubSpot Embed Code -->
    
            <script src="https://my.hellobar.com/4e0495c6f18cbd68731a1dc1978195a144e767ba.js" type="text/javascript" charset="utf-8" async="async"></script>
    </body>

</html>