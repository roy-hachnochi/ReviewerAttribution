The paper presents the results of a survey investigating the impact of the UK Software Sustainability Institute’s (SSI) Fellowship Programme on recipients’ research, institutions, and careers. The authors note that their approach to Programme evaluation is novel in that, unlike other reports on programme outcomes (e.g., the Humboldt Foundation), it is a peer-reviewed study using only the data collected via survey. Therefore, the results contribute empirical findings to the software sustainability literature. The study found that the Programme elevated the perceived importance of software development for research as well as the status of the fellowship awardees. The authors state that the survey’s findings indicate the importance and value of research software and the people who develop it. The paper also provides a sound overview of the SSI Fellowship’s goals: Supporting research software developers in their own work and in championing research software’s value (e.g., promoting reproducible research and open science). The introduction notes how awardees are selected and how the Programme fosters diversity in career stages and disciplines. Overall, I support the indexing of this study with one substantial addition (a discussion section) and several minor changes. I provide some details on what might be included in the discussion in Comment 3 below. The authors clearly state that they wish to contribute to the literature on software sustainability. However, they do not provide any definitions of software sustainability, generally, and the types of work and workers needed to achieve sustainability. These additions are necessary to contextualize the findings within the broader discussion about software sustainability. Although I am sure the authors are familiar with this emerging literature because they have made substantial contributions to it, I provide some references to start with (Crouch et al. , 2013 1 , Calero et al. , 2013 2 , Jimnez et al. , 2017 3 , Katz et al. , 2014 4 and Venters et al. , 2014 5 ). The authors could reflect more on why there were far more respondents who identified as male than female. For example, does this set of responses reflect the overall makeup of the Fellowship Programme? If not, why might that be? The paper lacks a discussion that integrates and synthesizes the discrete findings sections. There are several possible ways forward to develop such a discussion question. The first suggestion is to contextualize the free text themes within the forced choice responses. For example, did the 4 respondents who answered “no” to the question about career advancement thematically respond to free text questions, particularly the one about negative impacts? Because the sample size is small, it may be possible to point out the threads in the responses of the “no” participants vs. the “yes” participants. Another way forward is to put all of the sections into conversation with one another. For example, in the discussion, the authors could discuss why (in relation to the existing literature or public discourse) fellowship awards had a greater impact on professional development of others than on the individuals. The “how” is already present and appreciated—e.g., Software Carpentry workshops. Likewise, the authors might return to statements such as R17’s institution not being interested in the fellowship, and how that relates to the reported benefits to the institution. In sum, some more reflection on the responses and how they relate to the broader discourse around software sustainability and support for research software development would be very much appreciated. I commend the authors for explicitly stating the themes in the findings section. I have one issue with how the authors collaborated for the qualitative coding of the free text responses: Did the authors use any “test data” or something similar to ensure inter-rater reliability? For a study like this one, I do not think it is important to report a quantitative measure of IRR, but a bit more detail about how authors reached agreement would be helpful and contribute to a perception of validity for the reader. One way of doing this is to briefly describe an example of disagreement between the two authors on a particular theme or instance of a theme and describe how the authors reached a resolution. What software, if any, was used for qualitative coding of the data? I thank the authors for providing Table 4 with some illustrative examples of responses. I also appreciate how the authors presented some examples in the text and place them in conversation with one another as you might see in an interview-based study (indeed, the prevalence of free-text questions lends itself nicely to presenting the results in this way). With regard to the statement “Across the other questions, 17 comments related to professional benefits for the Fellows themselves that included: improving personal knowledge and practices; understanding how much of research is software driven; developing a habit for research related blogging; identifying new areas in their own research fields; and thinking about research software engineering as a career”: Can the authors provide some information about the prevalence of each category of professional benefits? Counts are not necessarily the only way to do this; the authors might add phrasing indicating whether one or more of the categories was more prominent than the others. In the limitations section, the authors might also note the bias in who would respond to such a survey. In other words, awardees who had a positive experience might be more inclined to respond to a survey about the program’s benefits. Miscellaneous notes: The authors might consider moving the sentence “The study received approval from the Computer Science School Panel (ref: 2017-2308-3295) on the delegated authority of the University Research Ethics Committee (UREC), University of Manchester” to the first paragraph under “Methods,” where it seems more appropriate. Given the experience of the authors in this domain, to what extent do they agree with/disagree with the suggested improvements, and what other improvements do they suggest? 