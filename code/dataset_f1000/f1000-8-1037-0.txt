This article presents the items comprising a minimum data set for a registry of congenital abnormalities in Rwanda, determined through a survey of health professionals. It addresses an important topic, since the set up and maintenance of a registry is no small feat, and increasing the likelihood that key, relevant items are measured is critical. I believe the authors are proposing a ‘minimum data set’ (MDS) rather than a core outcome set (COS). A MDS typically includes a COS plus additional variables (for example baseline, risk factors and treatment variables). Use of the term ‘items’ rather than ‘outcomes’, and ‘MDS’ rather than ‘COS’, throughout would be preferable therefore. Background How did the 15 African studies reviewed determine items for their registries? This information would be of interest to the reader. Is it clear that they did not use a consensus process, and if not, how did they determine what to measure? Methods In round one, a long list of potential items has been created. This is not usually referred to as a ‘draft COS’ however since it consists of a list of any outcome ever measured by one or more groups rather than being based on any consensus process. The list of items is long. Was there any randomisation to address the potential for survey fatigue? Could the authors examine the data for this problem? If not, this should be discussed as a potential limitation. Pre-defining various elements of the process can reduce the potential for bias. Although no study protocol has been published in a journal, might there be one available online? Is there a Research Ethics Committee (REC) application where the design is described or did the authors determine that this work did not require REC approval? If the latter, a statement to this effect, with explanation, should be included. It does not appear that an individual participant had the opportunity to review scores from other participants, to reflect on their own view, and then to rescore. The study design appears to be a series of two surveys therefore rather than a Delphi survey. This should be clarified. Results The authors state there was an ineligible participant but continue to include their results. This should be clarified and explained, and the tables amended as appropriate. The addition of 32 items is high. What might this imply? How many of these additional items were in the final 103? The number of new outcomes suggested in round 2 in the ‘syndrome/diagnosis’ domain is 6 in Table 1 but 8 in Table 3. Please clarify this inconsistency. Table 2 – please add footnotes to describe the ‘Other’ categories. Table 3 – please order ‘Patient (infant) details’ first to match Table 1. There were 8 items common to the previous registries. Were these 8 in the final set? This would be an interesting discussion point. Discussion When referring to the number of ‘outcomes’ in previous registries, is it outcomes or rather items? The COS-STAD standards require patients (here parents) to be involved in the determination of important outcomes. Some discussion as to why parents were not involved in this project would be of interest to the reader. MDS and COS projects often include an in-person meeting to finalise the set. Some discussion as to whether this was considered and, if so, why it was not pursued would be of interest to the reader. Why is ‘the use of non-African repository data-sets in the first draft’ necessarily a limitation? Conclusion The authors conclude that a new set of registry items should be developed for each setting. I believe this approach could contribute to research waste. I would recommend that each group wishing to implement a standardised set of registry items should consider existing sets first, to assess their generalisability to the setting at hand, and critically appraise the methods used. If a new set is still needed for the new setting, then a consensus process should be followed. Typos ‘core outcome’ not ‘core-outcome’ Abbreviations - COMET (Core Outcome Measures In Effectiveness Trials) 