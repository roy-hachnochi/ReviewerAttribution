This is a “proof of concept” publication that introduces a novel head-mounted camera apparatus for obtaining spatially accurate videos of facial expressions that is able to compensate for unwanted head movements that often occur during research projects, especially those that involve spontaneous facial expressions. The apparatus uses a small, light-weight and relatively inexpensive Go-Pro video camera (30 fps, 1,280 x 720 pixels) that is mounted on a rectangular(light-weight frame work that in turn has a head mount that rests on top of the head and over the ears so that it does not block or interfere with the facial muscles that give rise to forehead expressions (see Figure 1, panels D and C, and Figure 3, panel A). The authors provide directions for construction of the apparatus with blueprints and provide a means for the facial expression videos to be synchronized with audio recordings for accurate off-line analyses (FaceSync). In addition, the authors present 4 brief “proof of concept” experiments that demonstrate the utility of their apparatus and FaceSync. The most important is Study 1, in which the subject moves his head 90 degrees to the left and then 90 degrees to the right of center. The video was then analyzed off-line using the iMotion Emotient FACET engine that provides “face registration success, landmark positions, AU predictions and emotion predictions.” Face detection was 100% successful for the entire video. In comparison, using a webcam (stationary) video recording for the same sequence, only 75% of the video was successfully analyzed because the iMotion Emotient FACET engine failed to detect the face during head rotation. This publication makes a major contribution to the quantitative analysis of facial expressions that use video recordings. To date, research videos of facial expressions are obtained by using a fixed camera set-up that cannot compensate for spontaneous head movements, i.e. a computer webcam, a tripod-mounted camera or a pan-tilt-zoom camera (see Figure 1, panels A, B and C). Although software exists that can partially compensate for head movement in a given plane, it is mathematically very difficult, if not impossible, to compensate for head movements that occur over multiple planes, especially rotatory head movements, when attempting to quantitatively analyze facial expressions using computer software techniques. Thus, the head-mounted camera apparatus will allow researchers to obtain better and more complete quantitative data regarding facial expressions. My only suggestion to the authors is that they might consider adding an adjustable counter weight to the back of their apparatus to make the frame more comfortable for the subject. 