

    <!DOCTYPE html>
<html class="">

        
<head>
    <title>Progress in perceptual research: the case of... | F1000Research</title>
    <meta charset="utf-8">
    <!--<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>-->
    <!--<meta lang="$locale">-->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="9-QVycOO2_ob3Z9QzRmXv2CF08A9oyYXqWyTiVdKPlU" />
    <!-- This is commented out to fix display problems on mobile devices.
    We may use it again once we implement a responsive design that supports native device resolutions.
    <meta name="viewport" content="width=device-width"> -->

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <link rel="alternate" title="Recent articles published in F1000Research" href="/rss" type="application/rss+xml">
            <link rel="alternate" type="application/pdf" title="PDF" href="https://f1000research.com/articles/8-765/pdf"/>
        <link rel="canonical" href="https://f1000research.com/articles/8-765" />
    
            <meta name="description" content="Read the original article in full on F1000Research: Progress in perceptual research: the case of prosopagnosia" />
    
            <meta name="og:title" content="F1000Research Article: Progress in perceptual research: the case of prosopagnosia.">
            <meta name="og:description" content="Read the latest article version by Andrea Albonico, Jason Barton, at F1000Research.">
            <meta name="og:image" content="/img/sharing/og_research.png">
            <meta name="version-id" content="20234">
            <meta name="article-id" content="18492">
            <meta name="dc.title" content="Progress in perceptual research: the case of prosopagnosia">
            <meta name="dc.description" content="Prosopagnosia is an impairment in the ability to recognize faces and can be acquired after a brain lesion or occur as a developmental variant. Studies of prosopagnosia make important contributions to our understanding of face processing and object recognition in the human visual system. We review four areas of advances in the study of this condition in recent years. First are issues surrounding the diagnosis of prosopagnosia, including the development and evaluation of newer tests and proposals for diagnostic criteria, especially for the developmental variant. Second are studies of the structural basis of prosopagnosia, including the application of more advanced neuroimaging techniques in studies of the developmental variant. Third are issues concerning the face specificity of the defect in prosopagnosia, namely whether other object processing is affected to some degree and in particular the status of visual word processing in light of recent predictions from the &ldquo;many-to-many hypothesis&rdquo;. Finally, there have been recent rehabilitative trials of perceptual learning applied to larger groups of prosopagnosic subjects that show that face impairments are not immutable in this condition.">
            <meta name="dc.subject" content="face recognition, neuroimaging, diagnosis, rehabilitation, object recognition">
            <meta name="dc.creator" content="Albonico, Andrea">
            <meta name="dc.creator" content="Barton, Jason">
            <meta name="dc.date" content="2019/05/31">
            <meta name="dc.identifier" content="doi:10.12688/f1000research.18492.1">
            <meta name="dc.source" content="F1000Research 2019 8:765">
            <meta name="dc.format" content="text/html">
            <meta name="dc.language" content="en">
            <meta name="dc.publisher" content="F1000 Research Limited">
            <meta name="dc.rights" content="https://creativecommons.org/licenses/by/3.0/igo/">
            <meta name="dc.type" content="text">
            <meta name="prism.keyword" content="face recognition">
            <meta name="prism.keyword" content="neuroimaging">
            <meta name="prism.keyword" content="diagnosis">
            <meta name="prism.keyword" content="rehabilitation">
            <meta name="prism.keyword" content="object recognition">
            <meta name="prism.publication.Name" content="F1000Research">
            <meta name="prism.publicationDate" content="2019/05/31">
            <meta name="prism.volume" content="8">
            <meta name="prism.number" content="765">
            <meta name="prism.versionIdentifier" content="1">
            <meta name="prism.doi" content="10.12688/f1000research.18492.1">
            <meta name="prism.url" content="https://f1000research.com/articles/8-765">
            <meta name="citation_title" content="Progress in perceptual research: the case of prosopagnosia">
            <meta name="citation_abstract" content="Prosopagnosia is an impairment in the ability to recognize faces and can be acquired after a brain lesion or occur as a developmental variant. Studies of prosopagnosia make important contributions to our understanding of face processing and object recognition in the human visual system. We review four areas of advances in the study of this condition in recent years. First are issues surrounding the diagnosis of prosopagnosia, including the development and evaluation of newer tests and proposals for diagnostic criteria, especially for the developmental variant. Second are studies of the structural basis of prosopagnosia, including the application of more advanced neuroimaging techniques in studies of the developmental variant. Third are issues concerning the face specificity of the defect in prosopagnosia, namely whether other object processing is affected to some degree and in particular the status of visual word processing in light of recent predictions from the &ldquo;many-to-many hypothesis&rdquo;. Finally, there have been recent rehabilitative trials of perceptual learning applied to larger groups of prosopagnosic subjects that show that face impairments are not immutable in this condition.">
            <meta name="citation_description" content="Prosopagnosia is an impairment in the ability to recognize faces and can be acquired after a brain lesion or occur as a developmental variant. Studies of prosopagnosia make important contributions to our understanding of face processing and object recognition in the human visual system. We review four areas of advances in the study of this condition in recent years. First are issues surrounding the diagnosis of prosopagnosia, including the development and evaluation of newer tests and proposals for diagnostic criteria, especially for the developmental variant. Second are studies of the structural basis of prosopagnosia, including the application of more advanced neuroimaging techniques in studies of the developmental variant. Third are issues concerning the face specificity of the defect in prosopagnosia, namely whether other object processing is affected to some degree and in particular the status of visual word processing in light of recent predictions from the &ldquo;many-to-many hypothesis&rdquo;. Finally, there have been recent rehabilitative trials of perceptual learning applied to larger groups of prosopagnosic subjects that show that face impairments are not immutable in this condition.">
            <meta name="citation_keywords" content="face recognition, neuroimaging, diagnosis, rehabilitation, object recognition">
            <meta name="citation_journal_title" content="F1000Research">
            <meta name="citation_author" content="Andrea Albonico">
            <meta name="citation_author_institution" content="Human Vision and Eye Movement Laboratory, Departments of Medicine (Neurology), Ophthalmology and Visual Sciences, Psychology, University of British Columbia, Vancouver, Canada">
            <meta name="citation_author" content="Jason Barton">
            <meta name="citation_author_institution" content="Human Vision and Eye Movement Laboratory, Departments of Medicine (Neurology), Ophthalmology and Visual Sciences, Psychology, University of British Columbia, Vancouver, Canada">
            <meta name="citation_publication_date" content="2019/05/31">
            <meta name="citation_volume" content="8">
            <meta name="citation_publication_number" content="765">
            <meta name="citation_version_number" content="1">
            <meta name="citation_doi" content="10.12688/f1000research.18492.1">
            <meta name="citation_firstpage" content="765">
            <meta name="citation_pdf_url" content="https://f1000research.com/articles/8-765/v1/pdf">
    

    
    <link href="/img/favicon-research.ico" rel="shortcut icon" type="image/ico">
    <link href="/img/favicon-research.ico" rel="icon" type="image/ico">

        <link rel="stylesheet" href="/1597255280893/css/mdl/material-design-lite.css" type="text/css" media="all" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/MaterialDesign-Webfont/2.2.43/css/materialdesignicons.min.css" />

        
            
    <link rel="stylesheet" href="/1597255280893/css/F1000Research.css" type="text/css" media="all" />
    <link rel="stylesheet" href="/css/F1000ResearchFontIcons/F1000ResearchFontIcons.css" type="text/css" media="all" />
    <link rel="stylesheet" href="/css/F1000ResearchFontIcons/animation.css" type="text/css" media="all" />

        <!--[if IE 7]><link rel="stylesheet" href="/css/F1000ResearchFontIcons/F1000ResearchFontIcons-ie7.css" media="all" /><![endif]-->

                    <script>dataLayer = [];</script>
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-54Z2SBK');</script>
        <!-- End Google Tag Manager -->
    
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.1/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="/js/vendor/jquery-1.8.1.min.js"><\/script>')</script>
    <script src="/1597255280893/js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>
    <script src="/1597255280893/js/shared_scripts/sticky.js"></script>
    <script src="/1597255280893/js/shared_scripts/helpers.js"></script>
    <script src="/1597255280893/js/shared_scripts/menu.js"></script>
    <script src="/1597255280893/js/shared_scripts/navbar.js"></script>
    <script src="/1597255280893/js/shared_scripts/platforms.js"></script>
    <script src="/1597255280893/js/shared_scripts/object-polyfills.js"></script>
            <script src="/1597255280893/js/vendor/lodash.min.js"></script>
        <script>CKEDITOR_BASEPATH='https://f1000research.com/js/ckeditor/'</script>
    <script src="https://f1000researchdata.s3-eu-west-1.amazonaws.com/js/plugins.js"></script>
    <script src="/1597255280893/js/shared_scripts/helpers.js"></script>
    <script src="/1597255280893/js/app/research.js"></script>
    <script>window.reactTheme = 'research';</script>
    <script src="/1597255280893/js/public/bundle.js"></script>

    <script src="/1597255280893/js/app/research.ui.js"></script>
    <script src="/1597255280893/js/app/login.js"></script>
    <script src="/1597255280893/js/app/main.js"></script>
    <script src="/1597255280893/js/app/js-date-format.min.js"></script>
    <script src="/1597255280893/js/app/search.js"></script>
    <script src="/1597255280893/js/app/cookies_warning.js"></script>
    <script src="/1597255280893/js/mdl/mdl.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script src="https://f1000researchdata.s3-eu-west-1.amazonaws.com/js/ckeditor.js"></script>
            <script src="/js/ckeditor/adapters/jquery.js"></script>
                <script src="/js/article/article_scrolling_module.js"></script>
            <script src="/js/article/article_stats.js"></script>
            <script src="/js/article/article.js"></script>
            <script src="/js/shared_scripts/referee_timeline_pagination.js"></script>
            <script src="/js/app/text_editor_controller.js"></script>
            <script src="//s7.addthis.com/js/250/addthis_widget.js#pubid=ra-503e5e99593dc42c"></script>
            <script src="/js/article/article_metrics.js"></script>
        
                                                                            <script>
            if (window.location.hash == '#_=_'){
                window.location = window.location.href.split('#')[0]
            }
        </script>

                    
        
    <!-- pixelId: 1641728616063202 :: assetPixelId: 6034867600215 :: funderPixelId:  -->

            <!-- Facebook pixel code (merged with EP GTM code) -->
        <script>
            !function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function()

            {n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}
            ;if(!f._fbq)f._fbq=n;
            n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
            t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
            document,'script','https://connect.facebook.net/en_US/fbevents.js');

            fbq('init', '1641728616063202');

            
            fbq('track', "PixelInitialized", {});
        </script>

        <noscript><img height="1" width="1" style="display:none"
            src="https://www.facebook.com/tr?id=1641728616063202&noscript=1&amp;ev=PixelInitialized"
        /></noscript>
        <!-- End Facebook Pixel Code -->
    
                <script>
            (function(h,o,t,j,a,r){
                h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
                h._hjSettings={hjid:917825,hjsv:6};
                a=o.getElementsByTagName('head')[0];
                r=o.createElement('script');r.async=1;
                r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
                a.appendChild(r);
            })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
        </script>
    
</head>
<body  class="o-page-container no-js p-article o-layout-reset   ">

    
                            <!-- Google Tag Manager (noscript) -->
        <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-54Z2SBK"
        height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
        <!-- End Google Tag Manager (noscript) -->
    
        
    <div class="o-page">

        <div id="notify-container"></div>
        <div id="pageWarning"></div>
        <div id="pageMessage"></div>
        <div id="pageFooterMessage"></div>

                                <div id="f1r-ga-data" data-name="f1r-ga-data" class="f1r-ga-data"
                data-user-registered="false"
                data-user-module=""
                data-current-path=""
                data-location=""
                data-website="F1000Research"
                data-websiteDisplayName="F1000Research">
            </div>
        
                
        
        <div class="header-wrapper   js-navbar-space ">
                            


    










        
                            
    
            



<nav class="c-navbar js-navbar js-mini-nav js-sticky c-navbar--js-sticky c-navbar--userSite c-navbar__platform-bgcolor  c-navbar--bg-f1000research ">

    <div class="c-navbar__content">

                                <div class="c-navbar__extras">
            <div class="o-wrapper">
                <div class="o-actions o-actions--middle c-navbar__extras-row">
                    <div class="o-actions__primary">
                        
                                            </div>
                                    </div>
            </div>
        </div>

        <div class="o-wrapper t-inverted js-sticky-start">

            <div class="c-navbar__branding-row">
                <div class="c-navbar__row">


                                        
                    <div class="c-navbar__primary u-mr--2">

                                                                                                                                                                                                    <a href="/" class="c-navbar__branding u-ib u-middle"   data-test-id="nav_branding"  >
                                <img class="u-ib u-middle" src="/img/research/F1000Research_white_solid.svg" alt="F1000Research">
                            </a>
                                            </div>

                    <div class="c-navbar__secondary c-navbar__row">


                                                
                                                    <form action="/search" class="-navbar__secondary u-mr--2 c-search-form js-search-form u-hide u-show@navbar">
                                <label for="searchInput" class="c-search-form__label _mdl-layout">
                                    <input name="q" type="search" class="c-search-form__input" id="searchInput" placeholder="Search">
                                    <button type="submit" class="c-search-form__submit mdl-button mdl-js-button mdl-button--icon"><i class="material-icons">search</i></button>
                                </label>
                            </form>
                        
                                                
                                                    <div class="c-navbar__primary u-hide u-show@navbar">
                                <div class="_mdl-layout c-navbar__cta">
                                    <a class="mdl-button mdl-js-button mdl-button--raised mdl-button--no-shadow mdl-button--multi-line mdl-js-ripple-effect mdl-button--inverted c-navbar__submit" href="/for-authors/publish-your-research"   data-test-id="nav_submit_research"  ><i class="material-icons">file_upload</i>Submit your research</a>
                                </div>
                            </div>
                        

                                                
                        <span class="u-hide@navbar _mdl-layout u-nowrap">

                                                            <button type="button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon c-navbar__toggle c-navbar__toggle--menu js-navbar-toggle" data-focus="#navbar_mob_search_input" data-toggle="navbarMenu" data-target="navbarMenu" aria-controls="navbarMenu" aria-expanded="false" aria-label="Toggle navigation"   data-test-id="nav_menu_search_mob"  ><i class="material-icons">search</i></button>
                            
                                                            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-button--multi-line c-navbar__toggle c-navbar__toggle--menu js-navbar-toggle" type="button" data-toggle="navbarMenu" data-target="navbarMenu" aria-controls="navbarMenu" aria-expanded="false" aria-label="Toggle navigation"   data-test-id="nav_menu_toggle_mob"  >
                                    <i class="material-icons c-navbar__toggle-open">menu</i>
                                    <i class="material-icons c-navbar__toggle-close">close</i>
                                </button>
                                                    </span>
                    </div>

                </div>
            </div>

                        
                            <div class="c-navbar__menu-row js-navbar-block is-collapsed" id="navbarMenu">

                                                                                                                                                
                                                                    
                                                                    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                            

                                                                
                                                                                                                                                                                                                                
                                            
                    <div class="c-navbar__menu-row-content">

                                                                            <div class="u-hide@navbar c-navbar__menu-bar-spacing">
                                <form action="/search" class="c-search-form js-search-form">
                                    <label for="navbar_mob_search_input" class="c-search-form__label _mdl-layout">
                                        <input id="navbar_mob_search_input" name="q" type="search" class="c-search-form__input" placeholder="Search">
                                        <button type="submit" class="c-search-form__submit mdl-button mdl-js-button mdl-button--icon"><i class="material-icons">search</i></button>
                                    </label>
                                </form>
                            </div>
                        
                        <div class="o-actions o-actions--middle">

                            <div class="o-actions__primary">

                                                                
    <ul class="c-menubar c-navbar__menu-bar js-main-menu"   id="main-menu"   role="menubar" aria-label="Main Navigation"  data-menu-group="navbar" >

        
            
                                                                
                                
                                
                                    <li role="none"
                        data-index="0"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/browse/articles" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="0"
                              data-test-id="nav_browse"                              >Browse</a>

                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="1"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/gateways" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="-1"
                              data-test-id="nav_gatewaysViewAndBrowse"                              >Gateways & Collections</a>

                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="2"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="-1"
                              data-test-id="nav_for-authors"                              >How to Publish</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="How to Publish">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_submit-manuscript"                      href="/for-authors/publish-your-research"
                    role="menuitem"
                    tabindex="0">Submit your Research</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-submissions"                      href="/for-authors/my-submissions"
                    role="menuitem"
                    tabindex="-1">My Submissions</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-guidelines"                      href="/for-authors/article-guidelines"
                    role="menuitem"
                    tabindex="-1">Article Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-guidelines-new-versions"                      href="/for-authors/article-guidelines-new-versions"
                    role="menuitem"
                    tabindex="-1">Article Guidelines (New Versions)</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_data-guidelines"                      href="/for-authors/data-guidelines"
                    role="menuitem"
                    tabindex="-1">Data Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_asset-guidelines"                      href="/for-authors/posters-and-slides-guidelines"
                    role="menuitem"
                    tabindex="-1">Posters and Slides Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_document-guidelines"                      href="/for-authors/document-guidelines"
                    role="menuitem"
                    tabindex="-1">Document Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-processing-charges"                      href="/for-authors/article-processing-charges"
                    role="menuitem"
                    tabindex="-1">Article Processing Charges</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_finding-referees"                      href="/for-authors/tips-for-finding-referees"
                    role="menuitem"
                    tabindex="-1">Finding Article Reviewers</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="3"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="-1"
                              data-test-id="nav_about-contact"                              >About</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="About">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_about-page"                      href="/about"
                    role="menuitem"
                    tabindex="0">How it Works</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_referee-guidelines"                      href="/for-referees/guidelines"
                    role="menuitem"
                    tabindex="-1">For Reviewers</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_advisoryPanel"                      href="/advisors"
                    role="menuitem"
                    tabindex="-1">Our Advisors</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_policy-page"                      href="/about/policies"
                    role="menuitem"
                    tabindex="-1">Policies</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_glossary-page"                      href="/glossary"
                    role="menuitem"
                    tabindex="-1">Glossary</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_faqs-page"                      href="/faqs"
                    role="menuitem"
                    tabindex="-1">FAQs</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              u-hide u-show@navbar"
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      u-hide u-show@navbar"
                                          data-test-id="nav_for-developers"                      href="/developers"
                    role="menuitem"
                    tabindex="-1">For Developers</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_newsroom-page"                      href="/newsroom"
                    role="menuitem"
                    tabindex="-1">Newsroom</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_contact-page"                      href="/contact"
                    role="menuitem"
                    tabindex="-1">Contact</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="4"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="https://blog.f1000.com/blogs/f1000research/" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                             target="_blank"                                                         tabindex="-1"
                              data-test-id="nav_blog"                              >Blog</a>

                                            </li>
                
            
        
    </ul>



                            </div>

                            <div class="o-actions__secondary">

                                                                
    <ul class="c-menubar c-navbar__menu-bar js-main-menu"   id="secondary-items"   role="menubar" aria-label="My Account"  data-menu-group="navbar" >

        
            
                                                                
                                
                                
                                    <li role="none"
                        data-index="0"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="0"
                              data-test-id="nav_my-research"                              >My Research</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="My Research">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-submissions"                      href="/login?originalPath=/my/submissions"
                    role="menuitem"
                    tabindex="0">Submissions</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-email-alerts"                      href="/login?originalPath=/my/email-alerts"
                    role="menuitem"
                    tabindex="-1">Content and Tracking Alerts</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-user-details"                      href="/login?originalPath=/my/user-details"
                    role="menuitem"
                    tabindex="-1">My Details</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="1"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/login?originalPath=/articles/8-765.html" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="-1"
                              data-test-id="nav_sign-in"                              >Sign In</a>

                                            </li>
                
            
        
    </ul>



                            </div>

                                                                                        <div class="_mdl-layout c-navbar__cta u-hide@navbar c-navbar__menu-bar-spacing">
                                    <a class="mdl-button mdl-js-button mdl-button--raised mdl-button--multi-line mdl-button--no-shadow mdl-js-ripple-effect mdl-button--inverted c-navbar__submit" href="/for-authors/publish-your-research"   data-test-id="nav_submit_research_mob"  ><i class="material-icons">file_upload</i>Submit your research</a>
                                </div>
                                                    </div>

                    </div>

                </div>
            
        </div>

    </div>

</nav>
                    </div>

        <div class="content-wrapper o-page__main row ">
            <div id="highlight-area" class="content ">
                





<div id=article-metadata class=hidden> <input type=hidden name=versionId value=20234 /> <input type=hidden id=articleId name=articleId value=18492 /> <input type=hidden id=xmlUrl value="/articles/8-765/v1/xml"/> <input type=hidden id=xmlFileName value="-8-765-v1.xml"> <input type=hidden id=article_uuid value=22b4231b-6a84-47bf-888e-2fedb327499f /> <input type=hidden id=referer value=""/> <input type=hidden id=meta-article-title value="Progress in perceptual research: the case of prosopagnosia"/> <input type=hidden id=workspace-export-url value="https://sciwheel.com/work/api/import/external?doi=10.12688/f1000research.18492.1"/> <input type=hidden id=versionDoi value="10.12688/f1000research.18492.1"/> <input type=hidden id=usePmcStats value=true /> </div> <main class="o-wrapper p-article__wrapper js-wrapper"> <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "ScholarlyArticle",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://f1000research.com/articles/8-765"
  },
  "headline": "Progress in perceptual research: the case of prosopagnosia",
  "datePublished": "2019-05-31T16:48:21",
  "dateModified": "2019-05-31T16:48:21",
  "author": [
    {
      "@type": "Person",
      "name": "Andrea Albonico"
    },    {
      "@type": "Person",
      "name": "Jason Barton"
    }  ],
  "publisher": {
    "@type": "Organization",
    "name": "F1000Research",
    "logo": {
      "@type": "ImageObject",
      "url": "https://f1000research.com/img/AMP/F1000Research_image.png",
      "height": 480,
      "width": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://f1000research.com/img/AMP/F1000Research_image.png",
    "height": 1200,
    "width": 150
  },
  "description": "Prosopagnosia is an impairment in the ability to recognize faces and can be acquired after a brain lesion or occur as a developmental variant. Studies of prosopagnosia make important contributions to our understanding of face processing and object recognition in the human visual system. We review four areas of advances in the study of this condition in recent years. First are issues surrounding the diagnosis of prosopagnosia, including the development and evaluation of newer tests and proposals for diagnostic criteria, especially for the developmental variant. Second are studies of the structural basis of prosopagnosia, including the application of more advanced neuroimaging techniques in studies of the developmental variant. Third are issues concerning the face specificity of the defect in prosopagnosia, namely whether other object processing is affected to some degree and in particular the status of visual word processing in light of recent predictions from the &ldquo;many-to-many hypothesis&rdquo;. Finally, there have been recent rehabilitative trials of perceptual learning applied to larger groups of prosopagnosic subjects that show that face impairments are not immutable in this condition."
}
</script> <div class="o-layout o-layout--right-gutter"> <div id=article_secondary-column class="p-article__main o-layout__item u-font-size--legal u-2/3@article not-expanded "> <div class=float-left> <script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BreadcrumbList",
    "itemListElement": [
              {
          "@type": "ListItem",
          "position": "1",
          "item": {
            "@id": "https://f1000research.com/",
            "name": "Home"
          }
        },              {
          "@type": "ListItem",
          "position": "2",
          "item": {
            "@id": "https://f1000research.com/browse/articles",
            "name": "Browse"
          }
        },              {
          "@type": "ListItem",
          "position": "3",
          "item": {
            "@id": "https://f1000research.com/articles/8-765/v1",
            "name": "Progress in perceptual research: the case of prosopagnosia"
          }
        }          ]
  }
  </script> <div class="breadcrumbs js-breadcrumbs"> <a href="/" class=f1r-standard-link>Home</a> <span class=item_separator></span> <a href="/browse/articles" class=f1r-standard-link>Browse</a> <span class=item_separator></span> Progress in perceptual research: the case of prosopagnosia </div> </div> <div class="article-badges-container u-mb--2"> <div class=crossmark-new> <script src="https://crossmark-cdn.crossref.org/widget/v2.0/widget.js"></script> <a data-target=crossmark><img height=30 width=150 src="https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg"/></a> </div> <div id=crossmark-dialog style="display: none;" title=""> <iframe id=crossmark-dialog-frame frameborder=0></iframe> </div> <div class=clearfix></div> </div> <div class=article-interaction-container> <div id=main-article-count-box class=article-count-box> <div class="article-metrics-wrapper metrics-icon-wrapper" data-version-id=20234 data-id=18492 data-downloads="" data-views="" data-scholar="10.12688/f1000research.18492.1" data-recommended="" data-doi="10.12688/f1000research.18492.1" data-f1r-ga-helper="Article Page Metrics (Desktop)"> <span class="metrics-on-browse article-metrics-icon f1r-icon icon-89_metrics"></span> <div class="count-title article-metrics-text">ALL Metrics</div> <div class=js-article-metrics-container></div> </div> <div> <div class=count-delimiter></div> <div title="Total views from F1000Research and PubMed Central"> <div class="count-container view-count js-views-count">-</div> <div class=count-title><span class="count-title-icon count-title-views-icon"></span>Views</div> </div> <div class=download-counts hidden> <div class=count-delimiter></div> <div title="Total downloads from F1000Research and PubMed Central"> <div class="count-container js-downloads-count"></div> <div class=count-title><span class="count-title-icon f1r-icon icon-76_download_file"></span>Downloads</div> </div> </div> </div> </div> <div id=main-article-interaction-box class="article-interaction-box has-control-tab"> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-102_download_pdf"></span> <a href="https://f1000research.com/articles/8-765/v1/pdf?article_uuid=22b4231b-6a84-47bf-888e-2fedb327499f" title="Download PDF" class="button-link download pdf-download-helper" target=_blank>Get PDF</a> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-103_download_xml"></span> <a id=download-xml href="#" class="button-link download" title="Download XML">Get XML</a> </div> </div> <div class="article-interaction-info article-page"> <div class="cite-article-popup-wrapper article-page-interaction-box"> <div class="article-interaction-button cite-article-button" title="Cite this article" data-windowref=cite-article-popup-18492-1> <span class="f1r-icon icon-82_quote"></span> <a href="#" class="button-link cite-article-popup-link" title="Cite Article">Cite</a> </div> <div id=cite-article-popup-18492-1 class="popup-window-wrapper is-hidden"> <div class=cite-popup-background></div> <div class="popup-window top-popup cite-this-article-box research-layout"> <div class="popup-window-title small cite-title">How to cite this article</div> <span id=cite-article-text-18492-1 data-test-id=copy-citation_text> <span class="article-title-and-info in-popup">Albonico A and Barton J. Progress in perceptual research: the case of prosopagnosia [version 1; peer review: 2 approved]</span>. <i>F1000Research</i> 2019, <b>8</b>(F1000 Faculty Rev):765 (<a class=new-orange href="https://doi.org/10.12688/f1000research.18492.1" target=_blank>https://doi.org/10.12688/f1000research.18492.1</a>) </span> <div class="popup-window-title small margin-top-20 margin-bottom-20 note"> <strong>NOTE:</strong> it is important to ensure the information in square brackets after the title is included in all citations of this article. </div> <div class=float-right> <button class="secondary no-fill orange-text-and-border margin-right-20 close-cite-popup uppercase">Close</button> <button id=copy-citation-details class="secondary orange copy-cite-article-version uppercase js-clipboard" title="Copy the current citation details to the clipboard." data-clipboard-target="#cite-article-text-18492-1" data-test-id=copy-citation_button>Copy Citation Details</button> </div> </div> </div> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-76_download_file"></span> <a id=export-citation href="#" class="button-link download" title="Export Citation">Export</a> </div> <div class="modal-window-wrapper is-hidden"> <div id=export-citation-popup class="modal-window padding-20"> <div class=modal-window-close-button></div> <div class=modal-window-title>Export Citation</div> <div class=modal-window-row> <div> <input type=radio name=export-citation-option value=WORKSPACE /> <span class=radio-label>Sciwheel</span> </div> <div> <input type=radio name=export-citation-option value=ENDNOTE /> <span class=radio-label>EndNote</span> </div> <div> <input type=radio name=export-citation-option value=REF_MANAGER /> <span class=radio-label>Ref. Manager</span> </div> <div> <input type=radio name=export-citation-option value=BIBTEX /> <span class=radio-label>Bibtex</span> </div> <div> <input type=radio name=export-citation-option value=PROCITE /> <span class=radio-label>ProCite</span> </div> <div> <input type=radio name=export-citation-option value=SENTE /> <span class=radio-label>Sente</span> </div> </div> <div class=modal-window-footer> <button class=general-white-orange-button id=export-citation-submit>EXPORT</button> </div> <div class=default-error style="display: none;">Select a format first</div> </div> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-90_track"></span> <a class="button-link track-article" data-article-id=18492 id=track-article-signin-18492 title="Receive updates on new activity such as publication of new versions, peer reviews or author responses." href="/login?originalPath=/trackArticle/18492?target=/articles/8-765/v1">Track</a> </div> </div> <div class="article-interaction-info article-page"> <div class="article-interaction-button email-article"> <span class="f1r-icon icon-6_email"></span> <a href="#" class=button-link title="Email this article">Email</a> </div> <div class="email-article-version-container small-tooltip _chrome-fix"> <div class=close-icon><span class="f1r-icon icon-3_close_big"></span></div> <script src='https://www.recaptcha.net/recaptcha/api.js'></script> <form class="recommend-version-form research-layout"> <p>All fields are required.</p> <input name=versionId type=hidden value=20234 /> <input name=articleId type=hidden value=18492 /> <input name=senderName class="form-input-field reg-form" value="" type=text placeholder="Your name"/> <input name=senderEmail class="form-input-field reg-form margin-top" value="" type=text placeholder="Your email address"/> <textarea name=recipientEmails class="form-textarea-field ninetynine-percent-wide margin-top no-resize" placeholder="Recipient email address(es) (comma delimited)"></textarea> <input class="form-input-field reg-form margin-top" name=subject type=text value="Interesting article on F1000Research" placeholder=Subject /> <textarea name=message class="form-textarea-field reg-form margin-top no-resize">I thought this article from F1000Research (https://f1000research.com) would be of interest to you.</textarea> <div class="g-recaptcha margin-top" data-sitekey=6LcHqxoUAAAAANP3_0TzpGG6qFvl4DhbUcuRzw7W></div> <input value="" name=captcha type=hidden /> <p>A full article citation will be automatically included.</p> <p><img class="ticker-email-article-details hidden" src="/img/ticker.gif" alt=loading /></p> <button class="secondary orange margin-bottom" data-test-id=version_share_email_send>SEND EMAIL</button> <div class="orange-message margin-bottom is-hidden" data-test-id=version_share_email_message></div> </form> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-34_share"></span> <a href="#" class="button-link last addthis_button share-article" title="Share this article">Share</a> </div> </div> </div> <div id=article-interaction-control-tab class=article-interaction-control-tab> <div id=hide-article-interaction class=article-interaction-control title="Hide Toolbox">&#9644;</div> <div id=show-article-interaction class="article-interaction-control open" title="Show Toolbox">&#10010;</div> </div> </div> <div class="article-header-information article-page"> <div class="f1r-article-mobile article-heading-bar"></div> <div class="article-type article-display">Review </div> <div class="article-title-and-info article-view highlighted-article" id=anchor-title> <h1>Progress in perceptual research: the case of prosopagnosia</h1><span class=other-info> [version 1; peer review: 2 approved]</span> </div> <div class=article-subtitle></div> <div class=f1r-article-desk> <div class="authors _mdl-layout"><span class="">Andrea Albonico,&nbsp;</span><span class=""><a href="mailto:jasonbarton@shaw.ca" title="Send email" class="cauthor research-layout"><span class='f1r-icon icon-6_email orange'></span><span>Jason Barton</span></a><a href="https://orcid.org/0000-0001-8264-3795" target=_blank id=author-orcid-1><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=author-orcid-1><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0001-8264-3795</div></span></div> </div> <div class=f1r-article-mobile> <div class="authors _mdl-layout"><span class="">Andrea Albonico,&nbsp;</span><span class=""><a href="mailto:jasonbarton@shaw.ca" title="Send email" class="cauthor research-layout"><span class='f1r-icon icon-6_email orange'></span><span>Jason Barton</span></a><a href="http://orcid.org/0000-0001-8264-3795" target=_blank id=mauthor-orcid-1><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=mauthor-orcid-1><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0001-8264-3795</div></span></div> </div> <div class=f1r-article-mobile> <div class=article-pubinfo-mobile> PUBLISHED 31 May 2019 </div> </div> <span class=Z3988 title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;rft_id=info:doi/10.12688%2Ff1000research.18492.1"></span> <div class=f1r-article-desk> <div class="contracted-details first"> <a href="#" class="contracted-details-label author-affiliations"><span class=contracted></span>Author details</a> <a href="#" class=section-title>Author details</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details affiliations is-hidden"> Human Vision and Eye Movement Laboratory, Departments of Medicine (Neurology), Ophthalmology and Visual Sciences, Psychology, University of British Columbia, Vancouver, Canada<br/> <p> <div class=margin-bottom> Andrea Albonico <br/> <span>Roles: </span> Conceptualization, Methodology, Writing – Original Draft Preparation </div> <div class=margin-bottom> Jason Barton <br/> <span>Roles: </span> Conceptualization, Formal Analysis, Supervision, Writing – Review & Editing </div> </p> </div> </div> </div> <div class=f1r-article-mobile> <div class="article-page-section-box margin-bottom-40 research-layout"> <span class=box-title> <span class="f1r-icon icon-85_peer_review"></span> OPEN PEER REVIEW </span> <button class="tertiary grey float-right" data-scrollto=article-reports>DETAILS</button> <div class="status-row referee-reports-container"> REVIEWER STATUS <span class=status-icons> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved data-refInfo=51530-48967></span> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved data-refInfo=51531-48968></span> </span> </div> </div> </div> </div> <h2 class="article-headings article-page-abstract" id=anchor-abstract> <span class="f1r-article-mobile-inline abstract-heading-border"></span> Abstract </h2> <div class="article-abstract article-page-general-text-mobile research-layout"> <div class="abstract-text is-expanded"> Prosopagnosia is an impairment in the ability to recognize faces and can be acquired after a brain lesion or occur as a developmental variant. Studies of prosopagnosia make important contributions to our understanding of face processing and object recognition in the human visual system. We review four areas of advances in the study of this condition in recent years. First are issues surrounding the diagnosis of prosopagnosia, including the development and evaluation of newer tests and proposals for diagnostic criteria, especially for the developmental variant. Second are studies of the structural basis of prosopagnosia, including the application of more advanced neuroimaging techniques in studies of the developmental variant. Third are issues concerning the face specificity of the defect in prosopagnosia, namely whether other object processing is affected to some degree and in particular the status of visual word processing in light of recent predictions from the “many-to-many hypothesis”. Finally, there have been recent rehabilitative trials of perceptual learning applied to larger groups of prosopagnosic subjects that show that face impairments are not immutable in this condition. </div> <div class=abstract-for-mobile> <div class="margin-top-30 padding-bottom-30 research-layout is-centered"> <button class="primary orange-text white-bg bigger-text abstract-expand-button-mobile with-border show" style="display: none;"> READ ALL <span class="f1r-icon icon-14_more_small orange vmiddle big"></span> </button> <button class="primary orange-text white-bg bigger-text abstract-expand-button-mobile with-border hide"> READ LESS <span class="f1r-icon icon-10_less_small orange vmiddle big"></span> </button> </div> </div> </div> <div class=clearfix></div> <div class="article-context no-divider"> <div class="article-abstract article-page-general-text-mobile research-layout generated-article-body"> <h2 class=main-title>Keywords</h2> <p class="u-mb--0 u-pb--2"> face recognition, neuroimaging, diagnosis, rehabilitation, object recognition </p> </div> </div> <div class=article-information> <span class="info-separation padding-bottom"> <div id=corresponding-author-icon class="email-icon float-left"> <span class="f1r-icon icon-6_email orange"></span> <div id=corresponding-author-window class="margin-top-20 popup-window-wrapper is-hidden"> <div class="popup-window corresponding-authors-popup"> <div class=corresponding-author-container> <div class="popup-window-title small">Corresponding Author(s)</div> <div class=authors> Jason Barton (<a href="mailto:jasonbarton@shaw.ca">jasonbarton@shaw.ca</a>) </div> </div> <div class="margin-top margin-bottom float-left"> <button id=close-popup-window class=general-white-orange-button>Close</button> </div> </div> </div> </div> <span class="icon-text float-left" data-test-id=box-corresponding-author> <b>Corresponding author:</b> Jason Barton </span> <div class=clearfix></div> </span> <span class="info-separation padding-bottom competing-interests-display"> <span class=competing-interests-title>Competing interests:</span> No competing interests were disclosed. </span> <div class="info-separation padding-bottom grant-information-display"> <span class=grant-information-title>Grant information:</span> This work was supported by the Natural Sciences and Engineering Research Council of Canada (RGPIN 319129) and Canada Research Chairs (950-228984). <br/> <i>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</i> </div> <span class="f1r-article-desk info-separation padding-bottom"> <span class="copywrite-icon float-left"> <span class="f1r-icon icon-100_open_access"></span> </span> <span class="icon-text float-left" data-test-id=box-copyright-text> <b>Copyright:</b>&nbsp; © 2019 Albonico A and Barton J. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/" target=_blank data-test-id=box-licence-link>Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. </span> <div class=clearfix></div> </span> <span class="info-separation padding-bottom" data-test-id=box-how-to-cite> <b>How to cite:</b> <span class="article-title-and-info in-article-box"> Albonico A and Barton J. Progress in perceptual research: the case of prosopagnosia [version 1; peer review: 2 approved]</span>. <i>F1000Research</i> 2019, <b>8</b>(F1000 Faculty Rev):765 (<a href="https://doi.org/10.12688/f1000research.18492.1" target=_blank>https://doi.org/10.12688/f1000research.18492.1</a>) </span> <span class=info-separation data-test-id=box-first-published><b>First published:</b> 31 May 2019, <b>8</b>(F1000 Faculty Rev):765 (<a href="https://doi.org/10.12688/f1000research.18492.1" target=_blank>https://doi.org/10.12688/f1000research.18492.1</a>)</span> <span class=info-separation data-test-id=box-latest-published><b>Latest published:</b> 31 May 2019, <b>8</b>(F1000 Faculty Rev):765 (<a href="https://doi.org/10.12688/f1000research.18492.1" target=_blank>https://doi.org/10.12688/f1000research.18492.1</a>)</span> </div> <div class=clearfix></div> <div id=article-context class=article-context> <div id=article1-body class=generated-article-body><p class="" id=d12981e157>The face is a complex structure. It has a complicated three-dimensional shape, a substantial degree of mobility, and structural constraints that make all faces fairly similar; all of these issues present challenges to a perceptual system. Nevertheless, perhaps because of the social importance of faces, humans have developed the ability to recognize faces rapidly and accurately and with seemingly little effort. Indeed, recent estimates are that the typical person can remember and recognize about 5000 faces<sup><a href="#ref-1">1</a></sup>.</p><p class="" id=d12981e164>However, for some people, face recognition is not so easy. Prosopagnosia is a condition marked by the loss of familiarity for faces and the consequent inability to identify people by their faces<sup><a href="#ref-2">2</a></sup>. Although prosopagnosic subjects frequently turn to other cues such as voice, hairstyle, or anomalous facial features, these strategies have their limitations; as a result, prosopagnosic subjects still often find social situations stressful, and recent work has shown that they can suffer from anxiety, depression, and social withdrawal<sup><a href="#ref-3">3</a>,<a href="#ref-4">4</a></sup>.</p><p class="" id=d12981e178>Studies of prosopagnosia have a time-honoured place in research on face recognition. Neuropsychological observations have played key roles in the development of cognitive models of face processing<sup><a href="#ref-5">5</a></sup> and pointed to the cerebral substrates of face recognition<sup><a href="#ref-6">6</a>,<a href="#ref-7">7</a></sup>. Even in an era when advances in face research are coming from psychophysics, functional neuroimaging, and primate neurophysiology, there are still important contributions from work on prosopagnosia. This has been spurred particularly by the recognition of a developmental variant<sup><a href="#ref-8">8</a></sup>. Although acquired prosopagnosia is rare, developmental prosopagnosia appears to be more common but debate on its exact prevalence continues<sup><a href="#ref-9">9</a></sup>. Nevertheless, the greater availability of developmental subjects has led to an increase in the number of prosopagnosic studies. In this review, we focus on four areas of recent progress in the fields of acquired and developmental prosopagnosia.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d12981e203>The diagnosis of prosopagnosia</h2><p class="" id=d12981e206>Uniform definitions are a critical starting point for research into a condition. The core defects in prosopagnosia are the loss of familiarity for previously known faces and the inability to learn to recognize new faces. In the past, this was often shown by tests using famous faces or in case studies by demonstrations that the subject could not recognize friends or family members. However, it is difficult to derive uniform diagnostic criteria from such tests. Familiarity for famous faces is affected by the subject’s age, culture, education, and interests, for example, and carefully matched controls are essential for interpreting the results of such tests. This has led to supplementation of famous face tests by the increasing use of tests that assess short-term familiarity. These show faces in a learning phase and then present these “target” faces along with new “distractor” faces in a test phase in which subjects are asked to indicate which were the faces they had learned. The most well-known examples are the Warrington Recognition Memory Test<sup><a href="#ref-10">10</a></sup> and the Cambridge Face Memory Test<sup><a href="#ref-11">11</a></sup>, the latter of which has the desirable feature of testing recognition across changes in pose or lighting. Compared with tests that use famous or personally known faces, tests of short-term familiarity provide limited exposure and lack the semantic and perceptual richness of long experience but have the advantage of uniformity in the degree of learning and testing. For the Cambridge Face Memory Test, there has also been substantial normative work showing good internal consistency (Cronbach’s alpha ranges from 0.83 to 0.89) and no effects of intelligence or the ethnic mix of faces in the subject’s life experience. There is a very modest advantage for women but a more significant effect of age in that accuracy declines for those over the age of 50<sup><a href="#ref-11">11</a>–<a href="#ref-13">13</a></sup>. Also, versions of this test have been developed for use in children<sup><a href="#ref-14">14</a></sup>.</p><p class="" id=d12981e228>There are many other tests of face processing and these were recently reviewed in detail and categorized<sup><a href="#ref-15">15</a></sup>. Diagnostic tests can be divided into three main types: (a) tests of face perception, which can include detecting faces in arrays or discriminating or matching simultaneously seen faces; (b) tests of face recognition, such as the tests for short- and long-term familiarity which were discussed above; and (c) tests of face identification, which involve naming or providing other information learned about the person whose face is shown. Prosopagnosic subjects are impaired on both recognition and identification. Performance on tests of face perception can be used to differentiate between prosopagnosic subjects who have an apperceptive variant, in which there is an under-specification of facial structure by perceptual processing, or an associative or amnestic variant, in which the problem is not perception but the ability of perceptual information to access facial memories<sup><a href="#ref-16">16</a></sup>. Examples of tests assessing face perception are the Benton Facial Recognition Test<sup><a href="#ref-17">17</a></sup>, the Cambridge Face Perception Test<sup><a href="#ref-18">18</a></sup>, the Glasgow Face Matching Test<sup><a href="#ref-19">19</a></sup>, and the Caledonian Face Test<sup><a href="#ref-20">20</a></sup>. Tests of face imagery have also been used to clarify the status of facial memories and diagnose the amnestic variant<sup><a href="#ref-21">21</a></sup>.</p><p class="" id=d12981e260>Self-report questionnaires are becoming more common tools in diagnosing prosopagnosia. They are quick and easy, do not require equipment, do not need to be done in person and hence can be used to screen a large number of subjects, even at a distance. Among those are the Kennerknecht 15-item questionnaire<sup><a href="#ref-22">22</a></sup>, the 20-item Prosopagnosia Index<sup><a href="#ref-23">23</a></sup>, and the Cambridge Face Memory Questionnaire<sup><a href="#ref-24">24</a></sup>. A potential concern is that individuals may have only modest insight into their face recognition abilities<sup><a href="#ref-25">25</a>,<a href="#ref-26">26</a></sup>, particularly children<sup><a href="#ref-27">27</a></sup>, although some studies suggest that this might not be the case for adults using the Prosopagnosia Index<sup><a href="#ref-28">28</a>,<a href="#ref-29">29</a></sup>. This concern might account for the fact that questionnaires may have high reliability but only modest sensitivity and specificity for diagnosing prosopagnosia<sup><a href="#ref-24">24</a></sup>. Because of these concerns, some have advocated that questionnaires always be supplemented by objective tests for diagnosis<sup><a href="#ref-9">9</a>,<a href="#ref-24">24</a>,<a href="#ref-30">30</a></sup>.</p><p class="" id=d12981e308>Recent reviews have discussed how to incorporate these various instruments into a diagnostic approach. This may be less of an issue for acquired prosopagnosia, in which the combination of an appropriate lesion on imaging, the subject’s awareness of a change in face recognition after lesion onset, and poor performance on an objective test of face recognition makes the diagnosis plausible. For developmental prosopagnosia, there are no definite structural or genetic markers at present and so its diagnosis still rests solely on behavioural tests. One review pointed out the wide variations between studies in the types of tests, the number of tests, and the statistical cutoffs used<sup><a href="#ref-9">9</a></sup>. This creates variable confidence in the diagnosis and introduces heterogeneity that can confound comparisons across groups and studies, an obstacle to scientific progress. As a result, there have been proposals for more uniform diagnostic criteria<sup><a href="#ref-9">9</a>,<a href="#ref-31">31</a></sup>. These include (i) subjective difficulty recognizing faces in daily life; (ii) objectively impaired face recognition on at least two tests of face recognition and criteria of at least 2 standard deviations below control means; (iii) intact general perceptual and memory function; and (iv) exclusion of other disorders associated with impaired face recognition, such as autism spectrum disorders.</p><p class="" id=d12981e323>Although reaching a firm diagnosis of developmental prosopagnosia has its hurdles, a recent study using qualitative methods suggested that screening for it may be possible with a simple list of 16 “hallmark symptoms” from experiences in daily life, which anyone can review<sup><a href="#ref-27">27</a></sup>. The utility and sensitivity of this approach need to be explored.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d12981e333>The neural basis of prosopagnosia</h2><p class="" id=d12981e336>The older literature has shown that lesions of acquired prosopagnosia are bilateral<sup><a href="#ref-6">6</a>,<a href="#ref-7">7</a></sup> or limited to the right hemisphere<sup><a href="#ref-32">32</a>,<a href="#ref-33">33</a></sup>, and reports of left-sided lesions alone are rare<sup><a href="#ref-34">34</a>–<a href="#ref-36">36</a></sup>. This is consistent with evidence from functional neuroimaging that face processing induces greater activation in the right hemisphere<sup><a href="#ref-37">37</a></sup>. The areas involved are the ventral occipito-temporal and fusiform cortex or anterior temporal cortex or both. These anatomic variants may correspond to functional variants<sup><a href="#ref-16">16</a></sup>. Individuals with occipito-temporal or fusiform lesions are more likely to have an apperceptive variant<sup><a href="#ref-38">38</a></sup>, whereas those with anterior temporal lesions have an amnestic variant along with better perceptual function and more difficulty with face imagery<sup><a href="#ref-39">39</a></sup>.</p><p class="" id=d12981e377>Although by definition subjects with developmental prosopagnosia do not have large visible lesions, the status of their face processing networks can be studied with more subtle neuroimaging techniques, including measures of cortical thickness, the degree of functional activation, and connectivity within the network. The results as they currently stand are not conclusive. There are two main views. One proposes that developmental prosopagnosia is marked by alterations in various regions of the face network, particularly the fusiform gyrus, changes such as reduced cortical thickness or density<sup><a href="#ref-40">40</a>,<a href="#ref-41">41</a></sup>, reduced face selectivity of their activation<sup><a href="#ref-40">40</a>,<a href="#ref-42">42</a>–<a href="#ref-44">44</a></sup>, local white matter abnormalities on diffusion imaging<sup><a href="#ref-45">45</a>,<a href="#ref-46">46</a></sup>, or reduced feedforward connectivity from early visual to occipito-temporal cortex<sup><a href="#ref-47">47</a></sup>. The second proposes a disconnection between posterior and anterior regions within the face network<sup><a href="#ref-48">48</a>,<a href="#ref-49">49</a></sup> on the basis of observations of preserved activation of the fusiform and ventral occipito-temporal cortex by faces<sup><a href="#ref-50">50</a>–<a href="#ref-52">52</a></sup> and abnormalities in long white matter tracts that link posterior and anterior temporal cortex<sup><a href="#ref-53">53</a>,<a href="#ref-54">54</a></sup>.</p><p class="" id=d12981e430>Comparisons with other developmental disorders might be informative. Researchers on dyslexia have suggested a model in which a general risk for cortical anomalies is modulated by other genetic and/or environmental factors that determine the location and extent of such anomalies<sup><a href="#ref-55">55</a></sup>. The latter determines the specific syndrome and can explain the frequent co-association of developmental disorders. In this regard, we note recent observations of associations between congenital amusia and developmental prosopagnosia<sup><a href="#ref-56">56</a>,<a href="#ref-57">57</a></sup>. Along these lines, others have speculated that abnormal neural migration may be responsible for developmental prosopagnosia<sup><a href="#ref-8">8</a></sup>.</p><p class="" id=d12981e448>Does developmental prosopagnosia have a genetic cause? Face recognition abilities show a high degree of heritability in the general population<sup><a href="#ref-58">58</a>,<a href="#ref-59">59</a></sup>, and early observations were that developmental prosopagnosia tended to run in families<sup><a href="#ref-59">59</a>–<a href="#ref-63">63</a></sup>, possibly with an autosomal dominant pattern of inheritance<sup><a href="#ref-22">22</a>,<a href="#ref-64">64</a></sup>. However, most neurodevelopmental disorders are polygenic combinations of allelic variants present in the normal population. Along these lines, a recent study of 24 subjects reported that common single-nucleotide polymorphisms in the oxytocin receptor gene are associated with developmental prosopagnosia<sup><a href="#ref-65">65</a></sup>. These preliminary results require replication in larger samples.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d12981e479>Is prosopagnosia only about faces?</h2><p class="" id=d12981e482>A long-standing controversy is whether the impaired recognition in prosopagnosia is face-specific or affects other object types. This has important theoretical implications for how object recognition is organized in the visual system. The distributed view suggests that object processing is performed by networks of visual regions, and that some of these regions are involved in the perception of several types of stimuli<sup><a href="#ref-66">66</a>–<a href="#ref-68">68</a></sup>. The modular view claims that different categories of objects—particularly faces—are processed by distinct dedicated cortical regions<sup><a href="#ref-69">69</a>–<a href="#ref-71">71</a></sup>.</p><p class="" id=d12981e499>Case studies of acquired prosopagnosia have produced mixed results; some reported normal recognition of exemplars of other objects<sup><a href="#ref-72">72</a>–<a href="#ref-82">82</a></sup> and others showed impairments<sup><a href="#ref-80">80</a>,<a href="#ref-81">81</a>,<a href="#ref-83">83</a>–<a href="#ref-88">88</a></sup>. A recent major review<sup><a href="#ref-89">89</a></sup> examined 238 cases of developmental prosopagnosia in the literature. The majority of subjects had evidence of impaired object recognition, although a smaller number had reasonable evidence that object recognition was intact, given that they had both good accuracy and normal reaction times on tests. Although the authors concluded that the frequent association of face and object impairments supported a shared mechanism for recognizing faces and other objects<sup><a href="#ref-89">89</a></sup>, the challenge for any comprehensive explanation is to account for both frequent associations and occasional dissociations. One of the most useful aspects of this review was the collection of accompanying commentaries<sup><a href="#ref-90">90</a>–<a href="#ref-104">104</a></sup>, which suggested both various hypotheses to explain this fact and methodologic limitations in the currently available data that need to be addressed in future work to allow a more definitive set of conclusions to be drawn.</p><p class="" id=d12981e537>A particular object type deserves comment – namely, words. One of the difficulties in comparing faces and objects is that humans have a great deal of experience and expertise with faces but such expertise cannot be assumed for other object types. Take cars, for example. A recent study found that, as a group, subjects with developmental prosopagnosia tended to score low on the Cambridge Car Recognition Test but that individual scores ranged quite widely, from excellent to poor<sup><a href="#ref-105">105</a></sup>. However, not everyone is a car expert and variable expertise could affect recognition performance. In another group of studies, when visual car recognition scores were adjusted for car expertise, as reflected by a subject’s semantic knowledge about cars, subjects with both acquired and developmental prosopagnosia tended to perform worse than expected<sup><a href="#ref-16">16</a>,<a href="#ref-106">106</a>,<a href="#ref-107">107</a></sup>.</p><p class="" id=d12981e554>In literate societies, visual words, in contrast to cars, are a category for which almost all subjects have considerable perceptual expertise. The “many-to-many hypothesis” proposes that face and visual word processing share and compete for neural resources in regions like the fusiform gyrus and that structural constraints cause visual words to be processed more on the left, in proximity to language processing, and faces secondarily to lateralize to the right<sup><a href="#ref-108">108</a>–<a href="#ref-111">111</a></sup>. Lateralization is incomplete, though, and functional imaging shows overlap between face- and word-activated voxels<sup><a href="#ref-112">112</a></sup>. As a consequence, the hypothesis predicts that prosopagnosia from right lesions should be accompanied by mild reading deficits in the processing of words and that alexia from left lesions should be accompanied by mild face recognition problems<sup><a href="#ref-108">108</a></sup>. Whereas one study of three subjects with acquired prosopagnosia did show mild word recognition deficits<sup><a href="#ref-113">113</a></sup>, other studies of visual word processing in acquired prosopagnosia from right-sided lesions alone have not found impaired reading<sup><a href="#ref-114">114</a>,<a href="#ref-115">115</a></sup> and the same is true for developmental prosopagnosia<sup><a href="#ref-116">116</a>–<a href="#ref-118">118</a></sup>. On the other hand, the type of processing that is performed on words and faces may differ by hemisphere. Although subjects with acquired prosopagnosia from right-sided lesions may read normally, they often have trouble recognizing handwriting or font<sup><a href="#ref-119">119</a>–<a href="#ref-121">121</a></sup>, and subjects with alexia may recognize face identity<sup><a href="#ref-122">122</a></sup> but have trouble with lip reading<sup><a href="#ref-119">119</a>,<a href="#ref-123">123</a>,<a href="#ref-124">124</a></sup>.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d12981e615>Can prosopagnosia be treated?</h2><p class="" id=d12981e618>Spontaneous resolution of acquired prosopagnosia is rare<sup><a href="#ref-125">125</a>–<a href="#ref-127">127</a></sup>, and developmental prosopagnosia is a lifelong disorder. Hence, means of improving face recognition skills in these populations are of clinical interest. But can it be done? Neuroimaging shows that face processing activates a widely distributed network, including occipito-temporal, superior temporal, anterior temporal, and inferior frontal regions in both hemispheres, though more on the right<sup><a href="#ref-128">128</a></sup>. It is highly unlikely that acquired lesions will eliminate all components of this network; furthermore, some studies in developmental prosopagnosia continue to show activation of this network by faces<sup><a href="#ref-50">50</a>–<a href="#ref-52">52</a></sup>. The open question is whether surviving components of the face network in a given prosopagnosic subject have any capacity for functional reorganization or modulation that could allow face recognition to improve through a rehabilitative approach<sup><a href="#ref-129">129</a></sup>.</p><p class="" id=d12981e643>Most work has focused on behavioural interventions, although there is one intriguing report of transient improvement of developmental prosopagnosia after intranasal inhalation of oxytocin<sup><a href="#ref-130">130</a></sup>. These rehabilitative attempts have been reviewed in detail<sup><a href="#ref-129">129</a>,<a href="#ref-131">131</a>,<a href="#ref-132">132</a></sup>. Approaches can be divided into compensatory strategies, which aim to achieve person recognition by circumventing the face processing impairment, and remediation, which aims to improve that impairment. In terms of the process targeted, they can also be divided into those that focus on enhancing mnemonic function, which has been used in a few case studies<sup><a href="#ref-133">133</a>–<a href="#ref-135">135</a></sup>, and those that target perceptual function. As examples of the latter, a few older case studies attempted to enhance attention to facial features, though results on face recognition were variable<sup><a href="#ref-134">134</a>,<a href="#ref-136">136</a>–<a href="#ref-138">138</a></sup>.</p><p class="" id=d12981e677>The most significant recent advances have been trials of perceptual learning in groups rather than single cases of prosopagnosia. In one study of 24 subjects with developmental prosopagnosia<sup><a href="#ref-139">139</a></sup>, subjects learned over the course of 2 weeks to discriminate distances between facial features, namely the distance between the eyes and eyebrows or between the nose and the mouth. These “spatial relations” can be thought of as indices of the complex geometry of faces, and studies show that some people with prosopagnosia are impaired in perceiving them<sup><a href="#ref-38">38</a></sup>. This trial found improved face perception (but only if the test faces had a similar frontal view) and some modest improvements in subjective reports of daily experience with faces. A second study of 10 subjects with acquired prosopagnosia<sup><a href="#ref-132">132</a></sup> used morphed faces to train subjects over the course of 11 weeks to perceive finer and finer differences in facial shape; at the same time, the study introduced irrelevant variations in the expression and viewpoint of the face. In these subjects, compared with a control condition, there was a 21% absolute increase in perceptual sensitivity to facial shape after training, which generalized over new views and expressions. Importantly, there was also a 10% increase for new faces on which subjects had not trained, indicating that subjects were acquiring new skills rather than just learning a set of faces. The effects of training were still evident 3 months later. Although some but not all subjects related anecdotes pointing to improved face recognition in daily life, future studies will require formal evaluation of real-life benefit before such methods are translated to the clinic.</p><p class="" id=d12981e692>These rehabilitative studies represent a starting point. Although neither training method represents a “cure”, they provide evidence that face processing can be changed in prosopagnosia. They also suggest that there may be individual differences in training potential. Further work is required to determine whether the perceptual gains from learning can be augmented further by better training design or the use of adjunctive methods to promote plasticity during learning.</p></div><div id=article1-back class=generated-article-footer><div class=back-section><a name=d12981e1 class=n-a></a><h2 class=main-title id=d13282>Grant information</h2><p>This work was supported by the Natural Sciences and Engineering Research Council of Canada (RGPIN 319129) and Canada Research Chairs (950-228984).</p><p> <i>The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</i> </p></div><div class=back-section><a name=d12981e699 class=n-a></a><span class="research-layout prime-recommended-wrapper reference-heading"><span class="f1r-icon icon-79_faculty_recommended_badge red vmiddle default-cursor"></span><span class="prime-red big">F1000 recommended</span></span><h2 class=main-title id=d13722>References</h2><div class="section ref-list"><a name=d12981e699 class=n-a></a><ul><li><a name=ref-1 class=n-a></a><span class=label>1. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/734212686"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e706 class=n-a></a>Jenkins R, Dowsett AJ, Burton AM: How many faces do people know? <i>Proc Biol Sci.</i> 2018; <b>285</b>(1888): pii: 20181319. <a target=xrefwindow id=d12981e714 href="http://www.ncbi.nlm.nih.gov/pubmed/30305434">PubMed Abstract </a> | <a target=xrefwindow id=d12981e717 href="https://doi.org/10.1098/rspb.2018.1319">Publisher Full Text </a> | <a target=xrefwindow id=d12981e720 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6191703">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/734212686">F1000 Recommendation</a></span></li><li><a name=ref-2 class=n-a></a><span class=label>2. </span>&nbsp;<span class=citation><a name=d12981e733 class=n-a></a>Corrow SL, Dalrymple KA, Barton JJ: Prosopagnosia: current perspectives. <i>Eye Brain.</i> 2016; <b>8</b>: 165–75. <a target=xrefwindow id=d12981e741 href="http://www.ncbi.nlm.nih.gov/pubmed/28539812">PubMed Abstract </a> | <a target=xrefwindow id=d12981e744 href="https://doi.org/10.2147/EB.S92838">Publisher Full Text </a> | <a target=xrefwindow id=d12981e747 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5398751">Free Full Text </a></span></li><li><a name=ref-3 class=n-a></a><span class=label>3. </span>&nbsp;<span class=citation><a name=d12981e756 class=n-a></a>Yardley L, McDermott L, Pisarski S, <i> et al.</i>: Psychosocial consequences of developmental prosopagnosia: a problem of recognition. <i>J Psychosom Res.</i> 2008; <b>65</b>(5): 445–51. <a target=xrefwindow id=d12981e767 href="http://www.ncbi.nlm.nih.gov/pubmed/18940375">PubMed Abstract </a> | <a target=xrefwindow id=d12981e770 href="https://doi.org/10.1016/j.jpsychores.2008.03.013">Publisher Full Text </a></span></li><li><a name=ref-4 class=n-a></a><span class=label>4. </span>&nbsp;<span class=citation><a name=d12981e779 class=n-a></a>Dalrymple KA, Fletcher K, Corrow S, <i> et al.</i>: "A room full of strangers every day": the psychosocial impact of developmental prosopagnosia on children and their families. <i>J Psychosom Res.</i> 2014; <b>77</b>(2): 144–50. <a target=xrefwindow id=d12981e790 href="http://www.ncbi.nlm.nih.gov/pubmed/25077856">PubMed Abstract </a> | <a target=xrefwindow id=d12981e793 href="https://doi.org/10.1016/j.jpsychores.2014.06.001">Publisher Full Text </a> | <a target=xrefwindow id=d12981e797 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4211255">Free Full Text </a></span></li><li><a name=ref-5 class=n-a></a><span class=label>5. </span>&nbsp;<span class=citation><a name=d12981e806 class=n-a></a>Bruce V, Young A: Understanding face recognition. <i>Br J Psychol.</i> 1986; <b>77</b>(Pt 3): 305–27. <a target=xrefwindow id=d12981e814 href="http://www.ncbi.nlm.nih.gov/pubmed/3756376">PubMed Abstract </a> | <a target=xrefwindow id=d12981e817 href="https://doi.org/10.1111/j.2044-8295.1986.tb02199.x">Publisher Full Text </a></span></li><li><a name=ref-6 class=n-a></a><span class=label>6. </span>&nbsp;<span class=citation><a name=d12981e827 class=n-a></a>Meadows JC: The anatomical basis of prosopagnosia. <i>J Neurol Neurosurg Psychiatry.</i> 1974; <b>37</b>(5): 489–501. <a target=xrefwindow id=d12981e835 href="http://www.ncbi.nlm.nih.gov/pubmed/4209556">PubMed Abstract </a> | <a target=xrefwindow id=d12981e838 href="https://doi.org/10.1136/jnnp.37.5.489">Publisher Full Text </a> | <a target=xrefwindow id=d12981e841 href="http://www.ncbi.nlm.nih.gov/pmc/articles/494693">Free Full Text </a></span></li><li><a name=ref-7 class=n-a></a><span class=label>7. </span>&nbsp;<span class=citation><a name=d12981e850 class=n-a></a>Damasio AR, Damasio H, Van Hoesen GW: Prosopagnosia: anatomic basis and behavioral mechanisms. <i>Neurology.</i> 1982; <b>32</b>(4): 331–41. <a target=xrefwindow id=d12981e858 href="http://www.ncbi.nlm.nih.gov/pubmed/7199655">PubMed Abstract </a> | <a target=xrefwindow id=d12981e861 href="https://doi.org/10.1212/wnl.32.4.331">Publisher Full Text </a></span></li><li><a name=ref-8 class=n-a></a><span class=label>8. </span>&nbsp;<span class=citation><a name=d12981e870 class=n-a></a>Susilo T, Duchaine B: Advances in developmental prosopagnosia research. <i>Curr Opin Neurobiol.</i> 2013; <b>23</b>(3): 423–9. <a target=xrefwindow id=d12981e878 href="http://www.ncbi.nlm.nih.gov/pubmed/23391526">PubMed Abstract </a> | <a target=xrefwindow id=d12981e881 href="https://doi.org/10.1016/j.conb.2012.12.011">Publisher Full Text </a></span></li><li><a name=ref-9 class=n-a></a><span class=label>9. </span>&nbsp;<span class=citation><a name=d12981e890 class=n-a></a>Barton JJS, Corrow SL: The problem of being bad at faces. <i>Neuropsychologia.</i> 2016; <b>89</b>: 119–24. <a target=xrefwindow id=d12981e898 href="http://www.ncbi.nlm.nih.gov/pubmed/27312748">PubMed Abstract </a> | <a target=xrefwindow id=d12981e901 href="https://doi.org/10.1016/j.neuropsychologia.2016.06.008">Publisher Full Text </a> | <a target=xrefwindow id=d12981e904 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4996721">Free Full Text </a></span></li><li><a name=ref-10 class=n-a></a><span class=label>10. </span>&nbsp;<span class=citation><a name=d12981e913 class=n-a></a>Warrington EK: Recognition Memory Test:(Faces). Test Booklet 2a: Nfer-Nelson; 1984. <a target=xrefwindow id=d12981e915 href="https://www.wpspublish.com/store/p/2944/rmt-recognition-memory-test">Reference Source</a></span></li><li><a name=ref-11 class=n-a></a><span class=label>11. </span>&nbsp;<span class=citation><a name=d12981e924 class=n-a></a>Duchaine B, Nakayama K: The Cambridge Face Memory Test: results for neurologically intact individuals and an investigation of its validity using inverted face stimuli and prosopagnosic participants. <i>Neuropsychologia.</i> 2006; <b>44</b>(4): 576–85. <a target=xrefwindow id=d12981e932 href="http://www.ncbi.nlm.nih.gov/pubmed/16169565">PubMed Abstract </a> | <a target=xrefwindow id=d12981e935 href="https://doi.org/10.1016/j.neuropsychologia.2005.07.001">Publisher Full Text </a></span></li><li><a name=ref-12 class=n-a></a><span class=label>12. </span>&nbsp;<span class=citation><a name=d12981e945 class=n-a></a>Bowles DC, McKone E, Dawel A, <i> et al.</i>: Diagnosing prosopagnosia: effects of ageing, sex, and participant-stimulus ethnic match on the Cambridge Face Memory Test and Cambridge Face Perception Test. <i>Cogn Neuropsychol.</i> 2009; <b>26</b>(5): 423–55. <a target=xrefwindow id=d12981e956 href="http://www.ncbi.nlm.nih.gov/pubmed/19921582">PubMed Abstract </a> | <a target=xrefwindow id=d12981e959 href="https://doi.org/10.1080/02643290903343149">Publisher Full Text </a></span></li><li><a name=ref-13 class=n-a></a><span class=label>13. </span>&nbsp;<span class=citation><a name=d12981e968 class=n-a></a>Herzmann G, Danthiir V, Schacht A, <i> et al.</i>: Toward a comprehensive test battery for face cognition: assessment of the tasks. <i>Behav Res Methods.</i> 2008; <b>40</b>(3): 840–57. <a target=xrefwindow id=d12981e979 href="http://www.ncbi.nlm.nih.gov/pubmed/18697680">PubMed Abstract </a> | <a target=xrefwindow id=d12981e982 href="https://doi.org/10.3758/BRM.40.3.840">Publisher Full Text </a></span></li><li><a name=ref-14 class=n-a></a><span class=label>14. </span>&nbsp;<span class=citation><a name=d12981e991 class=n-a></a>Croydon A, Pimperton H, Ewing L, <i> et al.</i>: The Cambridge Face Memory Test for Children (CFMT-C): a new tool for measuring face recognition skills in childhood. <i>Neuropsychologia.</i> 2014; <b>62</b>: 60–7. <a target=xrefwindow id=d12981e1002 href="http://www.ncbi.nlm.nih.gov/pubmed/25054837">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1005 href="https://doi.org/10.1016/j.neuropsychologia.2014.07.008">Publisher Full Text </a></span></li><li><a name=ref-15 class=n-a></a><span class=label>15. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/734369490"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1014 class=n-a></a>Robotham RJ, Starrfelt R: Tests of whole upright face processing in prosopagnosia: A literature review. <i>Neuropsychologia.</i> 2018; <b>121</b>: 106–21. <a target=xrefwindow id=d12981e1022 href="http://www.ncbi.nlm.nih.gov/pubmed/30389553">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1025 href="https://doi.org/10.1016/j.neuropsychologia.2018.10.018">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/734369490">F1000 Recommendation</a></span></li><li><a name=ref-16 class=n-a></a><span class=label>16. </span>&nbsp;<span class=citation><a name=d12981e1038 class=n-a></a>Davies-Thompson J, Pancaroglu R, Barton J: Acquired prosopagnosia: structural basis and processing impairments. <i>Front Biosci (Elite Ed).</i> 2014; <b>6</b>: 159–74. <a target=xrefwindow id=d12981e1046 href="http://www.ncbi.nlm.nih.gov/pubmed/24389150">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1049 href="https://doi.org/10.2741/E699">Publisher Full Text </a></span></li><li><a name=ref-17 class=n-a></a><span class=label>17. </span>&nbsp;<span class=citation><a name=d12981e1058 class=n-a></a>Benton AL, van Allen MW: Impairment in Facial Recognition in Patients with Cerebral Disease. <i>Cortex.</i> 1968; <b>4</b>(4): 344–358, IN1. <a target=xrefwindow id=d12981e1066 href="https://doi.org/10.1016/S0010-9452(68)80018-8">Publisher Full Text </a></span></li><li><a name=ref-18 class=n-a></a><span class=label>18. </span>&nbsp;<span class=citation><a name=d12981e1076 class=n-a></a>Duchaine B, Yovel G, Nakayama K: No global processing deficit in the Navon task in 14 developmental prosopagnosics. <i>Soc Cogn Affect Neurosci.</i> 2007; <b>2</b>(2): 104–13. <a target=xrefwindow id=d12981e1084 href="http://www.ncbi.nlm.nih.gov/pubmed/18985129">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1087 href="https://doi.org/10.1093/scan/nsm003">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1090 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2555457">Free Full Text </a></span></li><li><a name=ref-19 class=n-a></a><span class=label>19. </span>&nbsp;<span class=citation><a name=d12981e1099 class=n-a></a>Burton AM, White D, McNeill A: The Glasgow Face Matching Test. <i>Behav Res Methods.</i> 2010; <b>42</b>(1): 286–91. <a target=xrefwindow id=d12981e1107 href="http://www.ncbi.nlm.nih.gov/pubmed/20160307">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1110 href="https://doi.org/10.3758/BRM.42.1.286">Publisher Full Text </a></span></li><li><a name=ref-20 class=n-a></a><span class=label>20. </span>&nbsp;<span class=citation><a name=d12981e1119 class=n-a></a>Logan AJ, Wilkinson F, Wilson HR, <i> et al.</i>: The Caledonian face test: A new test of face discrimination. <i>Vision Res.</i> 2016; <b>119</b>: 29–41. <a target=xrefwindow id=d12981e1130 href="http://www.ncbi.nlm.nih.gov/pubmed/26607479">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1133 href="https://doi.org/10.1016/j.visres.2015.11.003">Publisher Full Text </a></span></li><li><a name=ref-21 class=n-a></a><span class=label>21. </span>&nbsp;<span class=citation><a name=d12981e1142 class=n-a></a>Barton JJ, Cherkasova M: Face imagery and its relation to perception and covert recognition in prosopagnosia. <i>Neurology.</i> 2003; <b>61</b>(2): 220–5. <a target=xrefwindow id=d12981e1150 href="http://www.ncbi.nlm.nih.gov/pubmed/12874402">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1153 href="https://doi.org/10.1212/01.wnl.0000071229.11658.f8">Publisher Full Text </a></span></li><li><a name=ref-22 class=n-a></a><span class=label>22. </span>&nbsp;<span class=citation><a name=d12981e1162 class=n-a></a>Kennerknecht I, Ho NY, Wong VC: Prevalence of hereditary prosopagnosia (HPA) in Hong Kong Chinese population. <i>Am J Med Genet A.</i> 2008; <b>146A</b>(22): 2863–70. <a target=xrefwindow id=d12981e1170 href="http://www.ncbi.nlm.nih.gov/pubmed/18925678">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1173 href="https://doi.org/10.1002/ajmg.a.32552">Publisher Full Text </a></span></li><li><a name=ref-23 class=n-a></a><span class=label>23. </span>&nbsp;<span class=citation><a name=d12981e1182 class=n-a></a>Shah P, Gaule A, Sowden S, <i> et al.</i>: The 20-item prosopagnosia index (PI20): a self-report instrument for identifying developmental prosopagnosia. <i>R Soc Open Sci.</i> 2015; <b>2</b>(6): 140343. <a target=xrefwindow id=d12981e1193 href="http://www.ncbi.nlm.nih.gov/pubmed/26543567">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1196 href="https://doi.org/10.1098/rsos.140343">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1200 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4632531">Free Full Text </a></span></li><li><a name=ref-24 class=n-a></a><span class=label>24. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/735120997"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1210 class=n-a></a>Arizpe JM, Saad E, Douglas AO, <i> et al.</i>: Self-reported face recognition is highly valid, but alone is not highly discriminative of prosopagnosia-level performance on objective assessments. <i>Behav Res Methods.</i> 2019. <a target=xrefwindow id=d12981e1218 href="http://www.ncbi.nlm.nih.gov/pubmed/30761463">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1221 href="https://doi.org/10.3758/s13428-018-01195-w">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1224 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6527346">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/735120997">F1000 Recommendation</a></span></li><li><a name=ref-25 class=n-a></a><span class=label>25. </span>&nbsp;<span class=citation><a name=d12981e1237 class=n-a></a>Bindemann M, Attard J, Johnston RA, <i> et al.</i>: Perceived ability and actual recognition accuracy for unfamiliar and famous faces. <i>Cogent Psychol.</i> 2014; <b>1</b>(1): 735. <a target=xrefwindow id=d12981e1248 href="https://doi.org/10.1080/23311908.2014.986903">Publisher Full Text </a></span></li><li><a name=ref-26 class=n-a></a><span class=label>26. </span>&nbsp;<span class=citation><a name=d12981e1257 class=n-a></a>Palermo R, Rossion B, Rhodes G, <i> et al.</i>: Do people have insight into their face recognition abilities? <i>Q J Exp Psychol (Hove).</i> 2017; <b>70</b>(2): 218–33. <a target=xrefwindow id=d12981e1268 href="http://www.ncbi.nlm.nih.gov/pubmed/26935244">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1271 href="https://doi.org/10.1080/17470218.2016.1161058">Publisher Full Text </a></span></li><li><a name=ref-27 class=n-a></a><span class=label>27. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/732574116"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1280 class=n-a></a>Murray E, Hills PJ, Bennetts RJ, <i> et al.</i>: Identifying Hallmark Symptoms of Developmental Prosopagnosia for Non-Experts. <i>Sci Rep.</i> 2018; <b>8</b>: 1690. <a target=xrefwindow id=d12981e1291 href="https://doi.org/10.1038/s41598-018-20089-7">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/732574116">F1000 Recommendation</a></span></li><li><a name=ref-28 class=n-a></a><span class=label>28. </span>&nbsp;<span class=citation><a name=d12981e1304 class=n-a></a>Shah P, Sowden S, Gaule A, <i> et al.</i>: The 20 item prosopagnosia index (PI20): relationship with the Glasgow face-matching test. <i>R Soc Open Sci.</i> 2015; <b>2</b>(11): 150305. <a target=xrefwindow id=d12981e1315 href="http://www.ncbi.nlm.nih.gov/pubmed/26715995">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1318 href="https://doi.org/10.1098/rsos.150305">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1322 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4680610">Free Full Text </a></span></li><li><a name=ref-29 class=n-a></a><span class=label>29. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727818337"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1331 class=n-a></a>Livingston LA, Shah P: People with and without prosopagnosia have insight into their face recognition ability. <i>Q J Exp Psychol (Hove).</i> 2018; <b>71</b>(5): 1260–2. <a target=xrefwindow id=d12981e1339 href="http://www.ncbi.nlm.nih.gov/pubmed/28513322">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1342 href="https://doi.org/10.1080/17470218.2017.1310911">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727818337">F1000 Recommendation</a></span></li><li><a name=ref-30 class=n-a></a><span class=label>30. </span>&nbsp;<span class=citation><a name=d12981e1356 class=n-a></a>Duchaine B: Comment on prevalence of hereditary prosopagnosia (HPA) in Hong Kong Chinese population. <i>Am J Med Genet A.</i> 2008; <b>146A</b>(22): 2860–2. <a target=xrefwindow id=d12981e1364 href="http://www.ncbi.nlm.nih.gov/pubmed/18925672">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1367 href="https://doi.org/10.1002/ajmg.a.32548">Publisher Full Text </a></span></li><li><a name=ref-31 class=n-a></a><span class=label>31. </span>&nbsp;<span class=citation><a name=d12981e1376 class=n-a></a>Dalrymple KA, Palermo R: Guidelines for studying developmental prosopagnosia in adults and children. <i>Wiley Interdiscip Rev Cogn Sci.</i> 2016; <b>7</b>(1): 73–87. <a target=xrefwindow id=d12981e1384 href="http://www.ncbi.nlm.nih.gov/pubmed/26681428">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1387 href="https://doi.org/10.1002/wcs.1374">Publisher Full Text </a></span></li><li><a name=ref-32 class=n-a></a><span class=label>32. </span>&nbsp;<span class=citation><a name=d12981e1396 class=n-a></a>De Renzi E: Prosopagnosia in two patients with CT scan evidence of damage confined to the right hemisphere. <i>Neuropsychologia.</i> 1986; <b>24</b>(3): 385–9. <a target=xrefwindow id=d12981e1404 href="http://www.ncbi.nlm.nih.gov/pubmed/3736820">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1407 href="https://doi.org/10.1016/0028-3932(86)90023-0">Publisher Full Text </a></span></li><li><a name=ref-33 class=n-a></a><span class=label>33. </span>&nbsp;<span class=citation><a name=d12981e1416 class=n-a></a>Landis T, Cummings JL, Christen L, <i> et al.</i>: Are unilateral right posterior cerebral lesions sufficient to cause prosopagnosia? Clinical and radiological findings in six additional patients. <i>Cortex.</i> 1986; <b>22</b>(2): 243–52. <a target=xrefwindow id=d12981e1427 href="http://www.ncbi.nlm.nih.gov/pubmed/3731794">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1430 href="https://doi.org/10.1016/S0010-9452(86)80048-X">Publisher Full Text </a></span></li><li><a name=ref-34 class=n-a></a><span class=label>34. </span>&nbsp;<span class=citation><a name=d12981e1439 class=n-a></a>Mattson AJ, Levin HS, Grafman J: A case of prosopagnosia following moderate closed head injury with left hemisphere focal lesion. <i>Cortex.</i> 2000; <b>36</b>(1): 125–37. <a target=xrefwindow id=d12981e1447 href="http://www.ncbi.nlm.nih.gov/pubmed/10728902">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1450 href="https://doi.org/10.1016/S0010-9452(08)70841-4">Publisher Full Text </a></span></li><li><a name=ref-35 class=n-a></a><span class=label>35. </span>&nbsp;<span class=citation><a name=d12981e1459 class=n-a></a>Tzavaras A, Merienne L, Masure MC: [Prosopagnosia, amnesia and language disorders caused by left temporal lobe injury in a left-handed man] <i>Encephale.</i> 1973; <b>62</b>(4): 382–94. <a target=xrefwindow id=d12981e1467 href="http://www.ncbi.nlm.nih.gov/pubmed/4794621">PubMed Abstract </a></span></li><li><a name=ref-36 class=n-a></a><span class=label>36. </span>&nbsp;<span class=citation><a name=d12981e1477 class=n-a></a>Barton JJ: Prosopagnosia associated with a left occipitotemporal lesion. <i>Neuropsychologia.</i> 2008; <b>46</b>(8): 2214–24. <a target=xrefwindow id=d12981e1485 href="http://www.ncbi.nlm.nih.gov/pubmed/18374372">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1488 href="https://doi.org/10.1016/j.neuropsychologia.2008.02.014">Publisher Full Text </a></span></li><li><a name=ref-37 class=n-a></a><span class=label>37. </span>&nbsp;<span class=citation><a name=d12981e1497 class=n-a></a>Kanwisher N, McDermott J, Chun MM: The fusiform face area: a module in human extrastriate cortex specialized for face perception. <i>J Neurosci.</i> 1997; <b>17</b>(11): 4302–11. <a target=xrefwindow id=d12981e1505 href="http://www.ncbi.nlm.nih.gov/pubmed/9151747">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1508 href="https://doi.org/10.1523/JNEUROSCI.17-11-04302.1997">Publisher Full Text </a></span></li><li><a name=ref-38 class=n-a></a><span class=label>38. </span>&nbsp;<span class=citation><a name=d12981e1517 class=n-a></a>Barton JJ, Press DZ, Keenan JP, <i> et al.</i>: Lesions of the fusiform face area impair perception of facial configuration in prosopagnosia. <i>Neurology.</i> 2002; <b>58</b>(1): 71–8. <a target=xrefwindow id=d12981e1528 href="http://www.ncbi.nlm.nih.gov/pubmed/11781408">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1531 href="https://doi.org/10.1212/wnl.58.1.71">Publisher Full Text </a></span></li><li><a name=ref-39 class=n-a></a><span class=label>39. </span>&nbsp;<span class=citation><a name=d12981e1540 class=n-a></a>Barton JJ: Structure and function in acquired prosopagnosia: lessons from a series of 10 patients with brain damage. <i>J Neuropsychol.</i> 2008; <b>2</b>(Pt 1): 197–225. <a target=xrefwindow id=d12981e1548 href="http://www.ncbi.nlm.nih.gov/pubmed/19334311">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1551 href="https://doi.org/10.1348/174866407X214172">Publisher Full Text </a></span></li><li><a name=ref-40 class=n-a></a><span class=label>40. </span>&nbsp;<span class=citation><a name=d12981e1560 class=n-a></a>Dinkelacker V, Grüter M, Klaver P, <i> et al.</i>: Congenital prosopagnosia: multistage anatomical and functional deficits in face processing circuitry. <i>J Neurol.</i> 2011; <b>258</b>(5): 770–82. <a target=xrefwindow id=d12981e1571 href="http://www.ncbi.nlm.nih.gov/pubmed/21120515">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1574 href="https://doi.org/10.1007/s00415-010-5828-5">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1578 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3090571">Free Full Text </a></span></li><li><a name=ref-41 class=n-a></a><span class=label>41. </span>&nbsp;<span class=citation><a name=d12981e1587 class=n-a></a>Garrido L, Furl N, Draganski B, <i> et al.</i>: Voxel-based morphometry reveals reduced grey matter volume in the temporal cortex of developmental prosopagnosics. <i>Brain.</i> 2009; <b>132</b>(Pt 12): 3443–55. <a target=xrefwindow id=d12981e1598 href="http://www.ncbi.nlm.nih.gov/pubmed/19887506">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1601 href="https://doi.org/10.1093/brain/awp271">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1605 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2792372">Free Full Text </a></span></li><li><a name=ref-42 class=n-a></a><span class=label>42. </span>&nbsp;<span class=citation><a name=d12981e1615 class=n-a></a>Hadjikhani N, de Gelder B: Neural basis of prosopagnosia: an fMRI study. <i>Hum Brain Mapp.</i> 2002; <b>16</b>(3): 176–82. <a target=xrefwindow id=d12981e1623 href="http://www.ncbi.nlm.nih.gov/pubmed/12112771">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1626 href="https://doi.org/10.1002/hbm.10043">Publisher Full Text </a></span></li><li><a name=ref-43 class=n-a></a><span class=label>43. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/733512503"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1635 class=n-a></a>Jiahui G, Yang H, Duchaine B: Developmental prosopagnosics have widespread selectivity reductions across category-selective visual cortex. <i>Proc Natl Acad Sci U S A.</i> 2018; <b>115</b>(28): E6418–E6427. <a target=xrefwindow id=d12981e1643 href="http://www.ncbi.nlm.nih.gov/pubmed/29941554">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1646 href="https://doi.org/10.1073/pnas.1802246115">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1649 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6048498">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/733512503">F1000 Recommendation</a></span></li><li><a name=ref-44 class=n-a></a><span class=label>44. </span>&nbsp;<span class=citation><a name=d12981e1662 class=n-a></a>Furl N, Garrido L, Dolan RJ, <i> et al.</i>: Fusiform gyrus face selectivity relates to individual differences in facial recognition ability. <i>J Cogn Neurosci.</i> 2011; <b>23</b>(7): 1723–40. <a target=xrefwindow id=d12981e1673 href="http://www.ncbi.nlm.nih.gov/pubmed/20617881">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1676 href="https://doi.org/10.1162/jocn.2010.21545">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1680 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3322334">Free Full Text </a></span></li><li><a name=ref-45 class=n-a></a><span class=label>45. </span>&nbsp;<span class=citation><a name=d12981e1689 class=n-a></a>Gomez J, Pestilli F, Witthoft N, <i> et al.</i>: Functionally defined white matter reveals segregated pathways in human ventral temporal cortex associated with category-specific processing. <i>Neuron.</i> 2015; <b>85</b>(1): 216–27. <a target=xrefwindow id=d12981e1700 href="http://www.ncbi.nlm.nih.gov/pubmed/25569351">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1703 href="https://doi.org/10.1016/j.neuron.2014.12.027">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1707 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4287959">Free Full Text </a></span></li><li><a name=ref-46 class=n-a></a><span class=label>46. </span>&nbsp;<span class=citation><a name=d12981e1716 class=n-a></a>Song S, Garrido L, Nagy Z, <i> et al.</i>: Local but not long-range microstructural differences of the ventral temporal cortex in developmental prosopagnosia. <i>Neuropsychologia.</i> 2015; <b>78</b>: 195–206. <a target=xrefwindow id=d12981e1727 href="http://www.ncbi.nlm.nih.gov/pubmed/26456436">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1730 href="https://doi.org/10.1016/j.neuropsychologia.2015.10.010">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1734 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4640146">Free Full Text </a></span></li><li><a name=ref-47 class=n-a></a><span class=label>47. </span>&nbsp;<span class=citation><a name=d12981e1743 class=n-a></a>Lohse M, Garrido L, Driver J, <i> et al.</i>: Effective Connectivity from Early Visual Cortex to Posterior Occipitotemporal Face Areas Supports Face Selectivity and Predicts Developmental Prosopagnosia. <i>J. Neurosci.</i> 2016; <b>36</b>(13): 3821–8. <a target=xrefwindow id=d12981e1754 href="http://www.ncbi.nlm.nih.gov/pubmed/27030766">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1757 href="https://doi.org/10.1523/JNEUROSCI.3621-15.2016">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1761 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4812138">Free Full Text </a></span></li><li><a name=ref-48 class=n-a></a><span class=label>48. </span>&nbsp;<span class=citation><a name=d12981e1771 class=n-a></a>Avidan G, Behrmann M: Impairment of the face processing network in congenital prosopagnosia. <i>Front Biosci (Elite Ed).</i> 2014; <b>6</b>: 236–57. <a target=xrefwindow id=d12981e1779 href="http://www.ncbi.nlm.nih.gov/pubmed/24896205">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1782 href="https://doi.org/10.2741/e705">Publisher Full Text </a></span></li><li><a name=ref-49 class=n-a></a><span class=label>49. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/729069916"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1791 class=n-a></a>Rosenthal G, Tanzer M, Simony E, <i> et al.</i>: Altered topology of neural circuits in congenital prosopagnosia. <i>eLife.</i> 2017; <b>6</b>: pii: e25069. <a target=xrefwindow id=d12981e1802 href="http://www.ncbi.nlm.nih.gov/pubmed/28825896">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1805 href="https://doi.org/10.7554/eLife.25069">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1809 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5565317">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/729069916">F1000 Recommendation</a></span></li><li><a name=ref-50 class=n-a></a><span class=label>50. </span>&nbsp;<span class=citation><a name=d12981e1822 class=n-a></a>Hasson U, Avidan G, Deouell LY, <i> et al.</i>: Face-selective activation in a congenital prosopagnosic subject. <i>J Cogn Neurosci.</i> 2003; <b>15</b>(3): 419–31. <a target=xrefwindow id=d12981e1833 href="http://www.ncbi.nlm.nih.gov/pubmed/12729493">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1836 href="https://doi.org/10.1162/089892903321593135">Publisher Full Text </a></span></li><li><a name=ref-51 class=n-a></a><span class=label>51. </span>&nbsp;<span class=citation><a name=d12981e1845 class=n-a></a>Avidan G, Hasson U, Malach R, <i> et al.</i>: Detailed exploration of face-related processing in congenital prosopagnosia: 2. Functional neuroimaging findings. <i>J Cogn Neurosci.</i> 2005; <b>17</b>(7): 1150–67. <a target=xrefwindow id=d12981e1856 href="http://www.ncbi.nlm.nih.gov/pubmed/16102242">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1859 href="https://doi.org/10.1162/0898929054475145">Publisher Full Text </a></span></li><li><a name=ref-52 class=n-a></a><span class=label>52. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/1166197"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1868 class=n-a></a>Avidan G, Behrmann M: Functional MRI reveals compromised neural integrity of the face processing network in congenital prosopagnosia. <i>Curr Biol.</i> 2009; <b>19</b>(13): 1146–50. <a target=xrefwindow id=d12981e1876 href="http://www.ncbi.nlm.nih.gov/pubmed/19481456">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1879 href="https://doi.org/10.1016/j.cub.2009.04.060">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1882 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2711224">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/1166197">F1000 Recommendation</a></span></li><li><a name=ref-53 class=n-a></a><span class=label>53. </span>&nbsp;<span class=citation><a name=d12981e1895 class=n-a></a>Thomas C, Avidan G, Humphreys K, <i> et al.</i>: Reduced structural connectivity in ventral visual cortex in congenital prosopagnosia. <i>Nat Neurosci.</i> 2009; <b>12</b>(1): 29–31. <a target=xrefwindow id=d12981e1906 href="http://www.ncbi.nlm.nih.gov/pubmed/19029889">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1909 href="https://doi.org/10.1038/nn.2224">Publisher Full Text </a> | <a target=xrefwindow id=d12981e1913 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5989137">Free Full Text </a></span></li><li><a name=ref-54 class=n-a></a><span class=label>54. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/732305088"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e1923 class=n-a></a>Zhao Y, Zhen Z, Liu X, <i> et al.</i>: The neural network for face recognition: Insights from an fMRI study on developmental prosopagnosia. <i>NeuroImage.</i> 2018; <b>169</b>: 151–61. <a target=xrefwindow id=d12981e1934 href="http://www.ncbi.nlm.nih.gov/pubmed/29242103">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1937 href="https://doi.org/10.1016/j.neuroimage.2017.12.023">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/732305088">F1000 Recommendation</a></span></li><li><a name=ref-55 class=n-a></a><span class=label>55. </span>&nbsp;<span class=citation><a name=d12981e1950 class=n-a></a>Ramus F: Neurobiology of dyslexia: a reinterpretation of the data. <i>Trends Neurosci.</i> 2004; <b>27</b>(12): 720–6. <a target=xrefwindow id=d12981e1958 href="http://www.ncbi.nlm.nih.gov/pubmed/15541512">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1961 href="https://doi.org/10.1016/j.tins.2004.10.004">Publisher Full Text </a></span></li><li><a name=ref-56 class=n-a></a><span class=label>56. </span>&nbsp;<span class=citation><a name=d12981e1970 class=n-a></a>Corrow SL, Stubbs JL, Schlaug G, <i> et al.</i>: Perception of musical pitch in developmental prosopagnosia. <i>Neuropsychologia.</i> 2019; <b>124</b>: 87–97. <a target=xrefwindow id=d12981e1981 href="http://www.ncbi.nlm.nih.gov/pubmed/30625291">PubMed Abstract </a> | <a target=xrefwindow id=d12981e1984 href="https://doi.org/10.1016/j.neuropsychologia.2018.12.022">Publisher Full Text </a></span></li><li><a name=ref-57 class=n-a></a><span class=label>57. </span>&nbsp;<span class=citation><a name=d12981e1993 class=n-a></a>Paquette S, Li HC, Corrow SL, <i> et al.</i>: Developmental Perceptual Impairments: Cases When Tone-Deafness and Prosopagnosia Co-occur. <i>Front Hum Neurosci.</i> 2018; <b>12</b>: 438. <a target=xrefwindow id=d12981e2004 href="http://www.ncbi.nlm.nih.gov/pubmed/30425629">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2007 href="https://doi.org/10.3389/fnhum.2018.00438">Publisher Full Text </a> | <a target=xrefwindow id=d12981e2011 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6218620">Free Full Text </a></span></li><li><a name=ref-58 class=n-a></a><span class=label>58. </span>&nbsp;<span class=citation><a name=d12981e2020 class=n-a></a>Wilmer JB, Germine L, Chabris CF, <i> et al.</i>: Human face recognition ability is specific and highly heritable. <i>Proc Natl Acad Sci U S A.</i> 2010; <b>107</b>(11): 5238–41. <a target=xrefwindow id=d12981e2031 href="http://www.ncbi.nlm.nih.gov/pubmed/20176944">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2034 href="https://doi.org/10.1073/pnas.0913053107">Publisher Full Text </a> | <a target=xrefwindow id=d12981e2038 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2841913">Free Full Text </a></span></li><li><a name=ref-59 class=n-a></a><span class=label>59. </span>&nbsp;<span class=citation><a name=d12981e2047 class=n-a></a>Zhu Q, Song Y, Hu S, <i> et al.</i>: Heritability of the specific cognitive ability of face perception. <i>Curr Biol.</i> 2010; <b>20</b>(2): 137–42. <a target=xrefwindow id=d12981e2058 href="http://www.ncbi.nlm.nih.gov/pubmed/20060296">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2061 href="https://doi.org/10.1016/j.cub.2009.11.067">Publisher Full Text </a></span></li><li><a name=ref-60 class=n-a></a><span class=label>60. </span>&nbsp;<span class=citation><a name=d12981e2071 class=n-a></a>Grüter T, Grüter M, Carbon CC: Neural and genetic foundations of face recognition and prosopagnosia. <i>J Neuropsychol.</i> 2008; <b>2</b>(Pt 1): 79–97. <a target=xrefwindow id=d12981e2079 href="http://www.ncbi.nlm.nih.gov/pubmed/19334306">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2082 href="https://doi.org/10.1348/174866407X231001">Publisher Full Text </a></span></li><li><a name=ref-61 class=n-a></a><span class=label>61. </span>&nbsp;<span class=citation><a name=d12981e2091 class=n-a></a>Schmalzl L, Palermo R, Coltheart M: Cognitive heterogeneity in genetically based prosopagnosia: a family study. <i>J Neuropsychol.</i> 2008; <b>2</b>(Pt 1): 99–117. <a target=xrefwindow id=d12981e2099 href="http://www.ncbi.nlm.nih.gov/pubmed/19334307">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2102 href="https://doi.org/10.1348/174866407X256554">Publisher Full Text </a></span></li><li><a name=ref-62 class=n-a></a><span class=label>62. </span>&nbsp;<span class=citation><a name=d12981e2111 class=n-a></a>Duchaine B, Germine L, Nakayama K: Family resemblance: ten family members with prosopagnosia and within-class object agnosia. <i>Cogn Neuropsychol.</i> 2007; <b>24</b>(4): 419–30. <a target=xrefwindow id=d12981e2119 href="http://www.ncbi.nlm.nih.gov/pubmed/18416499">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2122 href="https://doi.org/10.1080/02643290701380491">Publisher Full Text </a></span></li><li><a name=ref-63 class=n-a></a><span class=label>63. </span>&nbsp;<span class=citation><a name=d12981e2131 class=n-a></a>Lee Y, Duchaine B, Wilson HR, <i> et al.</i>: Three cases of developmental prosopagnosia from one family: detailed neuropsychological and psychophysical investigation of face processing. <i>Cortex.</i> 2010; <b>46</b>(8): 949–64. <a target=xrefwindow id=d12981e2142 href="http://www.ncbi.nlm.nih.gov/pubmed/19726036">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2145 href="https://doi.org/10.1016/j.cortex.2009.07.012">Publisher Full Text </a></span></li><li><a name=ref-64 class=n-a></a><span class=label>64. </span>&nbsp;<span class=citation><a name=d12981e2154 class=n-a></a>Kennerknecht I, Grueter T, Welling B, <i> et al.</i>: First report of prevalence of non-syndromic hereditary prosopagnosia (HPA). <i>Am J Med Genet A.</i> 2006; <b>140</b>(15): 1617–22. <a target=xrefwindow id=d12981e2165 href="http://www.ncbi.nlm.nih.gov/pubmed/16817175">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2168 href="https://doi.org/10.1002/ajmg.a.31343">Publisher Full Text </a></span></li><li><a name=ref-65 class=n-a></a><span class=label>65. </span>&nbsp;<span class=citation><a name=d12981e2177 class=n-a></a>Cattaneo Z, Daini R, Malaspina M, <i> et al.</i>: Congenital prosopagnosia is associated with a genetic variation in the oxytocin receptor (<i>OXTR</i>) gene: An exploratory study. <i>Neuroscience.</i> 2016; <b>339</b>: 162–73. <a target=xrefwindow id=d12981e2191 href="http://www.ncbi.nlm.nih.gov/pubmed/27693815">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2195 href="https://doi.org/10.1016/j.neuroscience.2016.09.040">Publisher Full Text </a></span></li><li><a name=ref-66 class=n-a></a><span class=label>66. </span>&nbsp;<span class=citation><a name=d12981e2205 class=n-a></a>Behrmann M, Plaut DC: A vision of graded hemispheric specialization. <i>Ann N Y Acad Sci.</i> 2015; <b>1359</b>: 30–46. <a target=xrefwindow id=d12981e2213 href="http://www.ncbi.nlm.nih.gov/pubmed/26199998">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2216 href="https://doi.org/10.1111/nyas.12833">Publisher Full Text </a></span></li><li><a name=ref-67 class=n-a></a><span class=label>67. </span>&nbsp;<span class=citation><a name=d12981e2225 class=n-a></a>O'Toole AJ, Jiang F, Abdi H, <i> et al.</i>: Partially distributed representations of objects and faces in ventral temporal cortex. <i>J Cogn Neurosci.</i> 2005; <b>17</b>(4): 580–90. <a target=xrefwindow id=d12981e2236 href="http://www.ncbi.nlm.nih.gov/pubmed/15829079">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2239 href="https://doi.org/10.1162/0898929053467550">Publisher Full Text </a></span></li><li><a name=ref-68 class=n-a></a><span class=label>68. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727624583"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e2248 class=n-a></a>Robinson AK, Plaut DC, Behrmann M: Word and face processing engage overlapping distributed networks: Evidence from RSVP and EEG investigations. <i>J Exp Psychol Gen.</i> 2017; <b>146</b>(7): 943–61. <a target=xrefwindow id=d12981e2256 href="http://www.ncbi.nlm.nih.gov/pubmed/28368200">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2259 href="https://doi.org/10.1037/xge0000302">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727624583">F1000 Recommendation</a></span></li><li><a name=ref-69 class=n-a></a><span class=label>69. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727261697"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e2272 class=n-a></a>Kanwisher N: The Quest for the FFA and Where It Led. <i>J Neurosci.</i> 2017; <b>37</b>(5): 1056–61. <a target=xrefwindow id=d12981e2280 href="http://www.ncbi.nlm.nih.gov/pubmed/28148806">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2283 href="https://doi.org/10.1523/JNEUROSCI.1706-16.2016">Publisher Full Text </a> | <a target=xrefwindow id=d12981e2286 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5296790">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727261697">F1000 Recommendation</a></span></li><li><a name=ref-70 class=n-a></a><span class=label>70. </span>&nbsp;<span class=citation><a name=d12981e2299 class=n-a></a>McKone E, Kanwisher N: 17 Does the Human Brain Process Objects of Expertise Like Faces? A Review of the Evidence. <i>From monkey brain to human brain</i>. 2005; 339. <a target=xrefwindow id=d12981e2304 href="http://web.mit.edu/bcs/nklab/media/pdfs/McKoneKanwisher04.pdf">Reference Source</a></span></li><li><a name=ref-71 class=n-a></a><span class=label>71. </span>&nbsp;<span class=citation><a name=d12981e2313 class=n-a></a>McKone E, Crookes K, Jeffery L, <i> et al.</i>: A critical review of the development of face recognition: experience is less important than previously believed. <i>Cogn Neuropsychol.</i> 2012; <b>29</b>(1–2): 174–212. <a target=xrefwindow id=d12981e2324 href="http://www.ncbi.nlm.nih.gov/pubmed/22360676">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2327 href="https://doi.org/10.1080/02643294.2012.660138">Publisher Full Text </a></span></li><li><a name=ref-72 class=n-a></a><span class=label>72. </span>&nbsp;<span class=citation><a name=d12981e2337 class=n-a></a>Busigny T, Joubert S, Felician O, <i> et al.</i>: Holistic perception of the individual face is specific and necessary: evidence from an extensive case study of acquired prosopagnosia. <i>Neuropsychologia.</i> 2010; <b>48</b>(14): 4057–92. <a target=xrefwindow id=d12981e2348 href="http://www.ncbi.nlm.nih.gov/pubmed/20875437">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2351 href="https://doi.org/10.1016/j.neuropsychologia.2010.09.017">Publisher Full Text </a></span></li><li><a name=ref-73 class=n-a></a><span class=label>73. </span>&nbsp;<span class=citation><a name=d12981e2360 class=n-a></a>Farah MJ, Levinson KL, Klein KL: Face perception and within-category discrimination in prosopagnosia. <i>Neuropsychologia.</i> 1995; <b>33</b>(6): 661–74. <a target=xrefwindow id=d12981e2368 href="http://www.ncbi.nlm.nih.gov/pubmed/7675159">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2371 href="https://doi.org/10.1016/0028-3932(95)00002-K">Publisher Full Text </a></span></li><li><a name=ref-74 class=n-a></a><span class=label>74. </span>&nbsp;<span class=citation><a name=d12981e2380 class=n-a></a>Susilo T, Yovel G, Barton JJ, <i> et al.</i>: Face perception is category-specific: evidence from normal body perception in acquired prosopagnosia. <i>Cognition.</i> 2013; <b>129</b>(1): 88–94. <a target=xrefwindow id=d12981e2391 href="http://www.ncbi.nlm.nih.gov/pubmed/23856076">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2394 href="https://doi.org/10.1016/j.cognition.2013.06.004">Publisher Full Text </a></span></li><li><a name=ref-75 class=n-a></a><span class=label>75. </span>&nbsp;<span class=citation><a name=d12981e2403 class=n-a></a>Rezlescu C, Pitcher D, Duchaine B: Acquired prosopagnosia with spared within-class object recognition but impaired recognition of degraded basic-level objects. <i>Cogn Neuropsychol.</i> 2012; <b>29</b>(4): 325–47. <a target=xrefwindow id=d12981e2411 href="http://www.ncbi.nlm.nih.gov/pubmed/23216309">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2414 href="https://doi.org/10.1080/02643294.2012.749223">Publisher Full Text </a></span></li><li><a name=ref-76 class=n-a></a><span class=label>76. </span>&nbsp;<span class=citation><a name=d12981e2423 class=n-a></a>Rezlescu C, Barton JJ, Pitcher D, <i> et al.</i>: Normal acquisition of expertise with greebles in two cases of acquired prosopagnosia. <i>Proc Natl Acad Sci U S A.</i> 2014; <b>111</b>(14): 5123–8. <a target=xrefwindow id=d12981e2434 href="http://www.ncbi.nlm.nih.gov/pubmed/24706834">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2437 href="https://doi.org/10.1073/pnas.1317125111">Publisher Full Text </a> | <a target=xrefwindow id=d12981e2441 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3986175">Free Full Text </a></span></li><li><a name=ref-77 class=n-a></a><span class=label>77. </span>&nbsp;<span class=citation><a name=d12981e2450 class=n-a></a>Riddoch MJ, Johnston RA, Bracewell RM, <i> et al.</i>: Are faces special? A case of pure prosopagnosia. <i>Cogn Neuropsychol.</i> 2008; <b>25</b>(1): 3–26. <a target=xrefwindow id=d12981e2461 href="http://www.ncbi.nlm.nih.gov/pubmed/18340601">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2464 href="https://doi.org/10.1080/02643290801920113">Publisher Full Text </a></span></li><li><a name=ref-78 class=n-a></a><span class=label>78. </span>&nbsp;<span class=citation><a name=d12981e2474 class=n-a></a>McNeil JE, Warrington EK: Prosopagnosia: a face-specific disorder. <i>Q J Exp Psychol A.</i> 1993; <b>46</b>(1): 1–10. <a target=xrefwindow id=d12981e2482 href="http://www.ncbi.nlm.nih.gov/pubmed/8446761">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2485 href="https://doi.org/10.1080/14640749308401064">Publisher Full Text </a></span></li><li><a name=ref-79 class=n-a></a><span class=label>79. </span>&nbsp;<span class=citation><a name=d12981e2494 class=n-a></a>Farah MJ, Wilson KD, Drain HM, <i> et al.</i>: The inverted face inversion effect in prosopagnosia: evidence for mandatory, face-specific perceptual mechanisms. <i>Vision Res.</i> 1995; <b>35</b>(14): 2089–93. <a target=xrefwindow id=d12981e2505 href="http://www.ncbi.nlm.nih.gov/pubmed/7660612">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2508 href="https://doi.org/10.1016/0042-6989(94)00273-O">Publisher Full Text </a></span></li><li><a name=ref-80 class=n-a></a><span class=label>80. </span>&nbsp;<span class=citation><a name=d12981e2517 class=n-a></a>Henke K, Schweinberger SR, Grigo A, <i> et al.</i>: Specificity of face recognition: recognition of exemplars of non-face objects in prosopagnosia. <i>Cortex.</i> 1998; <b>34</b>(2): 289–96. <a target=xrefwindow id=d12981e2528 href="http://www.ncbi.nlm.nih.gov/pubmed/9606594">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2531 href="https://doi.org/10.1016/S0010-9452(08)70756-1">Publisher Full Text </a></span></li><li><a name=ref-81 class=n-a></a><span class=label>81. </span>&nbsp;<span class=citation><a name=d12981e2540 class=n-a></a>Barton JJ, Cherkasova MV, Press DZ, <i> et al.</i>: Perceptual functions in prosopagnosia. <i>Perception.</i> 2004; <b>33</b>(8): 939–56. <a target=xrefwindow id=d12981e2551 href="http://www.ncbi.nlm.nih.gov/pubmed/15521693">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2554 href="https://doi.org/10.1068/p5243">Publisher Full Text </a></span></li><li><a name=ref-82 class=n-a></a><span class=label>82. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/1027069"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e2563 class=n-a></a>Schiltz C, Sorger B, Caldara R, <i> et al.</i>: Impaired face discrimination in acquired prosopagnosia is associated with abnormal response to individual faces in the right middle fusiform gyrus. <i>Cereb Cortex.</i> 2006; <b>16</b>(4): 574–86. <a target=xrefwindow id=d12981e2574 href="http://www.ncbi.nlm.nih.gov/pubmed/16033923">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2577 href="https://doi.org/10.1093/cercor/bhj005">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/1027069">F1000 Recommendation</a></span></li><li><a name=ref-83 class=n-a></a><span class=label>83. </span>&nbsp;<span class=citation><a name=d12981e2590 class=n-a></a>Bornstein B, Sroka H, Munitz H: Prosopagnosia with animal face agnosia. <i>Cortex.</i> 1969; <b>5</b>(2): 164–9. <a target=xrefwindow id=d12981e2598 href="http://www.ncbi.nlm.nih.gov/pubmed/5387907">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2601 href="https://doi.org/10.1016/S0010-9452(69)80027-4">Publisher Full Text </a></span></li><li><a name=ref-84 class=n-a></a><span class=label>84. </span>&nbsp;<span class=citation><a name=d12981e2611 class=n-a></a>De Haan EH, Campbell R: A fifteen year follow-up of a case of developmental prosopagnosia. <i>Cortex.</i> 1991; <b>27</b>(4): 489–509. <a target=xrefwindow id=d12981e2619 href="http://www.ncbi.nlm.nih.gov/pubmed/1782786">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2622 href="https://doi.org/10.1016/S0010-9452(13)80001-9">Publisher Full Text </a></span></li><li><a name=ref-85 class=n-a></a><span class=label>85. </span>&nbsp;<span class=citation><a name=d12981e2631 class=n-a></a>Gauthier I, Behrmann M, Tarr MJ: Can face recognition really be dissociated from object recognition? <i>J Cogn Neurosci.</i> 1999; <b>11</b>(4): 349–70. <a target=xrefwindow id=d12981e2639 href="http://www.ncbi.nlm.nih.gov/pubmed/10471845">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2642 href="https://doi.org/10.1162/089892999563472">Publisher Full Text </a></span></li><li><a name=ref-86 class=n-a></a><span class=label>86. </span>&nbsp;<span class=citation><a name=d12981e2651 class=n-a></a>Gomori AJ, Hawryluk GA: Visual agnosia without alexia. <i>Neurology.</i> 1984; <b>34</b>(7): 947–50. <a target=xrefwindow id=d12981e2659 href="http://www.ncbi.nlm.nih.gov/pubmed/6539870">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2662 href="https://doi.org/10.1212/wnl.34.7.947">Publisher Full Text </a></span></li><li><a name=ref-87 class=n-a></a><span class=label>87. </span>&nbsp;<span class=citation><a name=d12981e2671 class=n-a></a>Newcombe F: The processing of visual information in prosopagnosia and acquired dyslexia: Functional versus physiological interpretation. <i>Research in psychology and medicine.</i> 1979; <b>1</b>: 315–22. </span></li><li><a name=ref-88 class=n-a></a><span class=label>88. </span>&nbsp;<span class=citation><a name=d12981e2686 class=n-a></a>Bruyer R, Laterre C, Seron X, <i> et al.</i>: A case of prosopagnosia with some preserved covert remembrance of familiar faces. <i>Brain Cogn.</i> 1983; <b>2</b>(3): 257–84. <a target=xrefwindow id=d12981e2697 href="http://www.ncbi.nlm.nih.gov/pubmed/6546027">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2700 href="https://doi.org/10.1016/0278-2626(83)90014-3">Publisher Full Text </a></span></li><li><a name=ref-89 class=n-a></a><span class=label>89. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/734361501"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e2709 class=n-a></a>Geskin J, Behrmann M: Congenital prosopagnosia without object agnosia? A literature review. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 4–54. <a target=xrefwindow id=d12981e2717 href="http://www.ncbi.nlm.nih.gov/pubmed/29165034">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2720 href="https://doi.org/10.1080/02643294.2017.1392295">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/734361501">F1000 Recommendation</a></span></li><li><a name=ref-90 class=n-a></a><span class=label>90. </span>&nbsp;<span class=citation><a name=d12981e2734 class=n-a></a>Rossion B: Prosopdysgnosia? What could it tell us about the neural organization of face and object recognition? <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 98–101. <a target=xrefwindow id=d12981e2742 href="http://www.ncbi.nlm.nih.gov/pubmed/29658423">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2745 href="https://doi.org/10.1080/02643294.2017.1414778">Publisher Full Text </a></span></li><li><a name=ref-91 class=n-a></a><span class=label>91. </span>&nbsp;<span class=citation><a name=d12981e2754 class=n-a></a>Starrfelt R, Robotham RJ: On the use of cognitive neuropsychological methods in developmental disorders. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 94–7. <a target=xrefwindow id=d12981e2762 href="http://www.ncbi.nlm.nih.gov/pubmed/29658416">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2765 href="https://doi.org/10.1080/02643294.2017.1423048">Publisher Full Text </a></span></li><li><a name=ref-92 class=n-a></a><span class=label>92. </span>&nbsp;<span class=citation><a name=d12981e2774 class=n-a></a>Barton JJS: Objects and faces, faces and objects …. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 90–3. <a target=xrefwindow id=d12981e2782 href="http://www.ncbi.nlm.nih.gov/pubmed/29658413">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2785 href="https://doi.org/10.1080/02643294.2017.1414693">Publisher Full Text </a></span></li><li><a name=ref-93 class=n-a></a><span class=label>93. </span>&nbsp;<span class=citation><a name=d12981e2794 class=n-a></a>de Gelder B, Van den Stock J: Face specificity of developmental prosopagnosia, moving beyond the debate on face specificity. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 87–9. <a target=xrefwindow id=d12981e2802 href="http://www.ncbi.nlm.nih.gov/pubmed/29658420">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2805 href="https://doi.org/10.1080/02643294.2018.1441818">Publisher Full Text </a></span></li><li><a name=ref-94 class=n-a></a><span class=label>94. </span>&nbsp;<span class=citation><a name=d12981e2814 class=n-a></a>Ramon M: The power of how-lessons learned from neuropsychology and face processing. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 83–6. <a target=xrefwindow id=d12981e2822 href="http://www.ncbi.nlm.nih.gov/pubmed/29658421">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2825 href="https://doi.org/10.1080/02643294.2017.1414777">Publisher Full Text </a></span></li><li><a name=ref-95 class=n-a></a><span class=label>95. </span>&nbsp;<span class=citation><a name=d12981e2834 class=n-a></a>Eimer M: What do associations and dissociations between face and object recognition abilities tell us about the domain-generality of face processing? <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 80–2. <a target=xrefwindow id=d12981e2842 href="http://www.ncbi.nlm.nih.gov/pubmed/29658415">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2845 href="https://doi.org/10.1080/02643294.2017.1414691">Publisher Full Text </a></span></li><li><a name=ref-96 class=n-a></a><span class=label>96. </span>&nbsp;<span class=citation><a name=d12981e2855 class=n-a></a>Nestor A: Congenital prosopagnosia: Deficit diagnosis and beyond. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 78–9. <a target=xrefwindow id=d12981e2863 href="http://www.ncbi.nlm.nih.gov/pubmed/29658422">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2866 href="https://doi.org/10.1080/02643294.2018.1424708">Publisher Full Text </a></span></li><li><a name=ref-97 class=n-a></a><span class=label>97. </span>&nbsp;<span class=citation><a name=d12981e2875 class=n-a></a>Rosenthal G, Avidan G: A possible neuronal account for the behavioural heterogeneity in congenital prosopagnosia. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 74–7. <a target=xrefwindow id=d12981e2883 href="http://www.ncbi.nlm.nih.gov/pubmed/29658411">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2886 href="https://doi.org/10.1080/02643294.2017.1417248">Publisher Full Text </a></span></li><li><a name=ref-98 class=n-a></a><span class=label>98. </span>&nbsp;<span class=citation><a name=d12981e2895 class=n-a></a>Towler JR, Tree JJ: Commonly associated face and object recognition impairments have implications for the cognitive architecture. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 70–3. <a target=xrefwindow id=d12981e2903 href="http://www.ncbi.nlm.nih.gov/pubmed/29658424">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2906 href="https://doi.org/10.1080/02643294.2018.1433155">Publisher Full Text </a></span></li><li><a name=ref-99 class=n-a></a><span class=label>99. </span>&nbsp;<span class=citation><a name=d12981e2915 class=n-a></a>Gerlach C, Lissau CH, Hildebrandt NK: On defining and interpreting dissociations. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 66–9. <a target=xrefwindow id=d12981e2923 href="http://www.ncbi.nlm.nih.gov/pubmed/29658412">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2926 href="https://doi.org/10.1080/02643294.2017.1414692">Publisher Full Text </a></span></li><li><a name=ref-100 class=n-a></a><span class=label>100. </span>&nbsp;<span class=citation><a name=d12981e2935 class=n-a></a>Campbell A, Tanaka JW: Decoupling category level and perceptual similarity in congenital prosopagnosia. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 63–5. <a target=xrefwindow id=d12981e2943 href="http://www.ncbi.nlm.nih.gov/pubmed/29658419">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2946 href="https://doi.org/10.1080/02643294.2018.1435525">Publisher Full Text </a></span></li><li><a name=ref-101 class=n-a></a><span class=label>101. </span>&nbsp;<span class=citation><a name=d12981e2955 class=n-a></a>Gray KLH, Cook R: Should developmental prosopagnosia, developmental body agnosia, and developmental object agnosia be considered independent neurodevelopmental conditions? <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 59–62. <a target=xrefwindow id=d12981e2963 href="http://www.ncbi.nlm.nih.gov/pubmed/29658410">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2966 href="https://doi.org/10.1080/02643294.2018.1433153">Publisher Full Text </a></span></li><li><a name=ref-102 class=n-a></a><span class=label>102. </span>&nbsp;<span class=citation><a name=d12981e2976 class=n-a></a>Garrido L, Duchaine B, DeGutis J: Association vs dissociation and setting appropriate criteria for object agnosia. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 55–8. <a target=xrefwindow id=d12981e2984 href="http://www.ncbi.nlm.nih.gov/pubmed/29658418">PubMed Abstract </a> | <a target=xrefwindow id=d12981e2987 href="https://doi.org/10.1080/02643294.2018.1431875">Publisher Full Text </a> | <a target=xrefwindow id=d12981e2990 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6522223">Free Full Text </a></span></li><li><a name=ref-103 class=n-a></a><span class=label>103. </span>&nbsp;<span class=citation><a name=d12981e2999 class=n-a></a>Behrmann M, Geskin J: Over time, the right results will emerge. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 102–11. <a target=xrefwindow id=d12981e3007 href="http://www.ncbi.nlm.nih.gov/pubmed/29658414">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3010 href="https://doi.org/10.1080/02643294.2018.1447917">Publisher Full Text </a></span></li><li><a name=ref-104 class=n-a></a><span class=label>104. </span>&nbsp;<span class=citation><a name=d12981e3019 class=n-a></a>Susilo T: The face specificity of lifelong prosopagnosia. <i>Cogn Neuropsychol.</i> 2018; <b>35</b>(1–2): 1–3. <a target=xrefwindow id=d12981e3027 href="http://www.ncbi.nlm.nih.gov/pubmed/29658417">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3030 href="https://doi.org/10.1080/02643294.2018.1438382">Publisher Full Text </a></span></li><li><a name=ref-105 class=n-a></a><span class=label>105. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/735802721"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e3039 class=n-a></a>Gray KLH, Biotti F, Cook R: Evaluating object recognition ability in developmental prosopagnosia using the Cambridge Car Memory Test. <i>Cogn Neuropsychol.</i> 2019; <b>26</b>: 1–8. <a target=xrefwindow id=d12981e3047 href="http://www.ncbi.nlm.nih.gov/pubmed/30973292">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3050 href="https://doi.org/10.1080/02643294.2019.1604503">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/735802721">F1000 Recommendation</a></span></li><li><a name=ref-106 class=n-a></a><span class=label>106. </span>&nbsp;<span class=citation><a name=d12981e3063 class=n-a></a>Barton JJ, Hanif H, Ashraf S: Relating visual to verbal semantic knowledge: the evaluation of object recognition in prosopagnosia. <i>Brain.</i> 2009; <b>132</b>(Pt 12): 3456–66. <a target=xrefwindow id=d12981e3071 href="http://www.ncbi.nlm.nih.gov/pubmed/19805494">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3074 href="https://doi.org/10.1093/brain/awp252">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3077 href="http://www.ncbi.nlm.nih.gov/pmc/articles/2800384">Free Full Text </a></span></li><li><a name=ref-107 class=n-a></a><span class=label>107. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/735479532"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e3086 class=n-a></a>Barton JJS, Albonico A, Susilo T, <i> et al.</i>: Object recognition in acquired and developmental prosopagnosia. <i>Cogn Neuropsychol.</i> 2019; 1–31. <a target=xrefwindow id=d12981e3094 href="http://www.ncbi.nlm.nih.gov/pubmed/30947609">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3097 href="https://doi.org/10.1080/02643294.2019.1593821">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/735479532">F1000 Recommendation</a></span></li><li><a name=ref-108 class=n-a></a><span class=label>108. </span>&nbsp;<span class=citation><a name=d12981e3111 class=n-a></a>Behrmann M, Plaut DC: Distributed circuits, not circumscribed centers, mediate visual recognition. <i>Trends Cogn Sci.</i> 2013; <b>17</b>(5): 210–9. <a target=xrefwindow id=d12981e3119 href="http://www.ncbi.nlm.nih.gov/pubmed/23608364">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3122 href="https://doi.org/10.1016/j.tics.2013.03.007">Publisher Full Text </a></span></li><li><a name=ref-109 class=n-a></a><span class=label>109. </span>&nbsp;<span class=citation><a name=d12981e3131 class=n-a></a>Dundas EM, Plaut DC, Behrmann M: The joint development of hemispheric lateralization for words and faces. <i>J Exp Psychol Gen.</i> 2013; <b>142</b>(2): 348–58. <a target=xrefwindow id=d12981e3139 href="http://www.ncbi.nlm.nih.gov/pubmed/22866684">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3142 href="https://doi.org/10.1037/a0029503">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3145 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4241688">Free Full Text </a></span></li><li><a name=ref-110 class=n-a></a><span class=label>110. </span>&nbsp;<span class=citation><a name=d12981e3154 class=n-a></a>Dehaene S, Pegado F, Braga LW, <i> et al.</i>: How learning to read changes the cortical networks for vision and language. <i>Science.</i> 2010; <b>330</b>(6009): 1359–64. <a target=xrefwindow id=d12981e3165 href="http://www.ncbi.nlm.nih.gov/pubmed/21071632">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3168 href="https://doi.org/10.1126/science.1194140">Publisher Full Text </a></span></li><li><a name=ref-111 class=n-a></a><span class=label>111. </span>&nbsp;<span class=citation><a name=d12981e3177 class=n-a></a>Plaut DC, Behrmann M: Complementary neural representations for faces and words: a computational exploration. <i>Cogn Neuropsychol.</i> 2011; <b>28</b>(3–4): 251–75. <a target=xrefwindow id=d12981e3185 href="http://www.ncbi.nlm.nih.gov/pubmed/22185237">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3188 href="https://doi.org/10.1080/02643294.2011.609812">Publisher Full Text </a></span></li><li><a name=ref-112 class=n-a></a><span class=label>112. </span>&nbsp;<span class=citation><a name=d12981e3197 class=n-a></a>Nestor A, Behrmann M, Plaut DC: The neural basis of visual word form processing: a multivariate investigation. <i>Cereb Cortex.</i> 2013; <b>23</b>(7): 1673–84. <a target=xrefwindow id=d12981e3205 href="http://www.ncbi.nlm.nih.gov/pubmed/22693338">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3208 href="https://doi.org/10.1093/cercor/bhs158">Publisher Full Text </a></span></li><li><a name=ref-113 class=n-a></a><span class=label>113. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/717987473"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e3217 class=n-a></a>Behrmann M, Plaut DC: Bilateral hemispheric processing of words and faces: evidence from word impairments in prosopagnosia and face impairments in pure alexia. <i>Cereb Cortex.</i> 2014; <b>24</b>(4): 1102–18. <a target=xrefwindow id=d12981e3225 href="http://www.ncbi.nlm.nih.gov/pubmed/23250954">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3228 href="https://doi.org/10.1093/cercor/bhs390">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/717987473">F1000 Recommendation</a></span></li><li><a name=ref-114 class=n-a></a><span class=label>114. </span>&nbsp;<span class=citation><a name=d12981e3242 class=n-a></a>Susilo T, Wright V, Tree JJ, <i> et al.</i>: Acquired prosopagnosia without word recognition deficits. <i>Cogn Neuropsychol.</i> 2015; <b>32</b>(6): 321–39. <a target=xrefwindow id=d12981e3253 href="http://www.ncbi.nlm.nih.gov/pubmed/26402384">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3256 href="https://doi.org/10.1080/02643294.2015.1081882">Publisher Full Text </a></span></li><li><a name=ref-115 class=n-a></a><span class=label>115. </span>&nbsp;<span class=citation><a name=d12981e3265 class=n-a></a>Hills CS, Pancaroglu R, Duchaine B, <i> et al.</i>: Word and text processing in acquired prosopagnosia. <i>Ann Neurol.</i> 2015; <b>78</b>(2): 258–71. <a target=xrefwindow id=d12981e3276 href="http://www.ncbi.nlm.nih.gov/pubmed/25976067">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3279 href="https://doi.org/10.1002/ana.24437">Publisher Full Text </a></span></li><li><a name=ref-116 class=n-a></a><span class=label>116. </span>&nbsp;<span class=citation><a name=d12981e3288 class=n-a></a>Rubino C, Corrow SL, Corrow JC, <i> et al.</i>: Word and text processing in developmental prosopagnosia. <i>Cogn Neuropsychol.</i> 2016; <b>33</b>(5–6): 315–28. <a target=xrefwindow id=d12981e3299 href="http://www.ncbi.nlm.nih.gov/pubmed/27593455">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3302 href="https://doi.org/10.1080/02643294.2016.1204281">Publisher Full Text </a></span></li><li><a name=ref-117 class=n-a></a><span class=label>117. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/735802758"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e3311 class=n-a></a>Starrfelt R, Klargaard SK, Petersen A, <i> et al.</i>: Reading in developmental prosopagnosia: Evidence for a dissociation between word and face recognition. <i>Neuropsychology.</i> 2018; <b>32</b>(2): 138–47. <a target=xrefwindow id=d12981e3322 href="http://www.ncbi.nlm.nih.gov/pubmed/29528680">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3325 href="https://doi.org/10.1037/neu0000428">Publisher Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/735802758">F1000 Recommendation</a></span></li><li><a name=ref-118 class=n-a></a><span class=label>118. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/727605043"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e3338 class=n-a></a>Burns EJ, Bennetts RJ, Bate S, <i> et al.</i>: Intact word processing in developmental prosopagnosia. <i>Sci Rep.</i> 2017; <b>7</b>(1): 1683. <a target=xrefwindow id=d12981e3349 href="http://www.ncbi.nlm.nih.gov/pubmed/28490791">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3352 href="https://doi.org/10.1038/s41598-017-01917-8">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3356 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5431912">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/727605043">F1000 Recommendation</a></span></li><li><a name=ref-119 class=n-a></a><span class=label>119. </span>&nbsp;<span class=citation><a name=d12981e3369 class=n-a></a>Campbell R, Landis T, Regard M: Face recognition and lipreading. A neurological dissociation. <i>Brain.</i> 1986; <b>109</b>(Pt 3): 509–21. <a target=xrefwindow id=d12981e3377 href="http://www.ncbi.nlm.nih.gov/pubmed/3719288">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3380 href="https://doi.org/10.1093/brain/109.3.509">Publisher Full Text </a></span></li><li><a name=ref-120 class=n-a></a><span class=label>120. </span>&nbsp;<span class=citation><a name=d12981e3390 class=n-a></a>Rentschler I, Treutwein B, Landis T: Dissociation of local and global processing in visual agnosia. <i>Vision Res.</i> 1994; <b>34</b>(7): 963–71. <a target=xrefwindow id=d12981e3398 href="http://www.ncbi.nlm.nih.gov/pubmed/8160408">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3401 href="https://doi.org/10.1016/0042-6989(94)90045-0">Publisher Full Text </a></span></li><li><a name=ref-121 class=n-a></a><span class=label>121. </span>&nbsp;<span class=citation><a name=d12981e3410 class=n-a></a>Barton JJ, Sekunova A, Sheldon C, <i> et al.</i>: Reading words, seeing style: the neuropsychology of word, font and handwriting perception. <i>Neuropsychologia.</i> 2010; <b>48</b>(13): 3868–77. <a target=xrefwindow id=d12981e3421 href="http://www.ncbi.nlm.nih.gov/pubmed/20863841">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3424 href="https://doi.org/10.1016/j.neuropsychologia.2010.09.012">Publisher Full Text </a></span></li><li><a name=ref-122 class=n-a></a><span class=label>122. </span>&nbsp;<span class=citation><a target=_blank title="F1000 recommended" class="research-layout prime-recommended-reference" href="https://f1000.com/prime/731253964"><span class="f1r-icon icon-79_faculty_recommended_badge small red vmiddle"></span></a><a name=d12981e3433 class=n-a></a>Robotham RJ, Starrfelt R: Face and Word Recognition Can Be Selectively Affected by Brain Injury or Developmental Disorders. <i>Front Psychol.</i> 2017; <b>8</b>: 1547. <a target=xrefwindow id=d12981e3441 href="http://www.ncbi.nlm.nih.gov/pubmed/28932205">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3444 href="https://doi.org/10.3389/fpsyg.2017.01547">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3447 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5592207">Free Full Text </a> | <a target=_blank title="F1000 recommended" href="https://f1000.com/prime/731253964">F1000 Recommendation</a></span></li><li><a name=ref-123 class=n-a></a><span class=label>123. </span>&nbsp;<span class=citation><a name=d12981e3460 class=n-a></a>Albonico A, Barton JJS: Face perception in pure alexia: Complementary contributions of the left fusiform gyrus to facial identity and facial speech processing. <i>Cortex.</i> 2017; <b>96</b>: 59–72. <a target=xrefwindow id=d12981e3468 href="http://www.ncbi.nlm.nih.gov/pubmed/28964939">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3471 href="https://doi.org/10.1016/j.cortex.2017.08.029">Publisher Full Text </a></span></li><li><a name=ref-124 class=n-a></a><span class=label>124. </span>&nbsp;<span class=citation><a name=d12981e3480 class=n-a></a>Campbell R, Garwood J, Franklin S, <i> et al.</i>: Neuropsychological studies of auditory-visual fusion illusions. Four case studies and their implications. <i>Neuropsychologia.</i> 1990; <b>28</b>(8): 787–802. <a target=xrefwindow id=d12981e3491 href="http://www.ncbi.nlm.nih.gov/pubmed/1701035">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3494 href="https://doi.org/10.1016/0028-3932(90)90003-7">Publisher Full Text </a></span></li><li><a name=ref-125 class=n-a></a><span class=label>125. </span>&nbsp;<span class=citation><a name=d12981e3503 class=n-a></a>Glowic C, Violon A: [A case of regressive prosopagnosia (author's transl)]. <i>Acta Neurol Belg.</i> 1981; <b>81</b>(2): 86–97. <a target=xrefwindow id=d12981e3511 href="http://www.ncbi.nlm.nih.gov/pubmed/7234323">PubMed Abstract </a></span></li><li><a name=ref-126 class=n-a></a><span class=label>126. </span>&nbsp;<span class=citation><a name=d12981e3521 class=n-a></a>Hier DB, Mondlock J, Caplan LR: Behavioral abnormalities after right hemisphere stroke. <i>Neurology.</i> 1983; <b>33</b>(3): 337–44. <a target=xrefwindow id=d12981e3529 href="http://www.ncbi.nlm.nih.gov/pubmed/6681879">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3532 href="https://doi.org/10.1212/wnl.33.3.337">Publisher Full Text </a></span></li><li><a name=ref-127 class=n-a></a><span class=label>127. </span>&nbsp;<span class=citation><a name=d12981e3541 class=n-a></a>Lang N, Baudewig J, Kallenberg K, <i> et al.</i>: Transient prosopagnosia after ischemic stroke. <i>Neurology.</i> 2006; <b>66</b>(6): 916. <a target=xrefwindow id=d12981e3552 href="http://www.ncbi.nlm.nih.gov/pubmed/16567712">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3555 href="https://doi.org/10.1212/01.wnl.0000203113.12324.57">Publisher Full Text </a></span></li><li><a name=ref-128 class=n-a></a><span class=label>128. </span>&nbsp;<span class=citation><a name=d12981e3564 class=n-a></a>Haxby JV, Hoffman EA, Gobbini MI: The distributed human neural system for face perception. <i>Trends Cogn Sci.</i> 2000; <b>4</b>(6): 223–33. <a target=xrefwindow id=d12981e3572 href="http://www.ncbi.nlm.nih.gov/pubmed/10827445">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3575 href="https://doi.org/10.1016/S1364-6613(00)01482-0">Publisher Full Text </a></span></li><li><a name=ref-129 class=n-a></a><span class=label>129. </span>&nbsp;<span class=citation><a name=d12981e3584 class=n-a></a>DeGutis JM, Chiu C, Grosso ME, <i> et al.</i>: Face processing improvements in prosopagnosia: successes and failures over the last 50 years. <i>Front Hum Neurosci.</i> 2014; <b>8</b>: 561. <a target=xrefwindow id=d12981e3595 href="http://www.ncbi.nlm.nih.gov/pubmed/25140137">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3598 href="https://doi.org/10.3389/fnhum.2014.00561">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3602 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4122168">Free Full Text </a></span></li><li><a name=ref-130 class=n-a></a><span class=label>130. </span>&nbsp;<span class=citation><a name=d12981e3611 class=n-a></a>Bate S, Cook SJ, Duchaine B, <i> et al.</i>: Intranasal inhalation of oxytocin improves face processing in developmental prosopagnosia. <i>Cortex.</i> 2014; <b>50</b>: 55–63. <a target=xrefwindow id=d12981e3622 href="http://www.ncbi.nlm.nih.gov/pubmed/24074457">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3625 href="https://doi.org/10.1016/j.cortex.2013.08.006">Publisher Full Text </a></span></li><li><a name=ref-131 class=n-a></a><span class=label>131. </span>&nbsp;<span class=citation><a name=d12981e3634 class=n-a></a>Bate S, Bennetts RJ: The rehabilitation of face recognition impairments: a critical review and future directions. <i>Front Hum Neurosci.</i> 2014; <b>8</b>: 491. <a target=xrefwindow id=d12981e3642 href="http://www.ncbi.nlm.nih.gov/pubmed/25100965">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3645 href="https://doi.org/10.3389/fnhum.2014.00491">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3648 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4107857">Free Full Text </a></span></li><li><a name=ref-132 class=n-a></a><span class=label>132. </span>&nbsp;<span class=citation><a name=d12981e3658 class=n-a></a>Davies-Thompson J, Fletcher K, Hills C, <i> et al.</i>: Perceptual Learning of Faces: A Rehabilitative Study of Acquired Prosopagnosia. <i>J Cogn Neurosci.</i> 2017; <b>29</b>(3): 573–91. <a target=xrefwindow id=d12981e3669 href="http://www.ncbi.nlm.nih.gov/pubmed/28139958">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3672 href="https://doi.org/10.1162/jocn_a_01063">Publisher Full Text </a></span></li><li><a name=ref-133 class=n-a></a><span class=label>133. </span>&nbsp;<span class=citation><a name=d12981e3681 class=n-a></a>Wilson BA: Rehabilitation of memory. New York: Guilford Publications; 1987. <a target=xrefwindow id=d12981e3683 href="https://books.google.co.in/books/about/Rehabilitation_of_Memory.html?id=32NDb4BOl4IC&amp;redir_esc=y">Reference Source</a></span></li><li><a name=ref-134 class=n-a></a><span class=label>134. </span>&nbsp;<span class=citation><a name=d12981e3692 class=n-a></a>Polster MR, Rapcsak SZ: Representations in learning new faces: evidence from prosopagnosia. <i>J Int Neuropsychol Soc.</i> 1996; <b>2</b>(3): 240–8. <a target=xrefwindow id=d12981e3700 href="http://www.ncbi.nlm.nih.gov/pubmed/9375190">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3703 href="https://doi.org/10.1017/S1355617700001181">Publisher Full Text </a></span></li><li><a name=ref-135 class=n-a></a><span class=label>135. </span>&nbsp;<span class=citation><a name=d12981e3712 class=n-a></a>Francis R, Riddoch MJ, Humphreys GW: 'Who's that girl?: ' Prosopagnosia, person-based semantic disorder, and the reacquisition of face identification ability. <i>Neuropsychol Rehabil.</i> 2002; <b>12</b>: 1–26. <a target=xrefwindow id=d12981e3720 href="https://doi.org/10.1080/09602010143000158">Publisher Full Text </a></span></li><li><a name=ref-136 class=n-a></a><span class=label>136. </span>&nbsp;<span class=citation><a name=d12981e3729 class=n-a></a>Powell J, Letson S, Davidoff J, <i> et al.</i>: Enhancement of face recognition learning in patients with brain injury using three cognitive training procedures. <i>Neuropsychol Rehabil.</i> 2008; <b>18</b>(2): 182–203. <a target=xrefwindow id=d12981e3740 href="http://www.ncbi.nlm.nih.gov/pubmed/18350413">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3743 href="https://doi.org/10.1080/09602010701419485">Publisher Full Text </a></span></li><li><a name=ref-137 class=n-a></a><span class=label>137. </span>&nbsp;<span class=citation><a name=d12981e3752 class=n-a></a>Mayer E, Rossion B, Godefroy O, <i> et al.</i>: The Behavioral Cognitive Neurology of Stroke. Cambridge University Press Cambridge; 2007. <a target=xrefwindow id=d12981e3757 href="https://books.google.co.in/books?id=60IRgz00ugsC&amp;printsec=frontcover&amp;source=gbs_ge_summary_r&amp;cad=0#v=onepage&amp;q&amp;f=false">Reference Source</a></span></li><li><a name=ref-138 class=n-a></a><span class=label>138. </span>&nbsp;<span class=citation><a name=d12981e3767 class=n-a></a>Beyn ES, Knyazeva GR: The problem of prosopagnosia. <i>J Neurol Neurosurg Psychiatry.</i> 1962; <b>25</b>: 154–8. <a target=xrefwindow id=d12981e3775 href="http://www.ncbi.nlm.nih.gov/pubmed/13868762">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3778 href="https://doi.org/10.1136/jnnp.25.2.154">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3781 href="http://www.ncbi.nlm.nih.gov/pmc/articles/495435">Free Full Text </a></span></li><li><a name=ref-139 class=n-a></a><span class=label>139. </span>&nbsp;<span class=citation><a name=d12981e3790 class=n-a></a>DeGutis J, Cohan S, Nakayama K: Holistic face training enhances face processing in developmental prosopagnosia. <i>Brain.</i> 2014; <b>137</b>(Pt 6): 1781–98. <a target=xrefwindow id=d12981e3798 href="http://www.ncbi.nlm.nih.gov/pubmed/24691394">PubMed Abstract </a> | <a target=xrefwindow id=d12981e3801 href="https://doi.org/10.1093/brain/awu062">Publisher Full Text </a> | <a target=xrefwindow id=d12981e3804 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4032098">Free Full Text </a></span></li></ul></div></div></div> </div> <div id=article-comments class="article-comments padding-bottom-20"> <div class=current-article-comment-section> <h2 class=main-title name=add-new-comment id=add-new-comment> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-104_comments size30"></span> </span> <span class=f1r-article-desk-inline>Comments on this article</span> <span class=f1r-article-mobile-inline>Comments (0)</span> <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> </div> <div class="f1r-article-desk-inline referee-report-info-box referee-report-version-box"> Version 1 </div> <div class="f1r-article-mobile research-layout mobile-version-info padding-top-30"> <span class=mversion>VERSION 1</span> <span class=details>PUBLISHED 31 May 2019</span> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div class="f1r-article-mobile research-layout margin-top-20 is-centered"> <a href="/login?originalPath=/articles/8-765/v1&scrollTo=add-new-comment" class=register-report-comment-button data-test-id=add-comment_mob> <button class="primary orange extra-padding comment-on-this-report">ADD YOUR COMMENT</button> </a> </div> <a href="/login?originalPath=/articles/8-765/v1&scrollTo=add-new-comment" class="f1r-article-desk register-report-comment-button" data-test-id=add-comment> <span class=contracted></span>Comment </a> </div> <div class="f1r-article-mobile margin-bottom-30"> <div class=contracted-details> <a href="#" class="contracted-details-label author-affiliations"><span class=contracted></span>Author details</a> <a href="#" class=section-title>Author details</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details affiliations is-hidden"> Human Vision and Eye Movement Laboratory, Departments of Medicine (Neurology), Ophthalmology and Visual Sciences, Psychology, University of British Columbia, Vancouver, Canada<br/> <p> <div class=margin-bottom> Andrea Albonico <br/> <span>Roles: </span> Conceptualization, Methodology, Writing – Original Draft Preparation </div> <div class=margin-bottom> Jason Barton <br/> <span>Roles: </span> Conceptualization, Formal Analysis, Supervision, Writing – Review & Editing </div> </p> </div> </div> <div class=contracted-details> <a href="#" class=section-title>Article Versions (1)</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details grant-information article-page is-hidden"> <div> <a href="https://f1000research.com/articles/8-765/v1" title="Open version 1 of this article." class="" gahelper=1>version 1</a> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div> Published: 31 May 2019, 8:765 </div> <div class=""><a href="https://doi.org/10.12688/f1000research.18492.1">https://doi.org/10.12688/f1000research.18492.1</a></div> </div> </div> <div class=contracted-details> <a href="#" class=section-title> <span class="f1r-icon icon-100_open_access"></span> Copyright </a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details grant-information article-page is-hidden"> © 2019 Albonico A and Barton J. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/" target=_blank data-test-id=box-licence-link>Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. </div> </div> <div class="padding-top-30 research-layout"> <div class=article-toolbox-wrapper-mobile> <div class=article-tools-icon-mobile data-section=download> <span class="f1r-icon icon-76_download_file white"></span> </div> <div class="article-tools-icon-mobile mobile-metrics article-metrics-wrapper metrics-icon-wrapper" data-section=metrics data-version-id=20234 data-id=18492 data-downloads="" data-views="" data-scholar="10.12688/f1000research.18492.1" data-recommended="" data-f1r-ga-helper="Article Page Metrics (Mobile)"> <span class="f1r-icon icon-89_metrics white"></span> </div> <div class=article-tools-divider-mobile></div> <div class=article-tools-icon-mobile data-section=cite> <span class="f1r-icon icon-82_quote white"></span> </div> <div class="article-tools-icon-mobile " data-section=track> <span class="f1r-icon icon-90_track white"></span> </div> <div class=article-tools-divider-mobile></div> <div class=article-tools-icon-mobile data-section=share> <span class="f1r-icon icon-34_share white"></span> </div> <span class=article-toolbox-stretch></span> </div> <div class=article-toolbox-content-mobile> <div class="toolbox-section download"> <div class=toolbox-section-heading>Download</div> <div class=toolbox-section-content> <a href="https://f1000research.com/articles/8-765/v1/pdf?article_uuid=22b4231b-6a84-47bf-888e-2fedb327499f" title="Download PDF" class="no-decoration pdf-download-helper"> <span class="f1r-icon icon-102_download_pdf toolbox-section-icon"></span> </a> <div class=toolbox-section-option-divider>&nbsp;</div> <a id=mobile-download-xml class=no-decoration href="#" title="Download XML"> <span class="f1r-icon icon-103_download_xml toolbox-section-icon"></span> </a> </div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>Export To</div> <div class=toolbox-section-content> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=WORKSPACE>Sciwheel</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=BIBTEX>Bibtex</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=ENDNOTE>EndNote</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=PROCITE>ProCite</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=REF_MANAGER>Ref. Manager (RIS)</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=SENTE>Sente</button> </div> </div> <div class="toolbox-section metrics"> <div class="toolbox-section-heading no-top-border">metrics</div> <div class="toolbox-section-divider toolbox-section-divider--no-height"></div> <div class=article-metrics-pageinfo> <div class=c-article-metrics-table> <table class=c-article-metrics-table__table> <thead> <tr> <th></th> <th><span class=c-article-metrics-table__heading>Views</span></th> <th><span class=c-article-metrics-table__heading>Downloads</span></th> </tr> </thead> <tbody> <tr> <th class=c-article-metrics-table__row-heading><span class="c-article-metrics-table__platform u-platform--" data-test-id=metrics_platform_name_mob>F1000Research</span></th> <td class="c-article-metrics-table__value js-article-views-count" data-test-id=metrics_platform_views_mob>-</td> <td class="c-article-metrics-table__value js-article-downloads-count" data-test-id=metrics_platform_downloads_mob>-</td> </tr> <tr> <th class=c-article-metrics-table__row-heading> <span class="u-ib u-middle c-article-metrics-table__pmc" data-test-id=metrics_pmc_name_mob>PubMed Central</span> <div class="c-block-tip c-block-tip--centered c-article-metrics-table__tooltip c-block-tip--md-padding c-block-tip--small-arrow u-ib u-middle"> <button type=button class="u-black--medium u-black--high@hover u-ib u-middle c-button--icon c-button--text c-block-tip__toggle"><i class="material-icons c-button--icon__icon">info_outline</i></button> <div class=c-block-tip__content>Data from PMC are received and updated monthly.</div> </div> </th> <td class="c-article-metrics-table__value js-pmc-views-count" data-test-id=metrics_pmc_views_mob>-</td> <td class="c-article-metrics-table__value js-pmc-downloads-count" data-test-id=metrics_pmc_downloads_mob>-</td> </tr> </tbody> </table> </div> </div> <span class=metrics-citations-container> <div class=toolbox-section-divider></div> <div class="toolbox-section-heading u-mb--1">Citations</div> <div> <div class=toolbox-section-colsplit> <div class=citations-scopus-logo> <a href="" target=_blank class="is-hidden metrics-citation-icon" title="View full citation details at www.scopus.com"><i class="material-icons scopus-icon">open_in_new</i></a> </div> <div class="toolbox-section-count scopus"> <a href='' class='scopus-citation-link is-hidden' target=_blank title='View full citation details at www.scopus.com'>0</a> </div> </div> <div class=toolbox-section-colsplit> <div class="citations-pubmed-logo f1000research"> <a href="" target=_blank class="is-hidden metrics-citation-icon f1000research" title="View full citation details"><i class="material-icons scopus-icon">open_in_new</i></a> </div> <div class="toolbox-section-count pubmed"> <a href='' class='pubmed-citation-link is-hidden' target=_blank title='View full citation details'>0</a> </div> </div> <div class=toolbox-section-divider></div> <div class=toolbox-section-content> <div class="citations-scholar-logo f1000research"> <a href="" target=_blank class="is-hidden metrics-citation-icon google-scholar f1000research" title="View full citation details" data-scholar="10.12688/f1000research.18492.1"><i class="material-icons scopus-icon">open_in_new</i></a> </div> </div> </div> </span> <span class=metrics-details-container> <div class=toolbox-section-divider></div> <div class="toolbox-section-content altmetric-section"> <div class=altmetrics-image></div> <div class=altmetrics-more-link> <a href="" target=_blank class=f1r-standard-link>SEE MORE DETAILS</a> </div> <div class=altmetric-mobile-column-counts></div> <div class=altmetric-mobile-column-readers></div> <div class=toolbox-section-divider></div> </div> </span> </div> <div class="toolbox-section cite"> <div class="toolbox-section-heading no-top-border">CITE</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>how to cite this article</div> <div id=citation-copy-mobile class="toolbox-section-content text-content heading9 small" data-test-id=mob_copy-citation_text> Albonico A and Barton J. Progress in perceptual research: the case of prosopagnosia [version 1; peer review: 2 approved] <i>F1000Research</i> 2019, <b>8</b>(F1000 Faculty Rev):765 (<a href="https://doi.org/10.12688/f1000research.18492.1" target=_blank>https://doi.org/10.12688/f1000research.18492.1</a>) </div> <div class=toolbox-section-divider></div> <div class="toolbox-section-content text-content heading9 small"> NOTE: <em>it is important to ensure the information in <b>square brackets after the title</b> is included in all citations of this article.</em> </div> <div class=toolbox-section-content> <button class="primary orange extra-padding copy-cite-article-mobile js-clipboard" data-clipboard-target="#citation-copy-mobile" title="Copy the current citation details." data-test-id=mob_copy-citation_button-mob>COPY CITATION DETAILS</button> </div> </div> <div class="toolbox-section track"> <div class="toolbox-section-heading no-top-border">track</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>receive updates on this article</div> <div class="toolbox-section-content padding-left-20 padding-right-20 heading9 small"> Track an article to receive email alerts on any updates to this article. </div> <div class=toolbox-section-content> <a data-article-id=18492 id=mobile-track-article-signin-18492 title="Receive updates on new activity such as publication of new versions, peer reviews or author responses." href="/login?originalPath=/trackArticle/18492?target=/articles/8-765/v1"> <button class="primary orange extra-padding"> TRACK THIS ARTICLE </button> </a> </div> </div> <div class="toolbox-section share"> <div class="toolbox-section-heading no-top-border">Share</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-content> <a target=_blank class="f1r-shares-icon-square f1r-shares-email" title="Email this article"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-twitter" title="Share on Twitter"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-facebook" title="Share on Facebook"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-linkedin" title="Share on LinkedIn"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-reddit" title="Share on Reddit"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-mendelay" title="Share on Mendeley"></a> <div class="email-article-wrapper email-article-version-container"> <div class=toolbox-section-divider></div> <script src='https://www.recaptcha.net/recaptcha/api.js'></script> <form class="recommend-version-form-mobile research-layout"> <p>All fields are required.</p> <input name=versionId type=hidden value=20234 /> <input name=articleId type=hidden value=18492 /> <input name=senderName class="form-input-field reg-form" value="" type=text placeholder="Your name"/> <input name=senderEmail class="form-input-field reg-form margin-top" value="" type=text placeholder="Your email address"/> <textarea name=recipientEmails class="form-textarea-field ninetynine-percent-wide margin-top no-resize" placeholder="Recipient email address(es) (comma delimited)"></textarea> <input class="form-input-field reg-form margin-top" name=subject type=text value="Interesting article on F1000Research" placeholder=Subject /> <textarea name=message class="form-textarea-field reg-form margin-top no-resize">I thought this article from F1000Research (https://f1000research.com) would be of interest to you.</textarea> <div class="g-recaptcha margin-top" data-sitekey=6LcHqxoUAAAAANP3_0TzpGG6qFvl4DhbUcuRzw7W></div> <input value="" name=captcha type=hidden /> <p>A full article citation will be automatically included.</p> <p><img class="ticker-email-article-details hidden" src="/img/ticker.gif" alt=loading /></p> <button class="secondary orange margin-bottom" data-test-id=version_share_email_send>SEND EMAIL</button> <div class="orange-message margin-bottom is-hidden" data-test-id=version_share_email_message></div> </form> </div> </div> </div> </div> </div> <a name=article-reports></a> <div id=article-reports class="u-mt--3 reports-comments no-divider"> <div class="current-referee-status current-referee-status--faculty "> <h2 class=main-title id=current-referee-status> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-85_peer_review size30"></span> </span> Open Peer Review <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> <a name=current-referee-status></a> <div class=current-referee-status__content name=add-new-report-comment id=add-new-report-comment> Current Reviewer Status: <span class="research-layout f1r-article-desk-inline"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-mobile float-right"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-desk-inline"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-mobile float-right"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> </span> <span class="research-layout f1r-article-mobile"> <div class=mobile-ref-status-help> Key to Reviewer Statuses <span class=referee-status-pointer></span> <span class="view-control float-right">VIEW</span> <span class="view-control float-right is-hidden">HIDE</span> <div class=mobile-ref-status-help-content> <div class="cf margin-top"> <span class="f1r-icon icon-86_approved status-green smaller float-left margin-bottom-40 margin-right" title=Approved></span> <span class=title>Approved</span>The paper is scientifically sound in its current form and only minor, if any, improvements are suggested </div> <div class="cf margin-top"> <span class="f1r-icon icon-87_approved_reservations status-green smaller float-left margin-bottom-40 margin-right" title="Approved with Reservations"></span> <span class=title>Approved with reservations</span> A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </div> <div class="cf margin-top"> <span class="f1r-icon icon-88_not_approved status-red small float-left margin-bottom-30 margin-right" title="Not Approved"></span> <span class=title>Not approved</span>Fundamental flaws in the paper seriously undermine the findings and conclusions </div> </div> </div> </span> <div class=editorial-note> <h5 class=editorial-note__title>Editorial Note on the Review Process</h5> <p class=editorial-note__text><a href="/browse/faculty-reviews">Faculty Reviews</a> are review articles written by the prestigious Members of <a href="https://facultyopinions.com/prime/home">Faculty Opinions</a>. The articles are commissioned and peer reviewed before publication to ensure that the final, published version is comprehensive and accessible. The reviewers who approved the final version are listed with their names and affiliations.</p> </div> <div class=approved-referee> <h4 class=approved-referee__title>Reviewers who approved this article</h4> <ol class=approved-referee__list> <li class="approved-referee__list-item "> <span class=approved-referee__co-referee> <strong>Galia Avidan</strong>, Department Psychology, Ben-Gurion University of the Negev, Israel </span> <span class=approved-referee__competing-list> <strong>Competing interests:</strong> No competing interests were declared. (for version 1) <br> </span> </li> <li class="approved-referee__list-item margin-top-20"> <span class=approved-referee__co-referee> <strong>Richard Cook</strong>, Department of Psychological Sciences, Birkbeck, University of London, UK </span> <span class=approved-referee__competing-list> <strong>Competing interests:</strong> No competing interests were declared. (for version 1) <br> </span> </li> </ol> </div> </div> </div> </div> <div class="f1r-article-mobile research-layout"> <div class="mobile-sections-divider before-comments"></div> </div> <div id=article-comments class="article-comments padding-bottom-20"> <div class=current-article-comment-section> <h2 class=main-title name=add-new-comment id=add-new-comment> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-104_comments size30"></span> </span> <span class=f1r-article-desk-inline>Comments on this article</span> <span class=f1r-article-mobile-inline>Comments (0)</span> <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> </div> <div class="f1r-article-desk-inline referee-report-info-box referee-report-version-box"> Version 1 </div> <div class="f1r-article-mobile research-layout mobile-version-info padding-top-30"> <span class=mversion>VERSION 1</span> <span class=details>PUBLISHED 31 May 2019</span> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div class="f1r-article-mobile research-layout margin-top-20 is-centered"> <a href="/login?originalPath=/articles/8-765/v1&scrollTo=add-new-comment" class=register-report-comment-button data-test-id=add-comment_mob> <button class="primary orange extra-padding comment-on-this-report">ADD YOUR COMMENT</button> </a> </div> <a href="/login?originalPath=/articles/8-765/v1&scrollTo=add-new-comment" class="f1r-article-desk register-report-comment-button" data-test-id=add-comment> <span class=contracted></span>Comment </a> </div> </div> </div> <div id=article_main-column class="p-article__sidebar o-layout__item u-1/3 not-expanded js-article-sidebar"> <div class="o-tab p-article__column-toggle-container"> <button class="c-tab c-tab--left js-column-toggle p-article__column-toggle not-expanded " type=button data-target-main=article_main-column data-target-secondary=article_secondary-column><i class="c-tab__icon material-icons u-hide@expanded">keyboard_arrow_left</i><i class="c-tab__icon material-icons u-show@expanded">keyboard_arrow_right</i></button> </div> <div class=p-article__sidebar-content> <div class="p-article__sidebar-scroller js-article-sidebar-scroller"> <section class="p-article__sidebar-view js-article-sidebar-view js-article-sidebar-main u-pt u-pb--8" data-view=peer-review> <div class="o-layout o-layout--flush"> <div class="o-layout__item u-pl"> <h3 class="u-mt--0 u-mb--2 t-h3 u-weight--md u-pl" data-test-id=article_sidebar_heading>Open Peer Review</h3> </div> <div class=o-layout__item> <section class=""> <div class="p-article__sidebar-highlight u-mb--2 u-pr--1"> <div class="o-actions o-actions--middle"> <div class=o-actions__primary> <h4 class="u-mt--0 u-mb--0 u-ib u-middle t-h4 u-weight--md u-mr--1/2">Reviewer Status</h4> <div class="c-referee-status__icons u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--approved " title=Approved #data-refInfo=51530-48967></i> <i class="c-icn--f1r-icon c-icn--approved " title=Approved #data-refInfo=51531-48968></i> </div> </div> <div class="o-actions__secondary _mdl-layout"> <div class="c-block-tip p-article__sidebar-tooltip c-block-tip--below c-block-tip--small-arrow c-block-tip--sm-padding"> <button type=button class="c-button c-button--icon c-button--text c-block-tip__toggle"><i class="material-icons c-button--icon__icon">info_outline</i></button> <div class=c-block-tip__content> <p class="t-body u-mt--0 u-mb--0"><em class=u-weight--md>Alongside their report, reviewers assign a status to the article:</em></p> <dl class=c-definitions> <dt class="c-definitions__term u-upper t-control u-weight--md u-black--high"><span class="u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--approved " title=Approved #data-refInfo=""></i> </span> <span class="u-middle u-ib u-ml--1/2">Approved</span></dt> <dd class="c-definitions__description t-caption">The paper is scientifically sound in its current form and only minor, if any, improvements are suggested</dd> <dt class="c-definitions__term u-upper t-control u-weight--md u-black--high"><span class="u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--reservations" title="Approved with Reservations" #data-refInfo=""></i> </span> <span class="u-middle u-ib u-ml--1/2">Approved with reservations</span></dt> <dd class="c-definitions__description t-caption"> A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </dd> <dt class="c-definitions__term u-upper t-control u-weight--md u-black--high"><span class="u-ib u-middle"> <i class="c-icn--f1r-icon c-icn--not-approved " title="Not Approved" #data-refInfo=""></i> </span> <span class="u-middle u-ib u-ml--1/2">Not approved</span></dt> <dd class="c-definitions__description t-caption">Fundamental flaws in the paper seriously undermine the findings and conclusions</dd> </dl> </div> </div> </div> </div> </div> <div class="o-layout__item u-mb--1"><h4 class="u-mt--0 u-mb--0 u-ib u-middle t-h4 u-weight--md">Reviewer Reports</h4></div> <table class="c-report-timeline u-mb--2"> <thead class=c-report-timeline__headings> <tr> <th></th> <th class="u-pb--1/2" colspan=2><em class="t-body u-weight--rg">Invited Reviewers</em></th> </tr> <tr class=c-report-timeline__headings-row> <th></th> <th class="c-report-timeline__headings-version p-article__color--dark">1</th> <th class="c-report-timeline__headings-version p-article__color--dark">2</th> </tr> </thead> <tbody> <tr class="c-report-timeline__row c-report-timeline__row--selected "> <th class=c-report-timeline__version> <a data-test-id=sidebar_timeline_v1_version href="https://f1000research.com/articles/8-765/v1">Version 1</a><br/> <span class=p-article__color--dark> <span data-test-id=sidebar_timeline_v1_date class=c-report-timeline__date>31 May 19</span> </span> </th> <td class="c-report-timeline__report c-report-timeline__cell "> <i class="c-icn--f1r-icon c-icn--approved small" title=Approved #data-refInfo=""></i> </td> <td class="c-report-timeline__report c-report-timeline__cell "> <i class="c-icn--f1r-icon c-icn--approved small" title=Approved #data-refInfo=""></i> </td> </tr> </tbody> </table> <div class=o-layout__item> <hr class="c-hr c-hr--low u-mb--2"> </div> </section> </div> <div class=o-layout__item> <div class="u-pl u-pr"> <p class="t-body u-mt--0 u-mb--2"><a href="/browse/faculty-reviews">Faculty Reviews</a> are review articles written by the prestigious Members of <a href="https://facultyopinions.com/prime/home" target=_blank class=in-text-link>Faculty Opinions</a>. The articles are commissioned and peer reviewed before publication to ensure that the final, published version is comprehensive and accessible. The reviewers who approved the final version are listed with their names and affiliations.</p> <ol class="p-article__faculty-referee-list t-caption"> <li> <p class=" u-mt--0 u-mb--1/2"><strong>Galia Avidan</strong>, Department Psychology, Ben-Gurion University of the Negev, Israel </p> <div class="c-read-more js-read-more " data-lines=3> <div class="c-read-more__content js-read-more-content "> <p class="u-mt--0 u-mb--0 p-article__color--light"> <strong class=u-weight--md>Competing interests:</strong> No competing interests were declared. </p> </div> <a href="#" class="c-read-more__toggle js-read-more-toggle t-caption"> <span class=c-read-more__expand>View more</span> <span class=c-read-more__contract>View less</span> </a> </div> </li> <li> <p class=" u-mt--0 u-mb--1/2"><strong>Richard Cook</strong>, Department of Psychological Sciences, Birkbeck, University of London, UK </p> <div class="c-read-more js-read-more " data-lines=3> <div class="c-read-more__content js-read-more-content "> <p class="u-mt--0 u-mb--0 p-article__color--light"> <strong class=u-weight--md>Competing interests:</strong> No competing interests were declared. </p> </div> <a href="#" class="c-read-more__toggle js-read-more-toggle t-caption"> <span class=c-read-more__expand>View more</span> <span class=c-read-more__contract>View less</span> </a> </div> </li> </ol> </div> </div> <section class="o-layout__item u-pl"> <div class=u-pl> <hr class="c-hr c-hr--low c-hr--md u-mb--3"> <h4 class="t-h3 u-weight--md u-mt--0 u-mb--2">Comments on this article</h4> <div class=u-mb--4> <p class="u-mt--0 u-mb--1 t-h4"><a class=p-article__color--light href="#article-comments">All Comments</a><span class=" u-ib u-ml--1/2 p-article__color--light">(0)</span></p> <a class=t-h4 href="/login?originalPath=/articles/8-765/v1&scrollTo=add-new-comment" data-test-id=add-comment>Add a comment</a> </div> <hr class="c-hr c-hr--low c-hr--md u-mb--4"> <div class="research-layout f1r-article-desk"> <div class="heading6 c-ribbon-wrapper c-ribbon-wrapper--etoc f1000research "> <div class=c-ribbon-wrapper__body>Sign up for content alerts</div> </div> </div> <div class="research-layout sidebar-sign-up-form f1r-article-desk u-mb--4 "> <form class=js-email-alert-signup action="#" method=POST data-email=tocAlertWeekly> <input type=hidden name=isUserLoggedIn class=js-email-alert-signup-logged-in value=N /> <input type=hidden name=userId class=js-email-alert-signup-user-id value=""/> <input type=hidden name=frequency class=js-email-alert-signup-frequency value=WEEKLY /> <div class="o-actions o-actions--middle"> <div class=o-actions__primary> <input type=email name=emailAddress class="form-input-field js-email-alert-signup-address u-1/1 u-bb" required=required placeholder=Email /> </div> <div class=o-actions__secondary> <div class="_mdl-layout u-ml--1/2"> <button class="mdl-button mdl-js-button mdl-button--colored mdl-button--small mdl-button--filled js-email-alert-signup-submit">Sign Up</button> </div> </div> </div> </form> <div id=sidebar-sign-up-message class="section-text js-email-alert-signup-msg is-hidden">You are now signed up to receive this alert</div> </div> <section class=js-terms-container> <hr class="c-hr c-hr--low c-hr--md u-mb--3"> <h4 class="t-h3 u-weight--md u-mt--0 u-mb--1">Browse by related subjects</h4> <div class="article-subcontainer article-subcontainer--sidebar"> <ul class=js-terms-list></ul> </div> </section> </div> </section> </div> </section> </div> <script src="/js/shared_scripts/modal-dialogue.js"></script> <script src="/js/shared_scripts/read-more.js"></script> <script src="/js/article/article-router.js"></script> <script src="/js/article/article-sidebar.js"></script> <script src="/js/referee/new/referee_helpers.js"></script> <script src="/js/article/article-column-toggle.js"></script> </div> </div> </div> </main> <input type=hidden id=_articleVersionUrl value="https://f1000research.com/articles/8-765/v1/"> <div class=research-help id=about-referee-status> <div class="research-layout research-help-content about-referee-status"> <span class="close-research-help dark-cross" title=Close></span> Alongside their report, reviewers assign a status to the article: <div class="cf research-help-row"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> <span class=research-help-text>Approved - the paper is scientifically sound in its current form and only minor, if any, improvements are suggested</span> </div> <div class="cf research-help-row"> <span class="f1r-icon icon-87_approved_reservations status-green smaller" title="Approved with Reservations"></span> <span class=research-help-text>Approved with reservations - A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </span> </div> <div class="cf research-help-row"> <span class="f1r-icon icon-88_not_approved status-red small" title="Not Approved"></span> <span class=research-help-text>Not approved - fundamental flaws in the paper seriously undermine the findings and conclusions</span> </div> </div> </div> <div id=datasets-info class=is-hidden> </div> <div class=article-interactive-content-container style="display: none;"> <a name=f-template class=n-a></a> <div class="interactive-content-wrapper padding-20"> <img src="" class=interactive-content-image title="Open the interactive image display"> <div class=interactive-content-title></div> <div class=interactive-content-text></div> <div class="f1r-article-desk interactive-content-ribbon" data-interactive-content-type=R-Script> <div class=interactive-content-label>Adjust parameters to alter display</div> <div class=interactive-content-button></div> </div> <div class="f1r-article-mobile mobile-interactive-note"> View on desktop for interactive features <img src="/img/icon/interactive_content.png" class="float-right margin-right-40"/> </div> <div class=clearfix></div> </div> </div> <div id=article-interactive-omero-container class=article-interactive-omero-container style="display: none;"> <div class=interactive-content-wrapper> <div class="interactive-omero-button omero-content" title="Open the interactive content window." data-interactive-content-type=Omero></div> <div class=has-interactive-content-image> <span class=box-arrow></span> <span class=box-middle>Includes Interactive Elements</span> <span class=box-end></span> </div> <div class="fig panel clearfix" style="margin: 0; padding-bottom: 20px;"> <a name=templatelink class=n-a></a> <a target=_blank href="" class=link-for-omero-image> <img src="" class=interactive-omero-image title="Open the image display window."> </a> <div class=caption> <div class=interactive-content-title></div> <div class=interactive-content-text></div> </div> <div class="is-hidden omero-image-list"></div> </div> <div class="f1r-article-mobile mobile-interactive-note omero"> View on desktop for interactive features <img src="/img/icon/interactive_content.png" class="float-right margin-right-40"/> </div> <div class=clearfix></div> </div> </div> <div class="add-comment-container shadow-box is-hidden" id=save-comment-container> <span id=save-comment-text class=intro-text>Edit comment</span> <textarea id=new-comment name=new-comment class="global-textarea comment margin-bottom margin-top"></textarea> <p><strong>Competing Interests</strong></p> <textarea id=new-competing-interests name=competing-interests class="global-textarea competing-interests margin-bottom check-xss"></textarea> <div class=clearfix></div> <button id=cancelComment type=button class="general-white-orange-button float-right no-background-button margin-left"> Cancel </button> <button id=save-comment-button commentId="" type=button class="general-white-orange-button float-right"> Save </button> <div class=clearfix></div> <div class="green-message margin-top is-hidden comment-is-saved">The comment has been saved.</div> <div class="red-message margin-top is-hidden comment-not-added">An error has occurred. Please try again.</div> <div class="red-message margin-top is-hidden comment-enter-text ucf">Your must enter a comment.</div> <div class="red-message margin-top is-hidden comment-references-error references">References error.</div> </div> <div class="modal-window-wrapper is-hidden"> <div id=conflicts-interests class="modal-window padding-20"> <div class=modal-window__content> <h2 class=h2-title>Competing Interests Policy</h2> <p> Provide sufficient details of any financial or non-financial competing interests to enable users to assess whether your comments might lead a reasonable person to question your impartiality. Consider the following examples, but note that this is not an exhaustive list: </p> <div class=heading5>Examples of 'Non-Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>Within the past 4 years, you have held joint grants, published or collaborated with any of the authors of the selected paper.</li> <li class=standard-padding>You have a close personal relationship (e.g. parent, spouse, sibling, or domestic partner) with any of the authors.</li> <li class=standard-padding>You are a close professional associate of any of the authors (e.g. scientific mentor, recent student).</li> <li class=standard-padding>You work at the same institute as any of the authors.</li> <li class=standard-padding>You hope/expect to benefit (e.g. favour or employment) as a result of your submission.</li> <li class=standard-padding>You are an Editor for the journal in which the article is published.</li> </ol> <div class="heading5 padding-top">Examples of 'Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>You expect to receive, or in the past 4 years have received, any of the following from any commercial organisation that may gain financially from your submission: a salary, fees, funding, reimbursements.</li> <li class=standard-padding>You expect to receive, or in the past 4 years have received, shared grant support or other funding with any of the authors.</li> <li class=standard-padding>You hold, or are currently applying for, any patents or significant stocks/shares relating to the subject matter of the paper you are commenting on.</li> </ol> </div> <div class="f1r-article-mobile research-layout"> <span class=modal-window-close-button></span> </div> </div> </div> <div class="o-modal c-email-alert-popup js-email-alert-popup is-hidden"> <div class="o-modal__body js-modal-body c-email-alert-popup__inner"> <h3 class=c-email-alert-popup__title>Stay Updated</h3> <p class=c-email-alert-popup__sub>Sign up for content alerts and receive a weekly or monthly email with all newly published articles</p> <p><a href="/register?originalPath=" class="c-email-alert-popup__lnk c-email-alert-popup__button js-email-alert-popup-action">Register with F1000Research</a></p> <p>Already registered? <a href="/login?originalPath=" class="c-email-alert-popup__lnk js-email-alert-popup-action">Sign in</a></p> <p class=c-email-alert-popup__footer><a class="c-email-alert-popup__lnk js-email-alert-popup-cancel" href="#">Not now, thanks</a></p> </div> </div> <div id=addCommentModal role=dialog aria-labelledby=addCommentModal_title aria-describedby=addCommentModal_description> <div class="c-modal js-modal is-closed p-article__add-comment-modal c-modal--xlarge js-article-comment-modal c-modal--scroll "> <aside class="c-modal__content u-black--high o-box u-pb--0 u-bg--2 c-modal--scroll-always "> <div class=c-modal__close> <button type=button class="c-button c-button--icon c-button--medium c-button--full@hover js-modal__close"><i class="c-button--icon__icon material-icons">close</i></button> </div> <div id=addCommentModal_description class="c-modal__description js-modal__content t-h4 u-mt--0 u-mb--2 u-black--medium"> <div class="js-add-comment-container t-caption u-black--high"> <div class=u-weight--bd>PLEASE NOTE</div> <div class=u-mt--1> <span class="red u-weight--bd">If you are an AUTHOR of this article,</span> please check that you signed in with the account associated with this article otherwise we cannot automatically identify your role as an author and your comment will be labelled as a &ldquo;User Comment&rdquo;. </div> <div class=u-mt--1> <span class="red u-weight--bd">If you are a REVIEWER of this article,</span> please check that you have signed in with the account associated with this article and then go to your <a href="/my/referee">account</a> to submit your report, please do not post your review here. </div> <div class="u-mt--1 u-mb--1"> If you do not have access to your original account, please <a href="mailto:research@f1000.com">contact us</a>. </div> <p class=no-top-margin>All commenters must hold a formal affiliation as per our <a href="/about/policies#commentspolicy" target=_blank>Policies</a>. The information that you give us will be displayed next to your comment.</p> <p>User comments must be in English, comprehensible and relevant to the article under discussion. We reserve the right to remove any comments that we consider to be inappropriate, offensive or otherwise in breach of the <a href="/about/legal/usercommenttermsandconditions" target=_blank>User Comment Terms and Conditions</a>. Commenters must not use a comment for personal attacks. When criticisms of the article are based on unpublished data, the data should be made available.</p> <div class="comments-note margin-bottom" id=accept-user-comments> <input class=js-add-comment-accept-terms type=checkbox id=acceptedTermsAndConditions name=acceptedTermsAndConditions> I accept the <a href="/about/legal/usercommenttermsandconditions" target=_blank> User Comment Terms and Conditions</a> <span class=required>&nbsp;</span> </div> <div class="default-error margin-top is-hidden comment-accept-conditions utac">Please confirm that you accept the User Comment Terms and Conditions.</div> <div class="research-layout registration-form u-mb--2"> <div class="u-mb--1 u-mt--2"> <strong>Affiliation</strong> </div> <div class=form-field> <input type=text name=institution class="form-input-field check-xss js-add-comment-institution" placeholder="Organization *" autocomplete=off /> <div class="default-error margin-top is-hidden comment-enter-institution institution">Please enter your organisation.</div> </div> <div class=form-field> <input type=text name=place class="form-input-field check-xss js-add-comment-place" placeholder=Place> </div> <div class=form-field> <div class="form-input-wrapper hundred-percent-wide"> <div class="new-select-standard-wrapper half-width inline-display heading10"> <select name=countryId id=country class="form-select-menu smaller js-add-comment-country"> <option value=-1>Country*</option> <option value=840>USA</option> <option value=826>UK</option> <option value=124>Canada</option> <option value=156>China</option> <option value=250>France</option> <option value=276>Germany</option> <optgroup label=-----------------------------------------------></optgroup> <option value=4>Afghanistan</option> <option value=248>Aland Islands</option> <option value=8>Albania</option> <option value=12>Algeria</option> <option value=16>American Samoa</option> <option value=20>Andorra</option> <option value=24>Angola</option> <option value=660>Anguilla</option> <option value=10>Antarctica</option> <option value=28>Antigua and Barbuda</option> <option value=32>Argentina</option> <option value=51>Armenia</option> <option value=533>Aruba</option> <option value=36>Australia</option> <option value=40>Austria</option> <option value=31>Azerbaijan</option> <option value=44>Bahamas</option> <option value=48>Bahrain</option> <option value=50>Bangladesh</option> <option value=52>Barbados</option> <option value=112>Belarus</option> <option value=56>Belgium</option> <option value=84>Belize</option> <option value=204>Benin</option> <option value=60>Bermuda</option> <option value=64>Bhutan</option> <option value=68>Bolivia</option> <option value=70>Bosnia and Herzegovina</option> <option value=72>Botswana</option> <option value=74>Bouvet Island</option> <option value=76>Brazil</option> <option value=86>British Indian Ocean Territory</option> <option value=92>British Virgin Islands</option> <option value=96>Brunei</option> <option value=100>Bulgaria</option> <option value=854>Burkina Faso</option> <option value=108>Burundi</option> <option value=116>Cambodia</option> <option value=120>Cameroon</option> <option value=124>Canada</option> <option value=132>Cape Verde</option> <option value=136>Cayman Islands</option> <option value=140>Central African Republic</option> <option value=148>Chad</option> <option value=152>Chile</option> <option value=156>China</option> <option value=162>Christmas Island</option> <option value=166>Cocos (Keeling) Islands</option> <option value=170>Colombia</option> <option value=174>Comoros</option> <option value=178>Congo</option> <option value=184>Cook Islands</option> <option value=188>Costa Rica</option> <option value=384>Cote d'Ivoire</option> <option value=191>Croatia</option> <option value=192>Cuba</option> <option value=196>Cyprus</option> <option value=203>Czech Republic</option> <option value=180>Democratic Republic of the Congo</option> <option value=208>Denmark</option> <option value=262>Djibouti</option> <option value=212>Dominica</option> <option value=214>Dominican Republic</option> <option value=218>Ecuador</option> <option value=818>Egypt</option> <option value=222>El Salvador</option> <option value=226>Equatorial Guinea</option> <option value=232>Eritrea</option> <option value=233>Estonia</option> <option value=231>Ethiopia</option> <option value=238>Falkland Islands</option> <option value=234>Faroe Islands</option> <option value=583>Federated States of Micronesia</option> <option value=242>Fiji</option> <option value=246>Finland</option> <option value=250>France</option> <option value=254>French Guiana</option> <option value=258>French Polynesia</option> <option value=260>French Southern Territories</option> <option value=266>Gabon</option> <option value=268>Georgia</option> <option value=276>Germany</option> <option value=288>Ghana</option> <option value=292>Gibraltar</option> <option value=300>Greece</option> <option value=304>Greenland</option> <option value=308>Grenada</option> <option value=312>Guadeloupe</option> <option value=316>Guam</option> <option value=320>Guatemala</option> <option value=831>Guernsey</option> <option value=324>Guinea</option> <option value=624>Guinea-Bissau</option> <option value=328>Guyana</option> <option value=332>Haiti</option> <option value=334>Heard Island and Mcdonald Islands</option> <option value=336>Holy See (Vatican City State)</option> <option value=340>Honduras</option> <option value=344>Hong Kong</option> <option value=348>Hungary</option> <option value=352>Iceland</option> <option value=356>India</option> <option value=360>Indonesia</option> <option value=364>Iran</option> <option value=368>Iraq</option> <option value=372>Ireland</option> <option value=376>Israel</option> <option value=380>Italy</option> <option value=388>Jamaica</option> <option value=392>Japan</option> <option value=832>Jersey</option> <option value=400>Jordan</option> <option value=398>Kazakhstan</option> <option value=404>Kenya</option> <option value=296>Kiribati</option> <option value=901>Kosovo (Serbia and Montenegro)</option> <option value=414>Kuwait</option> <option value=417>Kyrgyzstan</option> <option value=418>Lao People's Democratic Republic</option> <option value=428>Latvia</option> <option value=422>Lebanon</option> <option value=426>Lesotho</option> <option value=430>Liberia</option> <option value=434>Libya</option> <option value=438>Liechtenstein</option> <option value=440>Lithuania</option> <option value=442>Luxembourg</option> <option value=446>Macao</option> <option value=807>Macedonia</option> <option value=450>Madagascar</option> <option value=454>Malawi</option> <option value=458>Malaysia</option> <option value=462>Maldives</option> <option value=466>Mali</option> <option value=470>Malta</option> <option value=584>Marshall Islands</option> <option value=474>Martinique</option> <option value=478>Mauritania</option> <option value=480>Mauritius</option> <option value=175>Mayotte</option> <option value=484>Mexico</option> <option value=581>Minor Outlying Islands of the United States</option> <option value=498>Moldova</option> <option value=492>Monaco</option> <option value=496>Mongolia</option> <option value=499>Montenegro</option> <option value=500>Montserrat</option> <option value=504>Morocco</option> <option value=508>Mozambique</option> <option value=104>Myanmar</option> <option value=516>Namibia</option> <option value=520>Nauru</option> <option value=524>Nepal</option> <option value=530>Netherlands Antilles</option> <option value=540>New Caledonia</option> <option value=554>New Zealand</option> <option value=558>Nicaragua</option> <option value=562>Niger</option> <option value=566>Nigeria</option> <option value=570>Niue</option> <option value=574>Norfolk Island</option> <option value=580>Northern Mariana Islands</option> <option value=408>North Korea</option> <option value=578>Norway</option> <option value=512>Oman</option> <option value=586>Pakistan</option> <option value=585>Palau</option> <option value=275>Palestinian Territory</option> <option value=591>Panama</option> <option value=598>Papua New Guinea</option> <option value=600>Paraguay</option> <option value=604>Peru</option> <option value=608>Philippines</option> <option value=612>Pitcairn</option> <option value=616>Poland</option> <option value=620>Portugal</option> <option value=630>Puerto Rico</option> <option value=634>Qatar</option> <option value=638>Reunion</option> <option value=642>Romania</option> <option value=643>Russian Federation</option> <option value=646>Rwanda</option> <option value=654>Saint Helena</option> <option value=659>Saint Kitts and Nevis</option> <option value=662>Saint Lucia</option> <option value=666>Saint Pierre and Miquelon</option> <option value=670>Saint Vincent and the Grenadines</option> <option value=882>Samoa</option> <option value=674>San Marino</option> <option value=678>Sao Tome and Principe</option> <option value=682>Saudi Arabia</option> <option value=686>Senegal</option> <option value=688>Serbia</option> <option value=690>Seychelles</option> <option value=694>Sierra Leone</option> <option value=702>Singapore</option> <option value=703>Slovakia</option> <option value=705>Slovenia</option> <option value=90>Solomon Islands</option> <option value=706>Somalia</option> <option value=710>South Africa</option> <option value=239>South Georgia and the South Sandwich Is</option> <option value=410>South Korea</option> <option value=724>Spain</option> <option value=144>Sri Lanka</option> <option value=736>Sudan</option> <option value=740>Suriname</option> <option value=744>Svalbard and Jan Mayen</option> <option value=748>Swaziland</option> <option value=752>Sweden</option> <option value=756>Switzerland</option> <option value=760>Syria</option> <option value=158>Taiwan</option> <option value=762>Tajikistan</option> <option value=834>Tanzania</option> <option value=764>Thailand</option> <option value=270>The Gambia</option> <option value=528>The Netherlands</option> <option value=626>Timor-Leste</option> <option value=768>Togo</option> <option value=772>Tokelau</option> <option value=776>Tonga</option> <option value=780>Trinidad and Tobago</option> <option value=788>Tunisia</option> <option value=792>Turkey</option> <option value=795>Turkmenistan</option> <option value=796>Turks and Caicos Islands</option> <option value=798>Tuvalu</option> <option value=800>Uganda</option> <option value=826>UK</option> <option value=804>Ukraine</option> <option value=784>United Arab Emirates</option> <option value=850>United States Virgin Islands</option> <option value=858>Uruguay</option> <option value=840>USA</option> <option value=860>Uzbekistan</option> <option value=548>Vanuatu</option> <option value=862>Venezuela</option> <option value=704>Vietnam</option> <option value=876>Wallis and Futuna</option> <option value=905>West Bank and Gaza Strip</option> <option value=732>Western Sahara</option> <option value=887>Yemen</option> <option value=894>Zambia</option> <option value=716>Zimbabwe</option> </select> </div> </div> <div class="default-error margin-top is-hidden comment-enter-country country">Please select your country.</div> </div> </div> <textarea data-test-id=article_add-comment_comment name=new-comment class="js-add-comment-comment comment margin-bottom margin-top"></textarea> <div class="default-error margin-top comment-enter-text comment-error is-hidden ">You must enter a comment.</div> <label class="comments-note u-mt--2 u-mb--2" for=competingInterests_1> <div class="u-mb--1 u-mt--2"><strong data-test-id=article_report-add-comment_competing-interests-title>Competing Interests</strong></div> <p class="u-mb--2 u-mt--0" data-test-id=article_report-add-comment_competing-interests-description>Please disclose any <a href="#article-competing-intersts-policy" class=js-modal-competing-intersts-toggle>competing interests</a> that might be construed to influence your judgment of the article's or peer review report's validity or importance.</p> </label> <div id=article-competing-intersts-policy class=js-article-competing-interests-policy style="display: none;"> <h2 class="h2-title u-mt--0 u-pt--0">Competing Interests Policy</h2> <p> Provide sufficient details of any financial or non-financial competing interests to enable users to assess whether your comments might lead a reasonable person to question your impartiality. Consider the following examples, but note that this is not an exhaustive list: </p> <div class=heading5>Examples of 'Non-Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>Within the past 4 years, you have held joint grants, published or collaborated with any of the authors of the selected paper.</li> <li class=standard-padding>You have a close personal relationship (e.g. parent, spouse, sibling, or domestic partner) with any of the authors.</li> <li class=standard-padding>You are a close professional associate of any of the authors (e.g. scientific mentor, recent student).</li> <li class=standard-padding>You work at the same institute as any of the authors.</li> <li class=standard-padding>You hope/expect to benefit (e.g. favour or employment) as a result of your submission.</li> <li class=standard-padding>You are an Editor for the journal in which the article is published.</li> </ol> <div class="heading5 padding-top">Examples of 'Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>You expect to receive, or in the past 4 years have received, any of the following from any commercial organisation that may gain financially from your submission: a salary, fees, funding, reimbursements.</li> <li class=standard-padding>You expect to receive, or in the past 4 years have received, shared grant support or other funding with any of the authors.</li> <li class=standard-padding>You hold, or are currently applying for, any patents or significant stocks/shares relating to the subject matter of the paper you are commenting on.</li> </ol> </div> <div id=competingInterests_1 class="c-inline-editor js-inline-editor js-form_input u-bb--all u-mb--2 js-comment-competing-interests" data-name=competing-interests data-rows=3> <textarea id=competingInterests_1_input name=competing-interests placeholder="&nbsp;" required=false class="u-hide-visually js-inline-editor_input" tabindex=-1></textarea> <div class="c-inline-editor__editor js-inline-editor_editor o-box c-box o-box--tiny u-bg--11" data-target=competingInterests_1_input role=textbox required=false data-placeholder="&nbsp;" contenteditable=true></div> <span class="c-inline-editor__error js-inline-editor-message">Please state your competing interests</span> </div> <div data-test-id=article_add-comment_saved class="green-message comments is-hidden comment-is-saved">The comment has been saved.</div> <div data-test-id=article_add-comment_error class="default-error comments is-hidden comment-not-added">An error has occurred. Please try again.</div> <div class=clearfix></div> <div class=js-hook></div> </div> <div class="c-modal__extra-message js-modal__extra-message t-h4 u-black--medium"></div></div> <div class="c-modal__actions o-box__actions"> <a href="#" data-test-id=article_add-comment_cancel class="c-button c-button--full js-modal__close c-button--secondary">Cancel</a> <a href="#" data-test-id=article_add-comment_post class="c-button c-button--full js-modal__confirm c-button--primary">Post</a> </div> </aside> </div> </div> <style>
                .at-icon-wrapper {
        background-size: 100% !important;
    }
</style> <script src="/js/namespace.js"></script> <script src="/js/constants.js"></script> <script src="/js/utilities.js"></script> <script src="/js/article/alert-signup.js"></script> <script type='text/javascript'>
    var lTitle = "Progress in perceptual research: the case...".replace("'", '');
    var linkedInUrl = "http://www.linkedin.com/shareArticle?url=https://f1000research.com/articles/8-765/v1" + "&title=" + encodeURIComponent(lTitle) + "&summary=" + encodeURIComponent('Read the article by ');

    var deliciousUrl = "https://del.icio.us/post?url=https://f1000research.com/articles/8-765/v1&title=" + encodeURIComponent(lTitle);

    var redditUrl = "http://reddit.com/submit?url=https://f1000research.com/articles/8-765/v1" + "&title=" + encodeURIComponent(lTitle);

            linkedInUrl += encodeURIComponent('Albonico A and Barton J');
    
    var offsetTop = /chrome/i.test( navigator.userAgent ) ? 4 : -10; 
    var addthis_config = {
            ui_offset_top: offsetTop,
                                    services_compact : "facebook,twitter,www.linkedin.com,www.mendeley.com,reddit.com",
            services_expanded : "facebook,twitter,www.linkedin.com,www.mendeley.com,reddit.com",
            services_custom : [
                {
                    name: "LinkedIn",
                    url:  linkedInUrl,
                    icon:"/img/icon/at_linkedin.svg"
                },
                {
                    name: "Mendeley",
                    url:  "http://www.mendeley.com/import/?url=https://f1000research.com/articles/8-765/v1/mendeley",
                    icon:"/img/icon/at_mendeley.svg"
                },
                {
                    name: "Reddit",
                    url:  redditUrl,
                    icon:"/img/icon/at_reddit.svg"
                },
            ]
        };


    var addthis_share = {
            url: "https://f1000research.com/articles/8-765",
            templates : {
                twitter : "Progress in perceptual research: the case of prosopagnosia. Albonico A and Barton J, published by " + 
               "@F1000Research"
       + ", https://f1000research.com/articles/8-765/v1"
            }
        };

    if (typeof(addthis) != "undefined"){
        addthis.addEventListener('addthis.ready', checkCount);
        addthis.addEventListener('addthis.menu.share', checkCount);
    }

        $(".f1r-shares-twitter").attr("href", "https://twitter.com/intent/tweet?text=" + addthis_share.templates.twitter);
    $(".f1r-shares-facebook").attr("href", "https://www.facebook.com/sharer/sharer.php?u=" + addthis_share.url);
    $(".f1r-shares-linkedin").attr("href", addthis_config.services_custom[0].url);
    $(".f1r-shares-reddit").attr("href", addthis_config.services_custom[2].url);
    $(".f1r-shares-mendelay").attr("href", addthis_config.services_custom[1].url);

    function checkCount(){
        setTimeout(function(){
            $(".addthis_button_expanded").each(function(){
                var count = $(this).text();
                if (count !== "" && count != "0")
                    $(this).removeClass("is-hidden");
                else
                    $(this).addClass("is-hidden");
            });
        }, 1000);
    }
</script> <div id=citeReportModal role=dialog aria-labelledby=citeReportModal_title aria-describedby=citeReportModal_description> <div class="c-modal js-modal is-closed c-modal--large js-cite-report-modal "> <aside class="c-modal__content u-black--high o-box u-pb--0 u-black--high "> <div class=c-modal__close> <button type=button class="c-button c-button--icon c-button--medium c-button--full@hover js-modal__close"><i class="c-button--icon__icon material-icons">close</i></button> </div> <h1 id=citeReportModal_title class="c-modal__title t-h3 u-mt--0 u-mb--2 u-weight--md">How to cite this report</h1> <div id=citeReportModal_description class="c-modal__description js-modal__content t-h4 u-mt--0 u-mb--2 u-black--medium"> <div id="" class=js-report-citation-container>{{reportCitation}}</div> <div class="c-modal__extra-message js-modal__extra-message t-h4 u-black--medium"></div></div> <div class="c-modal__actions o-box__actions"> <a href="#" class="c-button c-button--full js-modal__close c-button--secondary">Cancel</a> <a href="#" title="Copy the current citation details to the clipboard." data-clipboard-target="#referee-report-citation" data-test-id=report_copy-citation_button class="c-button c-button--full js-modal__confirm c-button--primary js-clipboard c-mini-tooltip--above">Copy Citation Details</a> </div> </aside> </div> </div> <script src="/js/referee/new/referee_validators.js"></script> <script src="/js/referee/new/referee_helpers.js"></script> <script src="/js/referee/new/referee_checkbox-input.js"></script> <script src="/js/referee/new/referee_inline-editor.js"></script> <script type="text/javascript">
    $(function(){
        var gaCat = "F1000Research";
        if (gaCat === "") {
            gaCat = $("body").hasClass("wellcome-brand") ? "Wellcome Open Research" : "F1000Research";
        }
        GAHelper.track({category: gaCat, action: "Article Page: Progress in perceptual research: the case of prosopagnosia", label: "pageviews"});
        GAHelper.track({category: gaCat, action: "Article Type: Review", label: "Article Page"});
        $(".f1r-article-desk .collection-image").each(function (idx, el) {
            var whatChannel = $(el).find("a").attr("href"),
                channelName = $.trim($(el).parent().find(".collection-detail a").text()),
                gaRef = "(ID: " + whatChannel.replace("/collections/", "") + ") " + channelName;
            GAHelper.track({category: 'ChannelStats', action: "Article Page: Progress in perceptual research: the case of prosopagnosia", label: gaRef});
        });
    });
</script> <script>
    $(function(){R.ui.buttonDropdowns('.dropdown-for-downloads');});
    $(function(){R.ui.toolbarDropdowns('.toolbar-dropdown-for-downloads');});
</script> <script src="/js/article/track_article.js" type="text/javascript"></script> <script type="text/javascript">
    $.get("/articles/acj/18492/20234")
</script> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script type="text/javascript" src="/js/app/messenger.js"></script> <script type="text/javascript" src="/js/article/article_mobiles.js"></script> <script src="/js/vendor/clipboard.min.js"></script> <script src="/js/shared_scripts/modal-dialogue.js"></script> <script src="/js/shared_scripts/clipboard.js"></script> <script src="/js/article/thesaurus-terms-display.js"></script> <script>
    new F1000.Clipboard();
    new F1000.ThesaurusTermsDisplay("faculty-reviews", "article", "20234");
</script> <script>
    $(document).ready(function() {
        $( "#frame1" ).on('load', function() {
            var mydiv = $(this).contents().find("div");
            var h     = mydiv.height();
            console.log(h)
        });

        
        var tooltipLivingFigure = jQuery(".interactive-living-figure-label .icon-more-info"),
            titleLivingFigure = tooltipLivingFigure.attr("title");
        tooltipLivingFigure.simpletip({
            fixed: true,
            position: ["-115", "30"],
            baseClass: 'small-tooltip',
            content:titleLivingFigure + "<div class='tooltip-arrow'></div>"
        });
        tooltipLivingFigure.removeAttr("title");

        $("body").on("click", ".cite-living-figure", function(e) {
            e.preventDefault();
            var ref = $(this).attr("data-ref");
            $(this).closest(".living-figure-list-container").find("#" + ref).fadeIn(200);
        });
        $("body").on("click", ".close-cite-living-figure", function(e) {
            e.preventDefault();
            $(this).closest(".popup-window-wrapper").fadeOut(200);
        });

                $(document).on("mouseup", function(e) {
            var metricsContainer = $(".article-metrics-popover-wrapper");
            if (!metricsContainer.is(e.target) && metricsContainer.has(e.target).length === 0) {
                $(".article-metrics-close-button").click();
            }
        });

        var articleId = $('#articleId').val();

        if($("#main-article-count-box").attachArticleMetrics) {
            $("#main-article-count-box").attachArticleMetrics(articleId, {
                articleMetricsView: true
            });
        }
    });

    var figshareWidget = $(".new_figshare_widget");
    if (figshareWidget.length > 0) {
        window.figshare.load("f1000", function(Widget) {
            // Select a tag/tags defined in your page. In this tag we will place the widget.
            _.map(figshareWidget, function(el){
                var widget = new Widget({
                    articleId: $(el).attr("figshare_articleId")
                    //height:300 // this is the height of the viewer part. [Default: 550]
                });
                widget.initialize(); // initialize the widget
                widget.mount(el); // mount it in a tag that's on your page
                // this will save the widget on the global scope for later use from
                // your JS scripts. This line is optional.
                //window.widget = widget;
            });
        });
    }
</script>

<script>
    $(document).ready(function () {

        
        var reportIds = {
                           "48967": 1,
                           "48968": 0,
                    };

        $(".referee-response-container,.js-referee-report").each(function(index, el) {
            var reportId = $(el).attr("data-reportid"),
                reportCount = reportIds[reportId] || 0;
            $(el).find(".comments-count-container,.js-referee-report-views").html(reportCount);
        });

        var uuidInput = $("#article_uuid"),
            oldUUId = uuidInput.val(),
            newUUId = "ce4340d2-05f1-406c-acc7-a88a204e8f9c";
        uuidInput.val(newUUId);

        $("a[href*='article_uuid=']").each(function(index, el) {
            var newHref = $(el).attr("href").replace(oldUUId, newUUId);
            $(el).attr("href", newHref);
        });

    });
</script>              </div>
        </div>

        
            
            <div class="o-page__footer sticky-email-wrapper">
                
                

                


<footer class="c-footer t-inverted">

    <div class="o-wrapper">
        <div class="o-layout">


                        
            <div class="o-layout__item u-mb--3">
                <div class="c-branding c-branding--research">
                    <img src="/img/research/F1000Research_white.svg" alt="F1000Research">
                </div>
            </div>


                        
            <div class="o-layout__item u-1/3@md u-mb--3">

                <span class="c-hr c-hr--thick c-hr--low u-mb--2"></span>

                <p class="t-h3 u-mt--0 u-mb--0">An innovative open access publishing platform offering rapid publication and open peer review, whilst supporting data deposition and sharing.</p>

            </div>


                        
            <div class="o-layout__item u-2/3@md">

                <span class="c-hr c-hr--thick c-hr--low u-mb--2"></span>

                <div class="o-layout">
                    <nav class="c-footer__nav">

                            <div class="o-layout__item u-3/5@sm u-mb--3">


                                <div class="o-columns o-columns--2">

                                                                            <a href="/browse/articles" class="t-body c-footer__nav-item "      >Browse</a>
                                                                            <a href="/gateways" class="t-body c-footer__nav-item "      >Gateways</a>
                                                                            <a href="/collections" class="t-body c-footer__nav-item "      >Collections</a>
                                                                            <a href="/about" class="t-body c-footer__nav-item "      >How it Works</a>
                                                                            <a href="https://blog.f1000.com/blogs/f1000research/" class="t-body c-footer__nav-item "      >Blog</a>
                                                                            <a href="/contact" class="t-body c-footer__nav-item "      >Contact</a>
                                                                            <a href="/developers" class="t-body c-footer__nav-item u-hide u-show@navbar"      >For Developers</a>
                                                                            <a href="/published/rss" class="t-body c-footer__nav-item "   title="RSS feed of published articles"     >RSS</a>
                                    
                                </div>

                            </div>

                            <div class="o-layout__item u-2/5@sm u-center u-right@sm u-mb--3">

                                <div class="u-hide u-show@lg">
                                    <div class="_mdl-layout">
                                        <a class="mdl-button mdl-js-button mdl-button--inverted mdl-button--no-shadow mdl-js-ripple-effect mdl-button--outline" href="/for-authors/publish-your-research"   data-test-id="footer_submit_research"  >Submit Your Research</a>
                                    </div>
                                </div>

                            </div>

                    </nav>
                </div>

            </div>

            <div class="o-layout__item u-mb--2">
                <div class="c-footer__share">
                        <div class="c-footer__share">
        <span class="c-footer__share-icon" title="Open Access">
            <span class="f1r-icon icon-100_open_access license-icon"></span>
        </span>

        <a class="c-footer__share-icon" href="//creativecommons.org/licenses" target="_blank" title="Creative Commons License CC-BY">
            <span class="f1r-icon icon-116_cc license-icon license-icon-cc"></span>
            <span class="f1r-icon icon-117_ccby license-icon license-icon-cc"></span>
        </a>

        <a class="c-footer__share-icon" href="//creativecommons.org/about/cc0" target="_blank" title="Creative Commons License CC0">
            <span class="f1r-icon icon-118_cco license-icon"></span>
        </a>

    </div>
                </div>
            </div>


                        
            <div class="o-layout__item u-1/3@md u-mb--3">

                <span class="c-hr c-hr--low u-mb--3"></span>

                <p class="c-footer__social u-mt--0 u-mb--0 u-white--low-med">Follow us
                    <a href="https://www.facebook.com/F1000" target="_blank" class="c-footer__social-icon f1r-icon icon-55_footer_facebook"></a>
                    <a href="https://twitter.com/#!/F1000Research" target="_blank" class="c-footer__social-icon f1r-icon icon-56_footer_twitter"></a>
                    <a href="http://www.youtube.com/user/F1000research" target="_blank" class="c-footer__social-icon f1r-icon icon-57_footer_youtube"></a></p>

            </div>


                        
            <div class="o-layout__item u-2/3@md u-right@md">

                <span class="c-hr c-hr--low u-mb--3"></span>

                <p class="t-caption u-white--low-med">&copy; 2012-2020 F1000 Research Ltd. ISSN 2046-1402 | <a href="/about/legal" class="copyrightLegal">Legal</a> | Partner of <a target="_blank" href="http://www.who.int/hinari/en/">HINARI</a>  &bull; <a target="_blank" href="http://crossref.org/">CrossRef</a> &bull; <a target="_blank" href="http://about.orcid.org/">ORCID</a> &bull; <a target="_blank" href="http://www.fairsharing.org">FAIRSharing</a></p>

            </div>
        </div>
    </div>

</footer>            </div>
        
    </div>

            <div class="js-cookie-spacer"></div>
        <div class="cookie-warning">
            <div class="instruction">The F1000Research website uses cookies. By continuing to browse the site, you are agreeing to our use of cookies. <a class="js-scroll-to" href="/about/legal/privacypolicy#use-of-cookies" data-scroll-target="#use-of-cookies">Find out more &raquo;</a></div>
            <div class="close-button"></div>
        </div>
    
    <script>
                    R.templateTests.simpleTemplate = R.template('<p class="$variable.one">$text</p><p class="${variable.two}">$text</p><p class="$!variable.three">$text</p><p class="$!{variable.four}">$text</p><p class="${selector}.five">$text</p>');
            R.templateTests.runTests();
        
        var F1000platform = new F1000.Platform({
            name: "f1000research",
            displayName: "F1000Research",
            hostName: "f1000research.com",
            id: "1",
            editorialEmail: "research@f1000.com",
            infoEmail: "info@f1000.com",
            usePmcStats: true
        });

                    $(function(){R.ui.dropdowns('.dropdown-for-authors, .dropdown-for-about, .dropdown-for-myresearch');});
            // $(function(){R.ui.dropdowns('.dropdown-for-referees');});

            $(document).ready(function () {
                if ($(".cookie-warning").is(":visible")) {
                    $(".sticky").css("margin-bottom", "35px");
                    $(".devices").addClass("devices-and-cookie-warning");
                }
                $(".cookie-warning .close-button").click(function (e) {
                    $(".devices").removeClass("devices-and-cookie-warning");
                    $(".sticky").css("margin-bottom", "0");
                });

                $("#tweeter-feed .tweet-message").each(function (i, message) {
                    var self = $(message);
                    self.html(linkify(self.html()));
                });

                $(".partner").on("mouseenter mouseleave", function() {
                    $(this).find(".gray-scale, .colour").toggleClass("is-hidden");
                });
            });
        
    </script>

            
<div class="sign-in-popup">
	<!-- <a href="#" class="sign-in shadow">Sign in <span class="sign-in-image-active"></span></a> -->
	<a href="#" class="sign-in ${locale}">Sign In <span class="arrow-closed sign-in-arrow-padding arrow-opened"></span></a>
	<div class="sign-in-form">

            <form action="https://f1000research.com/j_spring_oauth_security_check" id="googleOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/8-765.html"/>
                            <input id="google-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-google" name="system" type="hidden" value="GOOGLE"/>
    </form>
            <form action="https://f1000research.com/j_spring_oauth_security_check" id="facebookOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/8-765.html"/>
                            <input id="facebook-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-fb" name="system" type="hidden" value="FACEBOOK"/>
    </form>
            <form action="https://f1000research.com/j_spring_oauth_security_check" id="orcidOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/8-765.html"/>
                            <input id="orcid-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-orcid" name="system" type="hidden" value="ORCID"/>
    </form>
		<form id="sign-in-form" class="login-container" action="https://f1000research.com/login" method="post" name="f">
           <div id="sign-in-form-gfb-popup"></div>

                                                            <input class="target-field" type="hidden" name="target" value="/articles/8-765.html"/>
                            			<input type="text" name="username" id="signin-email-box" class="sign-in-input" placeholder="Email address" autocomplete="email">
			<input type="password" name="password" id="signin-password-box" class="sign-in-input" placeholder="Password" autocomplete="current-password">
			<div class="sign-in-remember">
                <div class="checkbox-wrapper">
    				<input type="checkbox" id="remember-me" name="remember_me" class="checkbox is-hidden">
                </div>
                <span class="checkbox-label">Remember me</span>
			</div>
			<a href="#" class="sign-in-link" id="forgot-password-link">Forgotten your password?</a>
			<div class="sign-in-button-container margin-top margin-left-20 margin-bottom">
				<button type="submit" id="sign-in-button" class="sign-in-buttons general-white-orange-button">Sign In</button>
				<button type="button" id="sign-in-cancel" class="sign-in-buttons sign-in-cancel-button margin-left">Cancel</button>
				<div class="clearfix"></div>
			</div>
			<div class="sign-in-error">Email or password not correct. Please try again</div>
			<div class="sign-in-loading">Please wait...</div>
		</form>
		<div class="forgot-password-container">
			
<script type="text/javascript">
	$(function(){
		// Note: All the setup needs to run against a name attribute and *not* the id due the clonish
		// nature of facebox...
		$("a[id=googleSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("GOOGLE");
            $("form[id=oAuthForm]").submit();
        });
        $("a[id=facebookSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("FACEBOOK");
            $("form[id=oAuthForm]").submit();
        });
        $("a[id=orcidSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("ORCID");
            $("form[id=oAuthForm]").submit();
        });
	});
</script>

<span class="text first">
	If you've forgotten your password, please enter your email address below and we'll send you instructions on how to reset your password.
    <p>The email address should be the one you originally registered with F1000.</p>
</span>
<input name="email" class="sign-in-input" id="email-forgot-password" type="text" placeholder="Email address">
<div class="forgot-password-email-error">
	Email address not valid, please try again
</div>
<div class="forgot-password-google-email-error">
    <p>You registered with F1000 via Google, so we cannot reset your password.</p>
	<p>To sign in, please click <a href="#" id="googleSignInButton">here</a>.</p>
    <p>If you still need help with your Google account password, please click <a href="https://www.google.com/accounts/recovery">here</a>.</p>
</div>
<div class="forgot-password-facebook-email-error">
    <p>You registered with F1000 via Facebook, so we cannot reset your password.</p>
    <p>To sign in, please click <a href="#" id="facebookSignInButton">here</a>.</p>
	<p>If you still need help with your Facebook account password, please click <a href="https://www.facebook.com/recover/initiate">here</a>.</p>
</div>
<div class="clearfix"></div>
<div class="forgot-password-captcha-error">
	Code not correct, please try again
</div>
<div class="clearfix"></div>
<div class="sign-in-button-container margin-left-20 margin-bottom">
	<button type="button" id="sign-in-reset-password" class="sign-in-buttons general-white-orange-button">Reset password</button>
	<button type="button" id="forgot-password-cancel" class="sign-in-buttons sign-in-cancel-button margin-left">Cancel</button>
	<div class="clearfix"></div>
</div>
<span class="text last">
	<a href="mailto:">Email us</a> for further assistance.
</span>
<form action="https://f1000research.com/j_spring_oauth_security_check" id="oAuthForm" method="post" target="_top">
                        <input class="target-field" type="hidden" name="target" value="/articles/8-765.html"/>
                <input id="oAuthSystem" name="system" type="hidden"/>
</form>
			<div class="forgot-password-server-error">Server error, please try again.</div>
			<div class="sign-in-success">
                <p>We have sent an email to <span id="email-value"></span>, please follow the instructions to reset your password.</p>
                <p>If you don't receive this email, please check your spam filters and/or contact .</p>
            </div>
			<div class="sign-in-loading">Please wait...</div>
		</div>

		<div class="sign-in-form-register-section">
			<div class="sign-in-button-container margin-left-20 margin-bottom">
				<a href="/register" title="Register"><button type="button" id="sign-in-register-button" class="sign-in-buttons general-white-orange-button">Register</button></a>
				<div class="clearfix"></div>
			</div>
		</div>

	</div>
</div>

<script type="text/javascript">
$(document).ready(function () {

    signIn.createSignInAsRow($("#sign-in-form-gfb-popup"));

    $(".target-field").each(function () {
        var uris = $(this).val().split("/");
        if (uris.pop() === "login") {
        	$(this).val(uris.toString().replace(",","/"));
        }
    });
});
</script>
        <div id="templateOverlay" class="is-hidden" hidden="hidden">
  <div class="o-overlay js-overlay is-hidden" hidden="hidden"></div>
</div>

<div id="templateExternalMessages" class="is-hidden" hidden="hidden">
  <div class="o-modal o-modal--auto@md js-external-messages is-hidden" hidden="hidden">
    <div class="o-modal__body">
      <section class="c-console">
        <div class="_mdl-layout c-console__bdy js-external-messages-body"></div>
        <footer class="_mdl-layout c-console__ftr o-flex o-flex--reverse js-external-messages-footer">
          <button type="button" class="mdl-button mdl-js-button mdl-button--raised mdl-button--colored c-console__btn js-external-messages-close" data-action="maintenance-close">I Understand</button>
        </footer>
      </section>
    </div>
  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.1/moment.min.js"></script>

<script src="/js/namespace.js"></script>
<script src="/js/constants.js"></script>
<script src="/js/utilities.js"></script>

<script>
                  F1000.ExtenalMaintenanceItems = [
    {
      start: '2018-12-10T14:21:00Z',
      end: '2018-12-13T16:00:00Z',
      msg: 'This site will be down for a short time on XX December. It is advisable not to start any submissions on that day or you may lose your work unless you save regularly.',
      cookieName: 'outage23122018',
      editor: false,
    }
  ];
</script>

<script src="/js/shared_scripts/cookie-helper.js"></script>
<script src="/js/shared_scripts/mdl-helper.js"></script>

<script src="/js/app/external-maintenance.js"></script>

                <script type="text/javascript">
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-5646075-11', 'auto');
            ga('require', 'displayfeatures');
            ga('send', 'pageview');
        </script>
        
                <script type="text/javascript" src="/js/app/research.analytics.js"></script>

        <!-- Start of HubSpot Embed Code -->
        <script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/4475190.js"></script>
        <!-- End of HubSpot Embed Code -->
    
            <script src="https://my.hellobar.com/4e0495c6f18cbd68731a1dc1978195a144e767ba.js" type="text/javascript" charset="utf-8" async="async"></script>
    </body>

</html>