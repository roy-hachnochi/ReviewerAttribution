This article proposes what Peels et al. call a “normative taxonomy” of the “Big Five” epistemic responsibilities universities ought to meet: (1) fostering research integrity, (2) teaching (for) intellectual virtues, (3) addressing the big questions, (4) valuing the humanities, and (5) serving society. This normative taxonomy essentially serves as an analytical rubric designed to assess the performance of universities. One could easily imagine – and in fact, Peels et al. propose as much in 3 – refining the rubric presented in Table 1, using it to assess the performance of various universities, and then comparing their “Big Five” scores to their world university rankings. We agree that undertaking these tasks presents many enticing possibilities, especially to those of us inclined against bean counting approaches to accountability. Nevertheless, since they position themselves as aspiring university rankers, they should address the range of critiques targeting existing rankings, their methodologies, and the performativity of these rankings. They should then situate their own approach within that context, arguing especially that it is an improvement on – and escapes the criticisms levelled at – existing rankings. This is our global concern. Below, we offer a number of other substantial concerns, followed by a shorter list of minor issues to consider: Why these five? Peels et al. propose five epistemic responsibilities of universities as the Big Five. The authors point out that they consider each of the Big Five equally important. They also defend each of the five as indeed responsibilities that universities ought to meet. However, they fail to argue that these five epistemic responsibilities are the most important epistemic responsibilities for universities, that these five are in fact equally important, that these five are sufficient to capture the epistemic responsibilities universities ought to meet, or that universities have no other equally worthy responsibilities that ought to be included. Why five? We agree that the proposed Big Five are epistemic responsibilities that universities ought to meet. Using the proposed rubric to evaluate universities might provide valuable information about particular areas of strength and weakness at a given university. However, designing the rubric around five separate epistemic responsibilities suggests that universities could meet each of their epistemic responsibilities to varying degrees. One university might be particularly strong in terms of fostering research integrity but fail miserably at teaching for intellectual virtue. Another might excel at addressing the big questions but do a lousy job of valuing the humanities. Although these possibilities sound prima facie plausible, using an analytic approach to epistemic responsibilities also generates some less than desirable outcomes. Could a university that fails to teach for intellectual virtue really excel at fostering research integrity? That seems plausible only if we have a very limited procedural view of what counts as fostering research integrity. Without valuing the humanities, how could a university excel at addressing the big questions? Unless we adopt scientism, the answer seems to be that it could not. Similar problems arise when we consider the relations between the other proposed epistemic responsibilities. The use of a taxonomical vocabulary further strengthens this worry. Taxonomies should display not only differences, but also relationships and similarities. The current form of representation is not, in that sense, a taxonomy, but (for the most part) a normative list . Only when the ties binding the elements together are conceptualised convincingly can we convincingly speak of a taxonomy. For this reason, we suggest that the authors consider enriching their list to raise it to the level of a taxonomy or abandon talk of a ‘taxonomy’ altogether. The authors could adopt the vocabulary of an analytical rubric, instead. Even if the authors decide to use the language of rubrics rather than taxonomies, we suggest that the authors consider a more holistic approach along with an analytic one, just as virtue ethics appeals not only to the individual virtues, but also to the question of character. Rather than describing teaching for intellectual virtue as part of Bildung , perhaps the authors could consider fostering the ability to pursue Wissenschaft while cultivating Bildung as analogous to a university’s character. Call it the W-B rubric, under which different (now, no longer separate) epistemic responsibilities could be grouped together to indicate different levels of overall achievement. In order for a university to score best on the W-B rubric, it would have to excel at meeting all of its epistemic responsibilities (for a brief discussion of the difference between analytic and holistic rubrics, as well as examples and further references, see Rubrics: useful assessment tools. Centre for Teaching Excellence, University of Waterloo 1 ). Why insist on separating epistemic from other responsibilities universities have? This question follows on the previous one, in that it aims to nudge the authors away from using only an analytic approach. By insisting on distinguishing epistemic responsibilities from moral, practical, and social responsibilities, the authors impoverish the idea of what it means for universities to serve society. If the goal is to work towards alternative forms of assessment and accountability (thereby politicizing them further), excluding other responsibilities and artificially fragmenting the landscape accordingly, one would expect [a] the epistemic responsibility taxonomy to be situated within a larger responsibility taxonomy and/or [b] an argument that leaving other responsibilities aside is preferable. More in line with the suggestion to pursue a more holistic approach, we must ask: could we really say that a university is a good university if it meets only its epistemic responsibilities? We think not. Perhaps the W-B rubric we suggest, or another holistic approach, could help address this issue. Note that one could also include analytical rubrics for moral, practical, and social responsibilities of universities and incorporate the responsibilities included in each of these separate rubrics into a holistic approach. Our point is not that analysis is always bad. Indeed, analysis can be quite informative and useful as part of a formative evaluation. We are simply suggesting that the authors consider using their analytic approach to complement a more holistic approach. Who counts, and why do they count? In 3, the authors suggest optimising their rubric by means of a Delphi Study “with international experts”, which could lead to fine-tuning it, but possibly also to radical revisions. If the latter is the case, then what is the status of the current five epistemic responsibilities? When it comes to the actual Delphi study, whom they choose to participate in the study will likely make a very big difference to the final design of the rubric. Presumably, the authors focus on “experts” because they assume experts know more about epistemic responsibilities than non-experts do. Yet, the way in which the authors present it suggests a retreat to the deficit/diffusion model of public understanding of science. Not only has the deficit model been shown to be factually incorrect, it also presupposes a social contract for science and scholarship that imagines universities as ivory towers. In their discussion of a university’s responsibility to serve society epistemically, the authors focus on the supply side of knowledge production, suggesting that knowledge dissemination is how best to serve society. Arguably, however, serving society – even if we limit this to an epistemic responsibility – means something other than telling society what we academics think they need to know. Here again, the separation between epistemic and other responsibilities creates a lot of friction, since a departure from the deficit model requires a high degree of interaction and participation beyond universities. In fact, one could argue that interaction and participation are epistemic requirements (co production of knowledge). Along these lines, we suggest that non-experts may have valuable feedback to offer, even if the authors ultimately decide only to pursue the development of an analytic rubric for epistemic responsibilities of universities. One way to include the demand side of knowledge production in the design of their rubric would be to recruit non-expert stakeholders to participate in the proposed Delphi Study and workshops or organise parallel expert (Delphi) and citizen (Citizen Summit) consultations. We also have a few more minor points that nevertheless warrant attention: Despite the argument that the rubric is to be applied to entire universities, the responsibilities focus very much on individuals and groups (which seem to be multiple individuals in the ways in which they are discussed) and less on the level of structures and collectives. Peels et al. frame irreproducibility solely as the result of sub-par science and thus as a research integrity issue. Their previous work, as well current scholarly debates on the characters and qualities or irreproducibiluty and irreplicability, takes up a much more nuanced position. Perhaps the authors will consider adding some of that nuance here. Excusing a few universities (technical universities or polytechnics, in this case) of taking responsibility for one of the epistemic responsibilities (#4) suggests that giving humanistic inquiry and education a proper place is optional. This seems to conflict with the idea that all responsibilities are equally important. It also opens up possibilities for policies that deprioritise humanities research and teaching (cf. the current Van Rijn report in NL). 