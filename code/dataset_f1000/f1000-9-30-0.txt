This is an interesting paper about the impact of data sharing for a non-commercial repository (BioLINCC). From the viewpoint of the reviewer, the manuscript should be improved: In the section “data collection” the authors describe different data search methods for publications: Updated list of publications received from BioLINCC directly. List of published articles on the BioLINCC website. Manual search of Pubmed with the title of the dataset. The authors should describe the overlap/differences between the results of the different search strategies, preferably in a figure. The authors could use the PRISMA flow diagram as an example ( https://www.equator-network.org/reporting-guidelines/prisma/ ). The authors state in the “bibliometric analysis” section that “Any study that reported the use of the searched data set as part of its results was included in our analysis”. It is not clear, how the datasets were identified in the publication. Was this performed via the registration number of the underlying study in a registry (e.g. NCT-number) or by the title/acronym of the data set from the BioLINCC database? The authors should clarify how this was performed. Important to add would be a statistic describing the number of publications per data set (may be also dependent on the year of publication of the data set in BioLINCC). Are there many datasets without any or only very few publications? Is the majority of publications concentrated in a few datasets? This information is important because no requests for data sharing may not justify costs and resources for preparation of data sharing (e.g. de-identification, curation). One of the factors that is relevant for the number of publications is the year when the data set was published in BioLINCC. A figure correlating the date of publication of the data set with the number of publications could illustrate that. This is similar with the relation between the year of publication and the number of citations. These relationships should be worked out in the paper. Another aspect to be considered could be the role of outliers in the statistics. Are there datasets and/or publications with a very high number of citations (e.g. more than 100). Does the citation pattern mainly concentrate in a few outstanding datasets or is it more evenly distributed? The authors should include and discuss a cross-sectional web-based survey about access to clinical research data from BioLINCC, covering the period from 2007 to 2014 (Ross JS et al. Data sharing through an NIH central database repository: a cross-sectional survey of BioLINCC users. BMJ open 2016;6(9):e012769) 1 . The authors think that it would be good style to thank BioLINCC for providing datasets after contact. 