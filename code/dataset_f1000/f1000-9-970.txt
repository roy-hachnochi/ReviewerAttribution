

    <!DOCTYPE html>
<html class="">

        
<head>
    <title>Affective rating of audio and video clips using the... | F1000Research</title>
    <meta charset="utf-8">
    <!--<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>-->
    <!--<meta lang="$locale">-->
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="9-QVycOO2_ob3Z9QzRmXv2CF08A9oyYXqWyTiVdKPlU" />
    <!-- This is commented out to fix display problems on mobile devices.
    We may use it again once we implement a responsive design that supports native device resolutions.
    <meta name="viewport" content="width=device-width"> -->

    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



    <link rel="alternate" title="Recent articles published in F1000Research" href="/rss" type="application/rss+xml">
            <link rel="alternate" type="application/pdf" title="PDF" href="https://f1000research.com/articles/9-970/pdf"/>
        <link rel="canonical" href="https://f1000research.com/articles/9-970" />
    
            <meta name="description" content="Read the original article in full on F1000Research: Affective rating of audio and video clips using the EmojiGrid" />
    
            <meta name="og:title" content="F1000Research Article: Affective rating of audio and video clips using the EmojiGrid.">
            <meta name="og:description" content="Read the latest article version by Alexander Toet, Jan B. F. van Erp, at F1000Research.">
            <meta name="og:image" content="/img/sharing/og_research.png">
            <meta name="version-id" content="27685">
            <meta name="article-id" content="25088">
            <meta name="dc.title" content="Affective rating of audio and video clips using the EmojiGrid">
            <meta name="dc.description" content=" Background: In this study we measured the affective appraisal of sounds and video clips using a newly developed graphical self-report tool: the EmojiGrid. The EmojiGrid is a square grid, labeled with emoji that express different degrees of valence and arousal. Users rate the valence and arousal of a given stimulus by simply clicking on the grid. 
 Methods: In Experiment I, observers (N=150, 74 males, mean age=25.2&amp;plusmn;3.5) used the EmojiGrid to rate their affective appraisal of 77 validated sound clips from nine different semantic categories, covering a large area of the affective space. In Experiment II, observers (N=60, 32 males, mean age=24.5&amp;plusmn;3.3) used the EmojiGrid to rate their affective appraisal of 50 validated film fragments varying in positive and negative affect (20 positive, 20 negative, 10 neutral). 
 Results: The results of this study show that for both sound and video, the agreement between the mean ratings obtained with the EmojiGrid and those obtained with an alternative and validated affective rating tool in previous studies in the literature, is excellent for valence and good for arousal. Our results also show the typical universal U-shaped relation between mean valence and arousal that is commonly observed for affective sensory stimuli, both for sound and video. 
 Conclusions: We conclude that the EmojiGrid can be used as an affective self-report tool for the assessment of sound and video-evoked emotions.">
            <meta name="dc.subject" content="affective response, audio clips, video clips, EmojiGrid, valence, arousal">
            <meta name="dc.creator" content="Toet, Alexander">
            <meta name="dc.creator" content="van Erp, Jan B. F.">
            <meta name="dc.date" content="2020/08/11">
            <meta name="dc.identifier" content="doi:10.12688/f1000research.25088.1">
            <meta name="dc.source" content="F1000Research 2020 9:970">
            <meta name="dc.format" content="text/html">
            <meta name="dc.language" content="en">
            <meta name="dc.publisher" content="F1000 Research Limited">
            <meta name="dc.rights" content="https://creativecommons.org/licenses/by/3.0/igo/">
            <meta name="dc.type" content="text">
            <meta name="prism.keyword" content="affective response">
            <meta name="prism.keyword" content="audio clips">
            <meta name="prism.keyword" content="video clips">
            <meta name="prism.keyword" content="EmojiGrid">
            <meta name="prism.keyword" content="valence">
            <meta name="prism.keyword" content="arousal">
            <meta name="prism.publication.Name" content="F1000Research">
            <meta name="prism.publicationDate" content="2020/08/11">
            <meta name="prism.volume" content="9">
            <meta name="prism.number" content="970">
            <meta name="prism.versionIdentifier" content="1">
            <meta name="prism.doi" content="10.12688/f1000research.25088.1">
            <meta name="prism.url" content="https://f1000research.com/articles/9-970">
            <meta name="citation_title" content="Affective rating of audio and video clips using the EmojiGrid">
            <meta name="citation_abstract" content=" Background: In this study we measured the affective appraisal of sounds and video clips using a newly developed graphical self-report tool: the EmojiGrid. The EmojiGrid is a square grid, labeled with emoji that express different degrees of valence and arousal. Users rate the valence and arousal of a given stimulus by simply clicking on the grid. 
 Methods: In Experiment I, observers (N=150, 74 males, mean age=25.2&amp;plusmn;3.5) used the EmojiGrid to rate their affective appraisal of 77 validated sound clips from nine different semantic categories, covering a large area of the affective space. In Experiment II, observers (N=60, 32 males, mean age=24.5&amp;plusmn;3.3) used the EmojiGrid to rate their affective appraisal of 50 validated film fragments varying in positive and negative affect (20 positive, 20 negative, 10 neutral). 
 Results: The results of this study show that for both sound and video, the agreement between the mean ratings obtained with the EmojiGrid and those obtained with an alternative and validated affective rating tool in previous studies in the literature, is excellent for valence and good for arousal. Our results also show the typical universal U-shaped relation between mean valence and arousal that is commonly observed for affective sensory stimuli, both for sound and video. 
 Conclusions: We conclude that the EmojiGrid can be used as an affective self-report tool for the assessment of sound and video-evoked emotions.">
            <meta name="citation_description" content=" Background: In this study we measured the affective appraisal of sounds and video clips using a newly developed graphical self-report tool: the EmojiGrid. The EmojiGrid is a square grid, labeled with emoji that express different degrees of valence and arousal. Users rate the valence and arousal of a given stimulus by simply clicking on the grid. 
 Methods: In Experiment I, observers (N=150, 74 males, mean age=25.2&amp;plusmn;3.5) used the EmojiGrid to rate their affective appraisal of 77 validated sound clips from nine different semantic categories, covering a large area of the affective space. In Experiment II, observers (N=60, 32 males, mean age=24.5&amp;plusmn;3.3) used the EmojiGrid to rate their affective appraisal of 50 validated film fragments varying in positive and negative affect (20 positive, 20 negative, 10 neutral). 
 Results: The results of this study show that for both sound and video, the agreement between the mean ratings obtained with the EmojiGrid and those obtained with an alternative and validated affective rating tool in previous studies in the literature, is excellent for valence and good for arousal. Our results also show the typical universal U-shaped relation between mean valence and arousal that is commonly observed for affective sensory stimuli, both for sound and video. 
 Conclusions: We conclude that the EmojiGrid can be used as an affective self-report tool for the assessment of sound and video-evoked emotions.">
            <meta name="citation_keywords" content="affective response, audio clips, video clips, EmojiGrid, valence, arousal">
            <meta name="citation_journal_title" content="F1000Research">
            <meta name="citation_author" content="Alexander Toet">
            <meta name="citation_author_institution" content="Perceptual and Cognitive Systems, TNO, Soesterberg, 3769DE, The Netherlands">
            <meta name="citation_author_institution" content="Department of Experimental Psychology, Helmholtz Institute, Utrecht University, Utrecht, 3584 CS, The Netherlands">
            <meta name="citation_author" content="Jan B. F. van Erp">
            <meta name="citation_author_institution" content="Research Group Human Media Interaction, University of Twente, Enschede, 7522 NH, The Netherlands">
            <meta name="citation_author_institution" content="Perceptual and Cognitive Systems, TNO, Soesterberg, 3769DE, The Netherlands">
            <meta name="citation_publication_date" content="2020/08/11">
            <meta name="citation_volume" content="9">
            <meta name="citation_publication_number" content="970">
            <meta name="citation_version_number" content="1">
            <meta name="citation_doi" content="10.12688/f1000research.25088.1">
            <meta name="citation_firstpage" content="970">
            <meta name="citation_pdf_url" content="https://f1000research.com/articles/9-970/v1/pdf">
    

    
    <link href="/img/favicon-research.ico" rel="shortcut icon" type="image/ico">
    <link href="/img/favicon-research.ico" rel="icon" type="image/ico">

        <link rel="stylesheet" href="/1597255280893/css/mdl/material-design-lite.css" type="text/css" media="all" />
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto:100,100i,300,300i,400,400i,500,500i,700,700i,900,900i" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/MaterialDesign-Webfont/2.2.43/css/materialdesignicons.min.css" />

        
            
    <link rel="stylesheet" href="/1597255280893/css/F1000Research.css" type="text/css" media="all" />
    <link rel="stylesheet" href="/css/F1000ResearchFontIcons/F1000ResearchFontIcons.css" type="text/css" media="all" />
    <link rel="stylesheet" href="/css/F1000ResearchFontIcons/animation.css" type="text/css" media="all" />

        <!--[if IE 7]><link rel="stylesheet" href="/css/F1000ResearchFontIcons/F1000ResearchFontIcons-ie7.css" media="all" /><![endif]-->

                    <script>dataLayer = [];</script>
        <!-- Google Tag Manager -->
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-54Z2SBK');</script>
        <!-- End Google Tag Manager -->
    
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.1/jquery.min.js"></script>
    <script>window.jQuery || document.write('<script src="/js/vendor/jquery-1.8.1.min.js"><\/script>')</script>
    <script src="/1597255280893/js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>
    <script src="/1597255280893/js/shared_scripts/sticky.js"></script>
    <script src="/1597255280893/js/shared_scripts/helpers.js"></script>
    <script src="/1597255280893/js/shared_scripts/menu.js"></script>
    <script src="/1597255280893/js/shared_scripts/navbar.js"></script>
    <script src="/1597255280893/js/shared_scripts/platforms.js"></script>
    <script src="/1597255280893/js/shared_scripts/object-polyfills.js"></script>
            <script src="/1597255280893/js/vendor/lodash.min.js"></script>
        <script>CKEDITOR_BASEPATH='https://f1000research.com/js/ckeditor/'</script>
    <script src="https://f1000researchdata.s3-eu-west-1.amazonaws.com/js/plugins.js"></script>
    <script src="/1597255280893/js/shared_scripts/helpers.js"></script>
    <script src="/1597255280893/js/app/research.js"></script>
    <script>window.reactTheme = 'research';</script>
    <script src="/1597255280893/js/public/bundle.js"></script>

    <script src="/1597255280893/js/app/research.ui.js"></script>
    <script src="/1597255280893/js/app/login.js"></script>
    <script src="/1597255280893/js/app/main.js"></script>
    <script src="/1597255280893/js/app/js-date-format.min.js"></script>
    <script src="/1597255280893/js/app/search.js"></script>
    <script src="/1597255280893/js/app/cookies_warning.js"></script>
    <script src="/1597255280893/js/mdl/mdl.min.js"></script>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
                <script src="https://f1000researchdata.s3-eu-west-1.amazonaws.com/js/ckeditor.js"></script>
            <script src="/js/ckeditor/adapters/jquery.js"></script>
                <script src="/js/article/article_scrolling_module.js"></script>
            <script src="/js/article/article_stats.js"></script>
            <script src="/js/article/article.js"></script>
            <script src="/js/shared_scripts/referee_timeline_pagination.js"></script>
            <script src="/js/app/text_editor_controller.js"></script>
            <script src="//s7.addthis.com/js/250/addthis_widget.js#pubid=ra-503e5e99593dc42c"></script>
            <script src="/js/article/article_metrics.js"></script>
        
                                                                            <script>
            if (window.location.hash == '#_=_'){
                window.location = window.location.href.split('#')[0]
            }
        </script>

                    
        
    <!-- pixelId: 1641728616063202 :: assetPixelId: 6034867600215 :: funderPixelId:  -->

            <!-- Facebook pixel code (merged with EP GTM code) -->
        <script>
            !function(f,b,e,v,n,t,s){if(f.fbq)return;n=f.fbq=function()

            {n.callMethod? n.callMethod.apply(n,arguments):n.queue.push(arguments)}
            ;if(!f._fbq)f._fbq=n;
            n.push=n;n.loaded=!0;n.version='2.0';n.queue=[];t=b.createElement(e);t.async=!0;
            t.src=v;s=b.getElementsByTagName(e)[0];s.parentNode.insertBefore(t,s)}(window,
            document,'script','https://connect.facebook.net/en_US/fbevents.js');

            fbq('init', '1641728616063202');

            
            fbq('track', "PixelInitialized", {});
        </script>

        <noscript><img height="1" width="1" style="display:none"
            src="https://www.facebook.com/tr?id=1641728616063202&noscript=1&amp;ev=PixelInitialized"
        /></noscript>
        <!-- End Facebook Pixel Code -->
    
                <script>
            (function(h,o,t,j,a,r){
                h.hj=h.hj||function(){(h.hj.q=h.hj.q||[]).push(arguments)};
                h._hjSettings={hjid:917825,hjsv:6};
                a=o.getElementsByTagName('head')[0];
                r=o.createElement('script');r.async=1;
                r.src=t+h._hjSettings.hjid+j+h._hjSettings.hjsv;
                a.appendChild(r);
            })(window,document,'https://static.hotjar.com/c/hotjar-','.js?sv=');
        </script>
    
</head>
<body  class="o-page-container no-js p-article o-layout-reset   ">

    
                            <!-- Google Tag Manager (noscript) -->
        <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-54Z2SBK"
        height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
        <!-- End Google Tag Manager (noscript) -->
    
        
    <div class="o-page">

        <div id="notify-container"></div>
        <div id="pageWarning"></div>
        <div id="pageMessage"></div>
        <div id="pageFooterMessage"></div>

                                <div id="f1r-ga-data" data-name="f1r-ga-data" class="f1r-ga-data"
                data-user-registered="false"
                data-user-module=""
                data-current-path=""
                data-location=""
                data-website="F1000Research"
                data-websiteDisplayName="F1000Research">
            </div>
        
                
        
        <div class="header-wrapper   js-navbar-space ">
                            


    










        
                            
    
            



<nav class="c-navbar js-navbar js-mini-nav js-sticky c-navbar--js-sticky c-navbar--userSite c-navbar__platform-bgcolor  c-navbar--bg-f1000research ">

    <div class="c-navbar__content">

                                <div class="c-navbar__extras">
            <div class="o-wrapper">
                <div class="o-actions o-actions--middle c-navbar__extras-row">
                    <div class="o-actions__primary">
                        
                                            </div>
                                    </div>
            </div>
        </div>

        <div class="o-wrapper t-inverted js-sticky-start">

            <div class="c-navbar__branding-row">
                <div class="c-navbar__row">


                                        
                    <div class="c-navbar__primary u-mr--2">

                                                                                                                                                                                                    <a href="/" class="c-navbar__branding u-ib u-middle"   data-test-id="nav_branding"  >
                                <img class="u-ib u-middle" src="/img/research/F1000Research_white_solid.svg" alt="F1000Research">
                            </a>
                                            </div>

                    <div class="c-navbar__secondary c-navbar__row">


                                                
                                                    <form action="/search" class="-navbar__secondary u-mr--2 c-search-form js-search-form u-hide u-show@navbar">
                                <label for="searchInput" class="c-search-form__label _mdl-layout">
                                    <input name="q" type="search" class="c-search-form__input" id="searchInput" placeholder="Search">
                                    <button type="submit" class="c-search-form__submit mdl-button mdl-js-button mdl-button--icon"><i class="material-icons">search</i></button>
                                </label>
                            </form>
                        
                                                
                                                    <div class="c-navbar__primary u-hide u-show@navbar">
                                <div class="_mdl-layout c-navbar__cta">
                                    <a class="mdl-button mdl-js-button mdl-button--raised mdl-button--no-shadow mdl-button--multi-line mdl-js-ripple-effect mdl-button--inverted c-navbar__submit" href="/for-authors/publish-your-research"   data-test-id="nav_submit_research"  ><i class="material-icons">file_upload</i>Submit your research</a>
                                </div>
                            </div>
                        

                                                
                        <span class="u-hide@navbar _mdl-layout u-nowrap">

                                                            <button type="button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon c-navbar__toggle c-navbar__toggle--menu js-navbar-toggle" data-focus="#navbar_mob_search_input" data-toggle="navbarMenu" data-target="navbarMenu" aria-controls="navbarMenu" aria-expanded="false" aria-label="Toggle navigation"   data-test-id="nav_menu_search_mob"  ><i class="material-icons">search</i></button>
                            
                                                            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-button--multi-line c-navbar__toggle c-navbar__toggle--menu js-navbar-toggle" type="button" data-toggle="navbarMenu" data-target="navbarMenu" aria-controls="navbarMenu" aria-expanded="false" aria-label="Toggle navigation"   data-test-id="nav_menu_toggle_mob"  >
                                    <i class="material-icons c-navbar__toggle-open">menu</i>
                                    <i class="material-icons c-navbar__toggle-close">close</i>
                                </button>
                                                    </span>
                    </div>

                </div>
            </div>

                        
                            <div class="c-navbar__menu-row js-navbar-block is-collapsed" id="navbarMenu">

                                                                                                                                                
                                                                    
                                                                    
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
                                            

                                                                
                                                                                                                                                                                                                                
                                            
                    <div class="c-navbar__menu-row-content">

                                                                            <div class="u-hide@navbar c-navbar__menu-bar-spacing">
                                <form action="/search" class="c-search-form js-search-form">
                                    <label for="navbar_mob_search_input" class="c-search-form__label _mdl-layout">
                                        <input id="navbar_mob_search_input" name="q" type="search" class="c-search-form__input" placeholder="Search">
                                        <button type="submit" class="c-search-form__submit mdl-button mdl-js-button mdl-button--icon"><i class="material-icons">search</i></button>
                                    </label>
                                </form>
                            </div>
                        
                        <div class="o-actions o-actions--middle">

                            <div class="o-actions__primary">

                                                                
    <ul class="c-menubar c-navbar__menu-bar js-main-menu"   id="main-menu"   role="menubar" aria-label="Main Navigation"  data-menu-group="navbar" >

        
            
                                                                
                                
                                
                                    <li role="none"
                        data-index="0"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/browse/articles" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="0"
                              data-test-id="nav_browse"                              >Browse</a>

                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="1"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/gateways" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="-1"
                              data-test-id="nav_gatewaysViewAndBrowse"                              >Gateways & Collections</a>

                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="2"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="-1"
                              data-test-id="nav_for-authors"                              >How to Publish</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="How to Publish">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_submit-manuscript"                      href="/for-authors/publish-your-research"
                    role="menuitem"
                    tabindex="0">Submit your Research</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-submissions"                      href="/for-authors/my-submissions"
                    role="menuitem"
                    tabindex="-1">My Submissions</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-guidelines"                      href="/for-authors/article-guidelines"
                    role="menuitem"
                    tabindex="-1">Article Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-guidelines-new-versions"                      href="/for-authors/article-guidelines-new-versions"
                    role="menuitem"
                    tabindex="-1">Article Guidelines (New Versions)</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_data-guidelines"                      href="/for-authors/data-guidelines"
                    role="menuitem"
                    tabindex="-1">Data Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_asset-guidelines"                      href="/for-authors/posters-and-slides-guidelines"
                    role="menuitem"
                    tabindex="-1">Posters and Slides Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_document-guidelines"                      href="/for-authors/document-guidelines"
                    role="menuitem"
                    tabindex="-1">Document Guidelines</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_article-processing-charges"                      href="/for-authors/article-processing-charges"
                    role="menuitem"
                    tabindex="-1">Article Processing Charges</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_finding-referees"                      href="/for-authors/tips-for-finding-referees"
                    role="menuitem"
                    tabindex="-1">Finding Article Reviewers</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="3"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="-1"
                              data-test-id="nav_about-contact"                              >About</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="About">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_about-page"                      href="/about"
                    role="menuitem"
                    tabindex="0">How it Works</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_referee-guidelines"                      href="/for-referees/guidelines"
                    role="menuitem"
                    tabindex="-1">For Reviewers</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_advisoryPanel"                      href="/advisors"
                    role="menuitem"
                    tabindex="-1">Our Advisors</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_policy-page"                      href="/about/policies"
                    role="menuitem"
                    tabindex="-1">Policies</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_glossary-page"                      href="/glossary"
                    role="menuitem"
                    tabindex="-1">Glossary</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_faqs-page"                      href="/faqs"
                    role="menuitem"
                    tabindex="-1">FAQs</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              u-hide u-show@navbar"
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      u-hide u-show@navbar"
                                          data-test-id="nav_for-developers"                      href="/developers"
                    role="menuitem"
                    tabindex="-1">For Developers</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_newsroom-page"                      href="/newsroom"
                    role="menuitem"
                    tabindex="-1">Newsroom</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_contact-page"                      href="/contact"
                    role="menuitem"
                    tabindex="-1">Contact</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="4"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="https://blog.f1000.com/blogs/f1000research/" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                             target="_blank"                                                         tabindex="-1"
                              data-test-id="nav_blog"                              >Blog</a>

                                            </li>
                
            
        
    </ul>



                            </div>

                            <div class="o-actions__secondary">

                                                                
    <ul class="c-menubar c-navbar__menu-bar js-main-menu"   id="secondary-items"   role="menubar" aria-label="My Account"  data-menu-group="navbar" >

        
            
                                                                
                                
                                
                                    <li role="none"
                        data-index="0"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                               c-menubar__item--selected c-navbar__menu-bar-item--parent ">

                        <a href="#" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                         aria-haspopup="true" aria-expanded="false"                             tabindex="0"
                              data-test-id="nav_my-research"                              >My Research</a>

                                                    
    <ul class="c-menu js-menu
                is-collapsed                c-menubar__menu c-navbar__menu"
                  role="menu"
        aria-label="My Research">

        
            
                                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-submissions"                      href="/login?originalPath=/my/submissions"
                    role="menuitem"
                    tabindex="0">Submissions</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-email-alerts"                      href="/login?originalPath=/my/email-alerts"
                    role="menuitem"
                    tabindex="-1">Content and Tracking Alerts</a>

                </li>

                    
            
                
                                
                <li class="c-menu__item js-menu-item
                                              "
                        role="none">

                <a  class="c-menu__link js-menu-link
                                                      "
                                          data-test-id="nav_my-user-details"                      href="/login?originalPath=/my/user-details"
                    role="menuitem"
                    tabindex="-1">My Details</a>

                </li>

                        </ul>
                                            </li>
                
            
        
            
                                                                
                
                                
                                    <li role="none"
                        data-index="1"
                        class="c-menubar__item js-menu-item  c-navbar__menu-bar-item
                                                              ">

                        <a href="/login?originalPath=/articles/9-970.html" class="c-navbar__menu-bar-link js-menu-link " role="menuitem"
                                                                                    tabindex="-1"
                              data-test-id="nav_sign-in"                              >Sign In</a>

                                            </li>
                
            
        
    </ul>



                            </div>

                                                                                        <div class="_mdl-layout c-navbar__cta u-hide@navbar c-navbar__menu-bar-spacing">
                                    <a class="mdl-button mdl-js-button mdl-button--raised mdl-button--multi-line mdl-button--no-shadow mdl-js-ripple-effect mdl-button--inverted c-navbar__submit" href="/for-authors/publish-your-research"   data-test-id="nav_submit_research_mob"  ><i class="material-icons">file_upload</i>Submit your research</a>
                                </div>
                                                    </div>

                    </div>

                </div>
            
        </div>

    </div>

</nav>
                    </div>

        <div class="content-wrapper o-page__main row ">
            <div id="highlight-area" class="content ">
                





<div id=article-metadata class=hidden> <input type=hidden name=versionId value=27685 /> <input type=hidden id=articleId name=articleId value=25088 /> <input type=hidden id=xmlUrl value="/articles/9-970/v1/xml"/> <input type=hidden id=xmlFileName value="-9-970-v1.xml"> <input type=hidden id=article_uuid value=01a543b3-5b99-4b8c-a969-cabcf09bc69d /> <input type=hidden id=referer value=""/> <input type=hidden id=meta-article-title value="Affective rating of audio and video clips using the EmojiGrid"/> <input type=hidden id=workspace-export-url value="https://sciwheel.com/work/api/import/external?doi=10.12688/f1000research.25088.1"/> <input type=hidden id=versionDoi value="10.12688/f1000research.25088.1"/> <input type=hidden id=usePmcStats value=true /> </div> <main class="o-wrapper p-article__wrapper js-wrapper"> <script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "ScholarlyArticle",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://f1000research.com/articles/9-970"
  },
  "headline": "Affective rating of audio and video clips using the EmojiGrid",
  "datePublished": "2020-08-11T12:57:23",
  "dateModified": "2020-08-11T12:57:23",
  "author": [
    {
      "@type": "Person",
      "name": "Alexander Toet"
    },    {
      "@type": "Person",
      "name": "Jan B. F. van Erp"
    }  ],
  "publisher": {
    "@type": "Organization",
    "name": "F1000Research",
    "logo": {
      "@type": "ImageObject",
      "url": "https://f1000research.com/img/AMP/F1000Research_image.png",
      "height": 480,
      "width": 60
    }
  },
  "image": {
    "@type": "ImageObject",
    "url": "https://f1000research.com/img/AMP/F1000Research_image.png",
    "height": 1200,
    "width": 150
  },
  "description": "Background: In this study we measured the affective appraisal of sounds and video clips using a newly developed graphical self-report tool: the EmojiGrid. The EmojiGrid is a square grid, labeled with emoji that express different degrees of valence and arousal. Users rate the valence and arousal of a given stimulus by simply clicking on the grid.
Methods: In Experiment I, observers (N=150, 74 males, mean age=25.2&amp;plusmn;3.5) used the EmojiGrid to rate their affective appraisal of 77 validated sound clips from nine different semantic categories, covering a large area of the affective space. In Experiment II, observers (N=60, 32 males, mean age=24.5&amp;plusmn;3.3) used the EmojiGrid to rate their affective appraisal of 50 validated film fragments varying in positive and negative affect (20 positive, 20 negative, 10 neutral).
Results: The results of this study show that for both sound and video, the agreement between the mean ratings obtained with the EmojiGrid and those obtained with an alternative and validated affective rating tool in previous studies in the literature, is excellent for valence and good for arousal. Our results also show the typical universal U-shaped relation between mean valence and arousal that is commonly observed for affective sensory stimuli, both for sound and video.
Conclusions: We conclude that the EmojiGrid can be used as an affective self-report tool for the assessment of sound and video-evoked emotions."
}
</script> <div class="o-layout o-layout--right-gutter"> <div id=article_secondary-column class="p-article__main o-layout__item u-font-size--legal u-2/3@article not-expanded "> <div class=float-left> <script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "BreadcrumbList",
    "itemListElement": [
              {
          "@type": "ListItem",
          "position": "1",
          "item": {
            "@id": "https://f1000research.com/",
            "name": "Home"
          }
        },              {
          "@type": "ListItem",
          "position": "2",
          "item": {
            "@id": "https://f1000research.com/browse/articles",
            "name": "Browse"
          }
        },              {
          "@type": "ListItem",
          "position": "3",
          "item": {
            "@id": "https://f1000research.com/articles/9-970.html",
            "name": "Affective rating of audio and video clips using the EmojiGrid"
          }
        }          ]
  }
  </script> <div class="breadcrumbs js-breadcrumbs"> <a href="/" class=f1r-standard-link>Home</a> <span class=item_separator></span> <a href="/browse/articles" class=f1r-standard-link>Browse</a> <span class=item_separator></span> Affective rating of audio and video clips using the EmojiGrid </div> </div> <div class="article-badges-container u-mb--2"> <div class=crossmark-new> <script src="https://crossmark-cdn.crossref.org/widget/v2.0/widget.js"></script> <a data-target=crossmark><img height=30 width=150 src="https://crossmark-cdn.crossref.org/widget/v2.0/logos/CROSSMARK_Color_horizontal.svg"/></a> </div> <div id=crossmark-dialog style="display: none;" title=""> <iframe id=crossmark-dialog-frame frameborder=0></iframe> </div> <div class=clearfix></div> </div> <div class=article-interaction-container> <div id=main-article-count-box class=article-count-box> <div class="article-metrics-wrapper metrics-icon-wrapper" data-version-id=27685 data-id=25088 data-downloads="" data-views="" data-scholar="10.12688/f1000research.25088.1" data-recommended="" data-doi="10.12688/f1000research.25088.1" data-f1r-ga-helper="Article Page Metrics (Desktop)"> <span class="metrics-on-browse article-metrics-icon f1r-icon icon-89_metrics"></span> <div class="count-title article-metrics-text">ALL Metrics</div> <div class=js-article-metrics-container></div> </div> <div> <div class=count-delimiter></div> <div title="Total views from F1000Research and PubMed Central"> <div class="count-container view-count js-views-count">-</div> <div class=count-title><span class="count-title-icon count-title-views-icon"></span>Views</div> </div> <div class=download-counts hidden> <div class=count-delimiter></div> <div title="Total downloads from F1000Research and PubMed Central"> <div class="count-container js-downloads-count"></div> <div class=count-title><span class="count-title-icon f1r-icon icon-76_download_file"></span>Downloads</div> </div> </div> </div> </div> <div id=main-article-interaction-box class="article-interaction-box has-control-tab"> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-102_download_pdf"></span> <a href="https://f1000research.com/articles/9-970/v1/pdf?article_uuid=01a543b3-5b99-4b8c-a969-cabcf09bc69d" title="Download PDF" class="button-link download pdf-download-helper" target=_blank>Get PDF</a> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-103_download_xml"></span> <a id=download-xml href="#" class="button-link download" title="Download XML">Get XML</a> </div> </div> <div class="article-interaction-info article-page"> <div class="cite-article-popup-wrapper article-page-interaction-box"> <div class="article-interaction-button cite-article-button" title="Cite this article" data-windowref=cite-article-popup-25088-1> <span class="f1r-icon icon-82_quote"></span> <a href="#" class="button-link cite-article-popup-link" title="Cite Article">Cite</a> </div> <div id=cite-article-popup-25088-1 class="popup-window-wrapper is-hidden"> <div class=cite-popup-background></div> <div class="popup-window top-popup cite-this-article-box research-layout"> <div class="popup-window-title small cite-title">How to cite this article</div> <span id=cite-article-text-25088-1 data-test-id=copy-citation_text> <span class="article-title-and-info in-popup">Toet A and van Erp JBF. Affective rating of audio and video clips using the EmojiGrid [version 1; peer review: awaiting peer review]</span>. <i>F1000Research</i> 2020, <b>9</b>:970 (<a class=new-orange href="https://doi.org/10.12688/f1000research.25088.1" target=_blank>https://doi.org/10.12688/f1000research.25088.1</a>) </span> <div class="popup-window-title small margin-top-20 margin-bottom-20 note"> <strong>NOTE:</strong> it is important to ensure the information in square brackets after the title is included in all citations of this article. </div> <div class=float-right> <button class="secondary no-fill orange-text-and-border margin-right-20 close-cite-popup uppercase">Close</button> <button id=copy-citation-details class="secondary orange copy-cite-article-version uppercase js-clipboard" title="Copy the current citation details to the clipboard." data-clipboard-target="#cite-article-text-25088-1" data-test-id=copy-citation_button>Copy Citation Details</button> </div> </div> </div> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-76_download_file"></span> <a id=export-citation href="#" class="button-link download" title="Export Citation">Export</a> </div> <div class="modal-window-wrapper is-hidden"> <div id=export-citation-popup class="modal-window padding-20"> <div class=modal-window-close-button></div> <div class=modal-window-title>Export Citation</div> <div class=modal-window-row> <div> <input type=radio name=export-citation-option value=WORKSPACE /> <span class=radio-label>Sciwheel</span> </div> <div> <input type=radio name=export-citation-option value=ENDNOTE /> <span class=radio-label>EndNote</span> </div> <div> <input type=radio name=export-citation-option value=REF_MANAGER /> <span class=radio-label>Ref. Manager</span> </div> <div> <input type=radio name=export-citation-option value=BIBTEX /> <span class=radio-label>Bibtex</span> </div> <div> <input type=radio name=export-citation-option value=PROCITE /> <span class=radio-label>ProCite</span> </div> <div> <input type=radio name=export-citation-option value=SENTE /> <span class=radio-label>Sente</span> </div> </div> <div class=modal-window-footer> <button class=general-white-orange-button id=export-citation-submit>EXPORT</button> </div> <div class=default-error style="display: none;">Select a format first</div> </div> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-90_track"></span> <a class="button-link track-article" data-article-id=25088 id=track-article-signin-25088 title="Receive updates on new activity such as publication of new versions, peer reviews or author responses." href="/login?originalPath=/trackArticle/25088?target=/articles/9-970.html">Track</a> </div> </div> <div class="article-interaction-info article-page"> <div class="article-interaction-button email-article"> <span class="f1r-icon icon-6_email"></span> <a href="#" class=button-link title="Email this article">Email</a> </div> <div class="email-article-version-container small-tooltip _chrome-fix"> <div class=close-icon><span class="f1r-icon icon-3_close_big"></span></div> <script src='https://www.recaptcha.net/recaptcha/api.js'></script> <form class="recommend-version-form research-layout"> <p>All fields are required.</p> <input name=versionId type=hidden value=27685 /> <input name=articleId type=hidden value=25088 /> <input name=senderName class="form-input-field reg-form" value="" type=text placeholder="Your name"/> <input name=senderEmail class="form-input-field reg-form margin-top" value="" type=text placeholder="Your email address"/> <textarea name=recipientEmails class="form-textarea-field ninetynine-percent-wide margin-top no-resize" placeholder="Recipient email address(es) (comma delimited)"></textarea> <input class="form-input-field reg-form margin-top" name=subject type=text value="Interesting article on F1000Research" placeholder=Subject /> <textarea name=message class="form-textarea-field reg-form margin-top no-resize">I thought this article from F1000Research (https://f1000research.com) would be of interest to you.</textarea> <div class="g-recaptcha margin-top" data-sitekey=6LcHqxoUAAAAANP3_0TzpGG6qFvl4DhbUcuRzw7W></div> <input value="" name=captcha type=hidden /> <p>A full article citation will be automatically included.</p> <p><img class="ticker-email-article-details hidden" src="/img/ticker.gif" alt=loading /></p> <button class="secondary orange margin-bottom" data-test-id=version_share_email_send>SEND EMAIL</button> <div class="orange-message margin-bottom is-hidden" data-test-id=version_share_email_message></div> </form> </div> </div> <div class="article-interaction-info article-page"> <div class=article-interaction-button> <span class="f1r-icon icon-34_share"></span> <a href="#" class="button-link last addthis_button share-article" title="Share this article">Share</a> </div> </div> </div> <div id=article-interaction-control-tab class=article-interaction-control-tab> <div id=hide-article-interaction class=article-interaction-control title="Hide Toolbox">&#9644;</div> <div id=show-article-interaction class="article-interaction-control open" title="Show Toolbox">&#10010;</div> </div> </div> <div class="article-header-information article-page"> <div class="f1r-article-mobile article-heading-bar"></div> <div class="article-type article-display">Research Article </div> <div class="article-title-and-info article-view highlighted-article" id=anchor-title> <h1>Affective rating of audio and video clips using the EmojiGrid</h1><span class=other-info> [version 1; peer review: awaiting peer review]</span> </div> <div class=article-subtitle></div> <div class=f1r-article-desk> <div class="authors _mdl-layout"><span class=""><a href="mailto:lextoet@gmail.com" title="Send email" class="cauthor research-layout"><span class='f1r-icon icon-6_email orange'></span><span>Alexander Toet</span></a><a href="https://orcid.org/0000-0003-1051-5422" target=_blank id=author-orcid-0><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=author-orcid-0><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0003-1051-5422</div><sup>1,2</sup>,&nbsp;</span><span class="">Jan B. F. van Erp<a href="https://orcid.org/0000-0002-6511-2850" target=_blank id=author-orcid-1><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=author-orcid-1><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0002-6511-2850</div><sup>1,3</sup></span></div> </div> <div class=f1r-article-mobile> <div class="authors _mdl-layout"><span class=""><a href="mailto:lextoet@gmail.com" title="Send email" class="cauthor research-layout"><span class='f1r-icon icon-6_email orange'></span><span>Alexander Toet</span></a><a href="http://orcid.org/0000-0003-1051-5422" target=_blank id=mauthor-orcid-0><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=mauthor-orcid-0><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0003-1051-5422</div><sup>1,2</sup>,&nbsp;</span><span class="">Jan B. F. van Erp<a href="http://orcid.org/0000-0002-6511-2850" target=_blank id=mauthor-orcid-1><span class=orcid-logo-for-author-list></span></a><div class="mdl-tooltip mdl-tooltip--wider" for=mauthor-orcid-1><span class=orcid-logo-for-author-list></span> https://orcid.org/0000-0002-6511-2850</div><sup>1,3</sup></span></div> </div> <div class=f1r-article-mobile> <div class=article-pubinfo-mobile> PUBLISHED 11 Aug 2020 </div> </div> <span class=Z3988 title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:journal&amp;rft_id=info:doi/10.12688%2Ff1000research.25088.1"></span> <div class=f1r-article-desk> <div class="contracted-details first"> <a href="#" class="contracted-details-label author-affiliations"><span class=contracted></span>Author details</a> <a href="#" class=section-title>Author details</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details affiliations is-hidden"> <sup>1</sup> Perceptual and Cognitive Systems, TNO, Soesterberg, 3769DE, The Netherlands<br/> <sup>2</sup> Department of Experimental Psychology, Helmholtz Institute, Utrecht University, Utrecht, 3584 CS, The Netherlands<br/> <sup>3</sup> Research Group Human Media Interaction, University of Twente, Enschede, 7522 NH, The Netherlands<br/> <p> <div class=margin-bottom> Alexander Toet <br/> <span>Roles: </span> Conceptualization, Data Curation, Formal Analysis, Investigation, Methodology, Software, Supervision, Validation, Visualization, Writing – Original Draft Preparation, Writing – Review & Editing </div> <div class=margin-bottom> Jan B. F. van Erp <br/> <span>Roles: </span> Funding Acquisition, Methodology, Resources, Supervision, Validation, Writing – Original Draft Preparation, Writing – Review & Editing </div> </p> </div> </div> </div> <div class=f1r-article-mobile> <div class="article-page-section-box margin-bottom-40 research-layout"> <span class=box-title> <span class="f1r-icon icon-85_peer_review"></span> OPEN PEER REVIEW </span> <div class="status-row referee-reports-container"> REVIEWER STATUS <span class=status-icons> <em>AWAITING PEER REVIEW</em> </span> </div> </div> </div> </div> <h2 class="article-headings article-page-abstract" id=anchor-abstract> <span class="f1r-article-mobile-inline abstract-heading-border"></span> Abstract </h2> <div class="article-abstract article-page-general-text-mobile research-layout"> <div class="abstract-text is-expanded"> <b>Background:</b> In this study we measured the affective appraisal of sounds and video clips using a newly developed graphical self-report tool: the EmojiGrid. The EmojiGrid is a square grid, labeled with emoji that express different degrees of valence and arousal. Users rate the valence and arousal of a given stimulus by simply clicking on the grid.<br/> <b>Methods:</b> In Experiment I, observers (N=150, 74 males, mean age=25.2&plusmn;3.5) used the EmojiGrid to rate their affective appraisal of 77 validated sound clips from nine different semantic categories, covering a large area of the affective space. In Experiment II, observers (N=60, 32 males, mean age=24.5&plusmn;3.3) used the EmojiGrid to rate their affective appraisal of 50 validated film fragments varying in positive and negative affect (20 positive, 20 negative, 10 neutral).<br/> <b>Results:</b> The results of this study show that for both sound and video, the agreement between the mean ratings obtained with the EmojiGrid and those obtained with an alternative and validated affective rating tool in previous studies in the literature, is excellent for valence and good for arousal. Our results also show the typical universal U-shaped relation between mean valence and arousal that is commonly observed for affective sensory stimuli, both for sound and video.<br/> <b>Conclusions:</b> We conclude that the EmojiGrid can be used as an affective self-report tool for the assessment of sound and video-evoked emotions. </div> <div class=abstract-for-mobile> <div class="margin-top-30 padding-bottom-30 research-layout is-centered"> <button class="primary orange-text white-bg bigger-text abstract-expand-button-mobile with-border show" style="display: none;"> READ ALL <span class="f1r-icon icon-14_more_small orange vmiddle big"></span> </button> <button class="primary orange-text white-bg bigger-text abstract-expand-button-mobile with-border hide"> READ LESS <span class="f1r-icon icon-10_less_small orange vmiddle big"></span> </button> </div> </div> </div> <div class=clearfix></div> <div class="article-context no-divider"> <div class="article-abstract article-page-general-text-mobile research-layout generated-article-body"> <h2 class=main-title>Keywords</h2> <p class="u-mb--0 u-pb--2"> affective response, audio clips, video clips, EmojiGrid, valence, arousal </p> </div> </div> <div class=article-information> <span class="info-separation padding-bottom"> <div id=corresponding-author-icon class="email-icon float-left"> <span class="f1r-icon icon-6_email orange"></span> <div id=corresponding-author-window class="margin-top-20 popup-window-wrapper is-hidden"> <div class="popup-window corresponding-authors-popup"> <div class=corresponding-author-container> <div class="popup-window-title small">Corresponding Author(s)</div> <div class=authors> Alexander Toet (<a href="mailto:lextoet@gmail.com">lextoet@gmail.com</a>) </div> </div> <div class="margin-top margin-bottom float-left"> <button id=close-popup-window class=general-white-orange-button>Close</button> </div> </div> </div> </div> <span class="icon-text float-left" data-test-id=box-corresponding-author> <b>Corresponding author:</b> Alexander Toet </span> <div class=clearfix></div> </span> <span class="info-separation padding-bottom competing-interests-display"> <span class=competing-interests-title>Competing interests:</span> No competing interests were disclosed. </span> <div class="info-separation padding-bottom grant-information-display"> <span class=grant-information-title>Grant information:</span> The author(s) declared that no grants were involved in supporting this work. </div> <span class="f1r-article-desk info-separation padding-bottom"> <span class="copywrite-icon float-left"> <span class="f1r-icon icon-100_open_access"></span> </span> <span class="icon-text float-left" data-test-id=box-copyright-text> <b>Copyright:</b>&nbsp; © 2020 Toet A and van Erp JBF. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/" target=_blank data-test-id=box-licence-link>Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. </span> <div class=clearfix></div> </span> <span class="info-separation padding-bottom" data-test-id=box-how-to-cite> <b>How to cite:</b> <span class="article-title-and-info in-article-box"> Toet A and van Erp JBF. Affective rating of audio and video clips using the EmojiGrid [version 1; peer review: awaiting peer review]</span>. <i>F1000Research</i> 2020, <b>9</b>:970 (<a href="https://doi.org/10.12688/f1000research.25088.1" target=_blank>https://doi.org/10.12688/f1000research.25088.1</a>) </span> <span class=info-separation data-test-id=box-first-published><b>First published:</b> 11 Aug 2020, <b>9</b>:970 (<a href="https://doi.org/10.12688/f1000research.25088.1" target=_blank>https://doi.org/10.12688/f1000research.25088.1</a>)</span> <span class=info-separation data-test-id=box-latest-published><b>Latest published:</b> 11 Aug 2020, <b>9</b>:970 (<a href="https://doi.org/10.12688/f1000research.25088.1" target=_blank>https://doi.org/10.12688/f1000research.25088.1</a>)</span> </div> <div class=clearfix></div> <div id=article-context class=article-context> <div id=article1-body class=generated-article-body><h2 class=main-title id=d5188e177>Introduction</h2><p class="" id=d5188e180>In daily human life, visual and auditory input from our environment significantly determines our feelings, behavior and evaluations (<a href="#ref-27">Fazio, 2001</a>; <a href="#ref-43">Jaquet <i>et al.,</i> 2014</a>; <a href="#ref-91">Turley &amp; Milliman, 2000</a>, for a review see: <a href="#ref-74">Schreuder <i>et al.,</i> 2016</a>). The assessment of the affective response of users to the auditory and visual characteristics of for instance (built and natural) environments (<a href="#ref-3">Anderson <i>et al.,</i> 1983</a>; <a href="#ref-40">Huang <i>et al.,</i> 2014</a>; <a href="#ref-50">Kuijsters <i>et al.,</i> 2015</a>; <a href="#ref-58">Ma &amp; Thompson, 2015</a>;<a href="#ref-60"> Medvedev <i>et al.,</i> 2015</a>; <a href="#ref-87">Toet <i>et al.,</i> 2016</a>; <a href="#ref-93">Watts &amp; Pheasant, 2015</a>) and their virtual representations (<a href="#ref-38">Houtkamp &amp; Junger, 2010</a>; <a href="#ref-39">Houtkamp <i>et al.,</i> 2008</a>;<a href="#ref-69"> Rohrmann &amp; Bishop, 2002</a>; <a href="#ref-86">Toet <i>et al.,</i> 2013</a>; <a href="#ref-94">Westerdahl <i>et al.,</i> 2006</a>), multimedia content (<a href="#ref-6">Baveye <i>et al.,</i> 2018</a>; <a href="#ref-78">Soleymani <i>et al.,</i> 2015</a>), human-computer interaction systems (<a href="#ref-26">Fagerberg <i>et al.,</i> 2004</a>;<a href="#ref-41"> Hudlicka, 2003</a>;<a href="#ref-42"> Jaimes &amp; Sebe, 2010</a>; <a href="#ref-65">Peter &amp; Herbon, 2006</a>;<a href="#ref-66"> Pfister <i>et al.,</i> 2011</a>) and (serious) games (<a href="#ref-4">Anolli <i>et al.,</i> 2010</a>;<a href="#ref-23"> Ekman &amp; Lankoski, 2009</a>; <a href="#ref-31">Garner <i>et al.,</i> 2010</a>; <a href="#ref-33">Geslin <i>et al.,</i> 2016</a>; <a href="#ref-90">Tsukamoto <i>et al.,</i> 2010</a>; <a href="#ref-95">Wolfson &amp; Case, 2000</a>) is an essential part of their design and evaluation and requires efficient methods to assess whether the desired experiences are indeed achieved. A wide range of physiological, behavioral and cognitive measures is currently available to measure the affective response to sensorial stimuli, each with their own advantages and disadvantages (for a review see: <a href="#ref-43">Kaneko <i>et al.,</i> 2018a</a>). The most practical and widely used instruments to measure affective responses are questionnaires and rating scales. However, their application is typically time-consuming and requires a significant amount of mental effort (people typically find it difficult to name their emotions, especially mixed or complex ones), which affects the experience itself (<a href="#ref-19">Constantinou <i>et al.,</i> 2014</a>; <a href="#ref-55">Lieberman, 2019</a>; <a href="#ref-56">Lieberman <i>et al.,</i> 2011</a>; <a href="#ref-82">Taylor <i>et al.,</i> 2003</a>; <a href="#ref-83">Thomassin <i>et al.,</i> 2012</a>; for a review see: <a href="#ref-89">Torre &amp; Lieberman, 2018</a>) and restricts repeated application. While verbal rating scales are typically more efficient than questionnaires, they also require mental effort since users are required to relate their affective state to verbal descriptions (labels). Graphical rating tools however allow users to intuitively project their feelings to figural elements that correspond to their current affective state.</p><p class="" id=d5188e366>Arousal and pleasantness (valence) are principal dimensions of affective responses to environmental stimuli (<a href="#ref-61">Mehrabian &amp; Russell, 1974</a>). A popular graphical affective self-report tool is the Self-Assessment Mannikin (SAM) (<a href="#ref-11">Bradley &amp; Lang, 1994</a>): a set of iconic humanoid figures representing different degrees of valence, arousal, and dominance. Users respond by selecting from each of the three scales the figure that best expresses their own feeling. The SAM has previously been used for the affective rating of video fragments (e.g., <a href="#ref-10">Bos <i>et al.,</i> 2013</a>; <a href="#ref-20">Deng <i>et al.,</i> 2017</a>; <a href="#ref-21">Detenber <i>et al.,</i> 2000</a>; <a href="#ref-22">Detenber <i>et al.,</i> 1998</a>; <a href="#ref-24">Ellard <i>et al.,</i> 2012</a>; <a href="#ref-25">Ellis &amp; Simons, 2005</a>; <a href="#ref-28">Fernández <i>et al.,</i> 2012</a>; <a href="#ref-77">Soleymani <i>et al.,</i> 2008</a>) and auditory stimuli (e.g., <a href="#ref-7">Bergman <i>et al.,</i> 2009</a>; <a href="#ref-13">Bradley &amp; Lang, 2000</a>; <a href="#ref-54">Lemaitre <i>et al.,</i> 2012</a>; <a href="#ref-64">Morris &amp; Boone, 1998</a>; <a href="#ref-68">Redondo <i>et al.,</i> 2008</a>; <a href="#ref-92">Vastfjall <i>et al.,</i> 2012</a>). Although the SAM is validated and widely used, users often misunderstand the depicted emotions (<a href="#ref-36">Hayashi <i>et al.,</i> 2016</a>; <a href="#ref-99">Yusoff <i>et al.,</i> 2013</a>): especially the arousal dimension (shown as an ‘explosion’ in the belly area) is often interpreted incorrectly (<a href="#ref-8">Betella &amp; Verschure, 2016</a>; <a href="#ref-14">Broekens &amp; Brinkman, 2013</a>; <a href="#ref-16">Chen <i>et al.,</i> 2018</a>; <a href="#ref-88">Toet <i>et al.,</i> 2018</a>). The SAM also requires a successive assessment of the stimulus on each of its individual dimensions. To overcome these problems we developed an alternative intuitive graphical self-report tool to measure valence and arousal: the EmojiGrid (<a href="#ref-88">Toet <i>et al.,</i> 2018</a>). The EmojiGrid is a square grid (resembling the Affect Grid: <a href="#ref-72">Russell <i>et al.,</i> 1989</a>), labeled with emoji that express various degrees of valence and arousal. Users rate the valence and arousal of a given stimulus by simply clicking on the grid. It has been found that the use of emoji as scale anchors facilitates affective over cognitive responses (<a href="#ref-67">Phan <i>et al.,</i> 2019</a>). Previous studies on the assessment of affective responses to food images (<a href="#ref-88">Toet <i>et al.,</i> 2018</a>) and odorants (<a href="#ref-85">Toet <i>et al.,</i> 2019</a>) showed that the EmojiGrid is self-explaining: valence and arousal ratings did not depend on framing and verbal instructions (<a href="#ref-44">Kaneko <i>et al.,</i> 2019</a>; <a href="#ref-88">Toet <i>et al.,</i> 2018</a>). The current study was performed to investigate the EmojiGrid for the affective appraisal of auditory and visual stimuli.</p><p class="" id=d5188e526>Sounds can induce a wide range of affective and physiological responses (<a href="#ref-13">Bradley &amp; Lang, 2000</a>; <a href="#ref-34">Gomez &amp; Danuser, 2004</a>; <a href="#ref-68">Redondo <i>et al.,</i> 2008</a>). Ecological sounds have a clear association with objects or events. However, music can also elicit emotional responses that are as vivid and intense as emotions that are elicited by real-world events (<a href="#ref-2">Altenmüller <i>et al.,</i> 2002</a>; <a href="#ref-30">Gabrielsson &amp; Lindström, 2003</a>; <a href="#ref-49">Krumhansl, 1997</a>) and can activate brain regions associated with reward, motivation, pleasure and the mediation of dopaminergic levels (<a href="#ref-9">Blood &amp; Zatorre, 2001</a>; <a href="#ref-15">Brown <i>et al.,</i> 2004</a>; <a href="#ref-62">Menon &amp; Levitin, 2005</a>; <a href="#ref-76">Small <i>et al.,</i> 2001</a>). Even abstract or highly simplified sounds can convey different emotions (<a href="#ref-63">Mion <i>et al.,</i> 2010</a>; <a href="#ref-92">Vastfjall <i>et al.,</i> 2012</a>) and can elicit vivid affective mental images when they have some salient acoustic properties in common with the actual sounds. As a result, auditory perception is emotionally biased (<a href="#ref-80">Tajadura-Jiménez <i>et al.,</i> 2010</a>; <a href="#ref-81">Tajadura-Jiménez &amp; Västfjäll, 2008</a>). Video clips can also effectively evoke various affective and physiological responses (<a href="#ref-1">Aguado <i>et al.,</i> 2018</a>; <a href="#ref-16">Carvalho <i>et al.,</i> 2012</a>; <a href="#ref-70">Rottenberg <i>et al.,</i> 2007</a>; <a href="#ref-73">Schaefer <i>et al.,</i> 2010</a>). While sounds and imagery individually elicit various affective responses that recruit similar brain structures (<a href="#ref-32">Gerdes <i>et al.,</i> 2014</a>), a wide range of non-linear interactions at multiple processing levels in the brain make that their combined effects are not a priori evident (e.g., <a href="#ref-79">Spreckelmeyer <i>et al.,</i> 2006</a>; for a review see: <a href="#ref-74">Schreuder <i>et al.,</i> 2016</a>). Several standardized and validated affective databases have been presented to enable a systematic investigation of sound (<a href="#ref-12">Bradley &amp; Lang, 1999</a>; <a href="#ref-98">Yang <i>et al.,</i> 2018</a>) and video (<a href="#ref-1">Aguado <i>et al.,</i> 2018</a>; <a href="#ref-16">Carvalho <i>et al.,</i> 2012</a>; <a href="#ref-37">Hewig <i>et al.,</i> 2005</a>; <a href="#ref-73">Schaefer <i>et al.,</i> 2010</a>) elicited affective responses.</p><p class="" id=d5188e671>This study evaluates the EmojiGrid as a self-report tool for the affective appraisal of auditory and visual events. In two experiments, participants were presented with different sound and video clips, covering both a large part of the valence scale and a wide range of semantic categories. The video clips were stripped of their sound channel (silent) to avoid interaction effects. After perceiving each stimulus, participants reported their affective appraisal (valence and arousal) using the EmojiGrid. The sound samples (<a href="#ref-98">Yang <i>et al.,</i> 2018</a>) and video clips (<a href="#ref-1">Aguado <i>et al.,</i> 2018</a>) had been validated in previous studies in the literature using 9-point SAM affective rating scales. This enables an evaluation of the EmojiGrid by directly comparing the mean affective ratings obtained with it to those that were obtained with the SAM.</p><p class="" id=d5188e687>In this study we also investigate how the mean valence and arousal ratings for the different stimuli are related. Although the relation between valence and arousal for affective stimuli varies between individuals and cultures (<a href="#ref-52">Kuppens <i>et al.,</i> 2017</a>), it typically shows a quadratic (U-shaped) form across persons (i.e., at the group level): stimuli that are on average rated either high or low on valence are typically also rated as more arousing than stimuli that are on average rated near neutral on valence (<a href="#ref-51">Kuppens <i>et al.,</i> 2013</a>; <a href="#ref-59">Mattek <i>et al.,</i> 2017</a>). For the valence and arousal ratings obtained with the EmojiGrid, we therefore also investigate to what extent a quadratic form describes their relation at the group level. </p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d5188e711>Methods</h2><div class=section><a name=d5188e714 class=n-a></a><h3 class=section-title>Participants</h3><p class="" id=d5188e719>English speaking participants from the UK were recruited via the Prolific database (<a target=xrefwindow href="https://www.prolific.co/" id=d5188e721>https://www.prolific.co/</a>). Exclusion criteria were age (outside the range of 18–35 years old) and hearing or (color) vision deficiencies. No further attempts were made to eliminate any sampling bias.</p><p class="" id=d5188e725>We estimated the sample size required for this study with the “<a target=xrefwindow href="https://cran.r-project.org/package=ICC.Sample.Size" id=d5188e727>ICC.Sample.Size</a>” R-package, assuming an ICC of 0.70 (generally considered as ‘moderate’: <a href="#ref-53">Landis &amp; Koch, 1977</a>), and determined that sample sizes of 57 (Experiment 1) and 23 (Experiment 2) would yield a 95% confidence interval of sufficient precision (±0.07; <a href="#ref-53">Landis &amp; Koch, 1977</a>). Because the current experiment was run online and not in a well-controlled laboratory environment, we aimed to recruit about 2–3 times the minimum required number of participants.</p><p class="" id=d5188e737>This study was approved by the by TNO Ethics Committee (Application nr: 2019-012), and was conducted in accordance with the Helsinki Declaration of 1975, as revised in 2013 (<a href="#ref-96">World Medical Association, 2013</a>). Participants electronically signed an informed consent by clicking “<i>I agree to participate in this study</i>”, affirming that they were at least 18 years old and voluntarily participated in the study. The participants received a small financial compensation for their participation.</p></div><div class=section><a name=d5188e747 class=n-a></a><h3 class=section-title>Measures</h3><p class="" id=d5188e752><b><i>Demographics.</i></b> The participants in this study reported their nationality, gender and age.</p><p class="" id=d5188e758><b><i>Valence and arousal: the EmojiGrid.</i></b> The EmojiGrid is a square grid (similar to the Affect Grid: <a href="#ref-72">Russell <i>et al.,</i> 1989</a>), labeled with emoji that express various degrees of valence and arousal (<a href="#f1">Figure 1</a>). Users rate their affective appraisal (i.e., the valence and arousal) of a given stimulus by pointing and clicking at the location on the grid that that best represents their impression. The EmojiGrid was originally developed and validated for the affective appraisal of food stimuli, since the SAM appeared to be frequently misunderstood in that context (<a href="#ref-88">Toet <i>et al.,</i> 2018</a>). It has since also been used and validated for the affective appraisal of odors (<a href="#ref-85">Toet <i>et al.,</i> 2019</a>).</p><a name=f1 class=n-a></a><div class="fig panel clearfix"><a target=_blank href="https://f1000researchdata.s3.amazonaws.com/manuscripts/27685/61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure1.gif"><img alt="61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure1.gif" src="https://f1000researchdata.s3.amazonaws.com/manuscripts/27685/61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure1.gif"></a><div class=caption><h3>Figure 1. The EmojiGrid.</h3><p id=d5188e795>The iconic facial expressions range from disliking (unpleasant) via neutral to liking (pleasant) along the horizontal (valence) axis, while their intensity increases along the vertical (arousal) axis. This figure has been reproduced with permission from <a href="#ref-88">Toet <i>et al.,</i> 2018</a>.</p></div></div></div><div class=section><a name=d5188e809 class=n-a></a><h3 class=section-title>Procedure</h3><p class="" id=d5188e814>Participants took part in two anonymous online surveys, created with the Gorilla experiment builder (<a href="#ref-5">Anwyl-Irvine <i>et al.,</i> 2019</a>). After thanking the participants for their interest, the surveys first gave a general introduction to the experiment. The instructions asked the participants to perform the survey on a computer or tablet (but not on a device with a small screen such as a smartphone) and to activate the full-screen mode of their browser. This served to maximize the resolution of the questionnaire and to prevent distractions by other programs running in the background. In Experiment I (sounds) the participants were asked to turn off any potentially disturbing sound sources in their room. Then the participants were informed that they would be presented with a given number of different stimuli (sounds in Experiment I and video clips in Experiment II) during the experiment and they were asked to rate their affective appraisal of each stimulus. The instructions also mentioned that it was important to respond seriously, while there would be no correct or incorrect answers. Participants could electronically sign an informed consent. By clicking “ <i>I agree to participate in this study</i> ”, they confirmed that they were at least 18 years old and that their participation was voluntary. The survey then continued with an assessment of the demographic variables (nationality, gender, age).</p><p class="" id=d5188e826>Next, the participants were familiarized with the EmojiGrid. First, it was explained how the tool could be used to rate valence and arousal for each stimulus. The instructions were: “<i>To respond, first place the cursor inside the grid on a position that best represents how you feel about the stimulus, and then click the mouse button.</i>” Note that the dimensions of valence and arousal were not mentioned here. Then the participants performed two practice trials. In Experiment I, these practice trials also allowed the repeated playing of the sound stimulus. This was done to allow the participants to adjust the sound level of their computer system. The actual experiment started immediately after the practice trials. The stimuli were presented in random order. The participants rated each stimulus by clicking at the appropriate location on the EmojiGrid. The next stimulus appeared immediately after clicking. There were no time restrictions. On average, each experiment lasted about 15 minutes.</p><p class="" id=d5188e832>Experiment I: Sounds</p><p class="" id=d5188e835>This experiment served to validate the EmojiGrid as a rating tool for the affective appraisal of sound-evoked emotions. Thereto, participants rated valence and arousal for a selection of sounds from a validated sound database using the EmojiGrid. The results are compared with the corresponding SAM ratings provided for each sound in the database.</p><p class="" id=d5188e839><b><i>Stimuli.</i></b> The sound stimuli used in this experiment are 77 sound clips from the expanded version of the validated International Affective Digitized Sounds database (IADS-E, <a target=xrefwindow href="https://docs.google.com/forms/d/e/1FAIpQLSfCWszQ6Ljru0dcsmldxxz4yxzJmqf-tRWrG2JT7T364v-Etw/viewform" id=d5188e844>available upon request</a>; <a href="#ref-98">Yang <i>et al.,</i> 2018</a>). The sound clips were selected from 9 different semantic categories: scenarios (2), breaking sounds (8), daily routine sounds (8), electric sounds (8), people (8), sound effects (8), transport (8), animals (9), and music (10). For all sounds, <a href="#ref-98">Yang <i>et al.</i> (2018)</a> provided normative ratings for valence and arousal, obtained with 9-point SAM scales and collected by at least 22 participants from a total pool of 207 young Japanese adults (103 males, 104 females, mean age 21.3 years, SD=2.4). The selection used in the current study was such that the mean affective (valence and arousal) ratings provided for stimuli in the same semantic category were maximally distributed over the two-dimensional affective space (ranging from very negative like a car horn, hurricane sounds or sounds of vomiting, via neutral like people walking up a stairs, to very positive music). As a result, the entire stimulus set is a representative cross-section of the IADS-E covering a large area of the affective space. All sound clips had a fixed duration of 6s. The exact composition of the stimulus set is provided in the Supplementary Material. Each participant rated all sound clips.</p><p class="" id=d5188e860><b><i>Participants.</i></b> A total of 150 persons (74 males, 76 females) participated in this experiment. Their mean age was 25.2 (SD= 3.5) years.</p><p class="" id=d5188e866>Experiment II: Video clips</p><p class="" id=d5188e869>This experiment served to validate the EmojiGrid as a self-report tool for the assessment of emotions evoke by (silent) video clips. Participants rated valence and arousal for a selection of video clips from a validated set of video fragments using the EmojiGrid. The results are compared with the corresponding SAM ratings for the video clips (<a href="#ref-1">Aguado <i>et al.,</i> 2018</a>).</p><p class="" id=d5188e878><b><i>Stimuli.</i></b> The stimuli comprised of a set of 50 film fragments with different affective content (20 positive ones like a coral reef with swimming fishes and jumping dolphins, 10 neutral ones like a man walking in the street or an elevator going down, and 20 negative ones like someone being attacked or a car accident scene). All video clips had a fixed duration of 10 s and were stripped of their soundtracks (for detailed information about the video clips and their availability see <a href="#ref-1">Aguado <i>et al.,</i> 2018</a>). <a href="#ref-1">Aguado <i>et al.</i> (2018)</a> obtained normative ratings for valence and arousal, collected by 38 young adults (19 males, 19 females, mean age 22.3 years, SD=2.2) using 9-point SAM scales. In the present study, each participant rated all video clips using the EmojiGrid.</p><p class="" id=d5188e896><b><i>Participants.</i></b> A total of 60 persons (32 males, 28 females) participated in this experiment. Their mean age was 24.5 (SD= 3.3) years.</p></div><div class=section><a name=d5188e903 class=n-a></a><h3 class=section-title>Data analysis</h3><p class="" id=d5188e908>All statistical analyses were performed with IBM SPSS Statistics 26 (<a target=xrefwindow href="http://www.ibm.com" id=d5188e910>www.ibm.com</a>) for Windows. The computation of the intraclass correlation coefficient (ICC) estimates with their associated 95% confidence intervals was based on a mean-rating (k = 3), consistency, 2-way mixed-effects model (<a href="#ref-48">Koo &amp; Li, 2016</a>; <a href="#ref-75">Shrout &amp; Fleiss, 1979</a>). ICC values less than 0.5 indicate poor reliability, values between 0.5 and 0.75 suggest moderate reliability, values between 0.75 and 0.9 represent good reliability, while values greater than 0.9 indicate excellent reliability (<a href="#ref-48">Koo &amp; Li, 2016</a>; <a href="#ref-53">Landis &amp; Koch, 1977</a>). For all other analyses a probability level of p &lt; 0.05 was considered to be statistically significant.</p><p class="" id=d5188e926>MATLAB 2020a was used to further investigate the data. The mean valence and arousal responses were computed across all participants and for each of the stimuli. MATLAB’s Curve Fitting Toolbox (version 3.5.7) was used to compute a least-squares fit of a quadratic function to the data points. Adjusted R-squared values were calculated to quantify the agreement between the data and the quadratic fits.</p></div></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d5188e933>Results</h2><div class=section><a name=d5188e936 class=n-a></a><h3 class=section-title>Experiment I</h3><p class="" id=d5188e941><a href="#f2">Figure 2</a> shows the relation between the mean valence and arousal ratings for the 77 IADS-E sounds used as stimuli in the current study, measured both with the EmojiGrid (this study) and with a 9-point SAM scale by <a href="#ref-98">Yang <i>et al.</i> (2018)</a>. The curves in this figure represent least-squares quadratic fits to the data points. The adjusted R-squared values are 0.62 for results obtained with the EmojiGrid and 0.22 for the SAM results. Hence, both methods yield a relation between mean valence and arousal ratings that can indeed be described by a quadratic (U-shaped) relation at the nomothetic (group) level.</p><a name=f2 class=n-a></a><div class="fig panel clearfix"><a target=_blank href="https://f1000researchdata.s3.amazonaws.com/manuscripts/27685/61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure2.gif"><img alt="61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure2.gif" src="https://f1000researchdata.s3.amazonaws.com/manuscripts/27685/61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure2.gif"></a><div class=caption><h3>Figure 2. Mean valence and arousal ratings for selected sounds from the IADS-E database.</h3><p id=d5188e962> Blue circles represent data obtained with the SAM (<a href="#ref-98">Yang <i>et al.,</i> 2018</a>), while red dots represent data obtained with the EmojiGrid (this study). The curves represent quadratic fits to the corresponding data points.</p></div></div><p class="" id=d5188e975>The linear (two-tailed) Pearson correlation coefficients between the valence and arousal ratings obtained with the EmojiGrid (present study) and with the SAM (<a href="#ref-98">Yang <i>et al.,</i> 2018</a>) were, respectively, 0.881 and 0.760 (p&lt;0.001). To further quantify the agreement between both rating tools we computed intraclass correlation coefficients (ICC) with their 95% confidence intervals for the mean valence and arousal ratings between both studies. The ICC value for valence is 0.936 [0.899–0.959] while the ICC for arousal is 0.793 [0.674–0.868], indicating both studies show an excellent agreement for valence and a good agreement for arousal (even though the current study was performed via the internet and therefore did not provide the amount of control over many experimental factors as one would have in a lab experiment).</p></div><div class=section><a name=d5188e985 class=n-a></a><h3 class=section-title>Experiment II</h3><p class="" id=d5188e990><a href="#f3">Figure 3</a> shows the relation between the mean valence and arousal ratings for the 50 video clips tested, obtained with the EmojiGrid (this study) and with a nine-point SAM scale (<a href="#ref-1">Aguado <i>et al.,</i> 2018</a>). The curves in this figure represent quadratic fits to the data points. The adjusted R-squared values are respectively 0.68 and 0.78. Hence, both methods yield a relation between mean valence and arousal ratings that can be described by a quadratic (U-shaped) relation at the nomothetic (group) level.</p><a name=f3 class=n-a></a><div class="fig panel clearfix"><a target=_blank href="https://f1000researchdata.s3.amazonaws.com/manuscripts/27685/61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure3.gif"><img alt="61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure3.gif" src="https://f1000researchdata.s3.amazonaws.com/manuscripts/27685/61915fff-eaf5-45cf-aae9-6c4b5aa404db_figure3.gif"></a><div class=caption><h3>Figure 3. Mean valence and arousal ratings for affective film clips.</h3><p id=d5188e1011>Blue circles represent data obtained with the SAM (<a href="#ref-1">Aguado <i>et al.,</i> 2018</a>) while red dots represent data obtained with the EmojiGrid (this study). The curves show quadratic fits to the corresponding data points.</p></div></div><p class="" id=d5188e1024>The linear (two-tailed) Pearson correlation coefficients between the valence and arousal ratings obtained with the EmojiGrid (present study) and with the SAM (<a href="#ref-1">Aguado <i>et al.,</i> 2018</a>) were respectively 0.963 and 0.624 (p&lt;0.001). To further quantify the agreement between both rating tools we computed intraclass correlation coefficients (ICC) with their 95% confidence intervals for the mean valence and arousal ratings between both studies. The ICC value for valence is 0.981 [0.967 – 0.989] while the ICC for arousal is 0.721 [0.509 – 0.842], indicating both studies show an excellent agreement for valence and a good agreement for arousal.</p><p class="" id=d5188e1033>Raw data from each experiment are available as <i>Underlying data</i> (<a href="#ref-84">Toet, 2020</a>).</p></div></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d5188e1046>Conclusion</h2><p class="" id=d5188e1049>In this study we evaluated the recently developed EmojiGrid self-report tool for the affective rating of sounds and video. In two experiments, observers rated their affective appraisal of sound and video clips using the EmojiGrid. The results show a close correspondence between the mean ratings obtained with the EmojiGrid and those obtained with the validated SAM tool in previous validation studies in the literature: the agreement is excellent for valence and good for arousal, both for sound and video. Also, for both sound and video, the EmojiGrid yields the universal U-shaped (quadratic) relation between mean valence and arousal that is typically observed for affective sensory stimuli. We conclude that the EmojiGrid is an efficient affective self-report tool for the assessment of sound and video-evoked emotions.</p><p class="" id=d5188e1052>Future applications of the EmojiGrid may involve the real-time evaluation of affective events or the provision of affective feedback. For instance, in studies on affective communication in human-computer interaction (e.g., <a href="#ref-81">Tajadura-Jiménez &amp; Västfjäll, 2008</a>), the EmojiGrid can be deployed as a continuous response tool by moving a mouse-controlled cursor over the grid while logging the cursor coordinates. Such an implementation may also afford the affective annotation of multimedia (<a href="#ref-17">Chen <i>et al.,</i> 2007</a>; <a href="#ref-71">Runge <i>et al.,</i> 2016</a>), and could be useful for personalized affective video retrieval or recommender systems (<a href="#ref-35">Hanjalic &amp; Xu, 2005</a>; <a href="#ref-47">Koelstra <i>et al.,</i> 2012</a>; <a href="#ref-57">Lopatovska &amp; Arapakis, 2011</a>;<a href="#ref-97"> Xu <i>et al.,</i> 2008</a>), for real-time affective appraisal of entertainment (<a href="#ref-29">Fleureau <i>et al.,</i> 2012</a>) or to provide affective input to serious gaming applications (<a href="#ref-4">Anolli <i>et al.,</i> 2010</a>) and affective music generation (<a href="#ref-46">Kim &amp; André, 2004</a>). Sensiks (<a target=xrefwindow href="http://www.sensiks.com" id=d5188e1103>www.sensiks.com</a>) has adopted a simplified version of the EmojiGrid in its Sensory Reality Pod to enable the user to select and tune multisensory (visual, auditory, tactile and olfactory) affective experiences.</p></div><div id=article1-body class=generated-article-body><h2 class=main-title id=d5188e1110>Data availability</h2><div class=section><a name=d5188e1113 class=n-a></a><h3 class=section-title>Underlying data</h3><p class="" id=d5188e1118>Open Science Framework: Affective rating of audio and video clips using the EmojiGrid. <a target=xrefwindow href="https://doi.org/10.17605/OSF.IO/GTZH4" id=d5188e1120>https://doi.org/10.17605/OSF.IO/GTZH4</a> (<a href="#ref-84">Toet, 2020</a>).</p><p class="" id=d5188e1127>File ‘Results_sound_video’ (XLSX) contains the EmojiGrid co-ordinates selected by each participant following each stimulus.</p><p class="" id=d5188e1130>Data are available under the terms of the <a target=xrefwindow href="https://creativecommons.org/licenses/by/4.0/legalcode" id=d5188e1132>Creative Commons Attribution 4.0 International license</a> (CC-BY 4.0).</p></div></div><div id=article1-back class=generated-article-footer><div class=back-section><a name=d5188e1141 class=n-a></a><h2 class=main-title id=d5188e1143>Acknowledgements</h2><p class="" id=d5188e1146>The authors thank Dr. Wanlu Yang (Hiroshima University, Higashi-Hiroshima, Japan) for providing the IADS-E sound database, and Dr. Luis Aguado (Universidad Complutense de Madrid, Spain) for providing the validated movie clips.</p></div><div class=back-section><a name=d5188e1150 class=n-a></a><span class="research-layout prime-recommended-wrapper reference-heading is-hidden"><span class=faculty-opinion-icon></span><span class="prime-red big">Faculty Opinions recommended</span></span><h2 class=main-title id=d5699>References</h2><div class="section ref-list"><a name=d5188e1150 class=n-a></a><ul><li><a name=ref-1 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1154 class=n-a></a>Aguado L, Fernández-Cahill M, Román FJ, <i> et al.</i>: Evaluative and psychophysiological responses to short film clips of different emotional content. <i>J Psychophysiol.</i> 2018; <b>32</b>(1): 1–19. <a target=xrefwindow id=d5188e1165 href="https://doi.org/10.1027/0269-8803/a000180">Publisher Full Text </a></span></li><li><a name=ref-2 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1171 class=n-a></a>Altenmüller E, Schürmann K, Lim VK, <i> et al.</i>: Hits to the left, flops to the right: different emotions during listening to music are reflected in cortical lateralisation patterns. <i>Neuropsychologia.</i> 2002; <b>40</b>(13): 2242–2256. <a target=xrefwindow id=d5188e1182 href="http://www.ncbi.nlm.nih.gov/pubmed/12417455">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1185 href="https://doi.org/10.1016/s0028-3932(02)00107-0">Publisher Full Text </a></span></li><li><a name=ref-3 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1191 class=n-a></a>Anderson LM, Mulligan BE, Goodman LS, <i> et al.</i>: Effects of sounds on preferences for outdoor settings. <i>Environ Behav.</i> 1983; <b>15</b>(5): 539–566. <a target=xrefwindow id=d5188e1202 href="https://doi.org/10.1177/0013916583155001">Publisher Full Text </a></span></li><li><a name=ref-4 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1208 class=n-a></a>Anolli L, Mantovani F, Confalonieri L, <i> et al.</i>: Emotions in serious games: From experience to assessment. <i>International Journal of Emerging Technologies in Learning.</i> 2010; <b>5</b>(Special Issue 2): 7–16. <a target=xrefwindow id=d5188e1219 href="https://online-journals.org/index.php/i-jet/article/view/1496">Reference Source</a></span></li><li><a name=ref-5 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1225 class=n-a></a>Anwyl-Irvine A, Massonnié J, Flitton A, <i> et al.</i>: Gorilla in our Midst: An online behavioral experiment builder. <i>bioRxiv.</i> 2019; 438242. <a target=xrefwindow id=d5188e1233 href="https://doi.org/10.1101/438242">Publisher Full Text </a></span></li><li><a name=ref-6 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1240 class=n-a></a>Baveye Y, Chamaret C, Dellandréa E, <i> et al.</i>: Affective video content analysis: a multidisciplinary insight. <i>IEEE Trans Affect Comput.</i> 2018; <b>9</b>(4): 396–409. <a target=xrefwindow id=d5188e1251 href="https://doi.org/10.1109/TAFFC.2017.2661284">Publisher Full Text </a></span></li><li><a name=ref-7 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1257 class=n-a></a>Bergman P, Sköld A, Västfjäll D, <i> et al.</i>: Perceptual and emotional categorization of sound. <i>J Acoust Soc Am.</i> 2009; <b>126</b>(6): 3156–3167. <a target=xrefwindow id=d5188e1268 href="http://www.ncbi.nlm.nih.gov/pubmed/20000929">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1271 href="https://doi.org/10.1121/1.3243297">Publisher Full Text </a></span></li><li><a name=ref-8 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1277 class=n-a></a>Betella A, Verschure PFMJ: The Affective Slider: A digital self-assessment scale for the measurement of human emotions. <i>PLoS One.</i> 2016; <b>11</b>(2): e0148037. <a target=xrefwindow id=d5188e1285 href="http://www.ncbi.nlm.nih.gov/pubmed/26849361">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1288 href="https://doi.org/10.1371/journal.pone.0148037">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1291 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4743948">Free Full Text </a></span></li><li><a name=ref-9 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1297 class=n-a></a>Blood AJ, Zatorre RJ: Intensely pleasurable responses to music correlate with activity in brain regions implicated in reward and emotion. <i>Proc Natl Acad Sci U S A.</i> 2001; <b>98</b>(20): 11818–11823. <a target=xrefwindow id=d5188e1305 href="http://www.ncbi.nlm.nih.gov/pubmed/11573015">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1308 href="https://doi.org/10.1073/pnas.191355898">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1311 href="http://www.ncbi.nlm.nih.gov/pmc/articles/58814">Free Full Text </a></span></li><li><a name=ref-10 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1317 class=n-a></a>Bos MGN, Jentgens P, Beckers T, <i> et al.</i>: Psychophysiological response patterns to affective film stimuli. <i>PLoS One.</i> 2013; <b>8</b>(4): e62661. <a target=xrefwindow id=d5188e1328 href="http://www.ncbi.nlm.nih.gov/pubmed/23646134">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1331 href="https://doi.org/10.1371/journal.pone.0062661">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1335 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3639962">Free Full Text </a></span></li><li><a name=ref-11 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1341 class=n-a></a>Bradley MM, Lang PJ: Measuring emotion: the Self-Assessment Manikin and the semantic differential. <i>J Behav Ther Exp Psychiatry.</i> 1994; <b>25</b>(1): 49–59. <a target=xrefwindow id=d5188e1349 href="http://www.ncbi.nlm.nih.gov/pubmed/7962581">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1352 href="https://doi.org/10.1016/0005-7916(94)90063-9">Publisher Full Text </a></span></li><li><a name=ref-12 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1359 class=n-a></a>Bradley MM, Lang PJ: International affective digitized sounds (IADS): Stimuli, instruction manual and affective ratings. (Gainesville, FL: <i>The Center for Research in Psychophysiology</i>, University of Florida). 1999. <a target=xrefwindow id=d5188e1364 href="https://books.google.co.in/books/about/The_International_Affective_Digitized_So.html?id=NFeZMwEACAAJ&amp;redir_esc=y">Reference Source</a></span></li><li><a name=ref-13 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1370 class=n-a></a>Bradley MM, Lang PJ: Affective reactions to acoustic stimuli. <i>Psychophysiology.</i> 2000; <b>37</b>(2): 204–215. <a target=xrefwindow id=d5188e1378 href="http://www.ncbi.nlm.nih.gov/pubmed/10731770">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1381 href="https://doi.org/10.1111/1469-8986.3720204">Publisher Full Text </a></span></li><li><a name=ref-14 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1387 class=n-a></a>Broekens J, Brinkman WP: AffectButton: A method for reliable and valid affective self-report. <i>Int J Hum Comput Stud.</i> 2013; <b>71</b>(6): 641–667. <a target=xrefwindow id=d5188e1395 href="https://doi.org/10.1016/j.ijhcs.2013.02.003">Publisher Full Text </a></span></li><li><a name=ref-15 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1401 class=n-a></a>Brown S, Martinez MJ, Parsons LM: Passive music listening spontaneously engages limbic and paralimbic systems. <i>Neuroreport.</i> 2004; <b>15</b>(13): 2033–2037. <a target=xrefwindow id=d5188e1409 href="http://www.ncbi.nlm.nih.gov/pubmed/15486477">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1412 href="https://doi.org/10.1097/00001756-200409150-00008">Publisher Full Text </a></span></li><li><a name=ref-16 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1418 class=n-a></a>Carvalho S, Leite J, Galdo-Álvarez S, <i> et al.</i>: The emotional movie database (EMDB): A self-report and psychophysiological study. <i>Appl Psychophysiol Biofeedback.</i> 2012; <b>37</b>(4): 279–294. <a target=xrefwindow id=d5188e1429 href="http://www.ncbi.nlm.nih.gov/pubmed/22767079">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1432 href="https://doi.org/10.1007/s10484-012-9201-6">Publisher Full Text </a></span></li><li><a name=ref-17 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1438 class=n-a></a>Chen L, Chen GC, Xu CZ, <i> et al.</i>: EmoPlayer: A media player for video clips with affective annotations. <i>Interact Comput.</i> 2007; <b>20</b>(1): 17–28. <a target=xrefwindow id=d5188e1449 href="https://doi.org/10.1016/j.intcom.2007.06.003">Publisher Full Text </a></span></li><li><a name=ref-18 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1456 class=n-a></a>Chen Y, Gao Q, Lv Q, <i> et al.</i>: Comparing measurements for emotion evoked by oral care products. <i>Int J Ind Ergon.</i> 2018; <b>66</b>: 119–129. <a target=xrefwindow id=d5188e1467 href="https://doi.org/10.1016/j.ergon.2018.02.013">Publisher Full Text </a></span></li><li><a name=ref-19 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1473 class=n-a></a>Constantinou E, Van Den Houte M, Bogaerts K, <i> et al.</i>: Can words heal? Using affect labeling to reduce the effects of unpleasant cues on symptom reporting. <i>Front Psychol.</i> 2014; <b>5</b>: 807. <a target=xrefwindow id=d5188e1484 href="http://www.ncbi.nlm.nih.gov/pubmed/25101048">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1487 href="https://doi.org/10.3389/fpsyg.2014.00807">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1491 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4106456">Free Full Text </a></span></li><li><a name=ref-20 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1497 class=n-a></a>Deng Y, Yang M, Zhou R: A new standardized emotional film database for asian culture. <i>Front Psychol.</i> 2017; <b>8</b>: 1941. <a target=xrefwindow id=d5188e1505 href="http://www.ncbi.nlm.nih.gov/pubmed/29163312">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1508 href="https://doi.org/10.3389/fpsyg.2017.01941">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1511 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5675887">Free Full Text </a></span></li><li><a name=ref-21 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1517 class=n-a></a>Detenber BH, Simons RF, Reiss JE: The emotional significance of color in television presentations. <i>Media Psychol.</i> 2000; <b>2</b>(4): 331–355. <a target=xrefwindow id=d5188e1525 href="https://doi.org/10.1207/S1532785XMEP0204_02">Publisher Full Text </a></span></li><li><a name=ref-22 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1531 class=n-a></a>Detenber BH, Simons RF, Bennett GG Jr: Roll 'em!: The effects of picture motion on emotional responses. <i>J Broadcast Electron Media.</i> 1998; <b>42</b>(1): 113–128. <a target=xrefwindow id=d5188e1539 href="https://doi.org/10.1080/08838159809364437">Publisher Full Text </a></span></li><li><a name=ref-23 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1545 class=n-a></a>Ekman I, Lankoski P: Hair-raising entertainment: Emotions, sound, and structure in Silent Hill 2 and Fatal Frame. In: <i> Horro video games. Essyas on the fusion of fear and play.</i> ed. B. Perron. Jefferson, NC USA: Mc Farland &amp; Company, Inc., 2009; 181–199. <a target=xrefwindow id=d5188e1550 href="https://www.researchgate.net/publication/200808890_Hair-Raising_Entertainment_Emotions_Sound_and_Structure_in_Silent_Hill_2_and_Fatal_Frame">Reference Source</a></span></li><li><a name=ref-24 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1557 class=n-a></a>Ellard KK, Farchione TJ, Barlow DH: Relative effectiveness of emotion induction procedures and the role of personal relevance in a clinical sample: A comparison of film, images, and music. <i>J Psychopathol Behav Assess.</i> 2012; <b>34</b>(2): 232–243. <a target=xrefwindow id=d5188e1565 href="https://doi.org/10.1007/s10862-011-9271-4">Publisher Full Text </a></span></li><li><a name=ref-25 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1571 class=n-a></a>Ellis RJ, Simons RF: The impact of music on subjective and physiological indices of emotion while viewing films. <i>Psychomusicology: A Journal of Research in Music Cognition.</i> 2005; <b>19</b>(1): 15–40. <a target=xrefwindow id=d5188e1579 href="https://doi.org/10.1037/h0094042">Publisher Full Text </a></span></li><li><a name=ref-26 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1585 class=n-a></a>Fagerberg P, Ståhl A, Höök K: eMoto: emotionally engaging interaction. <i>Pers Ubiquitous Comput.</i> 2004; <b>8</b>(5): 377–381. <a target=xrefwindow id=d5188e1593 href="https://doi.org/10.1007/s00779-004-0301-z">Publisher Full Text </a></span></li><li><a name=ref-27 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1599 class=n-a></a>Fazio RH: On the automatic activation of associated evaluations: An overview. <i>Cognition &amp; Emotion.</i> 2001; <b>15</b>(2): 115–141. <a target=xrefwindow id=d5188e1607 href="https://doi.org/10.1080/02699930125908">Publisher Full Text </a></span></li><li><a name=ref-28 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1613 class=n-a></a>Fernández C, Pascual J, Soler J, <i> et al.</i>: Physiological responses induced by emotion-eliciting films. <i>Appl Psychophysiol Biofeedback.</i> 2012; <b>37</b>(2): 73–79. <a target=xrefwindow id=d5188e1624 href="http://www.ncbi.nlm.nih.gov/pubmed/22311202">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1627 href="https://doi.org/10.1007/s10484-012-9180-7">Publisher Full Text </a></span></li><li><a name=ref-29 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1633 class=n-a></a>Fleureau J, Guillotel P, Quan H: Physiological-based affect event detector for entertainment video applications. <i>IEEE Trans Affect Comput.</i> 2012; <b>3</b>(3): 379–385. <a target=xrefwindow id=d5188e1641 href="https://doi.org/10.1109/T-AFFC.2012.2">Publisher Full Text </a></span></li><li><a name=ref-30 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1648 class=n-a></a>Gabrielsson A, Lindström Wik S: Strong experiences related to music: A descriptive system. <i>Music Sci.</i> 2003; <b>7</b>(2): 157–217. <a target=xrefwindow id=d5188e1656 href="https://doi.org/10.1177/102986490300700201">Publisher Full Text </a></span></li><li><a name=ref-31 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1662 class=n-a></a>Garner T, Grimshaw M, Abdel Nabi D: A preliminary experiment to assess the fear value of preselected sound parameters in a survival horror game.<i>5th Audio Mostly Conference: A Conference on Interaction with Sound (AM'10)</i>. New York, NY USA: ACM. 2010; 1–9. <a target=xrefwindow id=d5188e1667 href="https://doi.org/10.1145/1859799.1859809">Publisher Full Text </a></span></li><li><a name=ref-32 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1673 class=n-a></a>Gerdes ABM, Wieser MJ, Alpers GW: Emotional pictures and sounds: A review of multimodal interactions of emotion cues in multiple domains. <i>Front Psychol.</i> 2014; <b>5</b>: 1351. <a target=xrefwindow id=d5188e1681 href="http://www.ncbi.nlm.nih.gov/pubmed/25520679">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1684 href="https://doi.org/10.3389/fpsyg.2014.01351">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1687 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4248815">Free Full Text </a></span></li><li><a name=ref-33 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1693 class=n-a></a>Geslin E, Jégou L, Beaudoin D: How color properties can be used to elicit emotions in video games. <i>International Journal of Computer Games Technology.</i> 2016; <b>2016</b>(Article ID 5182768): 1–9. <a target=xrefwindow id=d5188e1701 href="https://doi.org/10.1155/2016/5182768">Publisher Full Text </a></span></li><li><a name=ref-34 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1707 class=n-a></a>Gomez P, Danuser B: Affective and physiological responses to environmental noises and music. <i>Int J Psychophysiol.</i> 2004; <b>53</b>(2): 91–103. <a target=xrefwindow id=d5188e1715 href="http://www.ncbi.nlm.nih.gov/pubmed/15210287">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1718 href="https://doi.org/10.1016/j.ijpsycho.2004.02.002">Publisher Full Text </a></span></li><li><a name=ref-35 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1724 class=n-a></a>Hanjalic A, Xu LQ: Affective video content representation and modeling. <i>IEEE Trans Multimedia.</i> 2005; <b>7</b>(1): 143–154. <a target=xrefwindow id=d5188e1732 href="https://doi.org/10.1109/TMM.2004.840618">Publisher Full Text </a></span></li><li><a name=ref-36 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1739 class=n-a></a>Hayashi ECS, Gutiérrez Posada JE, Maike VRML, <i> et al.</i>: Exploring new formats of the Self-Assessment Manikin in the design with children.<i>15th Brazilian Symposium on Human Factors in Computer Systems</i>. New York, NY USA: ACM. 2016; 1–10. <a target=xrefwindow id=d5188e1747 href="https://doi.org/10.1145/3033701.3033728">Publisher Full Text </a></span></li><li><a name=ref-37 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1753 class=n-a></a>Hewig J, Hagemann D, Seifert J, <i> et al.</i>: A revised film set for the induction of basic emotions. <i>Cognition &amp; Emotion.</i> 2005; <b>19</b>(7): 1095–1109. <a target=xrefwindow id=d5188e1764 href="https://doi.org/10.1080/02699930541000084">Publisher Full Text </a></span></li><li><a name=ref-38 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1770 class=n-a></a>Houtkamp JM, Junger MLA: Affective qualities of an urban environment on a desktop computer.<i>14th International Conference Information Visualisation</i>., ed. E. Banissi, Los Alamitos, CA USA: IEEE Computer Society. 2010; 597–603. <a target=xrefwindow id=d5188e1775 href="https://doi.org/10.1109/IV.2010.87">Publisher Full Text </a></span></li><li><a name=ref-39 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1781 class=n-a></a>Houtkamp JM, Schuurink EL, Toet A: Thunderstorms in my computer: the effect of visual dynamics and sound in a 3D environment. eds. M Bannatyne &amp; J Counsell: IEEE Computer Society, 2008; 11–17. <a target=xrefwindow id=d5188e1783 href="https://doi.org/10.1109/VIS.2008.18">Publisher Full Text </a></span></li><li><a name=ref-40 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1789 class=n-a></a>Huang H, Klettner S, Schmidt M, <i> et al.</i>: AffectRoute – considering people’s affective responses to environments for enhancing route-planning services. <i>Int J Geogr Inf Sci.</i> 2014; <b>28</b>(12): 2456–2473. <a target=xrefwindow id=d5188e1800 href="https://doi.org/10.1080/13658816.2014.931585">Publisher Full Text </a></span></li><li><a name=ref-41 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1806 class=n-a></a>Hudlicka E: To feel or not to feel: the role of affect in human-computer interaction. <i>Int J Hum Comput Stud.</i> 2003; <b>59</b>(1–2): 1–32. <a target=xrefwindow id=d5188e1814 href="https://doi.org/10.1016/S1071-5819(03)00047-8">Publisher Full Text </a></span></li><li><a name=ref-42 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1821 class=n-a></a>Jaimes A, Sebe N: Multimodal human–computer interaction: a survey. <i>Comput Vis Image Underst.</i> 2010; <b>108</b>(1–2): 116–134. <a target=xrefwindow id=d5188e1829 href="https://doi.org/10.1016/j.cviu.2006.10.019">Publisher Full Text </a></span></li><li><a name=ref-43 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1835 class=n-a></a>Jaquet L, Danuser B, Gomez P: Music and felt emotions: How systematic pitch level variations affect the experience of pleasantness and arousal. <i>Psychol Music.</i> 2014; <b>42</b>(1): 51–70. <a target=xrefwindow id=d5188e1843 href="https://doi.org/10.1177/0305735612456583">Publisher Full Text </a></span></li><li><a name=ref-44 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1849 class=n-a></a>Kaneko D, Toet A, Brouwer AM, <i> et al.</i>: Methods for evaluating emotions evoked by food experiences: A literature review. <i>Front Psychol.</i> 2018a; <b>9</b>: 911. <a target=xrefwindow id=d5188e1860 href="http://www.ncbi.nlm.nih.gov/pubmed/29937744">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1863 href="https://doi.org/10.3389/fpsyg.2018.00911">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1867 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6002740">Free Full Text </a></span></li><li><a name=ref-45 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1873 class=n-a></a>Kaneko D, Toet A, Ushiama S, <i> et al.</i>: EmojiGrid: a 2D pictorial scale for cross-cultural emotion assessment of negatively and positively valenced food. <i>Food Res Int.</i> 2019; <b>115</b>: 541–551. <a target=xrefwindow id=d5188e1884 href="http://www.ncbi.nlm.nih.gov/pubmed/30599977">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1887 href="https://doi.org/10.1016/j.foodres.2018.09.049">Publisher Full Text </a></span></li><li><a name=ref-46 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1893 class=n-a></a>Kim S, André E: Composing affective music with a generate and sense approach. In: <i>Flairs 2004 - Special Track on AI and Music</i>. AAAI. 2004. <a target=xrefwindow id=d5188e1898 href="https://aaai.org/Papers/FLAIRS/2004/Flairs04-011.pdf">Reference Source</a></span></li><li><a name=ref-47 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1904 class=n-a></a>Koelstra S, Muhl C, Soleymani M, <i> et al.</i>: DEAP: A database for emotion analysis using physiological signals. <i>IEEE Trans Affect Comput.</i> 2012; <b>3</b>(1): 18–31. <a target=xrefwindow id=d5188e1915 href="https://doi.org/10.1109/T-AFFC.2011.15">Publisher Full Text </a></span></li><li><a name=ref-48 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1922 class=n-a></a>Koo TK, Li MY: A guideline of selecting and reporting intraclass correlation coefficients for reliability research. <i>J Chiropr Med.</i> 2016; <b>15</b>(2): 155–163. <a target=xrefwindow id=d5188e1930 href="http://www.ncbi.nlm.nih.gov/pubmed/27330520">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1933 href="https://doi.org/10.1016/j.jcm.2016.02.012">Publisher Full Text </a> | <a target=xrefwindow id=d5188e1936 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4913118">Free Full Text </a></span></li><li><a name=ref-49 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1942 class=n-a></a>Krumhansl CL: An exploratory study of musical emotions and psychophysiology. <i>Can J Exp Psychol.</i> 1997; <b>51</b>(4): 336–353. <a target=xrefwindow id=d5188e1950 href="http://www.ncbi.nlm.nih.gov/pubmed/9606949">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1953 href="https://doi.org/10.1037/1196-1961.51.4.336">Publisher Full Text </a></span></li><li><a name=ref-50 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1959 class=n-a></a>Kuijsters A, Redi J, de Ruyter B, <i> et al.</i>: Affective ambiences created with lighting for older people. <i>Light Res Technol.</i> 2015; <b>47</b>(7): 859–875. <a target=xrefwindow id=d5188e1970 href="https://doi.org/10.1177/1477153514560423">Publisher Full Text </a></span></li><li><a name=ref-51 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1976 class=n-a></a>Kuppens P, Tuerlinckx F, Russell JA, <i> et al.</i>: The relation between valence and arousal in subjective experience. <i>Psychol Bull.</i> 2013; <b>139</b>(4): 917–940. <a target=xrefwindow id=d5188e1987 href="http://www.ncbi.nlm.nih.gov/pubmed/23231533">PubMed Abstract </a> | <a target=xrefwindow id=d5188e1990 href="https://doi.org/10.1037/a0030811">Publisher Full Text </a></span></li><li><a name=ref-52 class=n-a></a>&nbsp;<span class=citation><a name=d5188e1996 class=n-a></a>Kuppens P, Tuerlinckx F, Yik M, <i> et al.</i>: The relation between valence and arousal in subjective experience varies with personality and culture. <i>J Pers.</i> 2017; <b>85</b>(4): 530–542. <a target=xrefwindow id=d5188e2007 href="http://www.ncbi.nlm.nih.gov/pubmed/27102867">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2010 href="https://doi.org/10.1111/jopy.12258">Publisher Full Text </a></span></li><li><a name=ref-53 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2016 class=n-a></a>Landis JR, Koch GG: The measurement of observer agreement for categorical data. <i>Biometrics.</i> 1977; <b>33</b>(1): 159–174. <a target=xrefwindow id=d5188e2024 href="http://www.ncbi.nlm.nih.gov/pubmed/843571">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2027 href="https://doi.org/10.2307/2529310">Publisher Full Text </a></span></li><li><a name=ref-54 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2034 class=n-a></a>Lemaitre G, Houix O, Susini P, <i> et al.</i>: Feelings elicited by auditory feedback from a computationally augmented artifact: The flops. <i>IEEE Trans Affect Comput.</i> 2012; <b>3</b>(3): 335–348. <a target=xrefwindow id=d5188e2045 href="https://doi.org/10.1109/T-AFFC.2012.1">Publisher Full Text </a></span></li><li><a name=ref-55 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2051 class=n-a></a>Lieberman MD: Affect labeling in the age of social media. <i>Nat Hum Behav.</i> 2019; <b>3</b>(1): 20–21. <a target=xrefwindow id=d5188e2059 href="http://www.ncbi.nlm.nih.gov/pubmed/30932056">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2062 href="https://doi.org/10.1038/s41562-018-0487-0">Publisher Full Text </a></span></li><li><a name=ref-56 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2068 class=n-a></a>Lieberman MD, Inagaki TK, Tabibnia G, <i> et al.</i>: Subjective responses to emotional stimuli during labeling, reappraisal, and distraction. <i>Emotion.</i> 2011; <b>11</b>(3): 468–480. <a target=xrefwindow id=d5188e2079 href="http://www.ncbi.nlm.nih.gov/pubmed/21534661">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2082 href="https://doi.org/10.1037/a0023503">Publisher Full Text </a> | <a target=xrefwindow id=d5188e2086 href="http://www.ncbi.nlm.nih.gov/pmc/articles/3444304">Free Full Text </a></span></li><li><a name=ref-57 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2092 class=n-a></a>Lopatovska I, Arapakis I: Theories, methods and current research on emotions in library and information science, information retrieval and human–computer interaction. <i>Inf Process Manag.</i> 2011; <b>47</b>(4): 575–592. <a target=xrefwindow id=d5188e2100 href="https://doi.org/10.1016/j.ipm.2010.09.001">Publisher Full Text </a></span></li><li><a name=ref-58 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2106 class=n-a></a>Ma W, Thompson WF: Human emotions track changes in the acoustic environment. <i>Proc Natl Acad Sci U S A.</i> 2015; <b>112</b>(47): 14563–14568. <a target=xrefwindow id=d5188e2114 href="http://www.ncbi.nlm.nih.gov/pubmed/26553987">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2117 href="https://doi.org/10.1073/pnas.1515087112">Publisher Full Text </a> | <a target=xrefwindow id=d5188e2120 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4664334">Free Full Text </a></span></li><li><a name=ref-59 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2126 class=n-a></a>Mattek AM, Wolford GL, Whalen PJ: A mathematical model captures the structure of subjective affect. <i>Perspect Psychol Sci.</i> 2017; <b>12</b>(3): 508–526. <a target=xrefwindow id=d5188e2134 href="http://www.ncbi.nlm.nih.gov/pubmed/28544868">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2137 href="https://doi.org/10.1177/1745691616685863">Publisher Full Text </a> | <a target=xrefwindow id=d5188e2140 href="http://www.ncbi.nlm.nih.gov/pmc/articles/5445940">Free Full Text </a></span></li><li><a name=ref-60 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2147 class=n-a></a>Medvedev O, Shepherd D, Hautus MJ: The restorative potential of soundscapes: A physiological investigation. <i>Applied Acoustics.</i> 2015; <b>96</b>: 20–26. <a target=xrefwindow id=d5188e2155 href="https://doi.org/10.1016/j.apacoust.2015.03.004">Publisher Full Text </a></span></li><li><a name=ref-61 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2161 class=n-a></a>Mehrabian A, Russell JA: An approach to environmental psychology. Boston, MA, USA: The MIT Press. 1974. <a target=xrefwindow id=d5188e2163 href="https://psycnet.apa.org/record/1974-22049-000">Reference Source</a></span></li><li><a name=ref-62 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2169 class=n-a></a>Menon V, Levitin DJ: The rewards of music listening: Response and physiological connectivity of the mesolimbic system. <i>Neuroimage.</i> 2005; <b>28</b>(1): 175–184. <a target=xrefwindow id=d5188e2177 href="http://www.ncbi.nlm.nih.gov/pubmed/16023376">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2180 href="https://doi.org/10.1016/j.neuroimage.2005.05.053">Publisher Full Text </a></span></li><li><a name=ref-63 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2186 class=n-a></a>Mion L, D'Incá G, de Götzen A, <i> et al.</i>: Modeling expression with perceptual audio features to enhance user interaction. <i>Computer Music Journal.</i> 2010; <b>34</b>(1): 65–79. <a target=xrefwindow id=d5188e2197 href="https://doi.org/10.1162/comj.2010.34.1.65">Publisher Full Text </a></span></li><li><a name=ref-64 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2203 class=n-a></a>Morris JD, Boone MA: The effects of music on emotional response, brand attitude, and purchase intent in an emotional advertising condition. <i>Advances in Consumer Research.</i> 1998; <b>25</b>(1): 518–526. <a target=xrefwindow id=d5188e2211 href="https://www.acrwebsite.org/volumes/8207/volumes/v25/NA-25">Reference Source</a></span></li><li><a name=ref-65 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2217 class=n-a></a>Peter C, Herbon A: Emotion representation and physiology assignments in digital systems. <i>Interact Comput.</i> 2006; <b>18</b>(2): 139–170. <a target=xrefwindow id=d5188e2225 href="https://doi.org/10.1016/j.intcom.2005.10.006">Publisher Full Text </a></span></li><li><a name=ref-66 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2232 class=n-a></a>Pfister HR, Wollstädter S, Peter C: Affective responses to system messages in human–computer-interaction: Effects of modality and message type. <i>Interact Comput.</i> 2011; <b>23</b>(4): 372–383. <a target=xrefwindow id=d5188e2240 href="https://doi.org/10.1016/j.intcom.2011.05.006">Publisher Full Text </a></span></li><li><a name=ref-67 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2246 class=n-a></a>Phan WMJ, Amrhein R, Rounds J, <i> et al.</i>: Contextualizing interest scales with emojis: Implications for measurement and validity. <i>J Career Assess.</i> 2019; <b>27</b>(1): 114–133. <a target=xrefwindow id=d5188e2257 href="https://doi.org/10.1177/1069072717748647">Publisher Full Text </a></span></li><li><a name=ref-68 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2263 class=n-a></a>Redondo J, Fraga I, Padrón I, <i> et al.</i>: Affective ratings of sound stimuli. <i>Behav Res Methods.</i> 2008; <b>40</b>(3): 784–790. <a target=xrefwindow id=d5188e2274 href="http://www.ncbi.nlm.nih.gov/pubmed/18697674">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2277 href="https://doi.org/10.3758/brm.40.3.784">Publisher Full Text </a></span></li><li><a name=ref-69 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2283 class=n-a></a>Rohrmann B, Bishop ID: Subjective responses to computer simulations of urban environments. <i>J Environ Psychol.</i> 2002; <b>22</b>(4): 319–331. <a target=xrefwindow id=d5188e2291 href="https://doi.org/10.1006/jevp.2001.0206">Publisher Full Text </a></span></li><li><a name=ref-70 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2297 class=n-a></a>Rottenberg J, Ray RR, Gross JJ: Emotion elicitation using films. eds. J.A. Coan &amp; J.J.B. Allen: Oxford University Press, 2007; 9–28. <a target=xrefwindow id=d5188e2299 href="https://psycnet.apa.org/record/2007-08864-001">Reference Source</a></span></li><li><a name=ref-71 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2305 class=n-a></a>Runge N, Hellmeier M, Wenig D, <i> et al.</i>: Tag your emotions: a novel mobile user interface for annotating images with emotions. in: <i>18th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct.</i> 2961836: ACM, 2016; 846–853. <a target=xrefwindow id=d5188e2313 href="https://doi.org/10.1145/2957265.2961836">Publisher Full Text </a></span></li><li><a name=ref-72 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2320 class=n-a></a>Russell JA, Weiss A, Mendelson GA: Affect grid: A single-item scale of pleasure and arousal. <i>Journal of Personality and Social Psychology.</i> 1989; <b>57</b>(3): 493–502. <a target=xrefwindow id=d5188e2328 href="https://doi.org/10.1037/0022-3514.57.3.493">Publisher Full Text </a></span></li><li><a name=ref-73 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2334 class=n-a></a>Schaefer A, Nils F, Sanchez X, <i> et al.</i>: Assessing the effectiveness of a large database of emotion-eliciting films: A new tool for emotion researchers. <i>Cognition &amp; Emotion.</i> 2010; <b>24</b>(7): 1153–1172. <a target=xrefwindow id=d5188e2345 href="https://doi.org/10.1080/02699930903274322">Publisher Full Text </a></span></li><li><a name=ref-74 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2351 class=n-a></a>Schreuder E, van Erp J, Toet A, <i> et al.</i>: Emotional responses to multisensory environmental stimuli. <i>SAGE Open.</i> 2016; <b>6</b>(1): 1–19. <a target=xrefwindow id=d5188e2362 href="https://doi.org/10.1177/2158244016630591">Publisher Full Text </a></span></li><li><a name=ref-75 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2368 class=n-a></a>Shrout PE, Fleiss JL: Intraclass correlations: Uses in assessing rater reliability. <i>Psychol Bull.</i> 1979; <b>86</b>(2): 420–428. <a target=xrefwindow id=d5188e2376 href="http://www.ncbi.nlm.nih.gov/pubmed/18839484">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2379 href="https://doi.org/10.1037//0033-2909.86.2.420">Publisher Full Text </a></span></li><li><a name=ref-76 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2385 class=n-a></a>Small DM, Zatorre RJ, Dagher A, <i> et al.</i>: Changes in brain activity related to eating chocolate: from pleasure to aversion. <i>Brain.</i> 2001; <b>124</b>(Pt 9): 1720–1733. <a target=xrefwindow id=d5188e2396 href="http://www.ncbi.nlm.nih.gov/pubmed/11522575">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2399 href="https://doi.org/10.1093/brain/124.9.1720">Publisher Full Text </a></span></li><li><a name=ref-77 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2405 class=n-a></a>Soleymani M, Chanel G, Kierkels JJM, <i> et al.</i>: Affective ranking of movie scenes using physiological signals and content analysis. in: <i>2nd ACM workshop on Multimedia semantics.</i> New York, NY, USA: ACM, 2008; 32–39. <a target=xrefwindow id=d5188e2413 href="https://doi.org/10.1145/1460676.1460684">Publisher Full Text </a></span></li><li><a name=ref-78 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2420 class=n-a></a>Soleymani M, Yang Y, Irie G, <i> et al.</i>: Guest editorial: Challenges and perspectives for affective analysis in multimedia. <i>IEEE Trans Affect Comput.</i> 2015; <b>6</b>(3): 206–208. <a target=xrefwindow id=d5188e2431 href="https://doi.org/10.1109/TAFFC.2015.2445233">Publisher Full Text </a></span></li><li><a name=ref-79 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2437 class=n-a></a>Spreckelmeyer KN, Kutas M, Urbach TP, <i> et al.</i>: Combined perception of emotion in pictures and musical sounds. <i>Brain Res.</i> 2006; <b>1070</b>(1): 160–170. <a target=xrefwindow id=d5188e2448 href="http://www.ncbi.nlm.nih.gov/pubmed/16403462">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2451 href="https://doi.org/10.1016/j.brainres.2005.11.075">Publisher Full Text </a></span></li><li><a name=ref-80 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2457 class=n-a></a>Tajadura-Jiménez A, Väljamäe A, Asutay E, <i> et al.</i>: Embodied auditory perception: the emotional impact of approaching and receding sound sources. <i>Emotion.</i> 2010; <b>10</b>(2): 216–229. <a target=xrefwindow id=d5188e2468 href="http://www.ncbi.nlm.nih.gov/pubmed/20364898">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2471 href="https://doi.org/10.1037/a0018422">Publisher Full Text </a></span></li><li><a name=ref-81 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2477 class=n-a></a>Tajadura-Jiménez A, Västfjäll D: Auditory-induced emotion: A neglected channel for communication in human-computer interaction. in: <i>Affect and Emotion in Human-Computer Interaction.</i> eds. C. Peter &amp; B. R. Berlin - Heidelberg, Germany: Springer, 2008; 63–74. <a target=xrefwindow id=d5188e2482 href="https://doi.org/10.1007/978-3-540-85099-1_6">Publisher Full Text </a></span></li><li><a name=ref-82 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2488 class=n-a></a>Taylor SF, Phan KL, Decker LR, <i> et al.</i>: Subjective rating of emotionally salient stimuli modulates neural activity. <i>NeuroImage.</i> 2003; <b>18</b>(3): 650–659. <a target=xrefwindow id=d5188e2499 href="https://doi.org/10.1016/S1053-8119(02)00051-4">Publisher Full Text </a></span></li><li><a name=ref-83 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2505 class=n-a></a>Thomassin K, Morelen D, Suveg C: Emotion reporting using electronic diaries reduces anxiety symptoms in girls with emotion dysregulation. <i>J Contemp Psychother.</i> 2012; <b>42</b>(4): 207–213. <a target=xrefwindow id=d5188e2513 href="https://doi.org/10.1007/s10879-012-9205-9">Publisher Full Text </a></span></li><li><a name=ref-84 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2520 class=n-a></a>Toet A: Affective rating of audio and video clips using the EmojiGrid. 2020. <a target=xrefwindow id=d5188e2522 href="http://www.doi.org/10.17605/OSF.IO/GTZH4">http://www.doi.org/10.17605/OSF.IO/GTZH4</a></span></li><li><a name=ref-85 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2528 class=n-a></a>Toet A, Eijsman S, Liu Y, <i> et al.</i>: The relation between valence and arousal in subjective odor experience. <i>Chemosens Percept.</i> Online first. 2019. <a target=xrefwindow id=d5188e2536 href="https://doi.org/10.1007/s12078-019-09275-7">Publisher Full Text </a></span></li><li><a name=ref-86 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2542 class=n-a></a>Toet A, Houtkamp JM, van der Meulen R: Visual and auditory cue effects on risk assessment in a highway training simulation. <i>Simul Games.</i> 2013; <b>44</b>(5): 732–753. <a target=xrefwindow id=d5188e2550 href="https://doi.org/10.1177/1046878113495349">Publisher Full Text </a></span></li><li><a name=ref-87 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2556 class=n-a></a>Toet A, Houtkamp JM, Vreugdenhil PE: Effects of personal relevance and simulated darkness on the affective appraisal of a virtual environment. <i>PeerJ.</i> 2016; <b>4</b>: e1743. <a target=xrefwindow id=d5188e2564 href="http://www.ncbi.nlm.nih.gov/pubmed/26977376">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2567 href="https://doi.org/10.7717/peerj.1743">Publisher Full Text </a> | <a target=xrefwindow id=d5188e2570 href="http://www.ncbi.nlm.nih.gov/pmc/articles/4788201">Free Full Text </a></span></li><li><a name=ref-88 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2576 class=n-a></a>Toet A, Kaneko D, Ushiama S, <i> et al.</i>: EmojiGrid: A 2D pictorial scale for the assessment of food elicited emotions. <i>Front Psychol.</i> 2018; <b>9</b>: 2396. <a target=xrefwindow id=d5188e2587 href="http://www.ncbi.nlm.nih.gov/pubmed/30546339">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2590 href="https://doi.org/10.3389/fpsyg.2018.02396">Publisher Full Text </a> | <a target=xrefwindow id=d5188e2594 href="http://www.ncbi.nlm.nih.gov/pmc/articles/6279862">Free Full Text </a></span></li><li><a name=ref-89 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2600 class=n-a></a>Torre JB, Lieberman MD: Putting feelings into words: Affect labeling as implicit emotion regulation. <i>Emotion Review.</i> 2018; <b>10</b>(2): 116–124. <a target=xrefwindow id=d5188e2608 href="https://doi.org/10.1177/1754073917742706">Publisher Full Text </a></span></li><li><a name=ref-90 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2615 class=n-a></a>Tsukamoto M, Yamada M, Yoneda R: A dimensional study on the emotion of musical pieces composed for video games. in: <i>20th International Congress on Acoustics 2010 (ICA 2010 ).</i> eds. M. Burgess, J. Davey, C. Don &amp; T. McMinn. Australian Acoustical Society, 2010; 4058–4060. <a target=xrefwindow id=d5188e2620 href="http://www.acoustics.asn.au/conference_proceedings/ICA2010/cdrom-ICA2010/papers/p918.pdf">Reference Source</a></span></li><li><a name=ref-91 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2626 class=n-a></a>Turley LW, Milliman RE: Atmospheric effects on shopping behavior: A review of the experimental evidence. <i>Journal of Business Research.</i> 2000; <b>49</b>(2): 193–211. <a target=xrefwindow id=d5188e2634 href="https://doi.org/10.1016/S0148-2963(99)00010-7">Publisher Full Text </a></span></li><li><a name=ref-92 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2640 class=n-a></a>Vastfjall D, Bergman P, Sköld A, <i> et al.</i>: Emotional responses to information and warning sounds. <i>Journal of Ergonomics.</i> 2012; <b>2</b>(3): 106. <a target=xrefwindow id=d5188e2651 href="https://doi.org/10.4172/2165-7556.1000106">Publisher Full Text </a></span></li><li><a name=ref-93 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2657 class=n-a></a>Watts GR, Pheasant RJ: Tranquillity in the Scottish Highlands and Dartmoor National Park - The importance of soundscapes and emotional factors. <i>Applied Acoustics.</i> 2015; <b>89</b>: 297–305. <a target=xrefwindow id=d5188e2665 href="https://doi.org/10.1016/j.apacoust.2014.10.006">Publisher Full Text </a></span></li><li><a name=ref-94 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2671 class=n-a></a>Westerdahl B, Suneson K, Wernemyr C, <i> et al.</i>: Users' evaluation of a virtual reality architectural model compared with the experience of the completed building. <i>Automation in Construction.</i> 2006; <b>15</b>(2): 150–165. <a target=xrefwindow id=d5188e2682 href="https://doi.org/10.1016/j.autcon.2005.02.010">Publisher Full Text </a></span></li><li><a name=ref-95 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2688 class=n-a></a>Wolfson S, Case G: The effects of sound and colour on responses to a computer game. <i>Interact Comput.</i> 2000; <b>13</b>(2): 183–192. <a target=xrefwindow id=d5188e2696 href="https://doi.org/10.1016/S0953-5438(00)00037-0">Publisher Full Text </a></span></li><li><a name=ref-96 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2703 class=n-a></a>World Medical Association: World Medical Association declaration of Helsinki: Ethical principles for medical research involving human subjects. <i>JAMA.</i> 2013; <b>310</b>(20): 2191–2194. <a target=xrefwindow id=d5188e2711 href="http://www.ncbi.nlm.nih.gov/pubmed/24141714">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2714 href="https://doi.org/10.1001/jama.2013.281053">Publisher Full Text </a></span></li><li><a name=ref-97 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2720 class=n-a></a>Xu C, Chen L, Chen G: A color bar based affective annotation method for media player. in: <i>Frontiers of WWW Research and Development - APWeb 2006.</i> eds. X. Zhou, J. Li, H.T. Shen, M. Kitsuregawa &amp; Y. Zhang. Heidelberg/Berlin, Germany: Springer, 2008; 759–764. <a target=xrefwindow id=d5188e2725 href="https://doi.org/10.1007/11610113_70">Publisher Full Text </a></span></li><li><a name=ref-98 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2731 class=n-a></a>Yang W, Makita K, Nakao T, <i> et al.</i>: Affective auditory stimulus database: An expanded version of the International Affective Digitized Sounds (IADS-E). <i>Behav Res Methods.</i> 2018; <b>50</b>(4): 1415–1429. <a target=xrefwindow id=d5188e2742 href="http://www.ncbi.nlm.nih.gov/pubmed/29520632">PubMed Abstract </a> | <a target=xrefwindow id=d5188e2745 href="https://doi.org/10.3758/s13428-018-1027-6">Publisher Full Text </a></span></li><li><a name=ref-99 class=n-a></a>&nbsp;<span class=citation><a name=d5188e2751 class=n-a></a>Yusoff YM, Ruthven I, Landoni M: Measuring emotion: A new evaluation tool for very young children. in: <i>4th Int. Conf. on Computing and Informatics (ICOCI 2013).</i> Sarawak, Malaysia: Universiti Utara Malaysia, 2013; 358–363. <a target=xrefwindow id=d5188e2756 href="http://repo.uum.edu.my/id/eprint/12040">Reference Source</a></span></li></ul></div></div></div> </div> <div class=f1r-article-desk> <section class="o-box o-box--medium u-bg--2 u-mt--2"> <h4 class="u-mt--0 u-mb--2 t-h3 u-weight--md">Looking for the Open Peer Review Reports?</h4> <p class="u-mt--0 u-mb--0 t-h4">They can now be found at the top of the panel on the right, linked from the box entitled Open Peer Review. Choose the reviewer report you wish to read and click the 'read' link. You can also read all the peer review reports by <a target=_blank href="https://f1000research.com/articles/9-970/v1/pdf?article_uuid=01a543b3-5b99-4b8c-a969-cabcf09bc69d">downloading the PDF</a>.</p> </section> </div> <div id=article-comments class="article-comments padding-bottom-20"> <div class=current-article-comment-section> <h2 class=main-title name=add-new-comment id=add-new-comment> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-104_comments size30"></span> </span> <span class=f1r-article-desk-inline>Comments on this article</span> <span class=f1r-article-mobile-inline>Comments (0)</span> <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> </div> <div class="f1r-article-desk-inline referee-report-info-box referee-report-version-box"> Version 1 </div> <div class="f1r-article-mobile research-layout mobile-version-info padding-top-30"> <span class=mversion>VERSION 1</span> <span class=details>PUBLISHED 11 Aug 2020</span> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div class="f1r-article-mobile research-layout margin-top-20 is-centered"> <a href="/login?originalPath=/articles/9-970.html&scrollTo=add-new-comment" class=register-report-comment-button data-test-id=add-comment_mob> <button class="primary orange extra-padding comment-on-this-report">ADD YOUR COMMENT</button> </a> </div> <a href="/login?originalPath=/articles/9-970.html&scrollTo=add-new-comment" class="f1r-article-desk register-report-comment-button" data-test-id=add-comment> <span class=contracted></span>Comment </a> </div> <div class="f1r-article-mobile margin-bottom-30"> <div class=contracted-details> <a href="#" class="contracted-details-label author-affiliations"><span class=contracted></span>Author details</a> <a href="#" class=section-title>Author details</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details affiliations is-hidden"> <sup>1</sup> Perceptual and Cognitive Systems, TNO, Soesterberg, 3769DE, The Netherlands<br/> <sup>2</sup> Department of Experimental Psychology, Helmholtz Institute, Utrecht University, Utrecht, 3584 CS, The Netherlands<br/> <sup>3</sup> Research Group Human Media Interaction, University of Twente, Enschede, 7522 NH, The Netherlands<br/> <p> <div class=margin-bottom> Alexander Toet <br/> <span>Roles: </span> Conceptualization, Data Curation, Formal Analysis, Investigation, Methodology, Software, Supervision, Validation, Visualization, Writing – Original Draft Preparation, Writing – Review & Editing </div> <div class=margin-bottom> Jan B. F. van Erp <br/> <span>Roles: </span> Funding Acquisition, Methodology, Resources, Supervision, Validation, Writing – Original Draft Preparation, Writing – Review & Editing </div> </p> </div> </div> <div class=contracted-details> <a href="#" class=section-title>Article Versions (1)</a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details grant-information article-page is-hidden"> <div> <a href="https://f1000research.com/articles/9-970/v1" title="Open version 1 of this article." class="" gahelper=1>version 1</a> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div> Published: 11 Aug 2020, 9:970 </div> <div class=""><a href="https://doi.org/10.12688/f1000research.25088.1">https://doi.org/10.12688/f1000research.25088.1</a></div> </div> </div> <div class=contracted-details> <a href="#" class=section-title> <span class="f1r-icon icon-100_open_access"></span> Copyright </a> <span class="f1r-icon icon-14_more_small section-control"></span> <span class="f1r-icon icon-10_less_small section-control"></span> <div class="expanded-details grant-information article-page is-hidden"> © 2020 Toet A and van Erp JBF. This is an open access article distributed under the terms of the <a href="http://creativecommons.org/licenses/by/4.0/" target=_blank data-test-id=box-licence-link>Creative Commons Attribution License</a>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. </div> </div> <div class="padding-top-30 research-layout"> <div class=article-toolbox-wrapper-mobile> <div class=article-tools-icon-mobile data-section=download> <span class="f1r-icon icon-76_download_file white"></span> </div> <div class="article-tools-icon-mobile mobile-metrics article-metrics-wrapper metrics-icon-wrapper" data-section=metrics data-version-id=27685 data-id=25088 data-downloads="" data-views="" data-scholar="10.12688/f1000research.25088.1" data-recommended="" data-f1r-ga-helper="Article Page Metrics (Mobile)"> <span class="f1r-icon icon-89_metrics white"></span> </div> <div class=article-tools-divider-mobile></div> <div class=article-tools-icon-mobile data-section=cite> <span class="f1r-icon icon-82_quote white"></span> </div> <div class="article-tools-icon-mobile " data-section=track> <span class="f1r-icon icon-90_track white"></span> </div> <div class=article-tools-divider-mobile></div> <div class=article-tools-icon-mobile data-section=share> <span class="f1r-icon icon-34_share white"></span> </div> <span class=article-toolbox-stretch></span> </div> <div class=article-toolbox-content-mobile> <div class="toolbox-section download"> <div class=toolbox-section-heading>Download</div> <div class=toolbox-section-content> <a href="https://f1000research.com/articles/9-970/v1/pdf?article_uuid=01a543b3-5b99-4b8c-a969-cabcf09bc69d" title="Download PDF" class="no-decoration pdf-download-helper"> <span class="f1r-icon icon-102_download_pdf toolbox-section-icon"></span> </a> <div class=toolbox-section-option-divider>&nbsp;</div> <a id=mobile-download-xml class=no-decoration href="#" title="Download XML"> <span class="f1r-icon icon-103_download_xml toolbox-section-icon"></span> </a> </div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>Export To</div> <div class=toolbox-section-content> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=WORKSPACE>Sciwheel</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=BIBTEX>Bibtex</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=ENDNOTE>EndNote</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=PROCITE>ProCite</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=REF_MANAGER>Ref. Manager (RIS)</button> <button class="primary no-fill orange-text-and-border mobile-export" data-etype=SENTE>Sente</button> </div> </div> <div class="toolbox-section metrics"> <div class="toolbox-section-heading no-top-border">metrics</div> <div class="toolbox-section-divider toolbox-section-divider--no-height"></div> <div class=article-metrics-pageinfo> <div class=c-article-metrics-table> <table class=c-article-metrics-table__table> <thead> <tr> <th></th> <th><span class=c-article-metrics-table__heading>Views</span></th> <th><span class=c-article-metrics-table__heading>Downloads</span></th> </tr> </thead> <tbody> <tr> <th class=c-article-metrics-table__row-heading><span class="c-article-metrics-table__platform u-platform--" data-test-id=metrics_platform_name_mob>F1000Research</span></th> <td class="c-article-metrics-table__value js-article-views-count" data-test-id=metrics_platform_views_mob>-</td> <td class="c-article-metrics-table__value js-article-downloads-count" data-test-id=metrics_platform_downloads_mob>-</td> </tr> <tr> <th class=c-article-metrics-table__row-heading> <span class="u-ib u-middle c-article-metrics-table__pmc" data-test-id=metrics_pmc_name_mob>PubMed Central</span> <div class="c-block-tip c-block-tip--centered c-article-metrics-table__tooltip c-block-tip--md-padding c-block-tip--small-arrow u-ib u-middle"> <button type=button class="u-black--medium u-black--high@hover u-ib u-middle c-button--icon c-button--text c-block-tip__toggle"><i class="material-icons c-button--icon__icon">info_outline</i></button> <div class=c-block-tip__content>Data from PMC are received and updated monthly.</div> </div> </th> <td class="c-article-metrics-table__value js-pmc-views-count" data-test-id=metrics_pmc_views_mob>-</td> <td class="c-article-metrics-table__value js-pmc-downloads-count" data-test-id=metrics_pmc_downloads_mob>-</td> </tr> </tbody> </table> </div> </div> <span class=metrics-citations-container> <div class=toolbox-section-divider></div> <div class="toolbox-section-heading u-mb--1">Citations</div> <div> <div class=toolbox-section-colsplit> <div class=citations-scopus-logo> <a href="" target=_blank class="is-hidden metrics-citation-icon" title="View full citation details at www.scopus.com"><i class="material-icons scopus-icon">open_in_new</i></a> </div> <div class="toolbox-section-count scopus"> <a href='' class='scopus-citation-link is-hidden' target=_blank title='View full citation details at www.scopus.com'>0</a> </div> </div> <div class=toolbox-section-colsplit> <div class="citations-pubmed-logo f1000research"> <a href="" target=_blank class="is-hidden metrics-citation-icon f1000research" title="View full citation details"><i class="material-icons scopus-icon">open_in_new</i></a> </div> <div class="toolbox-section-count pubmed"> <a href='' class='pubmed-citation-link is-hidden' target=_blank title='View full citation details'>0</a> </div> </div> <div class=toolbox-section-divider></div> <div class=toolbox-section-content> <div class="citations-scholar-logo f1000research"> <a href="" target=_blank class="is-hidden metrics-citation-icon google-scholar f1000research" title="View full citation details" data-scholar="10.12688/f1000research.25088.1"><i class="material-icons scopus-icon">open_in_new</i></a> </div> </div> </div> </span> <span class=metrics-details-container> <div class=toolbox-section-divider></div> <div class="toolbox-section-content altmetric-section"> <div class=altmetrics-image></div> <div class=altmetrics-more-link> <a href="" target=_blank class=f1r-standard-link>SEE MORE DETAILS</a> </div> <div class=altmetric-mobile-column-counts></div> <div class=altmetric-mobile-column-readers></div> <div class=toolbox-section-divider></div> </div> </span> </div> <div class="toolbox-section cite"> <div class="toolbox-section-heading no-top-border">CITE</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>how to cite this article</div> <div id=citation-copy-mobile class="toolbox-section-content text-content heading9 small" data-test-id=mob_copy-citation_text> Toet A and van Erp JBF. Affective rating of audio and video clips using the EmojiGrid [version 1; peer review: awaiting peer review] <i>F1000Research</i> 2020, <b>9</b>:970 (<a href="https://doi.org/10.12688/f1000research.25088.1" target=_blank>https://doi.org/10.12688/f1000research.25088.1</a>) </div> <div class=toolbox-section-divider></div> <div class="toolbox-section-content text-content heading9 small"> NOTE: <em>it is important to ensure the information in <b>square brackets after the title</b> is included in all citations of this article.</em> </div> <div class=toolbox-section-content> <button class="primary orange extra-padding copy-cite-article-mobile js-clipboard" data-clipboard-target="#citation-copy-mobile" title="Copy the current citation details." data-test-id=mob_copy-citation_button-mob>COPY CITATION DETAILS</button> </div> </div> <div class="toolbox-section track"> <div class="toolbox-section-heading no-top-border">track</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-heading>receive updates on this article</div> <div class="toolbox-section-content padding-left-20 padding-right-20 heading9 small"> Track an article to receive email alerts on any updates to this article. </div> <div class=toolbox-section-content> <a data-article-id=25088 id=mobile-track-article-signin-25088 title="Receive updates on new activity such as publication of new versions, peer reviews or author responses." href="/login?originalPath=/trackArticle/25088?target=/articles/9-970.html"> <button class="primary orange extra-padding"> TRACK THIS ARTICLE </button> </a> </div> </div> <div class="toolbox-section share"> <div class="toolbox-section-heading no-top-border">Share</div> <div class=toolbox-section-divider></div> <div class=toolbox-section-content> <a target=_blank class="f1r-shares-icon-square f1r-shares-email" title="Email this article"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-twitter" title="Share on Twitter"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-facebook" title="Share on Facebook"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-linkedin" title="Share on LinkedIn"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-reddit" title="Share on Reddit"></a> <a target=_blank class="f1r-shares-icon-square f1r-shares-mendelay" title="Share on Mendeley"></a> <div class="email-article-wrapper email-article-version-container"> <div class=toolbox-section-divider></div> <script src='https://www.recaptcha.net/recaptcha/api.js'></script> <form class="recommend-version-form-mobile research-layout"> <p>All fields are required.</p> <input name=versionId type=hidden value=27685 /> <input name=articleId type=hidden value=25088 /> <input name=senderName class="form-input-field reg-form" value="" type=text placeholder="Your name"/> <input name=senderEmail class="form-input-field reg-form margin-top" value="" type=text placeholder="Your email address"/> <textarea name=recipientEmails class="form-textarea-field ninetynine-percent-wide margin-top no-resize" placeholder="Recipient email address(es) (comma delimited)"></textarea> <input class="form-input-field reg-form margin-top" name=subject type=text value="Interesting article on F1000Research" placeholder=Subject /> <textarea name=message class="form-textarea-field reg-form margin-top no-resize">I thought this article from F1000Research (https://f1000research.com) would be of interest to you.</textarea> <div class="g-recaptcha margin-top" data-sitekey=6LcHqxoUAAAAANP3_0TzpGG6qFvl4DhbUcuRzw7W></div> <input value="" name=captcha type=hidden /> <p>A full article citation will be automatically included.</p> <p><img class="ticker-email-article-details hidden" src="/img/ticker.gif" alt=loading /></p> <button class="secondary orange margin-bottom" data-test-id=version_share_email_send>SEND EMAIL</button> <div class="orange-message margin-bottom is-hidden" data-test-id=version_share_email_message></div> </form> </div> </div> </div> </div> </div> <a name=article-reports></a> <div id=article-reports class="u-mt--3 reports-comments no-divider"> <div class="current-referee-status no-border-and-margin "> <h2 class=main-title id=current-referee-status> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-85_peer_review size30"></span> </span> Open Peer Review <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> <a name=current-referee-status></a> <div class=current-referee-status__content name=add-new-report-comment id=add-new-report-comment> Current Reviewer Status: <div class=f1r-article-desk-inline><em>AWAITING PEER REVIEW</em></div> <div class="f1r-article-mobile-inline float-right"><em>AWAITING PEER REVIEW</em></div> <span class="circle-icon-small to-right" data-window=about-referee-status title=Help>?</span> <span class="research-layout f1r-article-mobile"> <div class=mobile-ref-status-help> Key to Reviewer Statuses <span class=referee-status-pointer></span> <span class="view-control float-right">VIEW</span> <span class="view-control float-right is-hidden">HIDE</span> <div class=mobile-ref-status-help-content> <div class="cf margin-top"> <span class="f1r-icon icon-86_approved status-green smaller float-left margin-bottom-40 margin-right" title=Approved></span> <span class=title>Approved</span>The paper is scientifically sound in its current form and only minor, if any, improvements are suggested </div> <div class="cf margin-top"> <span class="f1r-icon icon-87_approved_reservations status-green smaller float-left margin-bottom-40 margin-right" title="Approved with Reservations"></span> <span class=title>Approved with reservations</span> A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </div> <div class="cf margin-top"> <span class="f1r-icon icon-88_not_approved status-red small float-left margin-bottom-30 margin-right" title="Not Approved"></span> <span class=title>Not approved</span>Fundamental flaws in the paper seriously undermine the findings and conclusions </div> </div> </div> </span> </div> </div> </div> <div class="f1r-article-mobile research-layout"> <div class="mobile-sections-divider before-comments"></div> </div> <div id=article-comments class="article-comments padding-bottom-20"> <div class=current-article-comment-section> <h2 class=main-title name=add-new-comment id=add-new-comment> <span class="research-layout f1r-article-mobile-inline valign-middle"> <span class="f1r-icon icon-104_comments size30"></span> </span> <span class=f1r-article-desk-inline>Comments on this article</span> <span class=f1r-article-mobile-inline>Comments (0)</span> <span class="f1r-article-mobile-inline float-right"> <span class="f1r-icon icon-14_more_small"></span> <span class="f1r-icon icon-10_less_small"></span> </span> </h2> </div> <div class="f1r-article-desk-inline referee-report-info-box referee-report-version-box"> Version 1 </div> <div class="f1r-article-mobile research-layout mobile-version-info padding-top-30"> <span class=mversion>VERSION 1</span> <span class=details>PUBLISHED 11 Aug 2020</span> <span class="article-pubinfo-mobile versions-section"> </span> </div> <div class="f1r-article-mobile research-layout margin-top-20 is-centered"> <a href="/login?originalPath=/articles/9-970.html&scrollTo=add-new-comment" class=register-report-comment-button data-test-id=add-comment_mob> <button class="primary orange extra-padding comment-on-this-report">ADD YOUR COMMENT</button> </a> </div> <a href="/login?originalPath=/articles/9-970.html&scrollTo=add-new-comment" class="f1r-article-desk register-report-comment-button" data-test-id=add-comment> <span class=contracted></span>Comment </a> </div> </div> </div> <div id=article_main-column class="p-article__sidebar o-layout__item u-1/3 not-expanded js-article-sidebar"> <div class="o-tab p-article__column-toggle-container"> <button class="c-tab c-tab--left js-column-toggle p-article__column-toggle not-expanded " type=button data-target-main=article_main-column data-target-secondary=article_secondary-column><i class="c-tab__icon material-icons u-hide@expanded">keyboard_arrow_left</i><i class="c-tab__icon material-icons u-show@expanded">keyboard_arrow_right</i></button> </div> <div class=p-article__sidebar-content> <div class="p-article__sidebar-scroller js-article-sidebar-scroller"> <section class="p-article__sidebar-view js-article-sidebar-view js-article-sidebar-main u-pt u-pb--8" data-view=peer-review> <div class="o-layout o-layout--flush"> <div class="o-layout__item u-pl"> <h3 class="u-mt--0 u-mb--2 t-h3 u-weight--md u-pl" data-test-id=article_sidebar_heading>Open Peer Review</h3> </div> <div class=o-layout__item> <div class="p-article__sidebar-highlight u-mb--2"> <h4 class="u-mt--0 u-mb--0 u-ib u-middle t-h4 u-weight--md u-mr--1/2">Reviewer Status</h4> <div class="u-ib u-middle"><em>AWAITING PEER REVIEW</em></div> </div> </div> <section class="o-layout__item u-pl"> <div class=u-pl> <hr class="c-hr c-hr--low c-hr--md u-mb--3"> <h4 class="t-h3 u-weight--md u-mt--0 u-mb--2">Comments on this article</h4> <div class=u-mb--4> <p class="u-mt--0 u-mb--1 t-h4"><a class=p-article__color--light href="#article-comments">All Comments</a><span class=" u-ib u-ml--1/2 p-article__color--light">(0)</span></p> <a class=t-h4 href="/login?originalPath=/articles/9-970.html&scrollTo=add-new-comment" data-test-id=add-comment>Add a comment</a> </div> <hr class="c-hr c-hr--low c-hr--md u-mb--4"> <div class="research-layout f1r-article-desk"> <div class="heading6 c-ribbon-wrapper c-ribbon-wrapper--etoc f1000research "> <div class=c-ribbon-wrapper__body>Sign up for content alerts</div> </div> </div> <div class="research-layout sidebar-sign-up-form f1r-article-desk u-mb--4 "> <form class=js-email-alert-signup action="#" method=POST data-email=tocAlertWeekly> <input type=hidden name=isUserLoggedIn class=js-email-alert-signup-logged-in value=N /> <input type=hidden name=userId class=js-email-alert-signup-user-id value=""/> <input type=hidden name=frequency class=js-email-alert-signup-frequency value=WEEKLY /> <div class="o-actions o-actions--middle"> <div class=o-actions__primary> <input type=email name=emailAddress class="form-input-field js-email-alert-signup-address u-1/1 u-bb" required=required placeholder=Email /> </div> <div class=o-actions__secondary> <div class="_mdl-layout u-ml--1/2"> <button class="mdl-button mdl-js-button mdl-button--colored mdl-button--small mdl-button--filled js-email-alert-signup-submit">Sign Up</button> </div> </div> </div> </form> <div id=sidebar-sign-up-message class="section-text js-email-alert-signup-msg is-hidden">You are now signed up to receive this alert</div> </div> <section class=js-terms-container> <hr class="c-hr c-hr--low c-hr--md u-mb--3"> <h4 class="t-h3 u-weight--md u-mt--0 u-mb--1">Browse by related subjects</h4> <div class="article-subcontainer article-subcontainer--sidebar"> <ul class=js-terms-list></ul> </div> </section> </div> </section> </div> </section> </div> <script src="/js/shared_scripts/modal-dialogue.js"></script> <script src="/js/shared_scripts/read-more.js"></script> <script src="/js/article/article-router.js"></script> <script src="/js/article/article-sidebar.js"></script> <script src="/js/referee/new/referee_helpers.js"></script> <script src="/js/article/article-column-toggle.js"></script> </div> </div> </div> </main> <input type=hidden id=_articleVersionUrl value="https://f1000research.com/articles/9-970/v1/"> <div class=research-help id=about-referee-status> <div class="research-layout research-help-content about-referee-status"> <span class="close-research-help dark-cross" title=Close></span> Alongside their report, reviewers assign a status to the article: <div class="cf research-help-row"> <span class="f1r-icon icon-86_approved status-green smaller" title=Approved></span> <span class=research-help-text>Approved - the paper is scientifically sound in its current form and only minor, if any, improvements are suggested</span> </div> <div class="cf research-help-row"> <span class="f1r-icon icon-87_approved_reservations status-green smaller" title="Approved with Reservations"></span> <span class=research-help-text>Approved with reservations - A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. </span> </div> <div class="cf research-help-row"> <span class="f1r-icon icon-88_not_approved status-red small" title="Not Approved"></span> <span class=research-help-text>Not approved - fundamental flaws in the paper seriously undermine the findings and conclusions</span> </div> </div> </div> <div id=datasets-info class=is-hidden> </div> <div class=article-interactive-content-container style="display: none;"> <a name=f-template class=n-a></a> <div class="interactive-content-wrapper padding-20"> <img src="" class=interactive-content-image title="Open the interactive image display"> <div class=interactive-content-title></div> <div class=interactive-content-text></div> <div class="f1r-article-desk interactive-content-ribbon" data-interactive-content-type=R-Script> <div class=interactive-content-label>Adjust parameters to alter display</div> <div class=interactive-content-button></div> </div> <div class="f1r-article-mobile mobile-interactive-note"> View on desktop for interactive features <img src="/img/icon/interactive_content.png" class="float-right margin-right-40"/> </div> <div class=clearfix></div> </div> </div> <div id=article-interactive-omero-container class=article-interactive-omero-container style="display: none;"> <div class=interactive-content-wrapper> <div class="interactive-omero-button omero-content" title="Open the interactive content window." data-interactive-content-type=Omero></div> <div class=has-interactive-content-image> <span class=box-arrow></span> <span class=box-middle>Includes Interactive Elements</span> <span class=box-end></span> </div> <div class="fig panel clearfix" style="margin: 0; padding-bottom: 20px;"> <a name=templatelink class=n-a></a> <a target=_blank href="" class=link-for-omero-image> <img src="" class=interactive-omero-image title="Open the image display window."> </a> <div class=caption> <div class=interactive-content-title></div> <div class=interactive-content-text></div> </div> <div class="is-hidden omero-image-list"></div> </div> <div class="f1r-article-mobile mobile-interactive-note omero"> View on desktop for interactive features <img src="/img/icon/interactive_content.png" class="float-right margin-right-40"/> </div> <div class=clearfix></div> </div> </div> <div class="add-comment-container shadow-box is-hidden" id=save-comment-container> <span id=save-comment-text class=intro-text>Edit comment</span> <textarea id=new-comment name=new-comment class="global-textarea comment margin-bottom margin-top"></textarea> <p><strong>Competing Interests</strong></p> <textarea id=new-competing-interests name=competing-interests class="global-textarea competing-interests margin-bottom check-xss"></textarea> <div class=clearfix></div> <button id=cancelComment type=button class="general-white-orange-button float-right no-background-button margin-left"> Cancel </button> <button id=save-comment-button commentId="" type=button class="general-white-orange-button float-right"> Save </button> <div class=clearfix></div> <div class="green-message margin-top is-hidden comment-is-saved">The comment has been saved.</div> <div class="red-message margin-top is-hidden comment-not-added">An error has occurred. Please try again.</div> <div class="red-message margin-top is-hidden comment-enter-text ucf">Your must enter a comment.</div> <div class="red-message margin-top is-hidden comment-references-error references">References error.</div> </div> <div class="modal-window-wrapper is-hidden"> <div id=conflicts-interests class="modal-window padding-20"> <div class=modal-window__content> <h2 class=h2-title>Competing Interests Policy</h2> <p> Provide sufficient details of any financial or non-financial competing interests to enable users to assess whether your comments might lead a reasonable person to question your impartiality. Consider the following examples, but note that this is not an exhaustive list: </p> <div class=heading5>Examples of 'Non-Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>Within the past 4 years, you have held joint grants, published or collaborated with any of the authors of the selected paper.</li> <li class=standard-padding>You have a close personal relationship (e.g. parent, spouse, sibling, or domestic partner) with any of the authors.</li> <li class=standard-padding>You are a close professional associate of any of the authors (e.g. scientific mentor, recent student).</li> <li class=standard-padding>You work at the same institute as any of the authors.</li> <li class=standard-padding>You hope/expect to benefit (e.g. favour or employment) as a result of your submission.</li> <li class=standard-padding>You are an Editor for the journal in which the article is published.</li> </ol> <div class="heading5 padding-top">Examples of 'Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>You expect to receive, or in the past 4 years have received, any of the following from any commercial organisation that may gain financially from your submission: a salary, fees, funding, reimbursements.</li> <li class=standard-padding>You expect to receive, or in the past 4 years have received, shared grant support or other funding with any of the authors.</li> <li class=standard-padding>You hold, or are currently applying for, any patents or significant stocks/shares relating to the subject matter of the paper you are commenting on.</li> </ol> </div> <div class="f1r-article-mobile research-layout"> <span class=modal-window-close-button></span> </div> </div> </div> <div class="o-modal c-email-alert-popup js-email-alert-popup is-hidden"> <div class="o-modal__body js-modal-body c-email-alert-popup__inner"> <h3 class=c-email-alert-popup__title>Stay Updated</h3> <p class=c-email-alert-popup__sub>Sign up for content alerts and receive a weekly or monthly email with all newly published articles</p> <p><a href="/register?originalPath=" class="c-email-alert-popup__lnk c-email-alert-popup__button js-email-alert-popup-action">Register with F1000Research</a></p> <p>Already registered? <a href="/login?originalPath=" class="c-email-alert-popup__lnk js-email-alert-popup-action">Sign in</a></p> <p class=c-email-alert-popup__footer><a class="c-email-alert-popup__lnk js-email-alert-popup-cancel" href="#">Not now, thanks</a></p> </div> </div> <div id=addCommentModal role=dialog aria-labelledby=addCommentModal_title aria-describedby=addCommentModal_description> <div class="c-modal js-modal is-closed p-article__add-comment-modal c-modal--xlarge js-article-comment-modal c-modal--scroll "> <aside class="c-modal__content u-black--high o-box u-pb--0 u-bg--2 c-modal--scroll-always "> <div class=c-modal__close> <button type=button class="c-button c-button--icon c-button--medium c-button--full@hover js-modal__close"><i class="c-button--icon__icon material-icons">close</i></button> </div> <div id=addCommentModal_description class="c-modal__description js-modal__content t-h4 u-mt--0 u-mb--2 u-black--medium"> <div class="js-add-comment-container t-caption u-black--high"> <div class=u-weight--bd>PLEASE NOTE</div> <div class=u-mt--1> <span class="red u-weight--bd">If you are an AUTHOR of this article,</span> please check that you signed in with the account associated with this article otherwise we cannot automatically identify your role as an author and your comment will be labelled as a &ldquo;User Comment&rdquo;. </div> <div class=u-mt--1> <span class="red u-weight--bd">If you are a REVIEWER of this article,</span> please check that you have signed in with the account associated with this article and then go to your <a href="/my/referee">account</a> to submit your report, please do not post your review here. </div> <div class="u-mt--1 u-mb--1"> If you do not have access to your original account, please <a href="mailto:research@f1000.com">contact us</a>. </div> <p class=no-top-margin>All commenters must hold a formal affiliation as per our <a href="/about/policies#commentspolicy" target=_blank>Policies</a>. The information that you give us will be displayed next to your comment.</p> <p>User comments must be in English, comprehensible and relevant to the article under discussion. We reserve the right to remove any comments that we consider to be inappropriate, offensive or otherwise in breach of the <a href="/about/legal/usercommenttermsandconditions" target=_blank>User Comment Terms and Conditions</a>. Commenters must not use a comment for personal attacks. When criticisms of the article are based on unpublished data, the data should be made available.</p> <div class="comments-note margin-bottom" id=accept-user-comments> <input class=js-add-comment-accept-terms type=checkbox id=acceptedTermsAndConditions name=acceptedTermsAndConditions> I accept the <a href="/about/legal/usercommenttermsandconditions" target=_blank> User Comment Terms and Conditions</a> <span class=required>&nbsp;</span> </div> <div class="default-error margin-top is-hidden comment-accept-conditions utac">Please confirm that you accept the User Comment Terms and Conditions.</div> <div class="research-layout registration-form u-mb--2"> <div class="u-mb--1 u-mt--2"> <strong>Affiliation</strong> </div> <div class=form-field> <input type=text name=institution class="form-input-field check-xss js-add-comment-institution" placeholder="Organization *" autocomplete=off /> <div class="default-error margin-top is-hidden comment-enter-institution institution">Please enter your organisation.</div> </div> <div class=form-field> <input type=text name=place class="form-input-field check-xss js-add-comment-place" placeholder=Place> </div> <div class=form-field> <div class="form-input-wrapper hundred-percent-wide"> <div class="new-select-standard-wrapper half-width inline-display heading10"> <select name=countryId id=country class="form-select-menu smaller js-add-comment-country"> <option value=-1>Country*</option> <option value=840>USA</option> <option value=826>UK</option> <option value=124>Canada</option> <option value=156>China</option> <option value=250>France</option> <option value=276>Germany</option> <optgroup label=-----------------------------------------------></optgroup> <option value=4>Afghanistan</option> <option value=248>Aland Islands</option> <option value=8>Albania</option> <option value=12>Algeria</option> <option value=16>American Samoa</option> <option value=20>Andorra</option> <option value=24>Angola</option> <option value=660>Anguilla</option> <option value=10>Antarctica</option> <option value=28>Antigua and Barbuda</option> <option value=32>Argentina</option> <option value=51>Armenia</option> <option value=533>Aruba</option> <option value=36>Australia</option> <option value=40>Austria</option> <option value=31>Azerbaijan</option> <option value=44>Bahamas</option> <option value=48>Bahrain</option> <option value=50>Bangladesh</option> <option value=52>Barbados</option> <option value=112>Belarus</option> <option value=56>Belgium</option> <option value=84>Belize</option> <option value=204>Benin</option> <option value=60>Bermuda</option> <option value=64>Bhutan</option> <option value=68>Bolivia</option> <option value=70>Bosnia and Herzegovina</option> <option value=72>Botswana</option> <option value=74>Bouvet Island</option> <option value=76>Brazil</option> <option value=86>British Indian Ocean Territory</option> <option value=92>British Virgin Islands</option> <option value=96>Brunei</option> <option value=100>Bulgaria</option> <option value=854>Burkina Faso</option> <option value=108>Burundi</option> <option value=116>Cambodia</option> <option value=120>Cameroon</option> <option value=124>Canada</option> <option value=132>Cape Verde</option> <option value=136>Cayman Islands</option> <option value=140>Central African Republic</option> <option value=148>Chad</option> <option value=152>Chile</option> <option value=156>China</option> <option value=162>Christmas Island</option> <option value=166>Cocos (Keeling) Islands</option> <option value=170>Colombia</option> <option value=174>Comoros</option> <option value=178>Congo</option> <option value=184>Cook Islands</option> <option value=188>Costa Rica</option> <option value=384>Cote d'Ivoire</option> <option value=191>Croatia</option> <option value=192>Cuba</option> <option value=196>Cyprus</option> <option value=203>Czech Republic</option> <option value=180>Democratic Republic of the Congo</option> <option value=208>Denmark</option> <option value=262>Djibouti</option> <option value=212>Dominica</option> <option value=214>Dominican Republic</option> <option value=218>Ecuador</option> <option value=818>Egypt</option> <option value=222>El Salvador</option> <option value=226>Equatorial Guinea</option> <option value=232>Eritrea</option> <option value=233>Estonia</option> <option value=231>Ethiopia</option> <option value=238>Falkland Islands</option> <option value=234>Faroe Islands</option> <option value=583>Federated States of Micronesia</option> <option value=242>Fiji</option> <option value=246>Finland</option> <option value=250>France</option> <option value=254>French Guiana</option> <option value=258>French Polynesia</option> <option value=260>French Southern Territories</option> <option value=266>Gabon</option> <option value=268>Georgia</option> <option value=276>Germany</option> <option value=288>Ghana</option> <option value=292>Gibraltar</option> <option value=300>Greece</option> <option value=304>Greenland</option> <option value=308>Grenada</option> <option value=312>Guadeloupe</option> <option value=316>Guam</option> <option value=320>Guatemala</option> <option value=831>Guernsey</option> <option value=324>Guinea</option> <option value=624>Guinea-Bissau</option> <option value=328>Guyana</option> <option value=332>Haiti</option> <option value=334>Heard Island and Mcdonald Islands</option> <option value=336>Holy See (Vatican City State)</option> <option value=340>Honduras</option> <option value=344>Hong Kong</option> <option value=348>Hungary</option> <option value=352>Iceland</option> <option value=356>India</option> <option value=360>Indonesia</option> <option value=364>Iran</option> <option value=368>Iraq</option> <option value=372>Ireland</option> <option value=376>Israel</option> <option value=380>Italy</option> <option value=388>Jamaica</option> <option value=392>Japan</option> <option value=832>Jersey</option> <option value=400>Jordan</option> <option value=398>Kazakhstan</option> <option value=404>Kenya</option> <option value=296>Kiribati</option> <option value=901>Kosovo (Serbia and Montenegro)</option> <option value=414>Kuwait</option> <option value=417>Kyrgyzstan</option> <option value=418>Lao People's Democratic Republic</option> <option value=428>Latvia</option> <option value=422>Lebanon</option> <option value=426>Lesotho</option> <option value=430>Liberia</option> <option value=434>Libya</option> <option value=438>Liechtenstein</option> <option value=440>Lithuania</option> <option value=442>Luxembourg</option> <option value=446>Macao</option> <option value=807>Macedonia</option> <option value=450>Madagascar</option> <option value=454>Malawi</option> <option value=458>Malaysia</option> <option value=462>Maldives</option> <option value=466>Mali</option> <option value=470>Malta</option> <option value=584>Marshall Islands</option> <option value=474>Martinique</option> <option value=478>Mauritania</option> <option value=480>Mauritius</option> <option value=175>Mayotte</option> <option value=484>Mexico</option> <option value=581>Minor Outlying Islands of the United States</option> <option value=498>Moldova</option> <option value=492>Monaco</option> <option value=496>Mongolia</option> <option value=499>Montenegro</option> <option value=500>Montserrat</option> <option value=504>Morocco</option> <option value=508>Mozambique</option> <option value=104>Myanmar</option> <option value=516>Namibia</option> <option value=520>Nauru</option> <option value=524>Nepal</option> <option value=530>Netherlands Antilles</option> <option value=540>New Caledonia</option> <option value=554>New Zealand</option> <option value=558>Nicaragua</option> <option value=562>Niger</option> <option value=566>Nigeria</option> <option value=570>Niue</option> <option value=574>Norfolk Island</option> <option value=580>Northern Mariana Islands</option> <option value=408>North Korea</option> <option value=578>Norway</option> <option value=512>Oman</option> <option value=586>Pakistan</option> <option value=585>Palau</option> <option value=275>Palestinian Territory</option> <option value=591>Panama</option> <option value=598>Papua New Guinea</option> <option value=600>Paraguay</option> <option value=604>Peru</option> <option value=608>Philippines</option> <option value=612>Pitcairn</option> <option value=616>Poland</option> <option value=620>Portugal</option> <option value=630>Puerto Rico</option> <option value=634>Qatar</option> <option value=638>Reunion</option> <option value=642>Romania</option> <option value=643>Russian Federation</option> <option value=646>Rwanda</option> <option value=654>Saint Helena</option> <option value=659>Saint Kitts and Nevis</option> <option value=662>Saint Lucia</option> <option value=666>Saint Pierre and Miquelon</option> <option value=670>Saint Vincent and the Grenadines</option> <option value=882>Samoa</option> <option value=674>San Marino</option> <option value=678>Sao Tome and Principe</option> <option value=682>Saudi Arabia</option> <option value=686>Senegal</option> <option value=688>Serbia</option> <option value=690>Seychelles</option> <option value=694>Sierra Leone</option> <option value=702>Singapore</option> <option value=703>Slovakia</option> <option value=705>Slovenia</option> <option value=90>Solomon Islands</option> <option value=706>Somalia</option> <option value=710>South Africa</option> <option value=239>South Georgia and the South Sandwich Is</option> <option value=410>South Korea</option> <option value=724>Spain</option> <option value=144>Sri Lanka</option> <option value=736>Sudan</option> <option value=740>Suriname</option> <option value=744>Svalbard and Jan Mayen</option> <option value=748>Swaziland</option> <option value=752>Sweden</option> <option value=756>Switzerland</option> <option value=760>Syria</option> <option value=158>Taiwan</option> <option value=762>Tajikistan</option> <option value=834>Tanzania</option> <option value=764>Thailand</option> <option value=270>The Gambia</option> <option value=528>The Netherlands</option> <option value=626>Timor-Leste</option> <option value=768>Togo</option> <option value=772>Tokelau</option> <option value=776>Tonga</option> <option value=780>Trinidad and Tobago</option> <option value=788>Tunisia</option> <option value=792>Turkey</option> <option value=795>Turkmenistan</option> <option value=796>Turks and Caicos Islands</option> <option value=798>Tuvalu</option> <option value=800>Uganda</option> <option value=826>UK</option> <option value=804>Ukraine</option> <option value=784>United Arab Emirates</option> <option value=850>United States Virgin Islands</option> <option value=858>Uruguay</option> <option value=840>USA</option> <option value=860>Uzbekistan</option> <option value=548>Vanuatu</option> <option value=862>Venezuela</option> <option value=704>Vietnam</option> <option value=876>Wallis and Futuna</option> <option value=905>West Bank and Gaza Strip</option> <option value=732>Western Sahara</option> <option value=887>Yemen</option> <option value=894>Zambia</option> <option value=716>Zimbabwe</option> </select> </div> </div> <div class="default-error margin-top is-hidden comment-enter-country country">Please select your country.</div> </div> </div> <textarea data-test-id=article_add-comment_comment name=new-comment class="js-add-comment-comment comment margin-bottom margin-top"></textarea> <div class="default-error margin-top comment-enter-text comment-error is-hidden ">You must enter a comment.</div> <label class="comments-note u-mt--2 u-mb--2" for=competingInterests_1> <div class="u-mb--1 u-mt--2"><strong data-test-id=article_report-add-comment_competing-interests-title>Competing Interests</strong></div> <p class="u-mb--2 u-mt--0" data-test-id=article_report-add-comment_competing-interests-description>Please disclose any <a href="#article-competing-intersts-policy" class=js-modal-competing-intersts-toggle>competing interests</a> that might be construed to influence your judgment of the article's or peer review report's validity or importance.</p> </label> <div id=article-competing-intersts-policy class=js-article-competing-interests-policy style="display: none;"> <h2 class="h2-title u-mt--0 u-pt--0">Competing Interests Policy</h2> <p> Provide sufficient details of any financial or non-financial competing interests to enable users to assess whether your comments might lead a reasonable person to question your impartiality. Consider the following examples, but note that this is not an exhaustive list: </p> <div class=heading5>Examples of 'Non-Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>Within the past 4 years, you have held joint grants, published or collaborated with any of the authors of the selected paper.</li> <li class=standard-padding>You have a close personal relationship (e.g. parent, spouse, sibling, or domestic partner) with any of the authors.</li> <li class=standard-padding>You are a close professional associate of any of the authors (e.g. scientific mentor, recent student).</li> <li class=standard-padding>You work at the same institute as any of the authors.</li> <li class=standard-padding>You hope/expect to benefit (e.g. favour or employment) as a result of your submission.</li> <li class=standard-padding>You are an Editor for the journal in which the article is published.</li> </ol> <div class="heading5 padding-top">Examples of 'Financial Competing Interests'</div> <ol class="numbered-list no-padding"> <li class=standard-padding>You expect to receive, or in the past 4 years have received, any of the following from any commercial organisation that may gain financially from your submission: a salary, fees, funding, reimbursements.</li> <li class=standard-padding>You expect to receive, or in the past 4 years have received, shared grant support or other funding with any of the authors.</li> <li class=standard-padding>You hold, or are currently applying for, any patents or significant stocks/shares relating to the subject matter of the paper you are commenting on.</li> </ol> </div> <div id=competingInterests_1 class="c-inline-editor js-inline-editor js-form_input u-bb--all u-mb--2 js-comment-competing-interests" data-name=competing-interests data-rows=3> <textarea id=competingInterests_1_input name=competing-interests placeholder="&nbsp;" required=false class="u-hide-visually js-inline-editor_input" tabindex=-1></textarea> <div class="c-inline-editor__editor js-inline-editor_editor o-box c-box o-box--tiny u-bg--11" data-target=competingInterests_1_input role=textbox required=false data-placeholder="&nbsp;" contenteditable=true></div> <span class="c-inline-editor__error js-inline-editor-message">Please state your competing interests</span> </div> <div data-test-id=article_add-comment_saved class="green-message comments is-hidden comment-is-saved">The comment has been saved.</div> <div data-test-id=article_add-comment_error class="default-error comments is-hidden comment-not-added">An error has occurred. Please try again.</div> <div class=clearfix></div> <div class=js-hook></div> </div> <div class="c-modal__extra-message js-modal__extra-message t-h4 u-black--medium"></div></div> <div class="c-modal__actions o-box__actions"> <a href="#" data-test-id=article_add-comment_cancel class="c-button c-button--full js-modal__close c-button--secondary">Cancel</a> <a href="#" data-test-id=article_add-comment_post class="c-button c-button--full js-modal__confirm c-button--primary">Post</a> </div> </aside> </div> </div> <style>
                .at-icon-wrapper {
        background-size: 100% !important;
    }
</style> <script src="/js/namespace.js"></script> <script src="/js/constants.js"></script> <script src="/js/utilities.js"></script> <script src="/js/article/alert-signup.js"></script> <script type='text/javascript'>
    var lTitle = "Affective rating of audio and video clips...".replace("'", '');
    var linkedInUrl = "http://www.linkedin.com/shareArticle?url=https://f1000research.com/articles/9-970/v1" + "&title=" + encodeURIComponent(lTitle) + "&summary=" + encodeURIComponent('Read the article by ');

    var deliciousUrl = "https://del.icio.us/post?url=https://f1000research.com/articles/9-970/v1&title=" + encodeURIComponent(lTitle);

    var redditUrl = "http://reddit.com/submit?url=https://f1000research.com/articles/9-970/v1" + "&title=" + encodeURIComponent(lTitle);

            linkedInUrl += encodeURIComponent('Toet A and van Erp JBF');
    
    var offsetTop = /chrome/i.test( navigator.userAgent ) ? 4 : -10; 
    var addthis_config = {
            ui_offset_top: offsetTop,
                                    services_compact : "facebook,twitter,www.linkedin.com,www.mendeley.com,reddit.com",
            services_expanded : "facebook,twitter,www.linkedin.com,www.mendeley.com,reddit.com",
            services_custom : [
                {
                    name: "LinkedIn",
                    url:  linkedInUrl,
                    icon:"/img/icon/at_linkedin.svg"
                },
                {
                    name: "Mendeley",
                    url:  "http://www.mendeley.com/import/?url=https://f1000research.com/articles/9-970/v1/mendeley",
                    icon:"/img/icon/at_mendeley.svg"
                },
                {
                    name: "Reddit",
                    url:  redditUrl,
                    icon:"/img/icon/at_reddit.svg"
                },
            ]
        };


    var addthis_share = {
            url: "https://f1000research.com/articles/9-970",
            templates : {
                twitter : "Affective rating of audio and video clips using the EmojiGrid. Toet A and van Erp JBF, published by " + 
               "@F1000Research"
       + ", https://f1000research.com/articles/9-970/v1"
            }
        };

    if (typeof(addthis) != "undefined"){
        addthis.addEventListener('addthis.ready', checkCount);
        addthis.addEventListener('addthis.menu.share', checkCount);
    }

        $(".f1r-shares-twitter").attr("href", "https://twitter.com/intent/tweet?text=" + addthis_share.templates.twitter);
    $(".f1r-shares-facebook").attr("href", "https://www.facebook.com/sharer/sharer.php?u=" + addthis_share.url);
    $(".f1r-shares-linkedin").attr("href", addthis_config.services_custom[0].url);
    $(".f1r-shares-reddit").attr("href", addthis_config.services_custom[2].url);
    $(".f1r-shares-mendelay").attr("href", addthis_config.services_custom[1].url);

    function checkCount(){
        setTimeout(function(){
            $(".addthis_button_expanded").each(function(){
                var count = $(this).text();
                if (count !== "" && count != "0")
                    $(this).removeClass("is-hidden");
                else
                    $(this).addClass("is-hidden");
            });
        }, 1000);
    }
</script> <div id=citeReportModal role=dialog aria-labelledby=citeReportModal_title aria-describedby=citeReportModal_description> <div class="c-modal js-modal is-closed c-modal--large js-cite-report-modal "> <aside class="c-modal__content u-black--high o-box u-pb--0 u-black--high "> <div class=c-modal__close> <button type=button class="c-button c-button--icon c-button--medium c-button--full@hover js-modal__close"><i class="c-button--icon__icon material-icons">close</i></button> </div> <h1 id=citeReportModal_title class="c-modal__title t-h3 u-mt--0 u-mb--2 u-weight--md">How to cite this report</h1> <div id=citeReportModal_description class="c-modal__description js-modal__content t-h4 u-mt--0 u-mb--2 u-black--medium"> <div id="" class=js-report-citation-container>{{reportCitation}}</div> <div class="c-modal__extra-message js-modal__extra-message t-h4 u-black--medium"></div></div> <div class="c-modal__actions o-box__actions"> <a href="#" class="c-button c-button--full js-modal__close c-button--secondary">Cancel</a> <a href="#" title="Copy the current citation details to the clipboard." data-clipboard-target="#referee-report-citation" data-test-id=report_copy-citation_button class="c-button c-button--full js-modal__confirm c-button--primary js-clipboard c-mini-tooltip--above">Copy Citation Details</a> </div> </aside> </div> </div> <script src="/js/referee/new/referee_validators.js"></script> <script src="/js/referee/new/referee_helpers.js"></script> <script src="/js/referee/new/referee_checkbox-input.js"></script> <script src="/js/referee/new/referee_inline-editor.js"></script> <script type="text/javascript">
    $(function(){
        var gaCat = "F1000Research";
        if (gaCat === "") {
            gaCat = $("body").hasClass("wellcome-brand") ? "Wellcome Open Research" : "F1000Research";
        }
        GAHelper.track({category: gaCat, action: "Article Page: Affective rating of audio and video clips using the EmojiGrid", label: "pageviews"});
        GAHelper.track({category: gaCat, action: "Article Type: Research Article", label: "Article Page"});
        $(".f1r-article-desk .collection-image").each(function (idx, el) {
            var whatChannel = $(el).find("a").attr("href"),
                channelName = $.trim($(el).parent().find(".collection-detail a").text()),
                gaRef = "(ID: " + whatChannel.replace("/collections/", "") + ") " + channelName;
            GAHelper.track({category: 'ChannelStats', action: "Article Page: Affective rating of audio and video clips using the EmojiGrid", label: gaRef});
        });
    });
</script> <script>
    $(function(){R.ui.buttonDropdowns('.dropdown-for-downloads');});
    $(function(){R.ui.toolbarDropdowns('.toolbar-dropdown-for-downloads');});
</script> <script src="/js/article/track_article.js" type="text/javascript"></script> <script type="text/javascript">
    $.get("/articles/acj/25088/27685")
</script> <script type="text/javascript" src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script type="text/javascript" src="/js/app/messenger.js"></script> <script type="text/javascript" src="/js/article/article_mobiles.js"></script> <script src="/js/vendor/clipboard.min.js"></script> <script src="/js/shared_scripts/modal-dialogue.js"></script> <script src="/js/shared_scripts/clipboard.js"></script> <script src="/js/article/thesaurus-terms-display.js"></script> <script>
    new F1000.Clipboard();
    new F1000.ThesaurusTermsDisplay("articles", "article", "27685");
</script> <script>
    $(document).ready(function() {
        $( "#frame1" ).on('load', function() {
            var mydiv = $(this).contents().find("div");
            var h     = mydiv.height();
            console.log(h)
        });

        
        var tooltipLivingFigure = jQuery(".interactive-living-figure-label .icon-more-info"),
            titleLivingFigure = tooltipLivingFigure.attr("title");
        tooltipLivingFigure.simpletip({
            fixed: true,
            position: ["-115", "30"],
            baseClass: 'small-tooltip',
            content:titleLivingFigure + "<div class='tooltip-arrow'></div>"
        });
        tooltipLivingFigure.removeAttr("title");

        $("body").on("click", ".cite-living-figure", function(e) {
            e.preventDefault();
            var ref = $(this).attr("data-ref");
            $(this).closest(".living-figure-list-container").find("#" + ref).fadeIn(200);
        });
        $("body").on("click", ".close-cite-living-figure", function(e) {
            e.preventDefault();
            $(this).closest(".popup-window-wrapper").fadeOut(200);
        });

                $(document).on("mouseup", function(e) {
            var metricsContainer = $(".article-metrics-popover-wrapper");
            if (!metricsContainer.is(e.target) && metricsContainer.has(e.target).length === 0) {
                $(".article-metrics-close-button").click();
            }
        });

        var articleId = $('#articleId').val();

        if($("#main-article-count-box").attachArticleMetrics) {
            $("#main-article-count-box").attachArticleMetrics(articleId, {
                articleMetricsView: true
            });
        }
    });

    var figshareWidget = $(".new_figshare_widget");
    if (figshareWidget.length > 0) {
        window.figshare.load("f1000", function(Widget) {
            // Select a tag/tags defined in your page. In this tag we will place the widget.
            _.map(figshareWidget, function(el){
                var widget = new Widget({
                    articleId: $(el).attr("figshare_articleId")
                    //height:300 // this is the height of the viewer part. [Default: 550]
                });
                widget.initialize(); // initialize the widget
                widget.mount(el); // mount it in a tag that's on your page
                // this will save the widget on the global scope for later use from
                // your JS scripts. This line is optional.
                //window.widget = widget;
            });
        });
    }
</script>

<script>
    $(document).ready(function () {

        
        var reportIds = {
                           "69205": 0,
                           "69204": 0,
                           "69207": 0,
                           "69206": 0,
                           "69209": 0,
                           "69208": 0,
                    };

        $(".referee-response-container,.js-referee-report").each(function(index, el) {
            var reportId = $(el).attr("data-reportid"),
                reportCount = reportIds[reportId] || 0;
            $(el).find(".comments-count-container,.js-referee-report-views").html(reportCount);
        });

        var uuidInput = $("#article_uuid"),
            oldUUId = uuidInput.val(),
            newUUId = "a51becd3-028e-4ae4-8e55-9a8600637b0c";
        uuidInput.val(newUUId);

        $("a[href*='article_uuid=']").each(function(index, el) {
            var newHref = $(el).attr("href").replace(oldUUId, newUUId);
            $(el).attr("href", newHref);
        });

    });
</script>              </div>
        </div>

        
            
            <div class="o-page__footer sticky-email-wrapper">
                
                

                


<footer class="c-footer t-inverted">

    <div class="o-wrapper">
        <div class="o-layout">


                        
            <div class="o-layout__item u-mb--3">
                <div class="c-branding c-branding--research">
                    <img src="/img/research/F1000Research_white.svg" alt="F1000Research">
                </div>
            </div>


                        
            <div class="o-layout__item u-1/3@md u-mb--3">

                <span class="c-hr c-hr--thick c-hr--low u-mb--2"></span>

                <p class="t-h3 u-mt--0 u-mb--0">An innovative open access publishing platform offering rapid publication and open peer review, whilst supporting data deposition and sharing.</p>

            </div>


                        
            <div class="o-layout__item u-2/3@md">

                <span class="c-hr c-hr--thick c-hr--low u-mb--2"></span>

                <div class="o-layout">
                    <nav class="c-footer__nav">

                            <div class="o-layout__item u-3/5@sm u-mb--3">


                                <div class="o-columns o-columns--2">

                                                                            <a href="/browse/articles" class="t-body c-footer__nav-item "      >Browse</a>
                                                                            <a href="/gateways" class="t-body c-footer__nav-item "      >Gateways</a>
                                                                            <a href="/collections" class="t-body c-footer__nav-item "      >Collections</a>
                                                                            <a href="/about" class="t-body c-footer__nav-item "      >How it Works</a>
                                                                            <a href="https://blog.f1000.com/blogs/f1000research/" class="t-body c-footer__nav-item "      >Blog</a>
                                                                            <a href="/contact" class="t-body c-footer__nav-item "      >Contact</a>
                                                                            <a href="/developers" class="t-body c-footer__nav-item u-hide u-show@navbar"      >For Developers</a>
                                                                            <a href="/published/rss" class="t-body c-footer__nav-item "   title="RSS feed of published articles"     >RSS</a>
                                    
                                </div>

                            </div>

                            <div class="o-layout__item u-2/5@sm u-center u-right@sm u-mb--3">

                                <div class="u-hide u-show@lg">
                                    <div class="_mdl-layout">
                                        <a class="mdl-button mdl-js-button mdl-button--inverted mdl-button--no-shadow mdl-js-ripple-effect mdl-button--outline" href="/for-authors/publish-your-research"   data-test-id="footer_submit_research"  >Submit Your Research</a>
                                    </div>
                                </div>

                            </div>

                    </nav>
                </div>

            </div>

            <div class="o-layout__item u-mb--2">
                <div class="c-footer__share">
                        <div class="c-footer__share">
        <span class="c-footer__share-icon" title="Open Access">
            <span class="f1r-icon icon-100_open_access license-icon"></span>
        </span>

        <a class="c-footer__share-icon" href="//creativecommons.org/licenses" target="_blank" title="Creative Commons License CC-BY">
            <span class="f1r-icon icon-116_cc license-icon license-icon-cc"></span>
            <span class="f1r-icon icon-117_ccby license-icon license-icon-cc"></span>
        </a>

        <a class="c-footer__share-icon" href="//creativecommons.org/about/cc0" target="_blank" title="Creative Commons License CC0">
            <span class="f1r-icon icon-118_cco license-icon"></span>
        </a>

    </div>
                </div>
            </div>


                        
            <div class="o-layout__item u-1/3@md u-mb--3">

                <span class="c-hr c-hr--low u-mb--3"></span>

                <p class="c-footer__social u-mt--0 u-mb--0 u-white--low-med">Follow us
                    <a href="https://www.facebook.com/F1000" target="_blank" class="c-footer__social-icon f1r-icon icon-55_footer_facebook"></a>
                    <a href="https://twitter.com/#!/F1000Research" target="_blank" class="c-footer__social-icon f1r-icon icon-56_footer_twitter"></a>
                    <a href="http://www.youtube.com/user/F1000research" target="_blank" class="c-footer__social-icon f1r-icon icon-57_footer_youtube"></a></p>

            </div>


                        
            <div class="o-layout__item u-2/3@md u-right@md">

                <span class="c-hr c-hr--low u-mb--3"></span>

                <p class="t-caption u-white--low-med">&copy; 2012-2020 F1000 Research Ltd. ISSN 2046-1402 | <a href="/about/legal" class="copyrightLegal">Legal</a> | Partner of <a target="_blank" href="http://www.who.int/hinari/en/">HINARI</a>  &bull; <a target="_blank" href="http://crossref.org/">CrossRef</a> &bull; <a target="_blank" href="http://about.orcid.org/">ORCID</a> &bull; <a target="_blank" href="http://www.fairsharing.org">FAIRSharing</a></p>

            </div>
        </div>
    </div>

</footer>            </div>
        
    </div>

            <div class="js-cookie-spacer"></div>
        <div class="cookie-warning">
            <div class="instruction">The F1000Research website uses cookies. By continuing to browse the site, you are agreeing to our use of cookies. <a class="js-scroll-to" href="/about/legal/privacypolicy#use-of-cookies" data-scroll-target="#use-of-cookies">Find out more &raquo;</a></div>
            <div class="close-button"></div>
        </div>
    
    <script>
                    R.templateTests.simpleTemplate = R.template('<p class="$variable.one">$text</p><p class="${variable.two}">$text</p><p class="$!variable.three">$text</p><p class="$!{variable.four}">$text</p><p class="${selector}.five">$text</p>');
            R.templateTests.runTests();
        
        var F1000platform = new F1000.Platform({
            name: "f1000research",
            displayName: "F1000Research",
            hostName: "f1000research.com",
            id: "1",
            editorialEmail: "research@f1000.com",
            infoEmail: "info@f1000.com",
            usePmcStats: true
        });

                    $(function(){R.ui.dropdowns('.dropdown-for-authors, .dropdown-for-about, .dropdown-for-myresearch');});
            // $(function(){R.ui.dropdowns('.dropdown-for-referees');});

            $(document).ready(function () {
                if ($(".cookie-warning").is(":visible")) {
                    $(".sticky").css("margin-bottom", "35px");
                    $(".devices").addClass("devices-and-cookie-warning");
                }
                $(".cookie-warning .close-button").click(function (e) {
                    $(".devices").removeClass("devices-and-cookie-warning");
                    $(".sticky").css("margin-bottom", "0");
                });

                $("#tweeter-feed .tweet-message").each(function (i, message) {
                    var self = $(message);
                    self.html(linkify(self.html()));
                });

                $(".partner").on("mouseenter mouseleave", function() {
                    $(this).find(".gray-scale, .colour").toggleClass("is-hidden");
                });
            });
        
    </script>

            
<div class="sign-in-popup">
	<!-- <a href="#" class="sign-in shadow">Sign in <span class="sign-in-image-active"></span></a> -->
	<a href="#" class="sign-in ${locale}">Sign In <span class="arrow-closed sign-in-arrow-padding arrow-opened"></span></a>
	<div class="sign-in-form">

            <form action="https://f1000research.com/j_spring_oauth_security_check" id="googleOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/9-970.html"/>
                            <input id="google-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-google" name="system" type="hidden" value="GOOGLE"/>
    </form>
            <form action="https://f1000research.com/j_spring_oauth_security_check" id="facebookOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/9-970.html"/>
                            <input id="facebook-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-fb" name="system" type="hidden" value="FACEBOOK"/>
    </form>
            <form action="https://f1000research.com/j_spring_oauth_security_check" id="orcidOAuth" method="post"  target="_top" >
                                    <input class="target-field" type="hidden" name="target" value="/articles/9-970.html"/>
                            <input id="orcid-remember-me" name="_spring_security_oauth_remember_me" type="hidden" value="true"/>
        <input id="system-orcid" name="system" type="hidden" value="ORCID"/>
    </form>
		<form id="sign-in-form" class="login-container" action="https://f1000research.com/login" method="post" name="f">
           <div id="sign-in-form-gfb-popup"></div>

                                                            <input class="target-field" type="hidden" name="target" value="/articles/9-970.html"/>
                            			<input type="text" name="username" id="signin-email-box" class="sign-in-input" placeholder="Email address" autocomplete="email">
			<input type="password" name="password" id="signin-password-box" class="sign-in-input" placeholder="Password" autocomplete="current-password">
			<div class="sign-in-remember">
                <div class="checkbox-wrapper">
    				<input type="checkbox" id="remember-me" name="remember_me" class="checkbox is-hidden">
                </div>
                <span class="checkbox-label">Remember me</span>
			</div>
			<a href="#" class="sign-in-link" id="forgot-password-link">Forgotten your password?</a>
			<div class="sign-in-button-container margin-top margin-left-20 margin-bottom">
				<button type="submit" id="sign-in-button" class="sign-in-buttons general-white-orange-button">Sign In</button>
				<button type="button" id="sign-in-cancel" class="sign-in-buttons sign-in-cancel-button margin-left">Cancel</button>
				<div class="clearfix"></div>
			</div>
			<div class="sign-in-error">Email or password not correct. Please try again</div>
			<div class="sign-in-loading">Please wait...</div>
		</form>
		<div class="forgot-password-container">
			
<script type="text/javascript">
	$(function(){
		// Note: All the setup needs to run against a name attribute and *not* the id due the clonish
		// nature of facebox...
		$("a[id=googleSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("GOOGLE");
            $("form[id=oAuthForm]").submit();
        });
        $("a[id=facebookSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("FACEBOOK");
            $("form[id=oAuthForm]").submit();
        });
        $("a[id=orcidSignInButton]").click(function(event){
            event.preventDefault();
            $("input[id=oAuthSystem]").val("ORCID");
            $("form[id=oAuthForm]").submit();
        });
	});
</script>

<span class="text first">
	If you've forgotten your password, please enter your email address below and we'll send you instructions on how to reset your password.
    <p>The email address should be the one you originally registered with F1000.</p>
</span>
<input name="email" class="sign-in-input" id="email-forgot-password" type="text" placeholder="Email address">
<div class="forgot-password-email-error">
	Email address not valid, please try again
</div>
<div class="forgot-password-google-email-error">
    <p>You registered with F1000 via Google, so we cannot reset your password.</p>
	<p>To sign in, please click <a href="#" id="googleSignInButton">here</a>.</p>
    <p>If you still need help with your Google account password, please click <a href="https://www.google.com/accounts/recovery">here</a>.</p>
</div>
<div class="forgot-password-facebook-email-error">
    <p>You registered with F1000 via Facebook, so we cannot reset your password.</p>
    <p>To sign in, please click <a href="#" id="facebookSignInButton">here</a>.</p>
	<p>If you still need help with your Facebook account password, please click <a href="https://www.facebook.com/recover/initiate">here</a>.</p>
</div>
<div class="clearfix"></div>
<div class="forgot-password-captcha-error">
	Code not correct, please try again
</div>
<div class="clearfix"></div>
<div class="sign-in-button-container margin-left-20 margin-bottom">
	<button type="button" id="sign-in-reset-password" class="sign-in-buttons general-white-orange-button">Reset password</button>
	<button type="button" id="forgot-password-cancel" class="sign-in-buttons sign-in-cancel-button margin-left">Cancel</button>
	<div class="clearfix"></div>
</div>
<span class="text last">
	<a href="mailto:">Email us</a> for further assistance.
</span>
<form action="https://f1000research.com/j_spring_oauth_security_check" id="oAuthForm" method="post" target="_top">
                        <input class="target-field" type="hidden" name="target" value="/articles/9-970.html"/>
                <input id="oAuthSystem" name="system" type="hidden"/>
</form>
			<div class="forgot-password-server-error">Server error, please try again.</div>
			<div class="sign-in-success">
                <p>We have sent an email to <span id="email-value"></span>, please follow the instructions to reset your password.</p>
                <p>If you don't receive this email, please check your spam filters and/or contact .</p>
            </div>
			<div class="sign-in-loading">Please wait...</div>
		</div>

		<div class="sign-in-form-register-section">
			<div class="sign-in-button-container margin-left-20 margin-bottom">
				<a href="/register" title="Register"><button type="button" id="sign-in-register-button" class="sign-in-buttons general-white-orange-button">Register</button></a>
				<div class="clearfix"></div>
			</div>
		</div>

	</div>
</div>

<script type="text/javascript">
$(document).ready(function () {

    signIn.createSignInAsRow($("#sign-in-form-gfb-popup"));

    $(".target-field").each(function () {
        var uris = $(this).val().split("/");
        if (uris.pop() === "login") {
        	$(this).val(uris.toString().replace(",","/"));
        }
    });
});
</script>
        <div id="templateOverlay" class="is-hidden" hidden="hidden">
  <div class="o-overlay js-overlay is-hidden" hidden="hidden"></div>
</div>

<div id="templateExternalMessages" class="is-hidden" hidden="hidden">
  <div class="o-modal o-modal--auto@md js-external-messages is-hidden" hidden="hidden">
    <div class="o-modal__body">
      <section class="c-console">
        <div class="_mdl-layout c-console__bdy js-external-messages-body"></div>
        <footer class="_mdl-layout c-console__ftr o-flex o-flex--reverse js-external-messages-footer">
          <button type="button" class="mdl-button mdl-js-button mdl-button--raised mdl-button--colored c-console__btn js-external-messages-close" data-action="maintenance-close">I Understand</button>
        </footer>
      </section>
    </div>
  </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.1/moment.min.js"></script>

<script src="/js/namespace.js"></script>
<script src="/js/constants.js"></script>
<script src="/js/utilities.js"></script>

<script>
                  F1000.ExtenalMaintenanceItems = [
    {
      start: '2018-12-10T14:21:00Z',
      end: '2018-12-13T16:00:00Z',
      msg: 'This site will be down for a short time on XX December. It is advisable not to start any submissions on that day or you may lose your work unless you save regularly.',
      cookieName: 'outage23122018',
      editor: false,
    }
  ];
</script>

<script src="/js/shared_scripts/cookie-helper.js"></script>
<script src="/js/shared_scripts/mdl-helper.js"></script>

<script src="/js/app/external-maintenance.js"></script>

                <script type="text/javascript">
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-5646075-11', 'auto');
            ga('require', 'displayfeatures');
            ga('send', 'pageview');
        </script>
        
                <script type="text/javascript" src="/js/app/research.analytics.js"></script>

        <!-- Start of HubSpot Embed Code -->
        <script type="text/javascript" id="hs-script-loader" async defer src="//js.hs-scripts.com/4475190.js"></script>
        <!-- End of HubSpot Embed Code -->
    
            <script src="https://my.hellobar.com/4e0495c6f18cbd68731a1dc1978195a144e767ba.js" type="text/javascript" charset="utf-8" async="async"></script>
    </body>

</html>