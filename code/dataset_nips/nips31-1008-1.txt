The paper focuses on generalized zero-shot learning, where prediction on unseen data is made over both source (visible during training) and target classes (not available during training). The proposed framework is called Deep Calibration Network (DCN).  Related work is short but informative.   The architecture of DCN consists of a visual model and a text model. An embedding space is filled with low-dimensional representation originated by both text (semantic representation) and images (visual representation). When an image is given, its visual representation is checked against the closest semantic representation, both projected in the embedded space. In this straightforward scheme, the novelty is in the temperature calibration, which acts as a sort of softmax regularizer, which mitigates the tendency toward to the source classes (intead of the unseen ones) caused by overfitting the seen data.   This becomes tangible into the DCN in an explicit entropic term, together with a complexity penalty which adds to the standard loss.   Experiments are consistent, convincing, detailed, exhaustive. In particular, and obviously, generalized tests make the wow effect.     