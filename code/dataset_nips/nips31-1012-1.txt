The paper describes a new distance metric for neural networks based on optimal transport. Based on this distance, the authors introduce a new Bayesian optimization strategy to optimize the architecture of neural networks.   Overall I think the methods is interesting and that the proposed distance might be also of interest for other applications than Bayesian optimization. However, it seems that computing the distance also requires some manual tuning such as defining the cost matrix which in turn requires expert knowledge. My only point of criticism is that this might hinder its success in automated machine learning applications, where human interaction should be reduced to a minimum.  Having said that, the method is well explained and the authors provide some meaningful empirical insights, such that the paper represents an important contribution for Bayesian optimization.  The following points need some further clarification:  1) How many actual function evaluation did every method perform in Figure 2. i.e how many architectures were trained? In the figure it seems that every method returns something after a discrete time step?  2) What do you mean with at least 5 independent runs for each method in the caption of Figure 2? Why did you perform less runs for some methods?  3) How are pending jobs treated in the parallel set up described in section 5?  4) In table 3, it says CIFAR-10 has 1k features instead of 32*32*3=3072. I guess that this is a typo?    --- Post Rebuttal ---  I thank the authors for taking their time to write the rebuttal and clarifying my points.