The paper describes an approach to learn to perform duplicate removal for object detection -- finding the right proposals for region classification. The proposed idea consists of two stages: in the first stage it learns to behave like NMS and reject most of the negative proposals; in the second stage it receives positive candidates from the first stage, and then select the final set of proposal outputs. Experiments are done on COCO with state of the art object detectors like FPN.   - Overall I think it is a decent paper. Replacing NMS has been an interesting topic in the recent years for object detection so the problem is of significance. While the current approach is based on the previous work that use relation networks for object detection, it has introduced new components (two-stage, global attention etc). The paper is quite well written and well illustrated with figures. The experiments are extensive, with multiple state of the art detectors and multiple analysis.  - It is missing citations for a recent work that also partially learns NMS: Chen, Xinlei, and Abhinav Gupta. "Spatial memory for context reasoning in object detection." ICCV (2017). - What is the training/validation set performance for stage I training? It is interesting that on the test set the learned model can "outperform" the teacher used for training. Is the 0.1-0.2 improvement statistically significant? I think the reason may be beyond what is mentioned in the paper. - Is stage I and stage II trained jointly or sequentially? - It would be interesting to see the total speed/memory usage for the proposed method. The paper mentioned that the proposed approach reduced the number of proposals used for second stage classification, however RoI operations can be done in parallel for multiple regions, whereas the entire region classification step will have to wait till the proposals are computed in the RPN. So I am not totally convinced about the speed argument.  