The work studies the greedy algorithm for linear contextual bandits under smoothed analysis. The contexts are chosen adversarially, and are then perturbed by a zero-mean i.i.d Gaussian. The reward per arm are chosen stochastically with expectation that is a linear function of the context.   The authors differentiate between the single parameter setting in which the same function is used for all arms, and the multiple paramter setting in which a different function is used for each arm. The behavior of the algorithm is different in each model. In the single parameter setting, exploring one arm can provide information regarding the expected reward of all other arms. In the multiple parameter setting this is not the case, and the authors show that the algorithm can lead to $\sqrt{T}$ regret only after a sufficiently long warm-start period.   The Gaussian perturbations ensures two things. First, that the second moment matrix of the context vectors is well-conditioned. This allows the least square estimator to properly identify the model parameters within reasonable sample complexity. Second, that there is nonneligible probability that the reward of the optimal arm is well-separated from the rewards of the rest of the arms. In the multiple parameter model, after the warm-start, this allows the greedy algorithm to pull the optimal arm in sufficiently many rounds which promotes exploration.   The paper is well-written. The results seem novel and interesting. I am missing a discussion about the motivation behind the analysis: why and in what way exactly is the greedy algorithm "fair" (simply picking an action uniformly at random can also be considered fair).  Minor comments: -------------- Line 243: must rounds  Throughout the paper, there seems to be some confusion regarding column and row vectors. I ask the authors to please use consistent notation.