The paper presents a method of single-image 3D reconstruction that works well also for unseen classes. The method is based on a sequence of networks/operations that 1) estimate the depth of the input object, 2) convert the depth map to a partial spherical map, 3) inpaint the spherical map, 4) refine the voxelized representation. These intermediate representations reduce the dependency in class-specific priors, allowing the system to generalize beyond the trained classes.  Overall, I like the paper and I find the use of intermediate representations useful for the task of both intra-class reconstruction and the generalization to unknown classes. In particular, the use of spherical maps for representing shapes and having a network to inpaint the hidden parts is interesting. Another strong point of the paper is its presentation: the paper is well written and easy to follow and the experimental setup is well performed.   In the weaknesses, the novelty in terms of network architecture seems limited as the method is using a sequence of standard blocks/losses. Also, I would expect to see more examples in the supp mat and applications on real images. I would like also to see more details why the different "Ours" variants perform that way for the "Train" case. Finally, including IoU for the voxel-based approaches will give a better insight in the comparisons. Also how well are the intermediate depths maps?