BourGAN: Generative Networks with Metric Embeddings  Overview: Generative Adversarial Networks (GANs) are the most widely used method for generative deep networks. However, GANs are suffered from the problem of mode-collapse, where generator is concentrated on a special mode to get good precision, but cannot learn to generate diverse samples. In this paper, the author proposed a novel method BourGAN to generate latent variables that represents different modes. By converting the samples to a distance-preserve embedding using Bourgain's theorem, the author used a mixture Gaussian distribution based on the new embedding to generate latent variables to avoid mode-collapse problem. The author provided extensive experiments in both synthetic and real dataset to show that BourGAN is capable of learning multi-mode dataset with impressive results. Besides the GANs related papers mentioned in the BourGAN paper, there's no known related work on solving mode-collapse problem in GAN as far as I know.  Quality: The paper is technically sound and well writtened. The experiments are well organized with impressive and expected results.  Clarity: The paper is very well organized and well written. The concepts are explained clearly with details.  Originality: The idea of identify the mode in the dataset using Bourgain theorem and construct mixture Gaussian for generators is very novel, at least to my knowledge.  Significance: The BourGAN provided a impressive solution for mode-collapse problem for GAN. I believe it could make significant impact on GAN applications and development.  