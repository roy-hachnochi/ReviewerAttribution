This paper considers the problem of repeatedly estimating statistics on users’ data while providing users with the strong privacy notion of local differential privacy (LDP). The local model of differential privacy differs from the more common central model in that there is no trusted party that can aggregate the data before adding noise, so noise must be added by each individual before aggregation. This is the model used by Apple and Google in practice to ensure that private data never reaches their servers in the clear.  Existing LDP techniques provide only "one shot" tools, with proven privacy guarantees only for a one time use of the algorithm. In contrast, industrial applications of LDP repeatedly apply such algorithms in order to obtain statistics on a daily basis. This paper presents a new framework for supporting such repeated estimations of users’ statistics under LDP.  RESULTS: Consider a setting in which there are n users, and suppose that in every one of R days, each user i gets as input a bit x_i. Our goal is to privately estimate the average of the bits on every day. Existing techniques allow for estimating these averages under LDP with error that grows with sqrt(R). In contrast, under several distributional assumptions, the results in this paper reduce the error to sqrt(k), where k is the number of times in which the average changes "significantly". The authors show that their techniques extend beyond bit averages to the well-studied problem of estimating heavy-hitters in the data.  CONSTRUCTION: Suppose that in every day, all of the users' bits are sampled iid from some distribution. Furthermore, assume that this distribution changes at most k<<R times during the execution (so on most days the distribution does not change). The idea is to recompute an estimate for the bit average only when the distribution changes, and hence save in privacy loss on "off days". To that end, the authors develop tools allowing each user to locally estimate (from its own data) when a distribution change occurs, and tools for recomputing the average when "enough" users detect a distribution change. * In fact different users can have different data distributions, provided that every user has the same data distribution as at least sqrt(n) other users.  EVALUATION: The results new, the problem considered is important, and the techniques presented here will be interesting to the community. While the results are not completely satisfying in terms of the distributional assumptions made here, I believe that this is a big step in the right direction, raising good open questions. Overall, I think that this paper is a good fit for NIPS, and I support acceptance.  COMMENTS AND QUESTIONS: Theorem 1.2: Missing a forall quantifier on v Line 158: E^t instead of E^T Line 159: 1/|S_i| instead of |S_i| Question: Can the groups S_i change throughout the execution, or are they fixed? Line 197 needs to be updated (leftovers from v1?) Question: Do we have to know m in advance in Algorithm 1? Question: Why do we need lines 19,20,21 of Algorithm 1? Algorithm HeavyVote line 3: needs to be a norm (L infinity?) and not abs value 