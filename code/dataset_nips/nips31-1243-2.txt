This paper studies deterministic column sampling using ridge leverage scores. These scores represent a global, operator motivated way of defining importance w.r.t rank-k approximations to the matrix, and have a variety of highly useful theoretical properties.  The paper combines these recent works with a result on deterministic column subset selection. It gives significantly better and more general theoretical bounds, using a combination of techniques from ridge leverage scores and matrix algorithms. Then, it demonstrates the good performances of this algorithm on matrix data arising from computational biology. Just as importantly, it demonstrates that the matrices addressed do have power-law decay in eigenvalues, a key assumption in the deterministic column subset selection literature.  I find both the theoretical and experimental studies in this paper impressive. It is an excellent demonstration of the power of newer definitions of leverage scores, and provides empirical justification for many underlying assumptions in the bounds. As a result, I strongly advocate for its acceptance. 