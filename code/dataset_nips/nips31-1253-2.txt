Thank you to the authors for the detailed response. I see your point for why you didn't compare the causal metric to SILO - SILO would have many more features, which makes it more complex than SLIM after DStumps features selection. I will keep my recommendation the same, mainly because the experiments are limited to small datasets.  Contributions: This paper introduces the SLIM algorithm for local intepretability. SLIM can be used as both a black-box explainer and as a self-explainable model.  The SLIM algorithm is a combination of two prior algorithms: SILO (for local linear modeling of decision trees), and DStumps (for feature selection from decision trees). SLIM proceeds as follows: 1. Given a trained forest of decision trees and an example x, use SILO to get example weights for all other training examples. 2. Use DStump to select d features. 3. Use SILO’s example weights and DStump’s d selected features to solve a weighted linear regression problem, and make the final precision for x using this linear model. Strengths: -SLIM provides a novel integration of the previously existing SILO and DStumps methods to produce a locally interpretable model. SLIM can be used as both a black-box explainer and as a self-explainable model.  -SLIM provides local interpretability in the form of locally linear models, local example weighting, and feature selection. -SLIM seems to produce at least as good accuracy as the most similar prior work (SILO alone).  -This paper also provides a way to get estimate global patterns using the local training distributions produced by SILO (Figures 2-4). Note that the paper only showed an example of this explanation method on simulated data, and it would be great to see similar figures on real data. Weaknesses: -It seems like SLIM requires re-solving the weighted linear regression problem for each new example x, since each example x will produce a different set of training example weights from SILO. This seems inefficient.  -It would be easier to read if the authors provided a more clear pseudocode of the SLIM algorithm.  -It’s not clear how much SLIM’s use of DStump feature selection helps improve the causal metric beyond SILO alone. Table 1 shows that SLIM’s addition of the DStump feature selection can help the overall RMSE in some cases. However, we don’t see a similar comparison for Table 3 or Table 4. Instead, in Table 4, SLIM is compared to LIME, which is not quite the same as SILO, since LIME fits a local sparse linear model to the given predictive model, while SILO (and SLIM) fit a tree model first and then uses that tree to build a weighted sparse linear model. In Tables 3 and 4, I would be curious to see a comparison between SLIM and SILO both for black box explanation and self-expanation. This should be possible since it should only require removing the DStump feature selection step in SLIM. -Line 181 mentions that d is selected to get the best validation accuracy, but perhaps it can be selected to get the best causal metric, especially if SLIM is being used as a black box explainer. -The datasets used in experiments are all fairly small, the largest having only 2214 examples. I would like to see an experiment with a larger dataset, particularly to see how SLIM interacts with more complex black box models with more training data. -The paper does not address any theoretical guarantees around SLIM, instead providing experimental evidence of how to use SLIM for interpretability. Recommendation: Overall, this paper presents a novel method for interpretability that seems to perform reasonably well on small datasets. Given some reservations in the experiments, my recommendation is a marginal accept.