In overall, I think this paper proposes a well-designed unified framework which benefits many applications. The rebuttal addresses my questions and the comparison results are convincing to me. I strongly suggest the authors add these results and discussions in the final version if this paper is accept. I raise my rating to accept. ============================================ This paper proposes a unified multi-domain feature disentangler framework which enables cross-domain image translation, image manipulation, and classification domain adaptation.  Pros: * This paper combines all the benefits from previous works into a simple unified framework which can be beneficial to many tasks.  * The learned domain-invariant features perform well on the unsupervised domain adaptation task, especially on SVHN → MNIST experiment.   Cons: * The domain vector/code is not explained clearly in the main paper. * Since there is paired ground truth for the face experiments, I think it is better to use some quantitative metrics (e.g. multi-channel SSIM) to evaluate the proposed method and compare to other methods (e.g. the close related work [17]) if possible. * As to the face experiment, do the images not overlap between the three domains (sketch/photo/paint) as mentioned in line 181?  Given that the proposed method also uses domain classifier to encourage the encoder to learn domain invariant representation, it is suggested to cite the related work,  K. Bousmalis, G. Trigeorgis, N. Silberman, D. Krishnan and D. Erhan. “Domain separation networks.” In NIPS, 2016. 