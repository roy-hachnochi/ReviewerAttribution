This paper takes on the difficult task of estimating individual treatment effects in observational data.  The authors propose a framework, SITE, which both ensures global balance and local similarity using deep representation learning.  Results are demonstrated on benchmark datasets.  This is a high quality paper.  I have some quibbles and concerns with it, but it is tackling a difficult problem in an interesting way.  I realize that the authors are building on an existing literature in computer science on the subject (e.g. Shalit et al) but I don’t think framing this as estimation of the individual treatment effect is quite right.  The individual treatment effect is completely intractable with the standard assumptions that are typically used, because there is only the one observation.  What the paper really estimates is heterogeneous treatment effects for high-dimensional covariates x.  A symptom of this issue comes in equation 1.  The authors invoke the potential outcomes framework and define the ITE in terms of E[Y_1(i) | x_i] etc.  but what’s the expectation over?  In the potential outcomes framework, the potential outcomes aren’t random and its not clear what the conditioning is doing. At some level this is just a squabble over notation but I think it points to some subtleties in what is meant by individual treatment effect.    I also have some concerns about the stated assumptions.  It seems in addition to assumptions 2.1 and 2.2, there is some kind of SUTVA or consistency assumption needed, right?  I also think that the authors are not taking seriously enough the strength of the positivity assumption.  Presumably enforcing local similarity would not be necessary if positivity straightforwardly held.  In other words, if you weren’t trying to smooth over a high-dimensional space, you wouldn’t need the latent representation in the first place.  This general point has been made in the high dimensional case by a recent paper by D’Amour et al (https://arxiv.org/abs/1711.02582) but I think it also applies here in these relatively low-dimensional settings because the estimand is so specific to a narrow region of the space.  Ultimately these quibbles are fairly small though.  The core idea here seems to be a good one and the paper cleverly brings representation learning into causal inference which is both original and likely to have a significant impact by bringing two distinct communities closer together.  I found the paper to be quite clear although I do worry that there is a relatively small group of scholars who have training in both causal inference and deep learning such that they can properly appreciate this work.  That may ultimately be one of the challenges of bridging communities like this though.  *** Response to Author Feeedback*** I thank the authors for the feedback and the additional study.  In going through the other reviews, it is clear to me that Reviewer 3 and I essentially agree on the weaknesses of the paper and the way the response memo does and doesn't address them.  The difference in scores is attributable primarily to how strongly we feel about those weaknesses.    The primary concern with the paper is the clarity both in the analysis of the experimental results (although I agree that the PDDM study in the memo is great and should be added) and in the estimands/assumptions. I followed R3's excellent example and also revisited the prior work.  I still disagree about framing this as an individual treatment effect rather than a conditional average treatment effect - and notice further that the ITE is actually defined as a CATE in one of the prior papers (which I still disagree with, but that correspondence might be worth referencing).  Obviously space is always at a premium but I think the work will have greater impact if you can summarize some of the key elements of the prior work you are building on.      I look forward to the discussion of the recent work on positivity.  I also do encourage you to explicitly add the consistency/SUTVA assumption for completeness.