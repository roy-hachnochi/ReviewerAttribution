This paper proposes an approach for differentially private estimation of the posterior distribution in conjugate exponential-family models. Similar to previous "naive" approaches, it enforces privacy by adding Laplace-distributed noise to the sufficient statistic. Where a naive approach would treat this noisy statistic as true, the main contribution of this paper is a Gibbs sampling algorithm to integrate over uncertainty in the true statistic given the observed noisy statistic. This is the proper Bayesian procedure, and the experiments show that this yields better-calibrated posterior estimates than naive updating or one-posterior sampling (OPS).  The paper is very clear, cleanly written and easy to follow; I found no obvious mistakes. It fills in a valuable part of the story for differentially private Bayesian inference. The proposed approach is sensible, appears to work well, and involves technically nontrivial contributions (CLT and variable-augmentation tricks to derive a tractable approximate Gibbs sampler, and handling unbounded sufficient statistics through truncation via autodiff and a random-sum CLT). This is a solid paper, certainly above the NIPS bar.  My main concerns for this paper involve its impact and applicability. Differential privacy is a strong condition, and my understanding (as an outsider to the field) is that it's been difficult to practically apply differentially private algorithms with meaningful privacy guarantees. From a motivation standpoint, it would be nice to see some discussion of applications where differentially private Bayesian inference on small datasets might be useful. In the experiments, I would prefer to see some analysis of the utility of inference results, which the calibration experiments say nothing about. If I'm understanding the setup correctly, ignoring the data entirely and just returning the prior would be perfectly 'calibrated', but that is not a useful inference method. Are the posteriors actually reasonable for potential applications? You could quantify this through divergence metrics (e.g. KL) from the non-private posterior, mean posterior log-density of the true parameter (essentially the same thing as KL in this setting up to a constant), or even through storytelling -- what's a plausible application and setting of parameters where this method seems to give a useful posterior?