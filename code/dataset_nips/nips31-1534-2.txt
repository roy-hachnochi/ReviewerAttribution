Update:  Thank you authors for your response.   1) My original comments regarding the lack of references is misleading. What I meant was that I think the authors should immediately (e.g. in the first paragraph) frame this work in the context of prior work, say, in semantic parsing. The introduction, as currently written, does not provide good grounding for this paper.   2) I think you should explicitly define what you mean by "consistent" such that the reader understands this claim.  4) I am now able to access the website for the dataset (it was down when I submitted my review). In future papers, please use the citation for the peer reviewed paper instead of the Arxiv version. This is especially important for work as crucial as the task your paper is working on.  Thanks for your response. I have increased my score.    Original text:  Even though the authors do not mention semantic parsing in the introduction, It seems to me that the authors proposed a semantic parser (e.g. one that maps utterances to logical forms). This parser does not use logical forms directly as supervision and rather learns from denotations (http://nlp.stanford.edu/pubs/pasupat2016inferring.pdf). This work aims to resolve coreference resolution in multi-turn semantic parsing by examining conversation history.  I think the writing needs more polish. In particular, Figure 1 lacks logical forms, which makes the references in the introduction difficult to follow. Moreover, the authors should just use accepted vocabulary instead of inventing their own (e.g. coreference resolution, though I may have misunderstood the motivation). The notation in section 4 and Figure 2 are not introduced. It is not clear what find(set, r1) means until section 5, despite the fact that this understanding is crucial in comprehension of the proposed method.   In section 6.2: - it is not clear to me what a subsequence is - it would help if the authors gave an example - What is v_sub? Is it the GRU encoding of sub? - On line 170, what do you mean by "consistent"?  The objective function described in 6.3 seems expensive and intractable for larger problems. Moreover, it seems highly prone to false positives from spurious logical forms.  The choice of evaluation is not ideal. This particular task seems to be un-refereed. I was also not able to access it at the time of review (e.g. the website was down), nor was I able to find refereed, related works on this task. I would be more convinced by the results if the authors either compare to previously refereed work or demonstrate the effectiveness of this work on an established, refereed task.  Minor feedback: - I would refrain from high subjective adjectives such as "huge margin", "outperforms dramatically", etc. and leave the judgement to the reader.   