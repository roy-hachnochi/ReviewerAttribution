The manuscript clearly motivates the issue with the state-of-the-art solution for approximate MIPS, and proposes a very intuitive idea to improve the performance of existing methods for approximate MIPS. The theoretical and the thorough empirical results clearly demonstrate the superiority of the proposed solution relative to the considered baselines.  The authors explain the cost of reducing MIPS to NNS via simple-lsh -- the squashing of the maximum inner-products when the 2-norms distribution of the points have a long tail. The manuscript presents the theoretical and practical consequences of this issue. The authors bypass this issue by splitting the dataset into subsets and solving MIPS in each of the subset with simple-lsh. This new scheme is guaranteed to be theoretically faster than simple-lsh on the whole dataset (under some regularity conditions). The authors also provide a technique to handle the practical issue of working with multiple hash indices obtained from having to create an index for each of the subsets of the dataset, which allows the use of schemes like multi-probe. The proposed technique is thoroughly evaluated in the empirical section; the authors present results both in terms of the actual runtimes (which is the quantity that matters at the end) as well as the number of points probed (which clearly demonstrates the gains obtained only by the algorithm and not by implementation specifics). The authors evaluate various aspects of the proposed solution and the results are extremely positive.  In my opinion, this paper presents a technique to improve the performance of existing MIPS solutions in a clear manner, addressing every aspect of the proposed technique. I do not have any comments/questions/concerns with the proposed technique in this manuscript. The only concern I have is with the premise of the paper that simple-lsh is the state-of-the-art when there are published results (see [A,B]) which have significantly improved upon the performance of simple-lsh.    [A] Christina Teflioudi and Rainer Gemulla. Exact and approximate maximum inner product search with lemp. ACM Transactions on Database Systems (TODS), 42(1):5, 2017. [B] Omid Keivani, Kaushik Sinha, and Parikshit Ram. Improved maximum inner product search with better theoretical guarantees. In Neural Networks (IJCNN), 2017 International Joint Conference on, pages 2927â€“2934. IEEE, 2017. 