Summary This paper leverages the theory of evidence to develop a framework for characterizing uncertainty in deep learnig and then evaluates the results on two standard benchmark datasets relative to a wide selection of benchmark methods. . The paper poses a probabilistic framework on the outputs of the neural net in order to develop a means of modeling the uncertainty.    Strengths:   Quantifying uncertainty is an important direction and an oft-cited weakness of deep learning adn a reason that deep learning is in appropriate for many problems solutions like the provied will enable extension of the impressive accuracies of deep learning into domaiss it has not yet been sucessful or trusted to date.   The experimental results are impressive, in particular the robustness to adversarial examples. The authors use the standard data sets in nonstandard cmbinations of tst train splits in order to deelop an appropriate framework  Weaknesses: figure 1 caption, degrees should be angle line 41: why call it simple? this should be qualified or the word ommitted.  (minor) inconsistent refeence to left vs right subfigured (eg compare figures 1 and 3)