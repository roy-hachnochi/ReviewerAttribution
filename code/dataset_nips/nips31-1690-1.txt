 This paper proposes to directly optimize the PAC-Bayesian bound of Gaussian process regression using a 0/1 loss with respect to the hyperparameters and the inducing points (for sparse GP). The tight version of the bound using the binary KL-divergence is used. The hyper-parameter space must be a-priori discretised for their approach to work. Experiments compare their approach with full-GP and VFE.  [Quality] In general, I find this paper to be of sound quality. However, I have some concerns: 1. In section 3.1, the regression form of GP is used --- this is using the Gaussian noise model, which directly targets the MSE of the prediction. However, the posterior under this noise model is then used as the $Q$ with the 0/1 loss. There seems to be some mismatch here --- the first level inference uses MSE, while the second level inference uses the 0/1 loss. For example, I should think that a more appropriate Bayesian inference model would be to use variational inference with a uniform noise model. 2. In section 3.2, the authors suggest to optimize over $\alpha$. However, this can potentially cause variances to be underestimated during prediction, since FITC is known to sometimes give negative variance. This aspect has not been addressed. For example, in Figure 1, is the sometimes smaller variance of kl-PAC-SGP caused by this? What are the $\alpha$s learnt? What if $\alpha$ is fixed at 0 instead of learnt? Not enough analysis is done. 3. Since this is a PAC-Bayesian analysis, comments on the experimental results should also address the tightness of the bounds. 4. There should be comments and analysis on why both kl-PAC-GP/SGP is worse than Full-GP/VFE in terms of both Gibbs test risk and MSE.  5. Eq 32 should use some probabilistic bounding between $R_S(Q)$ and the mini-batch average and then reinsert these into the PAC-Bayesian bound. In any case, if we use exactly $B$ data points, shouldn't the bound be on $B$ data points and not $N$? More justification other than efficiency is needed here.  [Clarity] L154. Please define $T$ before its use. What is the objective used for the gradient minimization? Since the objective cannot depend on the training data, it seems to be neither ML-II nor PAC-Bayesian bound? Also, please elaborate on "minimization to the closest point in the equispaced...". Footnote 4, last sentence. In what way do we "need" the noise parameter? Do you mean we need to optimize for it and bound it away from zero? Experiment 4a. It is not totally clear what are learnt and what are fixed. I assume that the hyperparameters are fixed in this exercise. Experiment 4b. I find no need to compare with sqrt-PAC-GP in the main paper --- suggest to move this to the supplementary.  [Originality]  This paper provides another objective for hyper-parameter optimization for GP learning,  [Significance] 1. The paper is primarily for bounded loss, so it is not directly application to MAE and MSE which are more natural and commonly used for regression. 2. The method does not do better than VFE for MSE, albeit it does not optimize directly for MSE during hyper-parameter optimization. In addition, it does not also do better for the Gibbs test risk.  [Minor] L3: Do you mean "tight" for "good"? L41: Add [10] as a reference for the binary KL divergence. Footnote 4, last sentence: "diverges" and 'vanishes" are redundant t. In what way do we "need" the noise parameter? Do you mean we need to optimize for it and bound it away from zero? L196-L198: The sentence does not seem to be well-formed. L200: PAC-SPG   [Comments after authors reply] I am satisfied with the reply and look forward to the authors addressing some of the points noted above in the paper.