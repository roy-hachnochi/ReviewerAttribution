Summary of the Paper:   This paper describes a new method of training Gaussian process for regression based on minimizing a bound on the generalization error. This approach can have advantages over others in the sense that it will provide generalization guarantees, which may be of practical importance in some applications. The proposed approach is evaluated in several regression tasks and compared with popular approaches for GP regression based on FITC or VAE.  Strengths:   - Well written paper.   - Complete related work section.   - Nice and illustrative experiments.  Weaknesses:   - The MSE of the proposed approach is worse than the one obtained by FITC of VFE.  Quality:   I think the quality of the paper is high. It addresses an important problem and the methodological steps and evaluation procedure are right.  Originality:   As far as I know this paper is original. I am not aware of other works trying to fit GPs by minimizing a generalization bound.  Significance:   The experiments confirm the utility of the proposed approach. A disadvantage is, however, that it performs worse in terms of MSE than VFE or FITC. Notwithstanding, it is normal since a different objective is being optimized here.  Other comments:   Summing up, I believe that this is an interesting paper that, although does not provide outstanding results, may attract the attention of the ML community working on GPs.  After reading the authors response and viewing the comments of the other reviewers, I have slightly increased my score.