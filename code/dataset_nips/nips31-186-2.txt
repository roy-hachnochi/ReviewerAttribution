This paper studies the task of semantic scene completion. Given a D / RGB-D image, the semantic scene completion problem is to be predict semantic labels for the full 3D volume of the scene. The current paper proposes a way to fuse information from discriminative 2D image-based CNNs with 3D information from the depth image to produce the semantic scene completion output. The paper evaluates the proposed approach on NYUD2, and SUNCG datasets and is able to outperform existing approaches for this task. The paper additionally also reports a number of ablations for this task.  I generally like the paper. The central contribution is to augment the 3D reasoning with discriminative features computed from the 2D by projecting these features into the voxel map using the camera intrinsics and extrinsics. Kar et al [23] have proposed a very similar feature unprojection operation in context of reasoning from RGB images alone, but I find the empirical evaluation of this idea for the task of semantic understanding interesting. The paper shows large improvements over past works in varies contexts (D / RGB-D).  The paper however has some shortcomings: Experimental evaluation on NYU Dataset. I will like to note that the evaluation for Semantic Scene Completion on the NYU dataset is somewhat flawed. The NYU dataset comes with approximate CAD models that are aligned to images. The same approximate models are used between the training and the testing sets, thus the problem as is framed on NYU is somewhat game-able by being treated as a retrieval problem. I worry that some of this might also happen with expressive CNN models that can memorize and regurgitate models from the training set. Past works such as [1,6,24] suffer from the same issue, but this issue should be noted in the paper, and these evaluations should be taken with a grain of salt. The same issue also plagues experiments on the SUNCG dataset (though possibly to a somewhat smaller extent given the relatively large number of CAD models in use there). Furthermore, I believe the paper should more properly attribute credit to [23]. The paper should also reconsider the choice of names for SeeNet and ThinkNet, I don't find them particularly evocative of what is happening in the paper.