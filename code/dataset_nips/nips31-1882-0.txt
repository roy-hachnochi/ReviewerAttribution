This paper introduces an algorithm for estimating the difference between two DAGs (dDAG) in the Gaussian-linear case. Importantly, the algorithm does not approach this by first learning the two DAGs separately, but instead relies on novel ideas to construct the dDAG directly.   This work draws on existing work in two areas: (1) estimating the difference between two undirected graphs (UGs); (2) estimates the invariant parts of two DAGs (the complementary problem to the one proposed here). These ingredients are combined with several novel ideas to obtain the dDAG estimation algorithm.  Strong aspects of the paper are:  - The problem is well motivated. While at first the idea of having two different DAGs representing the same causal system appears slightly counterintuitive, in the context of linear models this makes sense of one thinks about it in terms of effect modification (where the magnitudes of structural ceofficients are affected by an intervention).   - The presented algorithm is theoretically well developed and is convincingly shown to outperform other methods on simulated data. The ideas used in the algorithm appear novel to me and might be useful in other settings. Different versions of the algorithm are presented for high-dimensional and low-dimensional settings. The algorithm also does not try to "reinvent the weel" but makes good use of existing techniques, such as KLIEP, where this is appropriate.  - There appears to be clear potential for this method to be useful in practice, even if the existing empirical analysis on "real data" is not very convincing yet (see below).  - The paper is well-written and clear (but see a few minor issues below), and also the supporting information is of very high quality.   I see two main points of criticism:  - The approach seems to have some limitations that are not sufficiently discussed. First, there is the assumption that the two DAGs that are compared share the same topological order. This limitation should be stated more prominently, e.g., in the abstract, so users can decide immediately whether this can be justified for their application. As the authors mention, in biological networks, if one is willing to assume acyclicity in the first place then this assumption does not seem to be much more restrictive, but others might argue that already the acyclicity assumption is unrealistic to begin with. Second, the approach seems to have exponential time complexity because all subsets of S_\theta need ot be repeatedly considered, and some discussion of how this constrains applicability would be appreciated.  - The empirical part appears less convincing than the theoretical part. The authors look at the learn dDAGs and then give literature references for roles of the transcripts they find to be "hub genes", but this appears to be somewhat post-hoc. What would the goal of such an analysis be? Ideally, that goal should be pre-specified, and only then should the analysis be carried out. It is not suprising to find literature references claiming a function for many of the transcripts; such references will likely be available for most transcripts that are differentially expressed.   Specifically for the T cell data, the authors first focus on only the transcripts with a >10 fold change, which I would expect to lead to strong violations of the causal Markov assumption, since many important transcripts are now unobserved. Regardless, the authors present the finding that Granzyme B (GZMB) emerges as a root note with 3 children as a validation of the method. However, Interferon Gamma (IFNG) appears as a sink node with no children. This appears counterintuitive since both GZMB and IFNG are secreted by T cells upon activation, so they are end products of the activation process. As such the position of IFNG makes more sense to me, but in any case it shouldn't differ so substantially from GZMB.   In summary, these analyses do prove that we can use the algorithms on real data but I would be careful with any biological interpretation at this point. Any sensible interpretation would require a more careful analysis of the findings.  These issues nonewithstanding, I think this is a strong paper that makes an important contribution to the field.    Minor points / requests for clarification:  - Some of the symbols used in the notation are not very intuitive, such as the Delta with a bar for the skeleton and the A tilde for the arrows.  - In Algorithm 1, perhaps slightly rephrase to clarify that once Delta_\Theta is estimated, S_\Theta can just be read off from that. The way it is written, it suggests that the two objects would both need to be estimated.   - I believe that there is a typo in Algorithm 3 when you use the beta's instead of the sigma's . If that is not a typo, then I completely failed to understand what you mean in the explanation that starts at line 143.   - In Example 3.3., try making more space between the arrowheads and the numbers, it looks a bit as if there was an arrow pointing to 1.   - In line 161, I did not understand what you mean without consulting the supplementary material. After having a look at that, it appears to me that what you want to say is that some additional edges can be oriented given the requirement for acyclicity (which has nothing to do with v-structures per se). But then I don't see why this would be so computationally expensive. Why would you need to enumerate all directed paths (chains) to find one from x -- y? Is it not sufficient to perform a simple reachability query, which can be done in one graph traversal?   - Line 202, for consistency, would it be better to write \sigma_i(k) instead of "the variance of  \epsilon_i(k)" here?   = After author response =  Thank you for responding to my points and for agreeing to clarifying the paper in some respects.  