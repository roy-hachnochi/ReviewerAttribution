This paper analyzes the problem of estimating the neural net distance which is the optimization objective in GAN. The authors obtained improved upper and lower bounds on the minimax risk in estimating the distance, and for ReLU networks they showed that they match not only in terms of the sample sizes (which is quite trivial) but also the parameters of the network (which is more interesting). The analysis of quite solid and involves refined analysis of the Rademacher complexity, and the careful application of the Le Cam method for minimax lower bound. I think this paper helps people understand better the instrinsic discriminating power of ReLU networks, which is a good contribution. 