Overall, I appreciate this submission. It does almost all it can do in the theory part and also carries some experiments. My main concern is that while this paper does a good job under the topic of SVRG, the overall contribution may not be big. Some extra comments:  1. Do authors use batch normalization and dropout in their experiments? Hows the testing accuracy compared with the state-of-art method on MNIST, CIFAR, and SVHN datasets? Testing accuracy is more important than training and validation loss. The authors want to show their method is strong even on deep networks, however, the current form of Section 5.2 looks more like a toy example. The authors can use inception or Resnet instead. Besides, they can also compared their testing accuracy with the one obtained by Adam or adagrad.   -------- I've read author's feedback, I am ok with their reply.