This paper proposes an inexact variant fo Riemannian trust region algorithm, which is usually computationally expensive due to the Hessian term.   However, I’m not an expert in this specific area and I do have some difficulties appreciating the originality and importance of this paper. It’s true that calculating the full hessian in a Riemannian trust region algorithm is expensive, but there are a lot of efficient alternatives already. (I was referring to other numerical algorithms that escapes saddles rather than RTR.)  Technically, I found the first assumption made in this paper might be hard to verify in practice. Could the author give some justification for the applicability of this assumption?(Thanks for the clarification)  Theorem 4.1 claims that at any $x_k$, assumption 2 are satisfied with high probability. From my understanding, for the sub-sampled algorithm to perform as desired, we want the assumption to be satisfied at any iteration $k$. There seems to be a gap here. Could the author give me some clarification on this? (I went through the proof more carefully, and I was confused the first time.)  The numerical experiment part is sufficient and serves the goal.