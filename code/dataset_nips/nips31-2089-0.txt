Update after rebuttal:  The rebuttal has shown that the experiments were done to a rigorous, high standard, and further, reports new experiments with several larger scale data sets. If these results hold more generally, the findings could be widely used. I recommend acceptance.  ______________________  Summary:  This paper explores methods for regularizing deep convolutional networks towards orthogonal weight matrices. In extensive experiments with state of the art models, the paper shows that soft orthogonality can improve training stability and yield better classification accuracy than the same models trained without such regularization. The paper proposes a method to approximately enforce all singular values of the weight matrices to be equal to 1, using a sampling-based approach that does not require computing an expensive SVD operation.  Major comments:  This paper presents interesting experiments showing that regularization towards orthogonal weights can stabilize and speed up learning, particularly near the beginning of training; and improve final test accuracy in several large models. These results could be of broad interest. One concern with the experimental methods is that they use carefully sculpted hyper parameter trajectories for some methods. How were these trajectories selected? It is crucial that they be tuned on a validation set, not the final test set accuracy.  The SRIP version of the orthogonality regularization is a clever way of seeking orthogonality through a truncated power iteration approach. This makes the regularization readily compatible with standard automatic differentiation, and could be widely used. The paper could be improved by adding wall clock time comparisons. How expensive are each of these regularizers? This could also highlight the benefits of the proposed approach relative to hard orthogonality constraints.  The clarity of the paper is middling. The equations contain typos (eg, Eqn 5 is missing one side of the absolute value), and could be improved by a substantial editing effort.  It would be useful to more explicitly describe the difference between initializing to scaled orthogonal weights vs enforcing orthogonality throughout training. The former is a preconditioning scheme that can cause later learning to go quickly _without changing the optimization landscape_. The latter is a different optimization (minimize the loss subject to orthogonal weights), which will change the optimization landscape. The results presented here seem to show a complex story regarding which approach is better. The ‘scheme change’ results suggest that orthogonal regularization is better used as a preconditioner, and harms accuracy if enforced at the end of learning. However this may not be true for SRIP. A careful examination of these results would be helpful.  