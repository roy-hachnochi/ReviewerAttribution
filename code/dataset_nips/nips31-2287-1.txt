Summary: This paper reasons about a Pareto optimal social choice function in which the principles seek to agree on how to agree to use a system that acts in a sequential decision-making problem in which the principles may not share the same prior beliefs.  Results suggest that to obtain such a function, the mechanism must over time make choices that favor the principle who has beliefs that appear to be more correct.  Quality: The work appears to be correct as far as I have been able to discern.  However, I do not like the idea of not having the proof of the main theorem (Theorem 4) in the main paper, even if for the sake of brevity.  My opinion is that If the theorem is that important, its proof should be next to it.  Clarity: Overall, I found the paper to be well written.  However, the paper is a bit tough to follow.  I did not find the math to be so difficult to follow, but the whole idea is somewhat conceptually difficult to me.  I would recommend carrying examples through more thoroughly.  The example given at the start of Section 3 is illuminating — I think this example could be leveraged throughout Section 3 to make the various ideas and theorems more concrete.  Originality: A lot of work in multi-agent systems has dealt with computing fair equilibrium in sequential decision problems, particularly in ongoing relationships between the principles, much more than the authors acknowledge in their literature review (see for example work by Munoz and Littman, 2008 — “A polynomial-time Nash equilibrium algorithm for repeated stochastic games.” and various algorithms that cite and build on that work.)  However, as the authors point out, these works deal primarily with repeated interactions between the principles, and do not consider “one-shot” sequential decision problems in which a social choice mechanism must be implemented when the players have prior beliefs.    Furthermore, fair and Pareto optimal solutions in social choice are common, but I am not aware of work in this regard for sequential decision problems in which the principles have imperfect beliefs.  Thus, I believe this work is novel.  Significance: In some sense, I find this paper to be conceptually genius.  A lot of thought went into the work, and the authors clearly see things I would not have.  The ideas are quite intriguing.  On the other hand, the results of the paper rely on some pretty heavy assumptions that greatly reduce the practicality of the work and hence its significance.  First, the paper is based on the assumption that the principals will insist on a Pareto optimal solution.  While this is an axiom sometimes used in social choice theory, I do not believe the principles would agree to this or feel good about it in this particular scenario, particularly if they are human.  In practice people seem to often favor a fair a non-Pareto optimal (but more fair solution) than a Pareto optimal but unfair solution (that is unfair in the other principle’s favor).  Second, the mechanism assumes knowledge of the player’s beliefs, which is impractical since the players may not want to or may not be able to communicate their beliefs in precise enough a manner to make the mechanism work as intended.  Update after author response: I appreciated the author's response.  My view of the strengths and weaknesses of the paper remains essentially unchanged.