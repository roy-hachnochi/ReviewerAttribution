Summary: The authors present a new technique for MIPS that is closely related to (if not a direct application) an existing technique for NNS. The authors provide some theoretical backing for the algorithm, though not sufficient to prove the performance for the parameter settings that would be used in practice (which is typical for the field). Finally, they show experiments on two real-world music ratings datasets and a synthetic dataset.  Quality: The technique seems natural, relatively simple (a good thing), and yields strong performance. Iâ€™m not familiar enough with the MIPS literature to know if the list of baselines is complete. It is somewhat disappointing that the datasets were not very comprehensive. Only two real world datasets were used which are similar to each other (both music ratings datasets).  Clarity: The paper is easy to read and ordered in an intuitive way. Enough technical detail is included to make the paper concrete, but not too much.  Originality: While the idea of a nearest neighbor graph may be novel for the MIPS problem, it already exists for the NNS problem for metric spaces. The originality is probably the weakest part of this paper.  Significance: The MIPS problem is a fundamental problem in machine learning and other fields. The experiments lead me to believe that this technique provides major speed-ups on several datasets, both with real-world structure and drawn with uniform directions.  Small Comment: Line 5 of Algorithm 1 should it be s instead of d?