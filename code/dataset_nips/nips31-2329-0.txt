       This paper presents a branch-and-bound based unified framework for piecewise linear neural network (PLNN) verification, and demonstrates how two existing methods (Reluplex and Planet) can be cast in these common terms. It explores other variations of various components of B-and-B, finding that a "smart branching (SB)" heuristic inspired by Kotler and Wong [12] results in a substantially faster method.        My take on this paper is somewhat lukewarm, given the mix of strengths and weaknesses it has.        STRENGTHS:        The paper is very well-written, at least the first half of it. It motivates the problem well, sets the scope of the work (what it covers, what it doesn't), and summarizes the contributions in a meaningful way. The background text is easy for follow, especially for anyone with some background in optimization, MIP, branch-and-bound, etc.  It's a dense paper (which is also a weakness), with many details of the encodings described in the paper and the supplementary material.        Being able to see existing methods (well, two existing methods) in the light of a MIP-based branch-and-bound framework is useful in understanding how they relate and which other decision points might be worth exploring.              The experiments reveal that the proposed BaB-SB method clearly outperforms various baselines in the ACAS dataset.        WEAKNESSNES:        It's very confusing (somewhat disturbing) to me that you found Gurobi, a commercial MIP solver, to produce "invalid" counter-examples in about 12% of the CollisionDetection cases (going by Fig 2(a)) when Gurobi is running, in a sense, on the purest setting of the problem, Eq (2). Numerical instabilities are well-known in the discrete optimization literature, but over 10% error rate is unheard of. This makes me wonder about two things:        * In section 3.1, the description is imprecise as to whether the case of global minimum being zero is a proper counter-example or not. That is, do you mean 'negative' (less than 0) or 'non-positive' (less than or equal to 0) when encoding a counter example? Note that MIP solvers cannot encode strict inequalities of the form "a strictly less than b".        * If the error cases are when the generated (but invalid) counter-example evaluates exactly to 0, and that's errorneous because of numerical instability, would it be possible for you to try adding a little negative epsilon (e.g., -0.001) and searching for examples evaluate no more than that?        It may very well be that Gurobi on Eq (2) is slow, but if encoded correctly, it should not be inaccurate. I wonder if this affects any other findings too.        The extent of technical novelty is somewhat limited. The b-and-b framework of Algorithm 1 is, of course, very standard in discrete optimization literature, even if new to some NIPS readers; what's new here is its application to the verification problem formulated in Eq (3). In terms of techniques, the BaB-SB system is interesting, although it wasn't immediately clearly how difficult was it to adapt the work of Kotler and Wong [12] to the smart branching heuristic used here.         One aspect that was confusing for me is that Reluplex is described as maintaining a complete assignment to all variables at all times, and flipping values to try to satisfy more and more constraints. This is the nature of LOCAL SEARCH solvers, which are a distinct class of solvers in the discrete optimization community than branch-and-bound. It is not immediately clear how natural it is to fit a local search solver into a b-and-b one.        The motivation for introducing a new dataset, PCAMNIST, for the analysis in Fig 4 wasn't made clear. Could you have used either of the existing datasets for this purpose?        The figures, in general, were very difficult to follow. Larger fonts and larger size (at the expense of less text/caption) would help. It might even be worth cutting a figure or two to use the room to better explain what you do retain.  ADDED AFTER AUTHOR RESPONSE:  Thank you for the clarifications.  It was helpful to follow up on some of them in your supplementary material.  Although the space is always tight, it would be valuable if you are able to incorporate explanations for some of these points in the main paper (at the expense of some other parts, of course).       