This paper proposes the “double attention block” to aggregate and propagate informative global features from the entire spatio/spatio-temporal space of input. Specifically, the model first generates a set of attention distributions over the input and obtains a set of global feature vectors based on the attention. Then, for each input position, it generates another attention distribution over the set of global feature vectors and uses this to aggregate those global feature vectors into a position-specific feature vector. The proposed component can be easily plugged into existing architectures. Experiments on image recognition (ImageNet-1k) and video classification (Kinetics, UCF-101) show that the proposed model outperforms the baselines and is more efficient.  Strength 1.    The proposed module is efficient and easy to adapt to modern frameworks. 2.    Extensive empirical experiments show that the proposed method outperforms consistently outperform other baselines.  Weakness 1.    I am concerned about the originality of the proposed model. The idea of applying an attention over the global feature vectors is conceptually similar to the Transformer architecture (Vaswani et al.). 2.    Lack of theoretical analysis of the proposed model. 3.    The improvement over the baselines is not significant. For example, in the ablation studies (Table 2 and 3), the relative error reduction over “Non-local neural networks” is less than 2%.