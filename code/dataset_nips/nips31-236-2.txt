This work proposes a new problem of generating spatial audio for a 360 video with mono audio. To achieve the goal, the author proposes a neural network model that jointly analyzes the audio and video signals and generates the coefficients in the first-order ambisonics format, which is a commonly used spatial audio format. Because this is a new problem, the author collected two 360 video datasets with spatial audio ground truth for both training and evaluation and proposed three evaluation metrics for the problem. The author also perform user study on the generated audio to justify the results.  The main contribution of the work is the novel problem. While it is widely believed that spatial audio is important for 360 video viewing, most 360 videos contain only mono audio as described in the paper. This is an important problem in practice, considering the large amount of 360 videos being generated and existing online. This work addresses the problem by generating spatial audio from mono audio, which provides a cheaper solution compared with spatial audio recording and is applicable for existing 360 videos that do not contain spatial audio.  Another strength of the work is the evaluation. In particular, the user study clearly justifies not only the superior performance of the model but also the importance of spatial audio. The ablation study also provides further insights into both the problem and the model.  On the other hand, I have two concerns about the work. The first is the missing details of the training procedure. In L146, the author mentioned that the model is initialized with weights pre-trained on ImageNet. However, it is unclear how to pre-train the weights for the motion networks on a static image dataset. In L214, the author mentioned that the dataset is randomly split into 4 partition. Is the splitting based on video or on training examples?  The second concern is the lack of baseline methods. The author only performs ablation study of the proposed model but does not include simpler baselines. Because the content distribution in 360 video is usually highly biased, it is possible that a simple method (linear regression, etc.) or even the prior distribution on the dataset can achieve a good performance. Although the author addressed this during training (L219), it is unclear whether the superior performance comes from the model or simply the biased distribution in the test set. Simple baselines are still needed to justify that the problem requires a complex learning model.  === The author response addresses the concerns I have, except that I think a simpler learning based baseline is still necessary. Although the prior distribution baseline provides much insight for the problem, a simple baseline can help to gauge the performance and make the evaluation more complete.