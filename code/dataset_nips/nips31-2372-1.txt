The paper discusses the downstream inference effects of embedding. The paper discusses several properties that are desirable, and provide status of many different embeddings. The paper also shows a thorough list of experiments to make its point.  Overall the paper is a welcome addition to a recipe/faith/herd driven climate where "embedding X is the new thing and will solve this problem (never mind we forgot to find out if the embedding made sense at all". From a foundation perspective, the limit statements about embeddings were interesting.  One comment in this context is that  most embeddings (that work) are probabilistic. This is not the same as the discussion in lines 123 and the sequel, we are discussing choosing a random map from a collection of maps. So what would be limit analogue  in the probability context? Describing that would be a valuable contribution both in concepts and experiments.  One other comment is regarding outliers. This part is less clearly defined because the definition of outlier is not clear --- the authors themselves were compelled to make the distinction with outliers in distance etc., 