In this paper, an algorithm for matrix factorization (MF) is proposed, which provide better robustness to outlier’s behavior compared to state of the art algorithms for Robust MF (RMF). Another nice property of the new algorithm is that it is suitable for sparse data matrices which is a clear advantage when it is compared against previous approaches to RMF. Basically, the authors propose to replace the l1 penalty with a nonconvex regularizer and provide results for various selections of regularizers. Since the optimization in this case is not simple, the authors propose to use a Majorization Minimization (MM) optimization approach with a definition of a new MM surrogate. The paper provides a nice introduction to the problem of robust matrix factorization, providing a complete overview of the state of the art and giving good motivations for the development of a new algorithm. I found the paper well written, technically sounded and having a nice structure. The theoretical treatment of the results is adequate giving guarantees of convergence. The paper includes a rich experimental section with useful comparisons with previously proposed algorithms and evaluating several options for regularizers. I definitively recommend the acceptance of this submission for presentation in NIPS. However, I found few minor issues which need attention for the final submission. Issues: • Font sizes in all figures are too small. Please consider resizing figures. • In section 4.1 Synthetic Data, outliers are generated by using constant values {+5, -5} in the 5% of the entries. I think, it would be very useful to analyze the effect of varying the percentage of affected entries (instead of a fixed 5%) and also to consider other values for outliers with some probabilistic distribution. I think that, by adding these new analysis the applicability of the algorithm would be better assessed. The authors agreed to add these additional results to the final version.