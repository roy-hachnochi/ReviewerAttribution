The authors aim to achieve style transfer in text governed by controllable attributes. For this, authors propose a model which builds on prior works on unsupervised machine translation and style transfer. The proposed model uses reconstruction and back-translation losses. Authors propose to add denoising via dropping inputs and using an interpolated hidden representation. An additional adversarial loss is added to ensure the generated distribution of (hx,l) matches the input data distribution. An undesirable solution for D can be to simply use hx and hy, and ignore the attributes. To deal with this, (hx,l') is added as additional negative sample. Authors test their proposed model and training methods on  multiple datasets - sentiment change, Shakespearean English style transfer, active/passive/tense/etc. on Book Corpus dataset. Human evaluation is carried out in some cases.  An ablative study is also carried out to highlight the importance of different terms in the loss function.  While the proposed model and experiments seem interesting, there seems to be limited novelty in the used model compared to prior works.    Description of model and loss functions is not clear and seems incomplete at times. For example, in section 3.3, it seems that authors want to use adversarial loss to distinguish b/w 'real' and 'generated/fake' sentence-attribute tuples - shouldn't then the equation 4 use max over D and min over G?  Additionally, is there anything preventing decoder output states hx to encode information about attributes l without actually using it? If hx does include information about l, then isn't the task of D much easier? In such a situation, role of D is not clear. I would suggest authors to add more discussions and explanations for their model choices.  Most of the experiments seem convincing - the proposed method performs pretty well on a variety of datasets. 4.6 describes an important set of experiments wherein multiple attributes are changed - however this part misses on many details such as distribution of attribute values and number of sentences in data, and performance wrt content preservation. Discussions and analysis about the types of errors the model makes on the three datasets could be added for better understanding of the working of the model.   I am interested in understanding more about instructions provided for human evaluation, especially with respect to content preservation. Authors point out that annotators were asked 'whether the original and generated sentences are related by the desired property' - what is 'property' here? Is it same as attribute? In that case, this seems a bit ill-defined since 'related' is a very loose relation - can two wildly different sentences with negative sentiments can be said to be related wrt the sentiment attribute? How was the meaning of the term 'related' conveyed to the annotators? Authors could have provided more details or a screenshot of evaluation framework in the supplementary material.  Update: I have considered the authors' response, and have increased my score to 7.  