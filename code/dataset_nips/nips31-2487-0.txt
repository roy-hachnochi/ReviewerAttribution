The paper proposes channel-wise convolutions that address the full connections between feature maps and replace them with sparse connections (based on 1-D convolutions). This reduces the #params and #FLOPS significantly; while maintaining high accuracy. The authors show results on imagenet classification and compare it to VGG/MobileNet variants to demonstrate this.  Strengths:  + The paper is well written and easy to follow. Background and related work such as standard convolution+fc layers used in neural nets; mobilenet and shufflenet variants to reduce computation are described in sufficient detail. + The proposed approach is novel and it replaces fully connected pattern of feature maps with 1-D convolutions. As stated, starting from LeNet [13] prior work has experimented with sparse connections between feature maps. In fact libraries like Tensorflow/Torch allow to choose a sparse connection pattern for convolutional layers as well. However, the sparsity in these works is chosen at random  and output channels are connected to a fixed fraction of input channels. The proposed work introduces sparsity with 1-D convolutions to convolutional, fully connected and classification layers (i.e. all parts) of a neural net. With appropriate choice of group size and stride, 1-D convolution strategy; it can be ensured that all convolutional channels are used to produce output. + Tab. 1 compares the proposed network to standard approaches and shows good accuracy for less parameters. Tab. 2 does an ablation study on the effects of sparsity on different parts of the network. Convolutional classification causes 3% drop in accuracy but also reduces parameters by ~1M.  Weakness:  - Results are presented on imagenet classification only. Results on CIFAR or scene classification (Places dataset) or on other tasks such as segmentation/detection will help make the case for channel-wise convolutions stronger.  The idea is novel, the paper is well written and results are sufficient to establish that the strategy is effective on imagenet classification. Therefore, I recommend accept.