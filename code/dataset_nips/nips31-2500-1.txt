The authors propose a new way of evaluating generative models using a generalization of precision and recall to generative model. Intuitively, a model has high recall if it captures many modes of the target distribution; a model has high precision if it captures these models well. The authors propose describing the quality of a generative model via a precision-recall curve. The shape of this curve provides information that traditional measures like the Inception score miss (e.g. are we covering many modes well or just one mode).  I think the paper studies a very important topic in generative modeling and provides a way of measuring the quality of generative samples in a way that other models cannot. This allows formally quantifying several crucial issues in generative modeling such as mode collapse, which were only studies qualitatively until now. The paper is also very well written and offers a very thorough discussion of model quality. I suspect this metric will be used in practice.  Comments -------------  - I am still a bit confused as to why the proposed method looks at a tradeoff between precision and recall. In binary classification, there is truly a tradeoff because by varying the threshold outputs a different set of probabilities. But here, the model always produces the same samples; its not like we can explicitly construct the \mu. Hence, two distinct scalars measuring precision and recall (something like a snapshot along that curve) would make more sense to me. It would be great to have a more thorough discussion of this in the paper.  - All the (elegant) theory assumes that P, Q are over discrete spaces. In practice, the input space is quantized. What is lost during this approximation? How does the number of k-means clusters affect the results? How do we choose k? I don't see a good discussion in the paper.  - Is there a reason why the main results for real generative models are focused on MNIST and Fashion-MNIST? There some plots for Cifar10 and CelebA in the appendix, but there is clearly much more focus on MNIST. This makes the argument seem a bit weaker.  - What is the importance of the feature embedding in which you run k-means? How do I find such features for non-image data? How does the choice of features affect the quality of the results?  - Is it possible to summarize the curve by a single value (like the area under the curve)? Does it give useful insights?