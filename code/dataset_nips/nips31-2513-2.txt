Authors demonstrate a forward recursion (interpretable as a a data-dependent regularized follow-the-leader) is minimax optimal for linear regression given (scale) constraints on the adversary play.  Prior work established the minimax strategy (mms) given the complete sequence of covariates via a backwards recursion.  This work first shows that summarizing the complete sequence of covariates by an initial second-moment-style equality constraint is sufficient to compute the mms via a forward recursion. Then, the equality constraint is relaxed to an inequality constraint with additional conditions that ensure that the inequality constraint will be active given optimal adversarial play.  I have not verified any of the proofs.