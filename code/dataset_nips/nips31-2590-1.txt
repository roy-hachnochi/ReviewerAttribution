The authors propose to meta-learn a differentiable parameterised loss function to be used in policy gradients. They show that this loss function generalizes better than RL^2 and MAML to out-of-training-distribution tasks, but it is outperformed by RL^2 in-distribution. The loss function is learned by a simple evolution strategy that performs random perturbations to the parameters, as used in [Salimans, Evolution strategies as a scalable alternative to reinforcement learning, 2017].  Quality:  Overall I find the idea appealing. The idea and algorithm is conceptually straightforward. The loss network is quite complicated, it is hard to tell what the contributions of the components are and what it is actually doing. It would be useful to see an ablation study, for example on the ‘memory’ component, or the various components added to the context vector (Eqn (8)).  The experiments showcase various properties of the algorithm. The evolved loss function (EPG) yields better solutions (at a fixed budget) than PPO. EPG is substantially outperformed by RL2 when the test task has the same distributions to the training task. However it outperforms RL2 in the case where there is a small distributional shift in the task e.g. the direction of a target is at a novel angle. I like the experiments showcasing the wins/losses compared to RL2. The comparison to PPO hides the training time for the EPG loss function. I did not see mention of how much additional training time EPG gets, or how PPO would perform given the same computational budget.  Clarity:  The paper is easy to read. The section detailing the architecture is too dense, I don’t think the algorithm could be replicated from this. However the more detailed Appendix, and open-sourced code help here.  Originality:  As far as I know, this approach to meta-learning in the context of deep-RL is novel.  Significance:  The authors demonstrate some nice generalization behaviour of the algorithm. Although it is not a clear winner over other meta-learning approaches, I think the originality of the approach is significant and could spark further work on learning parameterised loss functions. 