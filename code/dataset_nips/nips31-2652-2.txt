The paper improves the decoder of an attention-based seq2seq model in two ways: 1. Middle-out decoding: the left-to-right RNN decoder is replaced with 2 RNNs, one going left-to-right and the other going right-to-left, both generating a half of the sentence and both conditioned on an important middle word  This allows easier control of the middle word, a task otherwise hard for RNNs. It also needs additional supervision in indicating the important middle word. 2. The decoders run the attention mechanism also over past outputs, and past hidden states. This is especially important for the middle-out case as it is its only way of synchronizing the two decoders.  The main benefit of the middle-out decoding is enhanced ability of controlling the model to output a given word - the network is literally forced to do so through conditioning on the middle word.  The enhanced self-attention is required by the middle-out decoder to be self-consistent, as it allows the two RNNs to see each other's outputs and hidden states (another obvious way of doing this would be to fully run one of he the RNNs, e.g. generating the first half of the sentence, then condition the other RNN on the output of the first).  The paper doesn't specify what is the sequence of evaluating the left-to-right and right-to-left rnns (I assume they alternate, essentially generating the sequence in order n/2, n/2+1, n/2-1, n/2+2, n/2-1,.../n,1), but this should be clarified in paragraph l.161-175.  On a toy task (denoising a symmetrical sequence corrupted with elementwise uniform noise) the middle-out decoding outperforms the unidirectional RNN, however it has the benefit of implicitly knowing the important middle input (it it separately trained to predict it. I am curious if the middle-out decoder would also be more efficient if the location of the peak was also randomized.  On a real-world task the results indicate that: 1. The vanilla seq2seq model slightly improves with the addition of self-attention 2. The middle-out decoder slightly underperforms the vanilla RNN, both with and without self-attention. It also clearly needs the self-attention. 3. On a dataset containing concatenations of videos, the middle-out decoder correctly selects the video to caption based on the most important word provided to it, while the seq2seq model often ignores the conditioning word. However, for a fair baseline one could constrain the beam search to emit the provided word by e.g.  running several beam searches, each forcing the emission of the word at a certain location - the grammar of the captions is simple enough that this strategy should work.  I am unsure about the fairness of comparing sample diversity using beam search, as it is a tool to find the most likely output and by design concentrates around the mode of a probability distribution. To get diverse samples, one should sample from a model. If the network is certain about the proper output the variations in the beam will concentrate near the end of the sequence. The middle-out decoder effectively has two ends (it does two beam searches in parallel), so it may naturally have more diversity - it has variations in the beginning and end of a sequence, rather than just at the end. However, even an unconditional language model, when searched with a beam search, will generate a fairly consistent set of hypotheses and for diversity it should be sampled from.  The novelty of the paper is fairly low: - the self-attention has been shown to improve language models in many prior papers, it is also older than the references given in the paper (e.g. https://arxiv.org/abs/1601.06733) - the solution to run a forward and backward LM to force the emission even if not published before is an obvious baseline to try  Minor remarks: - the order of evaluation of the left-to-right and right-to-left RNNs should be specified in the text - The experiments in Table 3 and 4 slightly confuse the impact of the middle-out decoding and self-attention - why is the vanilla decoder tested without it and the middle-out decoder tested with it? - earlier use of self-attention for text modeling is https://arxiv.org/abs/1601.06733 and it should be included in the references