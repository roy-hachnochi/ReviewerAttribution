This paper presents a method for approximating leverage scores for kernel regression. They propose an algorithm which takes a bottom-up approach and incrementally enlarging the size of the set of columns. Then they argue that combining the leverage score sampling with a preconditioned conjugate gradient method achieves optimal generalization error in time complexity O(n d_eff), where d_eff is the effective dimension of the kernel learning problem, and previously best known running time for this problem  is O(n d^2_eff). The presented algorithm and theoretical results are interesting. However, there are major presentation issues and omissions, especially in the numerical comparisons. Overall, the paper is worthy of publication based on technical contributions. Please see below for detailed comments.  1. The numerical comparisons don't seem to present a fair evaluation of the computational gains. When compared to uniform sampling, the authors only present comparisons within the FALCON algorithm (Figures 4 and 5). Uniform sampling can work better in practice when combined with other methods (e.g. Nystrom, direct solvers, CG and variants ).  2. The authors claim that the time complexity O(lambda^-1 d_eff) is independent in n, and the experiments employ a fixed value of lambda while n grows (Figure 1). However, as noted in Theorem 2, lambda must be set O(d_eff / n ) to achieve optimal generalization error. In this case, the complexity will depend on n.   3. What is 'OPT LS' in Figure 1 ? This doesn't appear in the text.  4. line 42, it's not clear what "state of the art accuracy" means since there is no mention of time complexity. Do you mean better accuracy in fixed time complexity?  5. line 44, typo 'our second,'  6. line 71, The notation for the empty subset \tilde l with double subscript looks odd, is this a typo ?  7. typo in Algorithm 2 description, 'rejection'