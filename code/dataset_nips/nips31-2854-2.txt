Contributions:  This paper addresses the problem of training diverse ensembles, with an additional goal of also training more efficiently. To do this, they introduce the DivE2 algorithm, which solves a continuous-combinatorial constrained optimization problem. To enforce diversity, DivE2 introduces two matroid constraints with parameters p and k, where p controls the maximum number of examples selected by each model, and k controls the maximum number of models that may be assigned to a given example. DivE2 also introduces two submodular regularization terms: one controling inter-model diversity (diversity of examples assigned between pairs of models), and one controlling intra-model diversity (diversity of examples assigned to a given model). The strength of these regularization terms are controlled by lambda and gamma parameters. DivE2 evolves the diversity requirements over the course of T “episodes” of training by gradually trading off p and k, and also gradually decreasing lambda and gamma.  Strengths: - The authors provide good theoretical justification of DivE2. In Section 3.2, the authors show that Algorithm 1 can converge to a local optimum for beta-strongly convex losses for a given (k,p,gamma,lambda) setting. The authors also describe how this approximate solution changes as (k,p,gamma,lambda) change over the course of the T episodes.  - The diversity constraints and regularizers are all fairly interpretable by users. Users can directly tune the regularization terms and set the diversity constraints. - In experiments, the authors also combine DivE2 with multiple state-of-the-art dynamic classifier selection (DCS) methods. This makes sense, since training locally diverse base classifiers naturally lends itself to performing well with DCS methods. However, the authors only present test accuracies for these methods, while the main purpose of DCS methods is to speed up evaluation time. As an extension to these experiments (perhaps in a later paper), I would be interested to see experimental results for evaluation time speedups using DCS methods with DivE2. Specifically I’d be interested in the question, does combining DivE2 with DCS methods provide better evaluation time speedups than DCS methods alone?  Weaknesses: - The DivE2 algorithm requires 4 user specified hyperparameters: T (the number of training “episodes”, where diversity requirements change for each episode), delta_k (change in k after each episode), delta_p (change in p after each episode), mu (change in gamma and delta after each episode. These hyperparameters all seem hard to select a priori, and would presumably have to be validated during training. - While DivE2 can reduce the number of examples seen by each base model, it also introduces additional overhead through the constrainted combinatorial optimization step. The authors show experimentally in Table 1 that the SubmodularMax step takes <10% of the total training time, which seems reasonable, so this is not a huge weakness. Recommendation: Overall, this paper presents a method for training diverse ensembles with strong theoretical and empirical results. My recommendation is to accept.