This paper deals with the problem of binary classification in the case  where the training sample consists of positive data equiped with confidence (Pconf) The authors show that the classification risk can be expressed in terms  of positive data. An empirical risk minimization framework is considered. they derive rates of convergence for the emprical risk minimizer estimator. Futhermore, they perform a simulation study which shows the good performances of the proposed method for classifcation problems.  I find the paper interesting and very clear.  Hereafter my comments/questions:  1) I am a bit suprised by the fact that the authors do not cite the following paper "Classification from Pairwise Similarity and Unlabeled Data" (Han Bao, Gang Niu, Masashi Sugiyama)    Indeed, this paper seems to consider similar techniques for the positive-unlabeled classification framework.  2)Can we improve the rate of convergence with some extra assumptions on the distribution (e.g margin conditions) and on the loss function (e.g on the modulus of convexity) ?   Response to the Rebuttal ---------------------------------- I read the rebuttal and the other reviews. I thank the authors for their responses. I update the overall score of the paper.