I think the authors provided a solid rebuttal. My concerns with a) comparison with ShiftNet, b) sampling vs learning shift and c) comparing also GPU times were all sufficiently addressed.  I am thus recommending to accept the paper. =============== The paper proposes a layer coined as ASL that combines learnable shifts with 1x1 convolutions. The overall framework, which can be viewed as a generalization of ShiftNet[23]. The ASL layer can fully capture the normal convolution (given enough channels) and can automatically trade off kernel size and the number of (traditional) channels, having only one hyperparameter: the number of output channels. For inference, the ASL only requires 1x1 convolution, and shifting operations (with interpolation for fractional pixel shifts). The authors do not mention the cost of the interpolation, but assuming that is small, the overall complexity is little compared to plain 1x1 convolution.  The paper is overall well written and easy to follow, and I think the proposed approach is sound and elegant. However I'm not an expert in this field and thus have a harder time assessing the significance of the experimental results. Overall, the network seems to be faster than competing approaches, but I have some concerns: * When comparing ASL to ShiftNet, why is not the exact same architecture used and only heuristic shifts vs learned shifts compared * It is a bit surprising that all the learned shifts look like gaussians in the range -3...3 in Fig 3. What would happen if you just randomly sampled the shifts instead? * How do the timings change when testing on a GPU instead of CPU?