This paper studies continual learning with generative adversarial networks. Specifically, two methods are proposed: 1) joint retraining with replayed samples 2) replay alignment.  This paper addressed relatively important problem and suggest a reasonable baseline.  I have concerns with the novelty of the proposed method because "joint retraining" and replay alignments are already employed in two papers referenced in each sections and application of the method in this problem seems straightforward.  However, I believe applying these method to new important domain is valuable enough to be published if the experiments are solid.  My another concern is the evaluation setting, where diversity of generated sampled in each class is not highlighted. - In the visualisations, only a single sample for each class is visualised. This visualisation make it hard to evaluate the catastrophic forgetting in terms of the sample diversity. I am not sure the proposed method keeps the model generate diverse sampled of previously learned task. - In the evaluation based on the classification accuracy, I believe sampled images should be used as a training examples, instead of the test examples. This is to evaluate the sample diversity. If generated samples for each class are identical, it is easy to achieve high accuracy if the samples are used as a test set, but it would be difficult to achieve high accuracy if the samples are used as a training set. Therefore I suggest to train classifier on samples and evaluate on oracle dataset (with true images).  [Update after author response] My primary concern about this paper was experimental setting and diversity within class.  These concerns are effectively addressed in the author response and I am convinced with the results. I highly recommend authors to include discussion related to the updated results in the main paper if the paper is accepted.