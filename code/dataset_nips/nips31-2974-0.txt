The paper presents a system for inferring vector graphics programs from hand drawn raster images. The proposed method first generates a 'spec' (which is conceptually just an unrolled program trace) using a neurally guided sequential monte carlo scheme, and then compresses this spec into a program using the Sketch synthesizer augmented with a neural policy.  I believe that this is a strong submission that should be accepted  Novelty: The task presented in the paper seems to not have been considered much in previous literature. One exception is  Ganin et al. "Synthesizing Programs for Images using Reinforced Adversarial Learning", which appeared on Arxiv before the NIPS submission date, so should be cited. The paper combines an number of ideas: (1) a novel CNN + MLP architecture for generating grammatically correct specs from images (2) neurally guided SMC sampling of specs (3) a robust learned distance metric between images (4) a learned bias optimal search policy on to of Sketch. This combination of methods is novel and figures illustrate the benefits that each component brings.  Significance: Combining the perceptual power of neural networks with the interpretability and extrapolation properties of programs is a very exciting research direction and this paper is a great demonstration of the utility of this combination. I think that the application is of real practical use for technical drawing generation and the extensive results presented in the paper show that the approach is already good enough to be a useful tool.  Clarity: Since there are many ideas in this paper (see (1)-(4) above) the presentation is very dense to fit in 8 pages. I had to refer to the appendix to really understand the neural network architecture and search policy training, but I think that with so much content it will be difficult to achieve a better balance between clarity and compactness. One thing that I could not find was a precise definition of "number of errors" in Fig 4.