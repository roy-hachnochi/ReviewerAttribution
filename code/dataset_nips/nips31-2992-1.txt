PAPER SUMMARY:  This paper proposes an interesting variational inference framework for a weakly supervised learning scenario (with counting data) where the corresponding output to each input datum is not directly observable. Instead, the training data is partitioned into subsets & a noisy observation of the aggregate output of each subset is provided. The task is to learn a mapping from each (unseen) input datum to its corresponding output.  SIGNIFICANCE & NOVELTY:  Addressing the regression task using aggregate observations instead of individual observations using GP with Poisson likelihood is interesting & fairly new to me. The technical development also appears correct and feasible.  The authors should, however, provide a more in-depth discussion to highlight the fundamental differences (in terms of both model formulation & solution  technique) between their proposed framework & the previous work of Gaussian process modulated Poisson process [17] (VBPP). This is only mentioned very briefly in the related work section that VBPP did not handle aggregation of output. While this is true, it is also interesting to know why it is non-trivial to extend VBPP to handle aggregate output & how did the authors' new formulation & solution technique address(or sidestep)  this challenge (hence, the significance of the proposed work).  EXPERIMENT:   A related work [17] (VBPP) was also tested on the same domain of Malaria prediction task. Is the experiment setting in [17] amenable to the proposed framework (e.g., one datum per bag)? It will be interesting to compare the performance of VBAgg and VBPP in such setting.   The authors may also want to include further experiments with varying the no. of inducing points. As we increase the no. of inducing points, the prediction quality should improve at the cost of extra processing time. For a specific task, I imagine this would help us determining the "right" no. of inducing points (i.e., too few inducing points will degrade the prediction quality but too many inducing point will incur extra computing cost).  CLARITY:  The paper is clearly written. I do, however, find the notations are a bit too dense & hard to follow. If possible, please consider simplifying the notations to improve readability.  REVIEW SUMMARY:  This is an interesting paper with novel contributions. The proposed theoretical framework is new to me (to the best of my knowledge) & is also demonstrated empirically in an important real-life problem with promising results.  ----  I have read the rebuttal. Thank you for the clarifications.