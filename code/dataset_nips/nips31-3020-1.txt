This paper proposes a recurrent transformer network (RTN) for semantic correspondence that aligns semantically similar images. The main idea is to perform an alternating process of estimating local spatial transformations between the input images and using these transformations to generate better aligned features for further estimations. This iterative residual regression gradually improves the dense alignment between the images. The training is done in weakly-supervised manner by maximizing the score of the estimated transformation relative to other transformations.  + The proposed method is clearly motivated and novel. + It combines the recent methods and improves them in an interesting direction.  + The weakly-supervised training is adopted with a new loss function.  + Experimental results demonstrate its state-of-the-art methods on standard benchmarks.  - The introduction is misleading and confusing in some aspects (see below).  - Some details are missing in the manuscript (see below).   I like the contributions of this paper overall. But, the exposition of this paper needs to be revised, in particular, in the introduction. The authors divide recent methods with geometric deformation into two classes: STN-based [5,18] vs. geometric matching [28,29]. Then, is it adequate to say “most of the state-of-the-art techniques take this approach (STN-based)” given Table 1? And, how about framing them as 'modeling local deformation vs. global deformation' based on line 78-89? To deliver better understanding to general readers, 'STN' sounds too specific and 'geometric matching' sounds ambiguous for the introduction. I highly recommend revising the introduction considering this. Line 31-35 is totally mistaken. The work of [28,29] does not require supervision: [28] is self-supervised and [29] is weakly-supervised. Also, feature representations of [28,29] are not learned independently from transformation learning. Actually, their feature representations are learned jointly end-to-end in [28,29]. Please check them out. In addition, the results of [29] in this submission is different from the CVPR paper version. Please check the final version: http://openaccess.thecvf.com/content_cvpr_2018/papers/Rocco_End-to-End_Weakly-Supervised_Semantic_CVPR_2018_paper.pdf  In section 4.4, the set M_i is not properly defined.  Each position i has its affine transformation and only the translation factor f_i looks used for final output. Then, is the affine transformation really necessary for better performance? It would be good to show the effect in the ablation study.   How is the running time of the proposed method compared to other methods?  The proposed method looks able to be trained with strong supervision if available. How is the performance trained with strong supervision from the benchmark datasets?