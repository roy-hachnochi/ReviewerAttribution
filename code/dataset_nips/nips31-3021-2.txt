* Summary of the paper This paper deals with the OCO framework where the learner may violate pre-defined constraints. In this setting our objective is to provide low regret with respect to the sequence of losses as well as with respect to the constraints.  This setting is useful when one would like to avoid projections which might be costly.  Previous works focused on the regret with the respect to the cumulative constraints, where constraint violation may be compensated by constrained satisfaction. In this work the authors consider a more appropriate measure of regret which accounts only for constraints violation.  In this case, the authors come up with a new algorithm (similar in spirit to previous approaches), which provides regret guarantees with respect to the sum of squared constrained violations. They also extend their approach to the strongly convex setting.     *Quality and Clarity -The paper is  well written. The setting is clear and so is the algorithmic approach. Unfortunately, the authors do not provide any proof sketches in the main body of the paper, in my view this will make the paper much more complete.   -I went through some of the proofs in the appendix and they look clean and sound.  -Their approach does not seem to apply to the case where we have an access to noisy versions of the constraints. It will be good if the authors can discuss this issue and mention what prevents them from extending their approach to this setting.  *Originality: -This paper tackles the more appropriate measure of regret for constraint violation.   -Their technique of Lagrangian formulation is very similar to previous works.    *Significance: In my view the main significance of this paper is in showing that one can provide guarantees with respect to the appropriate measure of constraints violation. The technique used is not very novel and is similar in spirit to other approaches.  As the authors demonstrate in practice, their new approach enables to obtain better performance in several settings. 