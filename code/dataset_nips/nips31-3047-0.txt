Thank you for the clarifications. I am inclined to keep my ratings. One concern I still have is the new approach (BoxERFNet) doesn't seem to be giving any gains in Cityscapes (test) so I not sure how effective the approach is. The results on the SUN RGBD are good but as mentioned, the earlier models were not tuned for that dataset, so it is hard to make a strong conclusion.  -----------------------------------  The paper introduces a way to use integral images in neural nets. Integral images used a trick for fast computation and has been used for many problems in computer vision but had not been used in neural networks yet. The learning allows the convolution filter dimensions and positions to be learned and that too in a faster manner.  The paper is easy to read and provides sufficient background to understand the problem and solution. The strength of the paper seems to be that using this technique can possibly reduce the computation time (but see concerns below) even though the segmentation accuracy does not increase in all instances.  It would be useful if the authors address some of these concerns.  It would be beneficial to summarize the contribution of the paper in a few bullet points.  Line 131, define L.  Why does Table 1 not include test results for ERFNet and BoxERFNet and Table 2 not contain ERFNet type results? The results of ERFNet and BoxERFNet seem to be very similar and so the integral images seem to only be beneficial in terms of reducing time.  Are the runs in Tables especially Table 3 averaged over multiple runs. Because it is interesting to see that the integral images helps in the ERFNet but not ENet in terms of GPU time (or what does it mean that the optimization does not reach the level of cuDNN)?  Do we get similar box positions and sizes during multiple runs on convergence. If not, are one set of results better than another?  minor:  line 271: The bigger the effective ... line 289: We have introduce"d" a new ...  The supplementary material have some equation numbers missing (i.e. ??).  