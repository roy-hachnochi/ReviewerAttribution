This paper considers a modification of a full Gaussian natural gradient variational approximation scheme suggested previously in the literature.  It achieves greater scalability through a low rank plus diagonal approximation to the precision matrix in the variational parameter updates.  The authors argue that the ability to capture dependence in the posterior is important in some applications and the approach can be implemented in high dimensions.  I think this is a high quality contribution, the manuscript is clearly written and I think the methods described are useful.    I have a few questions for the authors.  1.  How easy is it to relax the assumption of isotropic Gaussian priors?  Is there any prospect to incorporate dependence or non-Gaussian sparse shrinkage priors having Gaussian scale mixture representations?   2.  Given the many approximations made, is there anything that can be said theoretically about convergence?   3.  The examples consider logistic regression and neural networks with a single hidden layer.  This seems at odds with the deep learning title of the manuscript.  In the examples in Section 5.2, predictive performance is described for the case of L=1 and this works well.  For larger L Figure 3 explores the convergence rate in the optimization and larger L gives faster convergence in terms of the number of iterations.  However, for the case of neural networks I wonder whether larger L also means better predictive performance.  Relating to a remark at the end of Section 5.1 of the authors, if this is not the case it reflects the variational objective more than their proposed method but it would be nice to see some comment on that issue. 