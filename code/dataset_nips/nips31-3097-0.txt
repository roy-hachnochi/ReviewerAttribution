This paper carefully studies the privacy amplification effect of subsampling in differential privacy. That is, when a differentially private algorithm is run on a random subset of the whole dataset, the privacy guarantee for the whole dataset is amplified relative to that of the subset.  This is particularly important for analyzing private versions of algorithms like stochastic gradient descent.  This is a well-known and important property, but this paper gives a more thorough analysis than has previously been presented. Previously this property has only been analyzed "as needed" and, to my knowledge, no extensive study is available.  I think the tight bounds in this paper will be a useful reference and the techniques may find other applications. My only complaint about the paper is that it is very technical and hard for a non-expert to digest. I suggest including easily-interpretable self-contained statements of the main results that do not rely on all the notation developed. I.e., make it as easy as possible to cite a result from this paper using standard notation.