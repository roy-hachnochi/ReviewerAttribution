Main idea:  This paper extends SPEN by considering a special architecture of the energy network, where the potential/energy vector is explicitly computed as a hidden layer. This enables a dual decomposition inference algorithm, thus somehow circumvents the discrete optimization over the structured output space, which was the main difficulty/restriction of SPEN.   Strength: I would like to mention that the idea is a natural extension of structured SVM with dual decomposition inference [*, **] to SPEN. It would be better if the connection was discussed at Sec 3.1. I really like the way dual decomposition applies. It doesn't decompose over factors as originally it was intended to, but it separates the discrete optimization out from the continuous one, which sheds light on how we deal with discrete variables in a neural network.    Clarity: - A better explanation of Fig 1 should be added. It is really hard to see why SPEN corresponds "independent" while the proposed method is labeled structured.  - In (1) and L153, the difference between SPEN and the proposed T(c,H(x,c)) is not clear. I don't understand why is this more general than SPEN given the definition of SPEN is quite general as a neural network taking both x and c as the input.   Weakness: - (4) or (5) are nonconvex saddle point problems, there is no convergence guarantee for Alg 1. Moreover, as a subroutine for (7), it is not clear how many iterations (the hyperparameter n) should be taken to make sure (7) is convergent. Previously in structured SVM, people noticed that approximate inference could make the learning diverges.  - Performance boost due to more parameters? In Tab 1,2,3, if we think carefully, LinearTop and NLTop adds additional parameters, while Unary performs much worse comparing to the numbers reported e.g. in [14], where they used a different and probably better neural network. This raises a question: if we use a better Unary baseline, is there still a performance boost?  - In Table 1, the accuracies are extremely poor: testing accuracy = 0.0? Something must be wrong in this experiment.  - Scalability: since H(x,c) outputs the whole potential vector with length O(K^m), where m is the cardinality of the largest factor, which could be extremely long to be an input for T.  - The performance of NLTop is way behind the Oracle (which uses GT as input for T). Does this indicate (3) is poorly solved or because of the learning itself?  [*] N Komodakis Efficient training for pairwise or higher order CRFs via dual decompositio. CVPR 2011. [**] D Sontag et al. Learning efficiently with approximate inference via dual losses. ICML 2010.   