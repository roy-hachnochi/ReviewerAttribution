Summary: This paper presents a new algorithm called Bayesian Distributed SGD to mitigate the straggler problem when training deep learning on parallel clusters. Unlike Synchronous Distributed SGD approach where a fixed cut-off (number of workers) is predefined, BDSGD uses amortized inference to predict workers’ run-times and derive a straggler cut-off accordingly.  By discarding sub-gradients from slow workers, the overall system throughput increases and hence faster time to convergence. BDSGD models the joint run-time behaviour of workers which are likely to be correlated due to the underlying cluster architecture. The approach is incorporated as part of the parameter server framework, deciding which sub-gradients to drop in each iteration.        Strength: The proposed idea of adaptive cut-off and predicting joint worker runtime through amortized inference with variational auto encoder loss is novel and very interesting.  Well-written and straightforward for readers. The evaluations are done with real-world datasets and different workloads. Both model convergence and system profile are reported.  Weakness and comments: To handle censored observations, the authors propose to sample uncensored data points to impute the missing run-times. Will such sampling suffer from bias given that the uncensored data points are only available when the workers successfully pass the cut-off: uncensored run-times tend to be shorter than censored ones? In this case, wouldn’t this imputation negatively affect the subsequence inference performance? Since a new cut-off is derived in every iteration, can the authors also demonstrate more detail on the cut-off value over time? The training dataset is generated by instrumenting the cluster once and then used to train the model to encode worker’s runtime behaviour. If the cluster utilisation at test-time is very different from that when training dataset is gathered, will the model still be as accurate as expected? Also, since gradients produced by stragglers are dropped due to the cut-off mechanism, it seems difficult to collect the actual straggler run-times to further adapt the model (plus the effect of the imputation). In figure 3, would be useful to include convergence based on Chen et al technique. Can the authors comment why BDSGD results in high-variance throughput while Chen et al technique has a relatively stable trend? In the context of high communication cost, why is BDSGD’s throughput significantly lower than Chen et al’s? Can the authors give explanation on this?  Can BDSGD be used with distributed parameter servers?     *UPDATE* I would like to thank the authors for the rebuttal. I have read the discussion provided and am happy to increase the overall score. 