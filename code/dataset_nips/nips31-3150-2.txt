Summary of paper contributions:  This paper falls within the line of work on adaptive data analysis modeled on the basis of the statistical query model of Kearns. Their work is to show the limitations of algorithms that satisfy post hoc generalizations, as defined by Cummings et al.   They show that  1. Algorithms satisfying post hoc generalization are require at least order k/\eps^2 samples to answer k adaptive queries with accuracy \eps, on datasets of dimension at least logarithmic in n.   2. They demonstrate a similar sample complexity lower bound for polynomial time algorithms, based on the existence of one-way functions.   3. Finally they show that algorithms satisfying post hoc generalizations do not compose: i.e. they construct O(\log n) algorithms satisfying nontrivial post hoc generalization whose composition has essentially trivial post hoc generalization.    Summary opinion:  The paper is well-written and has interesting lower bound results on the post hoc generalization notion of Cummings et al.  It will be of significant interest to the community and a good addition to the program. Consequently, I recommend its acceptance.  Comments for authors:  1. For the natural algorithm lower bound, it is not mentioned what the sample X \subset [N] is. Presumably the definition is something simple.  2. Similarly there seems to be some notational inconsistency e.g. q^j_i vs q^j(i) for algorithm 2.   3. It is not clear in some places whether the notation O() or \Theta requires to be used, e.g. in Theorem 3.1. It  improves clarity for the reader to be careful with this.    I have read the author response. I would strongly recommend to the authors to include a proof overview highlighting and expanding the differences and technical novelty of their techniques to prior work, as they indicated in the response. 