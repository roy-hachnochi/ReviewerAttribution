The authors present a method of jointly training image2text and text2image methods which leads to faster training and better results.   The two biggest problems of the paper are from my perspective:  - there is no meaningful comparison with the literature. Table 1 and Table 2 have no single comparison result. - the authors should compare their training scheme (which I personally really like) to GAN training. In my view the idea of training two networks "against" each other is very similar in spirit. Further (but beyond the scope of this paper) - I am wondering whether some of the tricks that have recently been invented to make GAN training better/faster/more stable would also apply to the presented method.  Similarly, the authors shoudl relate their method for semi-supervised learning to the cyclegan approach   Section 3.3: While the method is arguably working well - I don't find the interpretatin in sec 3.3 compelling at all. It would be great to give some more experimental analysis of this point.   minor comments:   line 19: intensively -> instensely  line 18: that requires -> that require  line 24: leaving a -> leaving   line 39-46: reads as if the two training steps (left/right in Fig1) are performed sequentially - in fact they are performed alternatingly - the authors could make this part much clearer in the paper  fig 1:   - the visualization of the weight sharing is not really clear  - the arrows that go from the bottom back to the top - are not really clear  regaring the remaining description of the method the authors refer e.g. to L_r and L_l  meaning left part of the figure and right part of the figure. This makes it sometimes hard to follow the notation. If the authors would rewrite this as L_{DC} and L_{CD} (with C for caption, D for drawing) I feel the notation would become easier to follow  line 182: is very repetitive - says the same thing twice.  