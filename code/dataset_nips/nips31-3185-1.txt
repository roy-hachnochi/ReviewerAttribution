The paper presents a method for generating high resolution shapes from either a single image or a low resolution shape. Instead of increasing the resolution of the volume, the method is using the depthmaps (ODM) from 6 canonical views (orthographic images from the 6 primary views). The ODMs are estimated from the low resolution shape and then two networks estimate the high resolution depthmaps and the silhouettes of the shape. Finally, the high resolution shape is estimated with 3D model carving.   I like the idea of depthmap super-resolution for generating high resolution shapes. Also, the canonical views seem to capture well the details of the shape. Finally, the results look very good and accurate. Some questions: How does the method perform with concave shapes? Does the depth map estimation solve these cases? Regarding the learning of the residual details, was the accuracy of a direct approach inferior? Do you process the depthmaps independently with the same networks?  Regarding weaknesses, the use of silhouettes and depthmaps for shape reconstruction is not new, see missing references [A, B, C] (they should be included and discussed). Also the final shape is not estimated directly form the depthmaps but rather from a combination of depthmaps/silhouettes and up-sampled low res shape.Why you can't fuse the depthmaps to get the final shape?   [A] Synthesizing 3D Shapes via Modeling Multi-View Depth Maps and Silhouettes with Deep Generative Networks, Soltani et al CVPR 17 [B] Pixels, voxels, and views: A study of shape representations for single view 3D object shape prediction, Shin etal CVPR 18 [C] OctNetFusion: Learning Depth Fusion from Data. Riegler etal 3DV 17