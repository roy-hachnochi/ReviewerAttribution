Post-rebuttal: Thank you for taking the time to run additional experiments for the rebuttal and answer our questions. Your answers to my questions are generally convincing. Regarding WalkSAT, the 100%-solved result goes to show that problem-specific heuristics can be very powerful. The same could be done for MIS, see [z] for example (with code). I hope that future versions of this paper include better baseline heuristics for comparison, and wish you luck.  [z] Lijun Chang, Wei Li, Wenjie Zhang, "Computing A Near-Maximum Independent Set in Linear Time by Reducing-Peeling" Proceedings of the ACM SIGMOD International Conference on Management of Data (SIGMODâ€™17), 2017  Code for [z]: https://github.com/LijunChang/Near-Maximum-Independent-Set ------------------------------------- This paper proposes a new deep learning framework for generating solutions to some combinatorial optimization problems on graphs. The proposed method is supervised (instance-OptSolution pairs are provided in the training set), and uses graph convolutional networks (GCNs) as a deep learning model that maps an input graph to a latent space and then to a probability distribution over vertices. The distribution can then be used to generate a potential solution to the optimization problem. Since an instance may have multiple optima, learning to generate a single optimum may not generalize well. To address this issue, the first primary contribution of this paper is to generate multiple probability distributions, rather than a single one, and use the so-called "hindsight loss" for training. This allows the deep learning model to generate multiple guesses of what it thinks an optimum should look like, but the hindsight loss penalizes only for the best such guess produced. Another contribution is to hybridize the deep learning model with certain classical steps typically used in combinatorial optimization, namely graph reduction, tree search, and local search. In practice, the proposed method is used to solve the Maximum Independent Set (MIS) problem, and other graph problems are solved by reducing them to MIS, then transforming the MIS solution back to the original problem of interest. Experimentally, it is shown that the proposed method outperforms S2V-DQN, a reinforcement learning + graph embedding approach proposed recently. The proposed method also generalizes well across different sets of instances, as well as from small training instance to much larger test instances. An ablation and hyperparameter study illustrate that the various components of the proposed method all substantially contribute to its performance.  Overall, I am positive about this submission and so my score is 7/10. I think the paper is well-written, features some methodological contributions, and shows promising experimental results. I do have some questions that I would like the authors to address.  1- Efficacy beyond MIS: First, as the authors note in their conclusion, a reduction to MIS may involve a quadratic number of variables in the original problem size, limiting the applicability of an MIS-trained GCN to other problems. Second, it should be noted that the proposed method works for subset-selection type problems, like MIS, but not for permutation-type problems like the TSP; the authors do not claim otherwise, but it is important to acknowledge this point or discuss straightforward extensions to the method that would make it work for say the TSP and similar problems. Last but not least, I am concerned that the proposed method may be really good for the MIS, but not for other problems. It is clear that a good MIS algorithm will result in good solutions to the original SAT instance, since a higher MIS objective makes it more likely that the SAT instance becomes satisfiable; the same can be said for MVC and MC, and the authors demonstrate great results in this setting. However, what if you were to apply your procedure to a problem other than MIS during training, as done in [6] (tsp and knapsack) or [10) (tsp, mvc, maxcut)? Answering this question is necessary to understanding the generality of the proposed method.  2- Comparison against SAT methods: for the SAT experiments, it only makes sense to compare against SAT algorithms, rather than MIS algorithms on the transformed instance. For example, one can use GSAT or WalkSAT heuristics, or their more advanced versions. Additionally, the authors should compare against NeuroSAT [2], which uses neural graph message-passing on the bipartite graph encoding of a SAT instance to classify it as sat/unsat and eventually produce a potential assignment. The same can be said about the MC/MVC experiment of tables 3, 5, 6.  3- Role of graph reduction: related to point 1 above, the graph reduction procedure is very specific to MIS, and is a performance booster based on Table 4. If one were to apply your method during training time to a problem other than MIS, would they be able to leverage similar graph reduction techniques? Another point here is related to your training set: the graph reduction may work better because of the structure of the MIS graph, since it encodes a SAT instance, which is a very structured object. I am not sure the graph reduction procedure would be as effective on other types of graphs.  4- Hyperparameter tuning: How do you select L=20, C^0=32? The choice of M=32 is well-justified by Figure 3, but the other two seem to be based on intuition. Please comment on any hyperparameter search you may have performed, or why you think such values are inherently good and will generalize to another training distribution.  5- Hindsight loss minimization: This is just my lack of expertise with this particular loss, but how do you optimize it given that the min operator makes the function non-differentiable?  6- Tree search or beam search? Tree search is usually associated with complete methods that are guaranteed to find an optimum and certify its optimality. What you use is more like beam search that decodes the M probability distributions; worth thinking about the right name here.   7- Missing references: [1] hybridizes a learned TSP policy with local search methods - worth to connect it with your hybridization approach. [3-6], similarly to reference [19] by He et al., use supervised learning for branching/primal heuristics in tree search.  [1] Deudon, Michel, et al. "Learning Heuristics for the TSP by Policy Gradient." International Conference on the Integration of Constraint Programming, Artificial Intelligence, and Operations Research. Springer, Cham, 2018. [2] Selsam, Daniel, et al. "Learning a SAT Solver from Single-Bit Supervision." arXiv preprint arXiv:1802.03685 (2018). [3] Khalil, Elias Boutros, et al. "Learning to Branch in Mixed Integer Programming." AAAI. 2016. [4] Khalil, Elias B., et al. "Learning to run heuristics in tree search." 26th International Joint Conference on Artificial Intelligence (IJCAI). 2017. [5] Alvarez, Alejandro Marcos, Quentin Louveaux, and Louis Wehenkel. "A machine learning-based approximation of strong branching." INFORMS Journal on Computing 29.1 (2017): 185-195.  Minor typos: 179: breath-first -> breadth-first 181: bread-first -> breadth-first