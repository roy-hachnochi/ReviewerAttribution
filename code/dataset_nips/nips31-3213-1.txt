This paper examines the approximation of uniform and normal distributions using neural networks provided with a uniform or normal distribution at its input. The paper's main contributions are   1. the upper- and lower-bound for approximating higher dimensional uniform distributions with a lower dimensional one. The main idea is the use of an affine space-filling curve, which has been examined in a similar context before. 2. providing a neural network transformation to go from a uniform distribution to a normal and vice-versa.  Overall, the paper is a pleasure to read and tackles the important question of the required size/depth required for a neural network to approximate a given distribution.  Some minor notes:  Section 2.2 is not an easy read without delving into the appendix. Perhaps some intuition can be provided for the statement in line 138. Lines 145-148 are also a bit terse. An added explanation of how the lower and upper-bound compare (as is done in line 33 of the intro) would make the strength of this section more apparent.  Section 4 is somewhat trivial as it is stated. I would suggest adding a few sentences making the comparison with the result of Section 3.2 more explicit, so that the added benefit of more dimensions of uniform noise to approx. a normal becomes clear.  If more space is required, perhaps consider reducing the size of Figure 1 or placing proof of Th. 11 in the appendix.  Some typos:  l 53 This idea [h]as l 104 How easy [is it] to l 190 good behavior <- vague l 269 we [...] get a bound