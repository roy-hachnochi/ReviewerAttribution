Summary of the paper:  - This paper proposes a walk-based method for knowledge graph completion (KGC).  - For triples (s, q, o), an agent is trained so that given s and q, it traverses a path from the initial node s to the   terminal node t in a knowledge graph.  - This problem is formulated as that of Q-learning using RNN to model policy and Q functions, but the issue is the   sparseness of rewards.  - Monte Carlo tree search is used to overcome this issue.  Pros:  - The paper is clearly written.  - The approach is natural and sound.  - Very good performance compared with existing KGC methods.  - Ablation study with PG-Walk and Q-Walk is nice.  Cons:  - The work is mostly empirical, without much theoretical justification (admittedly, as in many deep learning papers).  - Not much novelty or surprise, given the success of AlphaGo.  This is a type of paper in which a successful technique   in other fields is applied to a different field.  I could not see exactly what is the novelty/creativity in terms of   how MCTS is applied for this specific problem of KGC.  - No analysis on running time is provided.   General Comments:  This paper is well written (but I would like the content of Section 4.2 to be more organized --- Page 7 consists of a single paragraph now!).  The novelty of the proposal is somewhat questionable, because reinforcement learning has already been introduced for KGC, and the application of MCTS naturally comes to mind.  Although this work is mostly empirical and little theoretical contribution is provided, it still achieves the state-of-the-art performance, and that could be a merit for its publication.  Questions:  * Related work  MCTS has been introduced in walk-based KGC by Sheng et al. in ICLR 2018 Workshop (ReinforceWalk: Learning to Walk in Graph with Monte Carlo Tree Search), and this work must be cited.  Please elaborate on how M-Walk differs from ReinforceWalk as much as you can tell from the extended abstract.  * Experiments:  - Dataset:  Is there any reason the comparison is done with NELL995 and WN18RR?  FB15k is also the standard dataset.  - Baselines  Why do the set of compared methods differ between datasets?  In particular, we know that TransE and TransR are somewhat weaker compared with more recent bilinear models, such as ComplEx, ANALOGY, and ConvE.  - Evaluation metrics  Also, why is the MAP score used on NELL995 whereas HITS@/MRR are used on WN18RR?  I have nothing against MAP scores, but typically HITS@/MRR are reported in literature on KGC even on the NELL-995 dataset (e.g., the MINERVA paper); using different metrics makes it difficult to validate the experimental results.  - Figure 6(a)  Is there any explanation as to why accuracy drops as the number of roll outs are increased to 256?  * Application to classification task  The method is only concerned with prediction of knowledge triple in which only one entity is missing. Can the proposed method be applied to the triple classification task where the truth of a given triple must be predicted? This is more or less straightforward in score-function-based models (provided that a suitable threshold can be determined), but I cannot see how this can be addressed with walk-based methods in general.  * Running time  Training and inference both involves roll-out, which raises concern about the running time of the algorithms.  How does M-walk fare against scoring-based methods (e.g., ComplEx) or MINERVA in terms of running time?  Please provide the time required for training and inference.  I am curious about inference time in particular. 