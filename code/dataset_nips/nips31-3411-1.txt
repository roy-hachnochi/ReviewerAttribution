This paper addresses the problem of multi-domain adaptation.  We are faced with several (closely) related tasks, each one with limited resources to train a classifier.  The classical approach is to map from one or several sources domains to the target domain, disregarding potential relations among the source domains.  In this paper, it is proposed to also consider weighted relations between the source domains.  The approach is named Multiple Domain Matching Network (MDMN). The paper is well written. I'm not an expert of transfer learning, but I was able to follow the motivation and main ideas of this work.  The algorithm is evaluated for an image classification task and two tasks of the medical domain. Each time, N-1 tasks are considered as source domain and the Nth task as target.  In image classification, the tasks are MNIST, MNISTM, USPS and SVHN. The proposed method nicely outperforms other domain adaption methods. I'm not working in computer vision, but it seems to me that the state-of-the-art performance on MNIST is better than 5.4% error.  The goal of the medical tasks is to predict emotion or treatment stage given EEG measurements while subjects are watching dedicated movie clips. Again, MDNN outperforms published work.  What is your recommendation when your approach should work best, in comparison to other domain adaptation frameworks ?  When we have several source domains which are rather heterogeneous ?  Does your algorithm scale with the number of source domains ? I guess that it does not improve on other domain adaptation or transfer learning approaches if you have only one source domain.  I also wonder if your approach could be used to outperform the best known separate baselines of several tasks ? For instance, the current state-of-the-art on MNIST, ImageNet and FlickR ?