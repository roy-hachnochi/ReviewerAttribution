summary:  This paper describes a probabilistic framework for anomaly detection using manifold learning by adversarial autoencoder. The data distribution is modeled as a smooth manifold with an independent noise component and the adversarial loss encourages the model to learn it by forcing the encoder to map x to a z with distribution close to N(0,1). A novelty test can then be derived from the product of the two independent probability density function components: one parallel to the manifold tangent space and one orthogonal to it (the noise). The paper shows that their approach provides state-of-the-art accuracy on 3 standard datasets (MNIST, COIL100, Fashion-MNIST).  The novelty of this approach is to leverage recent developments in adversarial autoencoders into a probabilistic framework for anomaly detection. The independence assumptions made are reasonable and the principles used are sound. The results appear compelling, at least for the datasets used in the experiments. Those datasets are relatively clean with nice separation between classes. It remains to be seen how well this approach extends to noisier real-life data.  The quality of the paper is ok. There are many grammatical errors (see below). The organization of the text is generally good, however i wished more emphasis would have been put into an intuitive interpretation of the approach in a discussion/conclusion section. In particular the conclusion is inadequate. Also there is no discussion about the computational complexity of the approach. Some details are lacking, such as the architecture used for the autoencoders. In general, it seems the quality of the paper is degrading substantially towards the end.  The math is well laid out and relatively easy to follow. I found only one notation error (see below). It think the algorithm should be reasonably easy to implement and the results should be reproducible.  Overall, i think this is a worthwhile paper for NIPS. It present a novel approach that can potentially be of interest to many practitioners. The technical quality is high despite some small issues.    Details:  - Table 1 is missing the definition of the value (is it F1, AUC ?).  - Table 2 is missing the reference [25] for L1-thresholding  - The architecture of the autoencoder is not given. At least the size of the bottleneck should be given.  - Equation (4): pW(w,w_|) should be pW(w||,w_|)  - Line 7: likely is -> likely it is  - Line 12: we improved -> we improve  - Line 39: generating -> generate  - Line 82: leanning -> learning  - Line 85: it represents -> we represent  - Line 85: sore -> score  - Line 101: we have that -> we have  - Line 245: Because count -> Because the count  - Line 247: on training set -> on the training set  - Line 249: since in [8] is used pretrained VGG -> since in [8], a pretrained VGG is used  - Line 252: before uses pretrained -> before, uses a pretrained  - Line 252: we train autoencoder -> we train an autoencoder  - Line 253: on very limited number samples -> on a very limited number of samples  - Line 257: we repeat experiment -> we repeat the experiment  - Line 261: We drop perpendicular -> we drop the perpendicular  - Line 266: because curve -> because the curve  - Line 266: only performs significantly better -> performs significantly better  - line 267: better than "pz(z) only" one -> better than the "pz(z)"-only one  - Line 267: plays essential role -> plays an essential role  - Line 269: presented a approach -> presented an approach  - Line 274: Our analysis showed that the method shows -> Our method shows   ======================= Update after author's feedback ========================  I appreciate that the authors promise to expand comparisons and add details on computational complexity. My overall score remains unchanged.