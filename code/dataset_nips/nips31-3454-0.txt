This paper provides theoretical analysis and empirical examples for two phenomenon in active learning. The first is it could be possible that the 0-1 loss on subset of the entire dataset generated uncertainty sampling is smaller than learning using the whole dataset. The second is uncertainty sampling could “converge” to different models and predictive results. In the analysis, it is shown that the reason for these is the expected gradient of the “surrogate” loss of the most uncertain point is in the direction of the gradient of the current 0-1 loss. This result is based on the setup that the most uncertain point is sampled from a minipool that is a subset sampled without replacement randomly from the entire set. The result is proven in the limit when size of this minipool goes to infinity. In experiments, the two phenomenon is reproduced in both synthetic data and real world data, with slight change of the setup, for example, uncertain points are sampled with replacement there.  My major concern of this paper is whether the theoretical analysis can explain the two wide observed phenomenon in active learning. The main result about 0-1 loss may be interesting. But it only says about the descent direction on the loss with current parameters in each iteration, not the true loss on the whole dataset. So the explanation that we are getting better 0-1 loss with subsets because we are minimizing actual 0-1 loss, not surrogate log loss or hinge loss, is not valid for me. Maybe I am missing some points. But at least there is something missing there in the paper.   Actually, there could be various reasons for the first phenomenon. For example, we may have some noise that is far away from the decision boundary in the dataset and uncertainty sampling could end up with a subset that is “cleaner” than the whole set.  Another issue is the experiments on real data to try different seed size. The setup is sampling the most uncertain points with replacement, which is different with the theoretical analysis and a rare case in active learning. I believe otherwise (without replacement) the variance would be much smaller, all converging to the same decision boundary. It is well known that with smaller random seeds, the active learner is easy to get stuck in wrong decision boundaries due to sampling bias. I am basically not convinced that it is due to multiple solutions of optimizing non-convex loss.  The convergence in this paper refers to the case when sampling data with replacement that the active learner does not query new data, which should be defined earlier in the paper. 