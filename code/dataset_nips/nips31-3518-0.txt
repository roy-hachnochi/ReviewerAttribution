The authors start by assuming that: (1) neural responses x are samples from  p(x|Image), and (2) the brain already has (or has pre-learned) a linear Gaussian generative model of images given responses i.e. p(Image|x) is N(Ax,noiseSD). Using these, they derive that the log posterior over some experimenter defined variable s (that generated the image using an arbitrary function) is a linearly weighted sum of neural responses x; i.e. the neural responses form a probabilisitic population code (PPC) which can be linearly decoded to give the posterior over any experimenter defined variable that generated the images.  The authors thus show that the sampling vs PPC hypotheses are not disjoint, but can actually co-exist by properly defining what is being sampled and what is coded in the PPC. This is a very significant result and definitely deserves to be widely disseminated in the community. Thus I recommend this work to be accepted at NIPS, after these corrections.  major: l 111: If I follow the math correctly, then in the second equality after line 111, there seems to be an extra factor of a normal distribution function with three dots trailing.  While the paper is clear, the authors must put in more effort in proof-reading their texts, so as to not burden reviewers with a huge number of trivial corrections as below! Laxity here also raises doubts on the rigour in the main results ...  minor: l 54: "and do not normally related to either log probability or probability directly." l 86: "presents a images" l 71-72: "Furthermore, and Orban et al. (2016)" l 90: p(s|x) not p(s|r) l 98: Equation 3 and the one below. How does the Normal distribution function have 3 arguments here compared to two arguments earlier? What is the symbol at the end that looks like an Identity symbol? pg 3 footnote: "infinitely samples" l 106: "we get Dr" l 106: equation 4: \bar{x} should be defined. l 165: "will have a global maximum for at the corresponding" l 199: "it will be under the experimenterâ€™s control of T whether the separability condition is met" l 200: " to be invariance over " l 230-231: "generally correspond samples" l 232: "a binary latents" l 228-229: "e.g. making addition and multiplication particularly, respectively" 