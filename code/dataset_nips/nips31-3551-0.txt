The problem of the study is detecting abnormalities within deep neural networks, to detect out-of-distribution inputs, adversarial inputs, and new classes (for class incremental learning). To achieve this, the authors integrate class-conditional Gaussian distributions with a tied covariance (linear discriminant analysis) at various stages of a target neural network and construct distributions over the valid input (in-liers). They use the Mahalanobis distance measure of the Gaussian distribution as a confidence measure (proportional to the log-likelihood). They further enhance the confidence measure by taking Fast Gradient-Sign Method-style steps in the input space to increase the score. Finally, they combine the scores gathered at different layers of the neural network through a linear combination. They evaluate the performance of their method for out-of-distribution detection on CIFAR10, CIFAR100, and SVHN against SVHN, TinyImageNet, and LSUN using DenseNet and ResNet where they establish a new baseline for the state-of-the-art under a variety of difficult conditions. To evaluate the detection of adversarial examples, the authors compare against two other methods ([23] and [7] in the paper) in a supervised (samples of the attack type) and an unsupervised way (only samples of FGSM attack) and they demonstrate superior performance in this area as well. In the incremental learning part, they also demonstrate superior results over the previous work.  Quality. The paper is technically sound and well-organized. The claims are supported by an exhaustive series of evaluations (half of which is in the supplemental material).  Clarity. The paper is easy to follow. The previous work is somewhat limited, only reflecting on the most recent studies of this problem. Someone who's not already familiar with the relevant literature would have difficulty appreciating the work. Although, the paper is already dense in content and analysis, and including more relevant work would clearly push it beyond the length limit. The authors also omit some crucial details. For instance, they mention downsampling of the intermediate tensors for computational efficiency but to the best of my memory, nowhere do they mentioned how much downsampling is applied (or what is the dimensionality of the processed intermediate tensors). A discussion of memory and compute requirement is also missing from the analysis, which presumably could be added to the supplemental material. They also do not mention releasing the source code, which I strongly recommend for consideration.  Originality. The work is clearly a novel combination of well-known techniques. To the best of my knowledge, they are the first group to demonstrate an effective application of the presented methods for these tasks.  Significance. The results are important, especially in the out-of-distribution detection domain. The results of the detection of adversarial samples are unlikely to stay true for a long time; although fooling the presented system is probably more difficult than the previous work because the adversarial samples need to satisfy several constraints at multiple stages of the network. The presented method seems to be effective at addressing the concerns. They demonstrate a new baseline for the state-of-art in several areas. It is likely that more future work would be built based on the observations and results presented in the paper. ----------- Update after rebuttal. The author response has addressed my (minor) concerns.