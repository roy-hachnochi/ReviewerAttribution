The paper proposes to include an intermediate differentiable physics “engine” i.e. a novel parameterization of an intermediate layer in a neural network that respects the forward dynamics as governed by physics. The proposed method is closer to the popular “system identification” paradigm and involves learning the parameters of the engine via gradient-decent, optimizing the squared loss between observed and predicted frames. The paper shows results on some simple, interesting simulation domains and demonstrates the value of including such a module.   Depending on the rebuttal for some of the questions below, I am happy to revise my ratings for this paper.   Positives: - In general, the paper addresses an interesting and challenging question of incorporating more domain / structured knowledge into differentiable and learnable networks.  - An interesting outcome of using a physics engine to transform the latent variable i.e. “step the physics engine” is that the dimensions of the latent space can now be assigned specific labels making the process interpretable to an extent.  Comments and Questions:  - L27 — such to to  - L117 — v in v_{t+h} is not defined before. Although it is not hard to figure out, prefer including what it denotes at first use.  - Given x, \phi_t, \phi_{t+h}., \hat{y} can be computed manually right ? What is the need to use a “decoder” network ? i.e. If I know ball is at position x_t and now has some velocity v for t seconds, I exactly know where the ball is at t+h and so, should be able to construct the next frame without having to “learn”. In this sense, I am not sure why one would burden the network with rendering the scene while also learning the physics of the process.  - The L_{phys} reduces the promise of the differentiable physics engine. One would hope that by directly regressing on to the next frame (of course, one may argue that this is sparsely available however, simulation environments are being considered anyway) and parameterizing the intermediate layers as discussed, the model naturally (i.e. by only optimizing L_dec) learns a reasonable set of parameters that lead to fairly natural \phi vectors. In this sense, having to explicitly supervise these feels slightly disappointing.  - The MLP baseline comparison is crucial to demonstrate the value of the method. From my understanding the provided results use labelled data (\phi_t, \phi_{t+h}) to train this MLP that sits in place of physics() module. Can the authors provide numbers for training such a module using only L_dec (and no labels) i.e. the dimensions of the latent variable are no longer “regularized” by the underlying physics ? Or in other words, if I am to predict \phi_{t+h} or \hat{y} directly, how well does the model perform ? In my opinion, this truly shows the gains due to not using the differentiable forward model. In the current setting, the MLP can be thought of as the physics engine only parametrized differently.  - MSE can sometimes be inadequate for learning — for example, MSE between images can be driven down while the two images look very different to a human eye. Did the authors consider trying out other losses for comparing the frames ?  After Rebuttal: With the additional evaluations and clarification of the discussions from the rebuttal into the paper, it will make for a reasonably interesting work to be accepted at NIPS. I am revising my rating accordingly. 