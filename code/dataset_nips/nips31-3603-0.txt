Main Ideas: -- They present a multi-agent RL framerork in which the agents choose when and who to colloborate based on a new attention network structure. -- This eliminates excessive communication among agents, as well as provides dynamic communication schema, which is less restrictive.  Strengths: -- The communication is selective based on the attention and only considers the nearby agents, without considering unnessary communication with distant agents. This type of learning fits to games scnearoies like finding lanmarks in a maze where muliple communative agents will be helpful.  -- The communication model tested on three different tasks, to show the strenght of the new approach. -- The paper is well written, organized and motivation is clear.  Weaknesses:  -- Only toy tasks are used. -- The same network with no communication or communication with all the rest of the agents should be two of the baselines of this model.  -- The experiments section investigates different episodes of the model yielding insteresting conclusions about the fact that when communication is necessary at first but later less communication is enough at later stages when the agents do reach the goal states. This is expected results but i would like to know if the improvement in the results can be attributed to the attention that enables dynamic communication among agents, or the DDPG or any other component they used to improve the performance. These ablations should be added to the paper.    Questions: -- The folloowing paper also uses hiearchial attention over multiple agents missing from the reference list: 'Deep Communicating Agents for Abstractive Summarization' Celikyilmaz et.al., NAACL 2018   Fix: -- Line 10 : 'how to integrates' -- Line 30-31 : Please indicate shortly what are these other communication models such as DIAL, etc. rather than listing their names, which does not make much sense.  