Summary: This work study a generalized linear bandit model that decouples the estimation of the CTR into a contextual and an examination part. The authors derives a Thompson Sampling based on a variational lower bound of the posterior.   TL;DR: Good paper but related work to be polished   General comment: I think this work presents a very relevant model for click-through rate estimation. The algorithm builds smartly on TS and they are able to provide an analysis for it as well as a solid experimental section. Overall, it is a good paper but I am concerned by the related work section. Little work has been done to link this work with existing models. In particular, the present click model is rather close to the Position-Based Model (PBM) than to the Cascading Model studied by Kveton et al. [16]. The PBM has been widely studied and would deserve some comments. Please, add such references in a future version of the paper.   This is a late review so I won't ask questions that the authors cannot answer. My only concern regarding the model is that in this setting, the features have to be somewhat arbitrarily split by the practitioner according to wether they encode rather context or examination. This has possibly an important impact on the final result. I wonder a bit how this is done in the MOOC experiment, it is not clear from the text. 