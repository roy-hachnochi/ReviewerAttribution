The paper proposes a new way for style-based transfer of text: using a language model as structured discriminator. Previous work using adversarial training to learn disentangled representations often results in non-fluent output and unstable training, two issues this paper addresses.  The idea to use a language model and hence a non-binary discriminator is very nice, and is novel as far as I can tell. It it a good addition to recently proposed methods that do not require parallel text. The idea has the potential to be more generally applicable.  The paper is well written and clear, particularly in the introduction. The experimental section though should be checked, as it contains several grammar mistakes (see below).   I have two questions:  1. Decipherment results. Why are the results in Table 1--referred to as (Shen et al., 2017)--lower than those reported in the original paper? In particular, in the 60% and 80% setup, the reported results largely differ from what they report, resulting in the proposed model to fall *below* their results. Can you elaborate?  2. It is nice to see work on closely-related languages. However, why taking automatically translated data? There exists data for Croatian and Serbian, for instance (see references in http://www.aclweb.org/anthology/W16-4806). Using existing data would make the results more convincing.  It would be nice if the paper could give some more details on how the classifier is integrated (line 243), as the LM alone is not sufficient to beat a simpler prior method (Li et al., 2018).  minor nits (cf. lines): 74: two text dataset 182: in NLP literature 185: performs in task 186: token in vocabulary 200: improve the results 209: the whole sentences 215: to one-to-one mapping 242: the best of both model 273: missing space 277: are use 315: normalize for 321: a based model  === Update after author response === Thanks for the insightful answers, particularly on my question #1. 