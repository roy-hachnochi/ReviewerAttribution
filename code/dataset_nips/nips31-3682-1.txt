The paper considers stochastic Chebyshev gradient descent for spectral optimization. Specifically, the paper develops unbiased stochastic gradients by combining randomized trace estimator with stochastic truncation of the Chebyshev expansion. This unbiased stochastic gradient is used in SGD and SVRG, and the experimental results on two applications demonstrate the effectiveness.  This Chebyshev expansion is based on a bound interval, and has two parameters a and b. Is this a limitation? For applications without accurate estimation on a and b, how can one construct the estimator?  There are quite some other types of methods in the literatures for solving the matrix completion problem. The results will be more convincing, if there are some comparison with them.  The proposed SGD and SVRG frameworks mainly focus on the unconstrained problems. Can they also be applied on formulations with complex constraints?  