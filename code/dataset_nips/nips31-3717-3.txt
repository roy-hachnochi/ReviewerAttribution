This paper proposes a Multi Agent Inverse Reinforcement Learning  paradigm  by finding connections of multi-agent reinforcement learning algorithms and implicit generative models when working with the occupancy measure. The problem is very important and the solution provided looks interesting. Experiments on cooperative and completive environments establish the effectiveness of the proposed framework.  The paper is very well written and easy to follow and read. It could improve by a proof check especially towards the end of the paper.  Intuitively, it looks that the generalization over reference [16] is achieved by considering other agents as part of the environment in the training. Is that the case? It’s good to be elaborated and the connections become more clear.  The reader may wonder how the method performs without the V_\phi and how the non-stationery of the environment will affect the variance. How much of the success is due to V_\phi and how much is the real contribution of the proposed method.  A minor comment is that T is used both for transition function and time horizon. Also, notation-wise D is overloaded. It’s better to change one of them.  It’s gonna help the reader grasp the connection to generative adversarial models if the max or min operators in important equations (like 9) are interpreted and their role in the optimization become more clear.   The experimental results look convincing. Though it could be more comprehensive to have an empirical ablation study to see how much each part is contributing to the performance.   ----------------------- Update: I've read other reviews and the author response. The author response is satisfactory. I'm still in favor of accepting this paper.