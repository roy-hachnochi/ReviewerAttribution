The paper considers a new generalized formulation of multi-armed bandits (MAB) where additional information each arm may appear arbitrarily even when that arm is not pulled.  The authors call this additional information as information flows.  The paper is very well written.   The authors derive a lower bound on regret and consider cases where the information flow is stationary (iid Bernoulli) and diminishing information flows.  The authors propose a near-optimal policy that adapts to unknown information flow.   The policy attempts to balance exploration and exploitation so that loss due to exploration would equal expected loss due to misidentification of the best arm,  The paper is technically sound; the proofs seem correct and sketched well in the paper. My only regret is that there is no discussion on any practical implications of this model - for what sort of sequential decision making problems is this class models suitable? 