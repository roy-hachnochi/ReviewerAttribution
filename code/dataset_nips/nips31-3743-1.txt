[I have read through the authors' response and modified my review accordingly. Remarks following the authors' response are included below in square brackets.]  The authors run experiments on humans and on standard DNNs to assess their robustness to different types of noise/distortion. They find that pretrained models do not perform well on distorted images except for color-related distortion, as compared to human subjects. When models are trained on distorted images, they also perform poorly when tested on any distortion other than that they were trained on.  The paper is clear and well-written, and the rigorous human experiments are potentially valuable to a machine learning problem. However, I find the overall conclusions unsurprising. It is to be expected that DNNs will perform quite poorly on data for which they were not trained. While a close comparison of the weakness of humans and DNNs would be very interesting, I feel the present paper does not include much analysis beyond the observation that new types of distortion break performance.  I am actually surprised that the DNNs did so well on grayscale images, where performance resembles that for undistorted images without any retraining. Further analysis of this regime could be instructive.  [The authors address this point in their response, noting that the exact points of divergence between human and deep learning are worthy of examination, which is absolutely true.  I would be very interested in this paper providing more interpretation of the excellent data that they have gathered.  What conclusions can be drawn?  What explanations are possible for the generalization of deep networks to some types of noise but not to others?  The authors are including detailed, category-level comparison in the supplementary material, hopefully, this will also include interpretation of the observations.]  The kinds of noise introduced should be more clearly described - for example, phase scrambling seems never to be defined. Even more importantly, the parameters by which these types of noise vary (the x-axes in Figure 3) should be much clearer.  [The authors have addressed this point in their revision.]  Minor issues: - ln 62: “once” should be “one”. - ln 104: “fair” should be “far”. - Figure 4 could be presented more clearly. In particular, the x axis should be labeled clearly to show the correspondence between the training distortion(s) and the testing distortion. - ln 674 (Supplementary Material): “compaired” should be “compared”.