The paper compares human and deep neural network generalizations using images that were distorted in a  number of different ways. These comparisons hint to "behavioral differences" between humans and deep neural nets.   The study is well executed and clearly written. The number of experiments conducted is impressive (both for the deep nets and the psychophysics experiments that were used as baseline). Overall, I think that the study can help to uncover systematic differences in visual generalization between humans and machines. Such empirical evidence will be needed to inspire algorithms that can counteract distortions.   The paper would have been much stronger if the first elements of algorithms that can counteract distortions were outlined. Although the empirical part is impressive and interesting, there was no theoretical contribution.  I seems to me that two relevant topics might be worth mentioning in the paper: 1) Captcha seem to exist exactly because the humans can better deal with distortions than machines. The paper could benefit from a note about that 2) I am curious what's the relation between this work and training with adversarial examples.   