This paper considers centralized collaborative PAC learning where k players collaborate to learn one classifier for all k tasks. In the realizable case, it improves the sample complexity from (ln k)^2 to ln k. It also gives an algorithm that works for non-realizable settings.  The paper is clearly written, well organized, and technically sound. The results are obtained by some careful analysis and refined analysis of boosting-style algorithms. The technique used in this paper is not completely new, but I think it makes some nice contribution to the theoretical understanding of the problem.  One weakness is that in the non-realizable case, the algorithm requires knowledge of OPT (the best achievable error rate) and can only obtain a multiplicative error bound.  After rebuttal: Thanks for providing details on how to remove the requirement of OPT. I do think adding a remark or even putting your explanation in Appendix would make the paper look stronger.