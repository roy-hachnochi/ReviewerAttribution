This paper proposes a posterior sampling algorithm for reinforcement learning in non-episodic MDPs. This work can handle continuous state and action spaces but assumes that the MDP is known up to a parameter that smoothly controls the transition probabilities. O(sqrt(T)lnT) Bayesian regret bounds are proved under relatively mild assumptions and the paper shows that these assumptions are satisfied in a class of sequential recommendation problems.  I like several things about this paper: - The paper is well written and easy to follow, including the proofs in the appendix. - It gives a good summary of relevant existing work and relates them well to this submission. - The simulations nicely demonstrate the practical performance of this method in various settings, though including lazyPSRL as a baseline would have been nice. - The proofs are simple but fairly novel and contain some nice insights that I have not seen elsewhere.  However, I also see the following issues: - I am concerned about the significance of this work. The main purpose of this paper is to go beyond finite MDPs and similar classes but at the price of a scalar parameterization assumption. Even more severe, the algorithm has to know the dependency of the transition kernel on the scalar parameter. This is quite a restrictive assumption and highly limits the scope of this work. While it can be okay to make strong assumptions, I believe they need to be discussed and motivated properly which isn't done here (see points below). - While the paper shows that the algorithm's assumptions are satisfied in sequential recommendation problems, it does not empirically test the method in such problems. That is a missed chance to demonstrate the practical relevance of the algorithm. - From what I see in the proofs in the appendix, the scalar assumption is made  to avoid a mismatch of norms of the concentrating posterior assumption and the application of Hoelder's inequality. I think the paper should discuss why the scalar is made and also discuss how one might generalize this result to the non-scalar case with potentially different assumptions.