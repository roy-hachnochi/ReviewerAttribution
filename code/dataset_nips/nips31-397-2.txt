The paper aims to offer a consolidating view of the different GAN architectures and aims to establish comparative baseline to establish comparison of their performance using large sclae study using statistical measures. It also tries to establish the need to report distribution of FID results (as opposed to best) with fixed computation budget, owing to randomization and model instability. It goes onto discussion on the metrics and covers IS and FID and their pros/cons, and how FID is robust to mode dropping, and use of different enconding network and best FID achievable on classic datasets. It also contributes manifold of complex polygons as e.g's of one of the tasks (for  which the manifold can be easily computed) that can be used for computing approximate precision and recall, F1 for comparing different GAN arechiectures that helps in surfacing overfitting (one of the weaknesses of both IS and FID). The authors also maintain they released their experimental setup as open source. Various DCGAN style architecture GANs are evaluated using above measures and setup (same archiecture, and corresponding loss function) on low-to-medium complexity datasets  (MNIST,Fashion MNIST, CIFAR, CELEBA) to arrive at the conclusion that there is no statistical difference (based on FID, given enough computation budget) in the different GANs from the original (minimax and non-saturating style) GAN's proposed by Goodfellow et. al. The large variation in results owing to sensitivity of GAN's to hyper parameters and dataset is also highlighted.   Main critiques - in terms of describing the GAN's the authors mention the make-up includes architecture, loss function and recipe/parameters, thus, when utilizing the loss function while keeping the archiecture same (for comparitive purposes), it seems rather than claiming that there were no statistically significant different across different GAN's for this 'neutral' setup, a more appropriate one would be for same choice of archiecture, the loss functions from different GAN's offer no statistically significant difference based on the setup and datasets evaluated - the choice of the parameters such as the learning rate is rather on higher side (any reason for that) -in some cases, such as Table 2, it appears that WGAN or WGAN GP has lowest FID across all datasets, I don't see mention of that in the results discussion on page 7 