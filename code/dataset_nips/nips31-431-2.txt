The authors address the topic of path following, namely how to train a deep network model that is able to remember a path in a novel environment and later retrace it. The classical approach to this would be simultaneous localization and mapping, however, the authors argue this is a needlessly complex task. In the proposed method, the agent does not explicitly measure its location or try to localize, it uses only image inputs to remember the path. The deep network consists of two sub-networks. The first, consisting of a convolutional network to encode the images and two fully-connected layers, serves to create an abstract representation of the shown path. The second, a recurrent neural network that uses the encoded path and reconstructs it emitting a series of actions. The complete network is trained end-to-end through reinforcement learning where any action leading to reduction of the distance to goal is rewarded.  The paper addresses an interesting question with a new approach. The presentation is relatively clear. I would suggest acceptance.  Remarks: - I would expect the implementation details section to come earlier in the paper, i was lacking the definition of phi, psi, pi, omega. - please check the usage of \pi vs \Pi - The pointer increments are passed through a sigmoid, does this mean that the attention cannot change by more than a single time point? This seems rather restrictive, is it needed? - L78-90 the writing style of this paragraph makes it hard to understand - please check the sentence "Note that..." (starting on L107), it does not make sense to me  UPDATE: Thanks for the clear authors response. I support accepting this paper.