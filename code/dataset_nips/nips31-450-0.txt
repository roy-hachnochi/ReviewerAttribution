This paper addresses the problem of representing unordered point sets for recognition applications. The key insights is a “chi-convolution” operator that learns to “permute" local points and point-features into a canonical order within a neural network. The approach is demonstrated on 3D point cloud recognition and segmentation and 2D sketch and image classification applications.  Positives: The paper addresses a known hard problem - how to properly represent unordered point sets for recognition. As far as I’m aware, the paper describes a novel and interesting approach for learning to “permute" local point neighborhoods in unordered point sets. The paper demonstrates strong results for a variety of tasks over different datasets and appears to perform as well or better than very recent approaches. As far as I can see, the paper cites well prior work in this area. The approach is reasonably well described.  Negatives: I have a few concerns:  A. The title and introduction are not clear. The title is not descriptive and is too similar to “PointNet”. To me, the main focus is on learning to permute the ordering of local point sets, so perhaps the title could be updated to reflect this. The introduction does not convey well the main contribution of the work. Also, Fig 1 showing the toy example was very confusing to me on first reading. For instance, what do the lines next to the points mean? Also, Equations (1a) and (1b) were not helpful to me. I think clearly illustrating and describing in words the permutation issue would be sufficient. Moreover, explicitly stating the contribution would be great.   B. The proposed hierarchical convolution technique (Section 3.1) is incremental to prior work (e.g., PointNet++). My suggestion is to move this later to “implementation details” and focus on the chi-convolution in Section 3.  C. The paper gives an intuition that the chi-convolution operator is learning permutation, but this is not explicitly demonstrated. There is some qualitative notion in the tsne plots in Fig 5, but it would be great to see this quantitatively somehow. One possibility is to show how sensitive the results are to local permutation changes in the test set (e.g., with error bars).  Overall, I think the results are very promising and the technique would be of interest to the NIPS community. It looks like source code will be released, so results should be reproducible. I’m inclined to recommend "accept as poster".  Minor comments:  + L121-123: This wasn’t clear to me how it’s implemented. Since source code will be released, this is not a major concern. One possibility is to add more details in the supplemental.  + Algorithm 1 L1: The local points are centered relative to p. Is there any sensitivity to scaling?  + L133: f_i is not redefined as p_i is.  + Fig 5: I was confused at first as to what the three plots corresponded to. Perhaps include F_o, F_*, F_x below each plot.