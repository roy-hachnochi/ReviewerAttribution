This paper proposed a generalized CNN to point-cloud which preserves the geometry shape information, compared to the existing methods. It introduces an X-transformation that aggregating the features, which can leverage both the feature the coordinate information.  Strength: This paper presents a clear motivation and solution, with comprehensive experimental validations and ablation studies.  Weakness: I have several technical concerns.  First, the presentation of the insight of (2) is not clear enough to me. It is described as "weighted" and "permuted", very briefly in 3.2. However, the formulation reminds me of several recent attention works [1][2], or more traditionally, the thin plate spline (TPS) with the 1st order case. The transformation X is more like a K*K affinity matrix where each entry represents some certain measurement (e.g., geometry closeness, or please check the radial basis function in TPS, where your paper provides a learnable such function by 4 in Algo.1) between a pair of points. Since X is a coordinate affinity and F_{*} contains the coordinate information, the step-5 in Algo. 1 actually represents a sense of linear spatial transformation. It is a nice formulation that corresponds to the concept of "transfer points to canonical space", however, the author did not go deep into it. I hope the author can provide more analysis of (2), or correct me if the above is wrong.  Second, I am not sure if the authors made some contradictory statements between line 156 (dependent on the order), and line 46 (invariant to the ordering)? There is another isolated statement (line 134) that S is an unordered set, why? My understanding towards this is that operations are dependent in any case to the ordering even if the points are in a canonical space, or in an image.  Third, the improvements over other sota methods are not obvious, and the results w.r.t PointNet++ in Cifar10 still does not make much sense to me.  Given the above strength and weakness, I would rate this work as 6: Marginally above the acceptance threshold.  [1] Vaswani et al., Attention is all you need. NIPS 2017. [2] Wang et al., Non-local Neural Networks. CVPR 2018.   Update: I would not change the score after reading the rebuttal. However, I still insist that this paper should be improved in terms of theoretical analysis, as a NIPS paper, instead of explaining that some future work will be delivered.