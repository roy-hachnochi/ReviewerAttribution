Summary  This paper revisits variational filtering by incorporating iterative inference models, i.e. amortization models of the form \lambda_{t+1} = f(\lambda_{t}, \nabla F) where \lambda_{t+1} are the new variational parameters, \lambda_{t} are the old ones, and \nabla F is the gradient of the objective.  As the filtering setting simplifies the multi-step objective into a one-step variational free energy (Equation 11), the paper proposes updating the generative parameters by (1) running one or more steps of an iterative inference model to minimize the local variational posterior at each time step, (2) compute the gradient of the one-step free energy, and (3) aggregate these gradients across time steps.  Experiments are reported comparing the proposed variational filtering approach to three previously proposed inference methods each having multi-step dependencies.  Speech, video, and music datasets are used for the experiments.  Pros  I found this paper interesting, informative, novel, and useful.  Using iterative inference models to simplify the classific filtering problem is a useful methodological contribution that is shown to result in experimental improvements on three very different datasets.  I also found the paper to be clear in its exposition; I especially like the diagrams in Figures 1 and 2.  Lastly, the paper’s references are extensive and clearly explains the works context (Section 2.4).  Cons  One important question the paper does not address to my satisfaction is: why do we expect this local optimization procedure to perform better than inference approaches that account for multiple steps (such as the others presented in Figure 2)?  And if in theory we don’t expect it to, why does it out-perform the other methods in practice?  Is it that other approaches ‘waste parameters’ in that they must learn each local posterior from scratch (i.e. similar to the top-down inference approaches)?  Or is it that the proposed approach’s initialization from the prior simplifies optimization?  What happens if the iterative inference is given a ‘dumb’ initialization?        Evaluation  This paper presents a simple yet effective inference strategy that is validated over several data sets.  Therefore I recommend acceptance.  Although, I think the paper could be improved by analysis / simulation studies of the inference mechanics and not just the model’s final predictive performance. 