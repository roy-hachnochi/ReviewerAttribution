This paper presents a collection of techniques which make parallel distributed SGD scale linearly - and exceed any preceding approaches.  While the paper highlights the pipelined approach (overlapping computation of one worker with communication of another), the authors also present a decentralized algorithm that takes advantage of the pipeline approach. The work is well motivated by wall-clock timing, which the authors point out is important as some factors, like the cost of computation for compression, are often left out in parallel and decentralized optimization studies. The only thing really lacking in this work is a more detailed analysis of where the allreduce algorithm is spending it;s time.  It's clear that the hierarchical sum is more efficient than a linear sum, but does this need to be done on separate machines (which invokes the need to compress and decompress at each level) - or could this be offset via other overlapping pipelined computation.