Thank you for the thoughtful response --- I have read the response and the other author reviews.  I believe the authors have addressed some of my concerns, although I still believe the empirical section could be more compelling.  For instance, optimization tuning accounted for more of an improvement than the HVAE over the baseline.  I realize this is a generally applicable concern, and I do like the idea and its presentation in this paper.  I am maintaining my score of a 6.    --------------  The authors present a new way to approximate the posterior distribution over latent variables in a deep generative model. The main idea is to construct an unbiased estimator of the marginal likelihood using a type of normalizing flow constructed from discretized Hamiltonian dynamics.  This estimator can be translated into a variational lower bound.  The authors show that this deterministic Leapfrog step coupled with a tempering operation results in a posterior approximation that uses the structure of the posterior and encourages exploration.  They empirically compare their variational inference framework to normalizing flows and mean field on a simple Gaussian example (varying by dimension), and then compare a standard VAE to their Hamiltonian VAE on MNIST digits.    - For the CNN VAE vs HVAE, the test NLL was statistically significantly lower, but by a small amount.  What is driving this difference?  Is it possible to point to the expressivity of the posterior approximation as the culprit?  Could it be related to the optimization procedure for the CNN VAE (e.g. perhaps it would take more iterations)? - How does normalizing flows compare to the HVAE on MNIST?    *Quality*: The paper is technically correct, and realizes a very nice idea --- that posterior approximations in these variational frameworks should be informed by the structure of the unnormalized posterior.  The empirical section could be more compelling with additional examples.  For instance, how does tempering affect inference on the real data example (and how does it interact with the number of leap frog steps)?  How does normalizing flows or inverse autoregressive flows (or real NVP) or any of the other flow-based posterior approximations compare to this framework?  How does the variance of this unbiased marginal likelihood estimator compare to other marginal likelihood estimators?    *Clarity*:  The paper is clearly written and easy to follow.  *Originality*:  The method is a nice variation on the normalizing flows idea.  The authors refer to related papers when describing their work, but a dedicated related work section that puts their research in a broader context would make their original contribution more obvious.   *Impact*: I think this is an interesting idea that has a lot of potential, but I am not sure the empirical examples showcased the potential for broad impact of this work.  What about the normalizing flows approximations came up short --- can their poor test performance be improved by increasing the size/number of layers in the normalizing flow?  That presents a computational/complexity tradeoff that could be compared to the computational/complexity tradeoff of the proposed method.  What do the HMC-based posterior approximations look like for the fake and real data examples?   