This paper derive a Bayesian approximate message passing (AMP) algorithms for recovering arbitrarily shaped low-rank tensors with additive noise and employ dynamic mean field theory to precisely characterize their performance. The theory reveals the existence of phase transitions between easy, hard and impossible inference regimes. The main contribution is to solve the low-rank tensor decomposition by AMP algorithm together with some theoretical properties. The clarity of the paper need to be further improved.   Strength:  This paper developed a new algorithm to solve low-rank tensor decomposition which shows much better than standard ALS algorithm. The theoretical analysis of this work is interesting.  Weakness: Since approximate message passing algorithm is well know, and low-rank tensor decomposition is formulated as a very standard probabilistic model with Gaussian noise, thus it is straightforward to apply AMP for low-rank decomposition. The novelty is incremental.   The experiment part is very weak and insufficient. It is only compared with very simple ALS algorithm. There are lots of algorithms developed for low-rank tensor decomposition including probabilistic tensor decomposition and Bayesian tensor decomposition. The comparison is far less than sufficient.   There is only one simple experiment on synthetic data, the data size is also quite small with N=500.  The experiment on real-world dataset or applications is missing, which is not convincing and promising from practical point of view.  