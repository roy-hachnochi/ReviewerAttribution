 The paper proposed a multitask approach to Automatic Machine Learning (AML) using reinforcement learning and Neural Architecture Search (NAS) to reduce the search space for the hyper-parameter optimization and transfers the knowledge from the previous tasks to speed up the network design for the novel tasks.   Zoph et. Al., ICLR 2017 performed transfer learning experiments by reusing the cell on a different task, although they considered character language modeling on the same dataset but the proposed approach used different datasets and achieved the transfer through the controller.  The paper is well-written and easy to understand. The proposed transfer AML/NAS is interesting and have practical importance but lacks some important details such as task embeddings, baselines etc and further analysis with additional baselines will help the paper.   It is unclear how the task representations are learned at each iteration. The paper mentioned that the task embeddings are generated similar to word embedding but it doesn't seems straight-forward from the details given in the paper. Since the network configurations are generated conditioned on the task representations (in addition to the action embedding), it will be helpful if the author(s) give some details on this part.   The proposed approach shows there exist two clusters of tasks (among the 8 tasks in the multitask training) not only based on the task embeddings but also on the hyper-parameters. It will be helpful if you include the hyper-parameters chosen for the transfer tasks to see how the configurations are chosen based on the clusters.  One of the puzzling questions is that why the multitask training (Figure 4 in the Appendix) did not achieve better results than the Single-Task NAS compared to the transfer training. In order of the transfer learning to give better performance, we expect that we get similar behavior in the multitask training. This is important for understanding how the transfer NAS outperforms other baselines considered in this paper.  It is unclear how the baselines are chosen for the experiments. No details are given about the baselines in the Experiments. Does RS optimization apply for each task separately? Does the Single-task NAS learn separate controller for each task? Does Single-task NAS use task embeddings?   The baselines considered in this paper are insufficient to understand the behaviors of the Transfer NAS. In addition to the baselines in the paper, I think the following baselines can give further insights into the above surprising behaviour: 1) Choose separate controller for each task (w/o task embedding) 2) one controller for all the tasks (w/o task embedding) 3) Use same fixed/RS hyper-parameter for all the tasks.  