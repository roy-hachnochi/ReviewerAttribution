This is a really interesting paper that proposes algorithm for self-supervised learning.  The innovation here is to import some ideas from adversarial learning and GANS to the topic of self-supervision.  Specifically and authors propose and test a model where a world model of some physics domain is “challenged” by a self-model that proposes actions that are expected to maximize the loss of the world models.  Both models then learn based on experience and the challenging by the self model help to guide the world model.  The findings from this paper are fascinating, particularly the result that the system initially learns the dynamics of its own motion before getting “bored” and moving on to attending to objects.  I think this type of result is likely to have important impact no only in computer science/AI/ML communities but also for developmental psychologists interested in how babies bootstrap their understanding of the world.  If I had to make a suggestion, I would say that the main text on page 4 (describing the world model) is a little abstract.  I get the authors are trying to present a very general version of the issue of learning a world model, however I found this discussion a little tangential and distracting.  It seems enough to describe the specific world model approach you use in more detail rather than exploring some of the general issues here.  The literature review was extensive and very well done.  None the less you might find this paper interesting given some of what you were saying: https://arxiv.org/abs/1711.06351.  Also for something on learning about the physical world through active exploration: https://psyarxiv.com/u9y4c . Don’t necessarily cite it just know about it!  They are possibly interesting and relevant for the future directions laid out about more complex, planned trajectories and actions.