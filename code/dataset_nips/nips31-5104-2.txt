Summary:  The paper presents a feed-forward trainable system for multiple human pose-related tasks of multiple people in monocular imagery.  In particular, the approach considers the tasks of 2D localization, 3D pose and shape estimation.  The approach consists of the following stages: image feature extraction, (redundant) 2D/3D pose encoding, limb scoring, people grouping, and 3D pose and shape estimation.  The people grouping is realized as a linear binary integer program.  State-of-the-art results are demonstrated on Human3.6M (official test set, contains a single person in each image) and Panoptic (contains multiple people).  Pros:  - novel with respect to the emerging literature on multi-person 3D sensing from monocular images - cyclic consistency ("auto-encoding") of 3D pose is an interesting idea - state-of-the-art results presented on suitable benchmarks; note, that more challenging ("in-the-wild" type benchmarks are sorely needed in the area)  Cons:  - the paper is frustratingly difficult to read in parts   The major issue with the paper is related to the clarity of the presentation.  In several key instances (e.g., Limb Scoring section), the manuscript passages are quite dense and terse rendering them difficult to follow.  Also details are missing:  - Line 31: "However, if some joints are occluded or hard to recover, their method may not succeed in providing accurate estimates."  What exactly does this refer to?  - Section 2.1: the description in the main body of the manuscript of the deep volume encoding via iterative processing is difficult to follow, more details are needed  - How exactly is the solution to the binary integer program realized?  - What is the source of the regressor, $\bf{R}$, in Section 2.3?  - Section 2.3: How many samples are taken along the direction of each 2D limb?  - Figure 5: What is the source of these images?  Figure 2 and the corresponding caption are also difficult to follow.  Maybe a simplified 2D figure would help.  Unless the reader is familiar with extant state-of-the-art work on 2D and 3D pose estimation, parts of the paper are unnecessarily difficult to follow.  It is suggested that Figure 5 be limited to three or four examples and the extra space used to address the clarity issues cited above.  Empirical results:  - What differences are there if any with the training data used for the proposed approach and the baselines?  - What are the failure cases?  Are the errors just due to inaccuracies in the estimates or are there cases of "catastrophic" failures, e.g., failure in predictions due to the 2D-3D ambiguities and people grouping (on Panoptic)?  For completeness, why not also report the scene translation as in Table 1 [21] using the approach detailed in Fig. 5 caption?  The authors have addressed my main concerns in their rebuttal regarding the evaluation and missing details.  As a result, I have increased my rating to 8.   