This work presents an extension of the anchor words topic modeling algorithm to the multilingual setting through two pieces: a greedy strategy to automatically select multilingual topic anchors that optimally expand the subspace of both languages, and an interactive workflow for adding and modifying anchor words for topics. Both models exceed the existing state of the art in interactive topic modeling, with the interactive workflow in particular performing the best.  I really like the balance of this work between a new algorithm, a new workflow, and a variety of evaluations; the work reads clearly and contributes meaningfully to the topic modeling literature. I think one piece I was missing was the clear motivation of the interactive multilingual modeling case; while the example of disaster relief message triage was invoked repeatedly, it was not totally clear what the intended use of a topic model instead of disaster-related keywords was in that application. It seems as if the process is focused on optimizing some known development task, e.g. classifying a labeled subset of the multilingual data and using that classification to extend to unseen text, but it is still not totally clear to me that topic models are the right approach to that. That is a lot more to approach for this paper than is necessary, but it seems worth addressing a bit more head-on given the running example.  I thought some of the writing on the interactive workflow could have used some additional development. Part of this may be because the figures displaying the interactive portions were a bit hard to read, as they are exceedingly small; making sure there is enough space for them in the camera-ready seems important for the model being presented. It also skimps a bit on details on what happens with topic addition and deletion - how are new words selected if a topic is deleted? Are other anchors downweighted if one close to them is rejected? Some additional references to the workflows for topic addition and removal from the referenced papers [9] and [12] in section 3.2 might help with filling in that quickly.  A recurring problem mentioned in the anchor word literature that motivates a lot of the development of new anchor-finding algorithms is that the "best" anchors in terms of their independence from other vectors and placement in a convex hull tend to be very rare, almost obscure words. Tandem anchors seem to help with this problem a bit, using a combination of words to get the individual meaning, but it seems like the interplay between that problem and the multilingual setting (where rare words are less likely to be translated) is interesting and worth discussing. Does the multilingual case actually help ensure these words are more common?  I had one more mathematical concern about the weighted minimum of distances in the two corpora in equation (5): are these metrics balanced? I know they are looking at entries in a probability matrix, but I would expect that corpora with different-sized vocabularies might have a tendency towards one language consistently having the minimum distance over the hull. I was wondering if there was a reason no normalization was necessary, either through choice of distance metric or other observation about the data.  I had some smaller notes about the writing: - line 54, "may be explained by" is a bit ambiguous - may co-occur with/have components represented by? - line 59, "the probability that a token of word type i belongs to topic k" is probably clearer? - using anchors as an example was clever and made me smile, a lot - line 192, "anchors are defined anchors" is this supposed to say "authors define anchors" or "anchors are defined by authors"? - table 1, bolding the MTAnchor (max) result would probably be okay - it seems worth having a few words about how you selected your MTurk workers to ensure your system wasn't cheated - line 264, I'm not sure that "supersedes" is actually the word you want there - it again might be good to revisit papers 9 and 12 in the related work, since they are close on the interactive work  Ultimately, I enjoyed this paper a lot, and believe it would be a worthy contribution to the NIPS program.  AUTHOR RESPONSE: I appreciate the author's notes in addressing some questions. In light of the information about model convergence being a little slower than I had initially thought, I would encourage the authors to spend some time reconsidering the choice of disaster response as their primary motivating example in favor of something less extremely time-sensitive. An example would be identifying news stories or Wikipedia articles in one language about a subject not being represented in another language.