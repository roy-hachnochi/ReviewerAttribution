Very good write up and presentation.  Theorem 2 is a very nice result, and an ingenious application of DP theory, demonstrating a good knowledge of relevant theory.  No further comments here.  Except, your approach requires some overhead for every token whose probability is estimated, a lot more than simply the min() function of current approach. So this should be discussed and demonstrated to show it is reasonable (which I expect it to be).  But the simulations where disappointing.  You simulate data according to known theory and of course the results match expectations.  Why bother?  What you should do here is embed your estimations into a real live run of CM-sketch and compare the results, also giving the additional compute time.  The poor experimental work, which should be easily fixed, makes the paper "rejectable".  References:   "nlp", "dirichlet"