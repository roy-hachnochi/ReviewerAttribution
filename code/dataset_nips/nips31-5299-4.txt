Strengths:  1. Theoretically sound tensor decomposition in terms of reconstructable tensors and optimizing the parameters an interesting approach that also seems to enjoy theoretical properties.  2. The relations to Boltzmann machines is a really interesting connection that links this method to a seemingly distant graphical model.  3. The implementation of the algorithm is also quite simple and seemingly reproducible (i.e., no randomness).  4. Despite the technical details, the paper is well-written and flows well.  Weaknesses/questions:  1. Analyzing the scaling of the algorithm with respect to the tensor sizes (not necessarily comparing against other methods) on even toy examples would have been nice to see.  2. Is 256GB of memory necessary for utilizing this method?  3. Are there cases where Legendre decomposition might be less preferred compared to other methods?  4. Can this be applied to higher order (>2) tensors?  5. Often times for various applications, the rank of the decomposition can be used to control the complexity/low-rankness of the tensor intentionally (i.e., as a hyper-parameter). Can Legendre decomposition incorporate such similar feature?  Final thoughts:  Methods for nonnegative tensor factorization problem itself has been known to be useful but scarcely developed. This paper could be a valuable alternative for already existing methods while providing more sound theoretical properties. Also, by construction, the method makes connections to the Boltzmann machine (although it is more of an observation). The quality of the paper is overall decent, but some questions from more broad aspects (listed in weaknesses/questions above) could be addressed to further clarifications.