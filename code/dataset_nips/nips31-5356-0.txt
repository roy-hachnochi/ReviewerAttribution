The authors consider distributionally robust finite MDPs over a finite horizon.  The transition probabilities conditionally to a state-action pair should remain at L1-bounded distance from a base measure, which is feasible as being generated using a given reference policy.  This is a nice idea. A few comments are mentioned next.  * One aspect I did not understand is how the reference policy should be chosen.  Related to that question, why the requirement of staying "close" to this policy would be beneficial. In safe RL for instance, we could want to remain close to "safe" states, but I can't make the connection with this and the identification of a single "safe" reference policy. In the first experiment, (line 253) the authors use a uniform policy as the reference. In the second experiment, there are only 2 actions and the authors use a state-independent randomized policy (line 301). What is the rationale? Is the choice of a "uniform" reference policy specific to these two problems?  * How should we read the results of Table 1, when p varies ? Is there a value of p that leads to a better policy? In which sense?  * I liked (line 274)  that the authors provided a sensitivity analysis of the stepsize they use to discretize a [0,1]-valued extra state variable.   * What is the exact definition of the softmin in equations (6) and (11)  * There are too few details to understand the benchmark policies such as LR, RECT, MLE to be able to reproduce the experiments (depicted in Figure 1). I would think that those methods have more parameters than those given in the supplementary material.  * (line 225) "converges when the statistics match", but "when statistics match" is unclear, can the authors explain.  * Section 2 introduces the notion of "Directed information theory for processes", but I interpret this as describing the fact that policies should be in the class of progressively measurable processes in discrete-time -- which is a normal math framework for history-dependent policies.  * The significance is somewhat difficult to assess because the test problems seem relatively low-dimensional, which, granted, facilitates benchmarking, but does not allow to demonstrate scalability of the proposed method.