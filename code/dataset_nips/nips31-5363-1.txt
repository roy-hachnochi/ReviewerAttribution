The work proposes a noval nn structure to unsupervisedly learn the underlying graph structures that describe the correlations between features. The extract graph structures is transferable and may help with multiple downstream supervised learning tasks.  I am not familiar with the related works while the authors describe clearly the relation to the previous works. They also give solid reasons on the proposed tricks that are used to build up the new network and justify the effectiveness of them via extensive experiments. Hence, the contribution reads non-trivial.   However, I have some doubt that prohibits me from giving strong recommendation. First, I think the method only works when the embedding methods of unsupervised part and supervised part are same/at least similar to each other, while the work claims that the embedding approach of the supervised part can be arbitrary. Apparently, the learnt graph strongly depends on the embedding layer of the unsupervised part due to the way that it is trained. As for this concern, I would like the authors to clarify the results obtained in Table 1. As there are different embedding methods used in the supervised part, do they share the same graph learnt from the unsupervised section? Second, essentially, the learnt graph performs as the correlation between features. So I think it should be more fair to add some cross layers within the baselines to make comparison, where the cross layers are learnt only within the supervised section. Only in this way, the effectiveness of transferability can be well established.