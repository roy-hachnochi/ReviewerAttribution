This paper introduces reversible recurrent neural network. The main idea behind  reversible networks is their ability to reconstruct the hidden state at time (or layer) t  using the hidden state (or layer) t+1. This allows to recompute all the hidden state  during back-propagation, without having to store anything, thus allowing big memory savings for training RNNs. The main contribution of this paper is to propose variants of LSTM and GRU which have this property. As discussed by the authors (and empirically observed in previous work), being able to "forget" is important for RNNs on tasks such as language modeling. However, the reversibility property also means that the RNNs do not forget (if you can reconstruct all hidden state from the last, you can predict the whole sequence). The solution considered in the paper is to allow the RNNs to forget a limited amount of information (2-5 bits per hidden units), and store this information for back-propagation. The method is evaluated on two language modeling benchmarks as well as machine translation.  This paper is very clear and well written, and I enjoyed reading it. In particular, the discussion regarding the impossibility of zero forgetting, as well as the link between finite precision, forget gate values and forgetting was interesting. The experimental evaluation of the method is thorough, and done on multiple benchmarks (in particular, showing how this can be applied with attention models is a big plus). My main nitpicking regarding the experimental results is that the authors did not include regular LSTM/GRU as baseline in the papers, and the reported results seem quite a bit worse than results for similar models reported in previous work. I am also wondering what is the impact of using dropout with reversible neural networks, and believe that the authors should add a discussion about this.  Overall, while the paper builds on existing work, and the method is similar to Gomez et al. (2017), I believe the contributions to be significant enough for acceptance to NIPS. Indeed, the forgetting issue which is crucial for RNNs (and is the focus of this work), was not discussed as far as I know in previous papers (Gomez et al. applied this method to CNN for computer vision).  To conclude, the paper is clearly written, technically sound and the contributions are different enough from previous work for acceptance to NIPS. I will increase my score based on the answers to my questions (baseline and dropout) after the rebuttal.  UPDATE: After the rebuttal, I have decided to update my score to 7. I suggest to put the performance of the baseline models in the tables, as it make it easier to compare them to the ones of the proposed method.