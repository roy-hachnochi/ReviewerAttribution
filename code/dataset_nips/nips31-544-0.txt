The authors propose to encode a sentence using (mean, variance). First training an autoencoder and then tuning it further using Wasserstein 2 distance functions on labeled sentence pairs. The results show competitive performance from the proposal.  By the repeat/reformulate do the authors just mean decode ?  Quality/Significance Among models that encode query/sentence independently, the proposal performing the best is not a breaking result.  This is because, - The similarity function (2-layer MLP) is reasonably expressive and a high cpu operation, comparable to the cost of encoding the text at runtime. - Because the costs are comparable, I do not see the benefit of this method vs BiMPM, pt-DECATT and DIIN.  This would've been an important result if the similarity function was really cheap, e.g. just a dot-product, as this enables the use of fast NN techniques for question retrieval.  Questions 1. "We did not consider training our model jointly on both tasks,... " Did the authors try this ? If so what were the results like ? Also why did the authors not consider combining both the tasks into a single task ?  2. what was the performance of question retrieval of BiMPM, pt-DECATT and DIIN. It might be slower, but surely, it can be computed ?   EDIT: After author's response, I'm okay with accepting the paper since the authors promised to remove the claim of state-of-art among siamese networks (this was mentioned 4 times and I assumed that was the core contribution).  Siamese networks are really useful when (a) there is improved test performance over non-siamese networks because of parameter sharing or (b) enable fast retrieval techniques when the distance metric between encodings are simple to compute. The proposed work does not show (a) and the distance metric is certainly not (b). Therefore the statement “state-of-art among siamese networks” is not very relevant since the model is not really giving any benefits of being a siamese network. 