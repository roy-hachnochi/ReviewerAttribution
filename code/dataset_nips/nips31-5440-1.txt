This paper deals with model-based reinforcement learning. The objective is to learn a model of the transition dynamics of the MDP at hand. This paper uses the Value aware Model learning [Farahmand et al., 2017a] where the problem is formulated as finding a good model of the MDP with respect to the task to solve therefore ignoring details of the MDP that could be not important to solve the task. For that purpose, this paper proposes to learn the model while solving the task and with respect to the current learned value function while other previous approaches proposed to be robust to a potentially large set of value functions.  The paper is clearly written. The new approach is convincing and seems to be the main contribution of the paper. It seems to give a natural way to guide the model learning with respect to the task at hand without being too conservative. The theoretical analysis seems to be following the classical tools in the literature. An experimental evaluation of the idea would have been of interest.