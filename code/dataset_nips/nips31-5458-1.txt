In this manuscript the authors introduce Bayesian Multi-Domain Learning (BMDL), a Bayesian model for learning latent spaces across related domains with high predictive power. The model’s sparsity structure allows some of the latent dimensions to be domain specific and others to be shared across domains and the authors derive an efficient blocked-gibbs sampler that allows for a negative binomial likelihood for NGS count data by using a data augmentation strategy. The authors apply BMDL to both synthetic data and real-world data, where they demonstrate their method on related domains (different RNA seq versions as an example of closely related domains, and different cancer types as an example of unrelated domains).   Overall, I think the model the authors propose is elegant and the problem they address (integrating multiple ‘omics datasets to improve predictive power) is important in a field with traditionally low predictive accuracy. However, I think the authors need to further convince the reader that their method is necessary over basic supervised machine learning techniques. The baseline model of a linear SVM on raw counts is inadequate: an implementation that appropriately normalizes (e.g. TPM) and scales (N(0,1)) the counts across a variety of techniques such as regularized logistic regression or even neural nets (see e.g. http://beamandrew.github.io/deeplearning/2017/06/04/deep_learning_works.html) could be used to get a true baseline.   It was difficult to fully evaluate this paper as the supplementary material submitted was identical to the main paper (I assume by mistake) - I would ask the authors submit the actual supplement as part of the rebuttal.   Further comments below -  The authors state “Traditional machine learning methods do not directly apply here as their fundamental assumption is that samples (training and testing) are from an identical probability distribution” - this is not addressed in the paper  - the authors “calculate a latent factor score for every sample in both the training and testing sets” - these come from same distribution for both training and test set so I do not see how the assertion in the introduction is addressed? (nor indeed how you could do any inference without making similarity assumptions about the training and test set)  In paragraph starting line 46 it would help if in the context of the problem the authors give examples of the domains they are targeting (RNA-seq technology version and cancer types)  Line 73 the authors say they exploit a “novel” data augmentation strategy for negative binomial distributions - is this the referenced [Zhou and Carin] (in which case it is not novel) or referencing the approximation scheme on line 183 for drawing from CRTs for large N ?  On line 127 it would help if the authors clarified what they mean by “cancer subtyping” - ultimately they use it to predict different cancer types based on gene expression, but it can mean other things in this context (e.g. identifying clusters of patients with high/low survival, etc).   In equation 2 the Gamma distribution has as its shape the product of s with a binary latent variable z - however, this can obviously lead to a Gamma with shape = 0 for which the density is undefined. It seems like the correct form for \theta would be a mixture of a point mass at 0 and a gamma distribution Gamma(s, 1/c) where the mixture component is controlled by z?  Line 223 d_t should be defined as the target domain when it is introduced  Line 277 - “1000 out of the top 5000 genes with higher log2 fc between LUAD and LUSC have been selected for analysis.” How were the 1000 out of the top 5000 selected? Importantly, this invalidates the accuracy claims in table 1 - the entire dataset has been used for feature selection rather than appropriately splitting the data into training and test (& validation) sets. While this has been uniformly applied across all algorithms and it appears BMDL has higher accuracy, if the point is to predict cancer subtypes based on gene expression then this is not proven.   Line 280 - what are the random SVM runs?  Line 286 - “From the table, BMDL clearly outperforms all the methods...more critically, BMDL consistently achieves better cancer subtyping.” What is the difference between these two? Isn’t the performance the subtyping? 