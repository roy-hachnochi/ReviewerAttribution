Summary: The authors consider the problem of phase retrieval with a particular generative prior for the underlying signal. The generative model is a d-layer, fully-connected, feedforward neural network with ReLU activation functions and no bias terms. The authors consider an \ell_2 empirical risk minimization problem, based on this generative model, and show that the corresponding objective function does not have any spurious local minima or saddle points away from neighborhoods of the true solution (module sign changes). Therefore, if a gradient descent algorithm converges then the solution would be close to the true solution. This result is the main contribution of the paper.    Assessment: The paper is well written and well organized, and the work is properly placed in the context of prior art. The contribution is sufficiently original and significant enough to warant acceptance.   . 