Summary:  This paper focuses on the training efficiency of SNIP (and multi-scale training) and proposes to train on pre-cropped chips. Authors propose a greedy strategy to crop positive chips at different scales to cover object bounding boxes and use an RPN trained on positive chips only to mine negative chips which are likely to contain false positives. By training only on those chips, the proposed method can take advantage of multi-scale training without huge computation. It can also benefit from large batch size training and thus can perform efficient batch normalization training.   Strength:  + The proposed method makes the training images to be the same small size (512x512). This makes detector training can benefits from the large batch size and single GPU batch normalization, which reduces the training time of synchronizing batch normalization.  + During training, it proposes an effective sampling strategy, which reduces the training time of multi-scale training.  + Elaborate experiments are carried out on the COCO and OpenImage datasets. Results show that the proposed method obtains better performance than the SNIP when using the batch normalization.   Weakness:  - Long range contexts may be helpful for object detection as shown in [a, b]. For example, the sofa in Figure 1 may help detect the monitor. But in the SNIPER, images are cropped into chips, which makes the detector cannot benefit from long range contexts. Is there any idea to address this?  - The writing should be improved. Some points in the paper is unclear to me. 1. In line 121, authors said partially overlapped ground-truth instances are cropped. But is there any threshold for the partial overlap? In the lower left figure of the Figure 1 right side, there is a sofa whose bounding-box is partially overlapped with the chip, but not shown in a red rectangle. 2. In line 165, authors claimed that a large object which may generate a valid small proposal after being cropped. This is a follow-up question of the previous one. In the upper left figure of the Figure 1 right side, I would imagine the corner of the sofa would make some very small proposals to be valid and labelled as sofa. Does that distract the training process since there may be too little information to classify the little proposal to sofa? 3. Are the negative chips fixed after being generated from the lightweight RPN? Or they will be updated while the RPN is trained in the later stage? Would this (alternating between generating negative chips and train the network) help the performance? 4. What are the r^i_{min}'s, r^i_{max}'s and n in line 112? 5. In the last line of table3, the AP50 is claimed to be 48.5. Is it a typo?   [a] Wang et al. Non-local neural networks. In CVPR 2018. [b] Hu et al. Relation Networks for Object Detection. In CVPR 2018.   -----  Authors' response addressed most of my questions. After reading the response, I'd like to remain my overall score. I think the proposed method is useful in object detection by enabling BN and improving the speed, and I vote for acceptance. The writing issues should be fixed in the later versions.