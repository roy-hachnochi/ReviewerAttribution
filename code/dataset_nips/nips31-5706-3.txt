Given a domain adaptation algorithm that aligns the source and target feature spaces, the paper suggests leveraging the adaptation by learning several distinct alignments while enjoining them to agree on unlabeled target samples. It implements this idea by adding new losses to already successful domain adaptation neural network models.  The idea is appealing and the empirical results are convincing. I appreciate that the experiments reuse the recent network architecture and training procedure of Shu et al. (ICML 2018). It allows to truly isolate the benefit of the new method. It should be easy to reuse it in many contexts by adding to existing neural networks the new components. For these reasons, I tend to suggest paper acceptance.  However, I think the contribution could be greater, and does not provide enough insights (either theoretical or empirical) to understand in which context the method is working. Section 2.1 discusses the domain adaptation bound of Ben-David et al. (2006) (as many previous domain adaptation papers, but the proposed co-alignment algorithm is not really supported by the cited theorem (at least it is not discussed in the paper).  The novelties of the paper are presented very succinctly in less than a half page: The target prediction alignment of Equation 4 and the diversity component of Equation 5. In both cases, the authors mention that many strategies could be used to implement these concepts. Their choices should be discussed more. In particular, few is said about the diversity component of Equation 5 (the equation itself is ambiguous, as x_j is drawn according to P_s and j iterates from 1 to b. Also, b is undefined). What is the influence of the minibatch size? How can we extend this equation to more than two alignments?  On the theoretical side, the role of the disagreement on the unlabeled target sample could be related to the analysis of the following paper: "A New PAC-Bayesian Perspective on Domain Adaptation" (Germain et al., 2016).  That being said, the best way to give insights about the proposed method would probably be to provide a well-designed toy example where we can see the benefit of co-alignment in action.  Minor comments: * The fact that the objective function is presented twice is confusing. It is first said that CoDA is summarized by Equation 2, and we have to continue to read to learn that it is in fact given by Equation 7 (including new losses) * Please choose between "CoDA" or "Co-DA" * References [14] and [15] seems to refer to the same paper   