The authors provide a clear and succinct introduction to the problems and approaches of biologically plausible forms of backprop in the brain. They argue for behavioural realism apart from physiological realism and undertake a detailed comparison of backprop versus difference target prop and its variants (some of which they newly propose) and also direct feedback alignment. In the end though, they find that all proposed forms of bio-plausible alternatives to backprop fall quite short on complex image recognition tasks.  Despite the negative results, I find such a comparison very timely to consolidate results and push the community to search for better and more diverse alternatives. Overall I find the work impressive. Just a few comments.  1. The authors claim that weight sharing is not plausible in the brain. If one approaches from the point of view of propagating errors back, yes weight sharing is difficult to imagine. But from the point of view of unsupervised learning, if each local patch receives similar local statistics of images, it is conceivable that all the different local patches of neurons will end up responding to similar features, effectively having similar weights. Thus one might wish to train initial layers with some form of weight sharing and only train the output layers with forms of backprop, TP etc.  Further in the discussion the authors claim: " weâ€™ve aimed at the simplest models that allow us to address questions around (1) weight sharing, ". However, it seems to me that the authors actually did not implement weight sharing at all in the networks. This should be clarified.  2. The authors only consider image recognition tasks and it is conceivable that here the network structure matters far more than the learning rule. For example the brain may use some form of recurrence for pattern completion and might also build internal 3D models of objects from the images. For later, possibly other tasks should be also tested, but here at least this lacuna should be emphasized in the discussion.  Minor: l 68: "is unlikely unveil"  Overall, if the authors addressed these points, I think that the paper is suited for publication at NIPS.  ---------------------------------------------  After reading the other reviews and the author rebuttal, and after discussions with other reviewers on the forum, I still feel that the work is impressive, but perhaps not in the top 50% of accepted NIPS papers. Also, the results may not be conclusive since the training was only for a fixed number of epochs and test error was still decreasing in Fig 1 (right) for some variants.  ---------------------------------------------