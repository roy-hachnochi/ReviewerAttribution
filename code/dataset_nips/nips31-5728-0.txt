This paper is about methods for comparing embedding spaces.  The paper suggests a extension of a local technique that looks at just the differences in distances from a few words (rows) to a global generalization that considers the differences between all words.  The paper then theoretically shows that this metric is equivalent (and within a small constant) of an alignment method, which is widely used but more expensive to compute.  The proposed method is then used to compare embeddings across years of the Google book corpus.  The distance between each pair of years falls within the small constant that was proven (an empirical sanity check) and the distances over time correspond well to real word events.  The writing is very clear, and the paper is well-organized.  The proofs are clean and compact (although I admit I did not check all the math).  A figure or diagram might improve the exposition of the methods section.  The paper includes both theoretical and empirical results.  Besides being algorithmically simpler than the alignment approach, the global anchors approach allows comparisons of embeddings of different dimensionality.  The proposed application is identifying linguistic shifts over time, which is somewhat narrowly defined.  However others have used related methods for aligning word embeddings cross-lingually, so this may have broader implications.  I have read the author response and my review above still stands.