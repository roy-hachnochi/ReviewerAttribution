Updated post-rebuttal.  I want to thank the authors for addressing many of the concerns. I believe most of them were discussed. Though the method isn’t necessarily novel, the exploration and toy experiments are thorough and compelling and the paper is clear and well written. I agree with the author's statement about the work “leading to a simple explanation that unifies previously disconnected observations”.  I think it might be relevant to look at/cite the following papers that also use positional encoding: A simple neural network module for relational reasoning Image Transformer Attention Is All You Need  I also think the phrase "CoordConv layer improves Resnet-40 Top-5 accuracy on average by 0.04%..." is still a little weak to include in the paper. I think a clearer explanation would be that it doesn't though it doesn't improve accuracy by a statistically relevant margin but this is not surprising given it is a problem that is helped by translation invariance. Perhaps this even shows that CoordConv doesn't decrease accuracy on translation invariant problems, which is a useful result.   I do think the VQA and Clevr extensions would be useful as well as discussions about max pooling and data augmentation with CoordConv but I think that is fair to classify those as future work.  ---------------------------------------------------------------------------------------------------------  The paper discusses a failing of convolutional networks when doing coordinate transforms. They explore variations of a toy problem generated from the Clevr dataset in order to experiment with this issue. They further test this method with a comparison on the effects on a GAN, RL for game play, and Resnet-50 on imagenet.   The authors propose an interesting solution and although it is well explained in the paper, there are many similar methods in VQA papers that have a similar approach as just a small part of their method. The toy evaluation here is very useful and I think a good look into what is happening but there is not much evaluation past that and it is very limited. The effect of data augmentation is fully removed here, which is an important part of how current state of the art methods deal with invariance. It would be interesting to see how much of this effect is mitigated by that.  The authors cite [22] “A simple neural network module for relational reasoning”, which discusses a methodology for relational reasoning that is very much related to the proposed method where relative spatial methods are given to the RN as as input with the convolutional feature maps. The authors do not discuss this related work nor compare to it directly. Other methods that do something related to this include “Inferring and Executing Programs for Visual Reasoning” and “Modeling Relationships in Referential Expressions with Compositional Modular Networks”.  With the bold claims (“CoordConv allows networks to learn either perfect translation invariance or varying degrees of translation dependence, as required by the end task […] and with perfect generalization.”) the authors have for relational reasoning given in the abstract, why not compare directly with these methods by just adding the CoordConv layer to these existing methods and checking for improvement?  Overall, I feel that the work is interesting, very clear, and the toy problem and it’s evaluation are well explained. However, little to no discussion is given to related work and their is little to no evaluation on real datasets. The resnet results are not statistically significant nor are they convincingly better. The Atari experiments are barely discussed with little insight into how the evaluation is done and no comparison with existing work and state-of-the-art. There is also no state-of-the-art comparison with Clevr where locational relevance is an important feature.  The authors state: “similar coordinate transforms are often embedded within such models and might also benefit from CoordConv layers”. This is the type of evaluation I think the paper needs to be successful. Test the inclusion of the layer on existing methods on Clevr or other benchmarks to show that the method is successful on more than a toy problem. I think that if they can show this method’s impact on convolutional networks in a much more convincing manner. With the proper evaluation, I think this could be a very strong paper that would fit well at NIPS, however, it is currently missing that.   Note on references: [5] and [6] are the same work. 