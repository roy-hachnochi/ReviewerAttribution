The paper presents a new representation of strategies, a number of theoretical results on the properties in team games, and an algorithm to compute a team max-min correlated equilibrium (TMECor). Results are given on 3-player parameterized  versions of common Poker benchmark games (where the team game is interpreted to be two players colluding against the third.)  This is a nice paper with some novel and significant contributions, but I am confused about a number of things. My assessment depends on clarifications needed by the authors, so I encourage them to answer the questions below in the rebuttal. However, apart from these points, the paper is well-written and conveys some complex ideas well. The necessary background knowledge in extensive-form games is rather steep, but the paper does a good mix of explaining the ideas on a high-level complemented by technical depth. The problem is important and there is little research on how to find a TMECor, so a new algorithm in this setting is welcome. This algorithm, in particular, has the anytime property which is particularly appealing.  Questions:  1. In Definition 1, rho^x(z) where x is a normal-form strategy was never defined anywhere, or I missed it. Is it the sum of the rho^sigma(z) over all sigma(I) that x is mixing over times the probability x(sigma)?  2. Section 3, why are the same constraints of summing to 1 not included for wl?  3a. It is not especially clear what role the realization strategies play in this paper. It seems they are mostly used to prove the realization equivalences in the theory, but it seems strategies are never actually stored in this representation. Is that correct?  3b. It seems like there is a many-to-one mapping from normal-form strategies to realization-form strategies, in the sense that there can be many normal form strategies that induce the same realization form strategy. Is this true? So given a realization form strategy, one cannot find a unique normal form strategy in general? Isn't this a problem if the algorithms are to use this representation?  3c. The text claims that the realization form allows using the behavior strategies directly. But in section 5 the algorithm is defined over the sequence form (not behavior stratgies). Am I missing something?  I found Section 5 difficult to understand. In particular, I am having trouble understanding how the theory developed in Sections 3-4 is leveraged by the algorithm.  4. What is the gradient \bar{g}_A? This is not a common component of ficitious play, and it is not defined anywhere.  5. Line 14: what does it mean to 'compute gradient by fixing r_1^t, r_2^t'? r_1^t, r_2^t are passed in as arguments; why would they not be "fixed", and what does this line do? (What is \hat{g}_A)?  6. The algorithm works on sequence-form strategies. Does this not directly conflict with the motivation that the team game can be thought of as an imperfect recall game? Is it that \Gamma^* is a perfect recall equivalent of the imperfect recall \Gamma?  7. It is unclear what parts of the algorithm operate within \Gamma^* and what parts in \Gamma. Can you clarify this?  Other comments:  - Page 1: "This is not the case for games with multiple players". Two players counts as "multiple players", so this should be rephrased to "with more than two players".  - Page 4: Last sentence of Def 1, rho_i^{x_1} should be rho_i^{x_i}  - Page 6: Lemma 2 uses a non-standard co(set) to mean that the left hand side is a convex combination of the set. Define this or simply write out ConvexCombination(set). Also the formal equals is not technically correct, why not just write it out: \Omega_T^\Gamma is a convex combination of set ?  - Page 6: "tre" -> "tree"  ************************** Post-rebuttal:  The authors have clarified many points, thank you.   One last point: I have not encountered the concept of a gradient (as defined by the authors) in fictitious play. I do not think it is "standard" (nor is its definition): a reference (and definition) should be provided. 