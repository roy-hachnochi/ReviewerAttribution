Summary  This paper proposes an invariant Gaussian process as prior for regression and classification models. A variational inference shame is derived and the invariance is described by a probability distribution that can be sampled from.   Strength  The authors provided a relatively new perspective on how the model should be robust to the minor changes of the input variable values.   Weakness  The logical flow and technical presentation are very confusing, which is the biggest problem of this paper.  First, in Section 2, the authors introduced the definition of a strong and weak form of invariance. If such invariance is already accepted and studied, the authors should have pointed out previous works. Otherwise, the authors should have explained many details, such as the range of transformation T, i.e., what kind of transformations should be considered. Also, why the invariance is defined through Equation (1) and (2). Are there any other proper form of definitions? Second, the authors confused many things, including the purpose of regularization and the purpose of making the model robust to input. So the review on Regularization and Model Constraints in Section 2 is not necessary.  Third, in the most important part, Section 4, the authors introduced too many concepts and notation without a proper definition. In Section 4.1, what should be the set of G? What is the meaning of orbit? It is directly related to how many Gaussian processes are being summed in Equation (4). In Section 4.4, the entire notation, especially x_a and x_n, x_aâ€™ are used without definition.   Overall, the quality of this paper is hard for me to assess, due to its poor technical development and presentation. I am not convinced that this work contains some original idea and has any kind of significance to the supervise learning community. 