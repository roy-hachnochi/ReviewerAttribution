The paper proposes combining Cross Entropy (CE) minimization with Proximal Policy Optimization (PPO) for optimizing placement decisions of operations in TensorFlow graphs across multiple devices. Results show faster and better optimization results than previous RL-based approach of Mirhoseini et al.  Strengths: - The paper is written very clearly and is easy to follow. - Algorithm seems to be simpler than that proposed by Mirhoseini et al. - The results are significantly better than Mirhoseini et al.  Weaknesses: - The evaluation is incomplete. The previous papers by Mirhoseini et al. unfortunately didn't compare against simple/trivial baseline algorithms like random search (try random placements and keep track of the best), hill climbing, genetic algorithms, etc. to show whether a learning approach outperforms them given the same computational budget and placement evaluation budget. This paper also doesn't address the shortcoming. So it's not at all clear whether placement optimization really requires any sophisticated optimization in the first place.  Comments/Questions: - Please include in the Appendix the type of graphs shown in Figure 2 for all the entries in Table 1. This way it will be clear that the same kind of behavior seen in the three graphs in Figure 2 hold for all the settings.  - Are the results in Table 1 strictly controlled for the same amount of computation and the same number of placement evaluations allowed to Policy Gradient and Post? The text does not say this. If they are not, then the results may not be meaningful.  - For many TensorFlow graphs for which placement optimization is difficult, a key challenge is to stay within the memory limits of the devices. So it may be difficult to find placements, especially early on in the optimization, that satisfy memory constraints. How is this problem handled by the proposed algorithm?  - TensorFlow graph running times can show high variance. What are the error bars for Figure 2 and Table 1?  - Is the algorithm that is labelled as Policy Gradient a re-implementation of the Mirhoseini et al.'s approach? If so, their work relied on grouping the ops and making group-level device placements, and how were the grouping decisions made?