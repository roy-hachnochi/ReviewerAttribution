Summary:  This paper proposes to combine tensor product representations (TPRs) with RNNs for learning to reason. The entire model is end-to-end learnable including the TPRs. Experiments on bAbI tasks show that the proposed TPR-RNN is better than other state-of-the-art methods like RENs. Authors do some post analysis of learnt TPRs and claim that the results are human interpretable. TPR-RNN also shows systematic generalization to new entities.  Comments:  1. How did you choose 15 entities and 10 relations in the experiments? What is the effect of choosing more entities or more relations? It would be good to have such an ablation study. 2. What is the intuition behind having 3 inference steps? Again it is good to have a study on what is the effect of increasing or decreasing the number of inference steps. 3. I appreciate authorsâ€™ effort to report the mean scores (with standard deviation) in bAbI task. Scores from the best runs are not very indicative of the performance of the algorithm. Mean scores give a much better picture. 4. Will you release the source code of the model to reproduce the results reported in the paper?  I do not have any major concerns about this paper. The model is novel and the experimental results are convincing. There is enough technical novelty in the paper to accept it.  Minor comments:  1. Line 27: line repeated. 2. Line 223: correct the sentence ending. 