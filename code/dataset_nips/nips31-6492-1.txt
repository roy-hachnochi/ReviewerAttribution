The paper proposes a generic method for testing whether a distribution belongs to a family of distributions, or it is far from it (w.r.t. TV distance) This generic method works when the Fourier spectrums of distributions in the family are sparse. The authors then show the corollaries for learning certain families of distributions, namely SIIRVs, PBDs, PMDs, and Log-concave distributions.  The authors argue that the provided results improve over the (trivial) learning by testing approach. While this seems to be true for SIIRV (improving from n^(1/2) to n^(1/4) in sample complexity), it does not seem to be true for these two other cases:  + Testing Log-concavity (Theorem 4) does not improve over the (trivial) testing by learning paradigm, using the known efficient learners for log-concave distributions [4,5,6]  + Testing PMDs (Theorem 3) does not improve much over the (trivial) testing by learning paradigm, using the efficient learning algorithm of [2]. (both will give (nk)^(O(k))   Please clarify if I am wrong. Otherwise, I think the current write-up is misleading (I am surprised the authors do not mention this).    The overall idea of exploiting the sparsity of Fourier spectrum is reminiscent of [2] and [3]. Although these papers do not address testing specifically, they are similar in techniques used.    [1] I. Diakonikolas, D. M. Kane, and A. Stewart. Properly learning Poisson binomial distributions in almost polynomial time, COLT 2016  [2] I. Diakonikolas, D. M. Kane, and A. Stewart. The Fourier Transform of Poisson Multinomial Distributions and its Algorithmic Applications. STOC 2016  [3] I. Diakonikolas, D. M. Kane, and A. Stewart. Optimal Learning via the Fourier Transform for Sums of Independent Integer Random Variables. COLT 2016  [4] Chan, S. O., Diakonikolas, I., Servedio, R. A., & Sun, X. Efficient density estimation via piecewise polynomial approximation. STOC 2014  [5] Acharya, J., Diakonikolas, I., Li, J., & Schmidt, L. Sample-optimal density estimation in nearly-linear time. SODA 2017  This one seems to be a 2016 Arxiv preprint, but I use it because the authors themselves have cited to it. [6] I. Diakonikolas, D. M. Kane, and A. Stewart. Efficient robust proper learning of log-concave distributions. CoRR, abs/1606.03077, 2016.   ==== After reading the authors response, I changed my decision to accept. As the author mentioned, the testing by learning paradigm requires a tolerant testing (rather than identity testing) after the learning step. So the trivial upper bounds that I was mentioning don't work. 