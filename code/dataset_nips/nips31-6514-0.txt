The paper presents a view on adversarially robust features motivated by spectral graph theory. Bounds on the feature robustness are proved and shown to be empirically useful on toy datasets as well as a small-scale dataset (MNIST).  The paper flows clearly and is well-motivated, and the connection to spectral graph theory is a very interesting non-obvious one, which gives the work novelty and originality. Some of the lower bounds are vacuous on realistic-scale problems, however the authors do well to clarify which theorems result in vacuous bounds and which do not. The theorems are also given along with toy examples which help readability.  The main downside I found in this paper was the clarity of the writing itself, which can be improved. The paper includes quite a bit of informality and some typos, and some sentences which are unclear (e.g. line 37, inherent in what?). The related work also needs a revision: FGSM denotes an attack and not a defense (line 117, it seems that the paper is referring to adversarial training _using_ FGSM). Other papers that may help contextualize the work are [1] and [2], which also attempt to answer the "why" question of adversarial examples. The related work should also be its own section which contextualizes the work in the space of adversarial examples research, with background being reserved for defining adversarial examples, laplacians, etc.  Specific/writing comments on intro: - Line 27: Should cite [3] which seems to be the first work on real-world examples - Line 31: Interest on -> interest in - Line 34: Models of -> Models for classifying - Line 35-36 are a bit unclear/hard to read  [1] https://arxiv.org/abs/1804.11285 [2] https://arxiv.org/abs/1805.10204 [3] https://arxiv.org/abs/1707.07397