The paper descries Lantern, a framework for automatic differentiation in Scala, based on callbacks and continuation passing style. It compares against PyTorch and TensorFlow on several benchmark tasks. There are two main aspects of the paper: Reverse-mode automatic differentiation with continuations, and code generation via multi-stage programming.  The submission does not provide code for the proposed framework, which I don't find acceptable for a paper on a software package.  It's unclear to me how the first is different from any other implementation of automatic differentiation via operator overloading. This is usually done using a call-back mechanism, and the delimited continuation seem only syntactic sugar on this concept - which doesn't even enter the user code. The paper also mentions that the proposed solution is different from previous solutions in that it requires no auxiliary data structure. However, OO based approaches typically don't need any additional data structures.  The authors explicitly say "Indeed, our computation graph is never reified, but instead remains implicit in the function call stack.", which is typical for OO approaches.  The multi-stage programming approach seems more interesting, as it seems Scala with LMS can create compute graphs on the fly within Scala. This is much more flexible than other approaches, like TensorFlow, which have to construct the compute-graph explicitly, or Myia which works on the Python AST, but basically has to reimplement parsing of the Python AST, which restricts Myria to a subset of Python.  The LMS approach seems more elegant, but I'm not familiar enough with the internals of scala and LMS to judge the contribution of this paper.  The benchmarks comparing this implementation to PyTorch and TensorFlow are quite misleading as most graphs are shown with a batchsize of 1. This is an extreme case of little practical relevance in which both PyTorch and TensorFlow are likely to fail. More realistic cases are also discussed briefly in the text, but not shown in graphics. This seems quite dishonest. One sentence reads "For training time, Lantern with batch size 1 outperformed both PyTorch and TensorFold at batch size 1, and was similar to TensorFold at batch size 20." It seems PyTorch with a larger batchsize is omitted because it faster than Lantern.  The paper is written well, though the explanation of shift/reset operators seems cryptic to me (possibly because I'm not overly familiar with scala). It's very unclear however what the contributions of the paper are, and the presentation seems to obscure both the novelty of the OO approach and the results of the benchmark. 