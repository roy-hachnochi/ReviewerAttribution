This paper provides another formalism for gradient estimation in probabilistic computation graphs. Using pathwise derivative and likelihood ratio estimators, existing and well-known policy gradient theorems are cast into the proposed formalism. This intuition is then used to propose two new methods for gradient estimation that can be used in a model-based RL framework. Some results are shown that demonstrate comparable results to PILCO on the cart-pole task.  Quality: the idea in this work is interesting, and the proposed framework and methods may prove useful in RL settings. However, as the authors themselves state in line 251, "DEL is feasible and may be useful if further developed". It seems that this further development is necessary to truly evaluate the potential benefits of the method. In particular, how would the proposed gradient estimation methods scale to more complex, high-dimensional tasks, such as real robots? If the methods are difficult to scale, is there some other insight that can be derived from the formalism that can help?  Clarity: the paper is generally well-written with minor grammatical mistakes. The material is technically dense and will likely require careful reading for most readers, but at a glance the math seems to check out. The relationships to other methods is useful for situating the work within the larger body of prior work.  Originality: the paper proposes a framework analogous to, but more general than, stochastic computation graphs, and uses this framework to derive novel gradient estimation methods. In this sense, the work is fairly novel.  Significance: as stated earlier, further development of the proposed methods is necessary to evaluate the significance of this work, and without this development, it is unclear whether the proposed methods and their benefits warrant acceptance.  ------ Update after reading the other reviews and author response and discussing with the other reviewers: I have bumped up my original score from a 3 to a 5. The main reason for this is that, as the authors point out, the DEL estimator is only a small part of what they wish to present, and I unnecessarily focused too much attention on this part. But I do not necessarily agree with the rest of the rebuttal.  The authors mention stochastic computation graphs from NIPS '15 and how they derived known gradient estimators as opposed to new estimators. However, I see this as a strength of the paper, not a weakness, because the known estimators were already shown to be useful in practice and unifying them under a single framework was useful for tying theory together with practice simply and elegantly. Are there any gradient estimators used in practice that can be explained with the proposed PCG framework but not with previous frameworks such as stochastic computation graphs? This would certainly be interesting, and I did not see this in the paper or the rebuttal, though I may have missed it.  The authors also mention that GS allows for better understanding the success of PILCO. But after reading the PIPPS paper, I do not think that this paper does much to further explain PILCO's strong empirical performance. Section 6.4 could perhaps be rewritten to make this more clear, but parts of this still seem speculative. Is the claim that both PILCO and GS-based methods are successful due to the Gaussian approximations? I'm not entirely sure what strong evidence backs this claim while eliminating other possibilities, e.g., is there evidence that the trajectory distributions indeed stay more unimodal for these approaches compared to the other approaches?  In summary, I agree with the points that the contributions could be valuable, and for that reason in particular I think that the paper should be thoroughly revised, the experiments fleshed out more concretely, and the speculations addressed empirically. I think that by doing so, the authors could potentially arrive at a truly impactful contribution.