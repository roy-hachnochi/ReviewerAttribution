This paper proposes a deep flow based generative model which builds on techniques introduced in the NICE and RealNVP (Dinh 2014,2016). The proposed model has layers of invertible transformations (consisting of 1X1 convolutions and NICE-like affine coupling functions) and some tricks like data dependent activation normalization for stable learning are involved. The empirical results are promising and achieve better log-likelihoods than RealNVP models. Also, the qualitative results are interesting as they result in sharp(non-blurry) images which is unusual for a non-autoregressive or GAN based generative model. The interpolation  and face synthesis experiments are especially encouraging. While the results on image generative modeling are promising, the underlying approach itself is not novel and as authors acknowledge, builds upon the work introduced in NICE, RealNVP. My major concern is that I am not able to understand what actually makes the proposed model generate sharp images and better likelihoods. Is it because of the depth (no. of transformations in the flow based model)? Or is it because of the data dependent activation normalization, or is it an effect of some other modeling choice like channel permutation? An ablation based analysis, or even a qualitative analysis of what makes the proposed model work would have been very helpful in understanding the impact of the techniques described in the paper. Thanks to the authors for their response and while I do think that this paper can benefit from a more thorough ablation analysis, I think that good performance of their approach, presumably due to learning the permutation with the new flow, makes this paper a good fit for NIPS.