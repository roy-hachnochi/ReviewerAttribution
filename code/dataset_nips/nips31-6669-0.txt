This paper has an interesting explanation and analysis of a tensor-oriented implementation of model parallel training of huge models. Personally I would have preferred an explanation that was a bit more "code-like" and looked less like equations, but I suppose a certain 'look' is expected for NIPS papers.  The state-of-the-art results for language modeling are also very interesting and probably warrant inclusion in NIPS.  (I don't have anything particular to add after seeing the reviewer feedback, since they were addressing points from other reviewers.  Leaving my review as-is).