Overall. The paper is about introducing a new language of abstraction for distributed tensor operations, with a focus on shallow, feed-forward neural networks. Specifically, the paper describes the concept of laid-out tensors, which are "sub-tensors" that can either stand for weights or data and be distributed among different processors to allow for data- or model-parallelism. A new symbolic language for computations with laid-out tensors is described and is shown to be convenient for describing a big variety of possible model constructs, involving model and/or data parallelisms. A theoretical performance analysis is provided, explaining how to avoid "wasted" resources when defining models and data in parallel. Experiments are performed on TPUs obtaining improved results on models that run on 256 cores on language tasks.  Details. The main question about the paper is whether it is a good fit content-wise to NIPS. While distributed machine learning is clearly relevant, the paper focuses mostly on describing a new abstraction layout for making the computations and the models more scalable. Perhaps, as a work it would be more relevant to a conference on distributed systems.  From a technical point of view, what seems to be unclear is whether the proposed language is also applicable to more complex architectures, like multi-layered neural networks, recurrent neural networks, or DAG neural networks. Will the proposed language be sufficient when there must be increased communication between interweaved layers, or increased communication between layers over time? For instance, what if there are states that need to be stored and communicated between nodes.  What is further unclear is what is the effect of the mesh shape on the final computations. Would the theoretical costs provided in Table 1 change for different mesh shapes? Or is this already determined by the respective layout (leftmost column in Table 1).   Last, from the experimental point of view it would be interesting to have some deeper analysis. First of all, are there any benefits regarding the training time, or the only improvement is on the growing of the models? Also, are the theoretical costs from Table 1 also verified experimentally? Is it possible to provide a similar table or figure that compared the theoretical costs with the empirical ones, to validate the proposed language abstraction?  Regarding the writing, the paper could improve its clarity at points. - It would be useful to summarize all notations in a table.  - Providing a schematic of the model that is used to train for the experiments would help reading.  - Giving a better explanation on pleasantness, as it seems to be an important concept later on. Perhaps a graphical illustration can help the reading. - Regarding Table 1, it would be useful to explain how are these costs exactly derived? 