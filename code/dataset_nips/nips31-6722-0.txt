In this paper, the authors propose to improve exploration in deep RL algorithms by adding a distance term into the loss function. They show that adding this term provides better results that not doing so.  After rebuttal: The authors did a much better job explaining their work in the rebuttal, so I'm now convinced that they have a contribution. I'm now more inclined in favor of this paper, but the authors will have to explain much more carefully what they are doing (included a better presentation of the formalism) and how it is positionned with respect to the literature.  I keep the rest of the review as it was.  The first issue with this paper is that the authors seem to completely ignore the very large "relative entropy" or "entropy-regularized" body of work, as they cite none of the relevant work in the domain (e.g. Haarnoja et al., Neu et al., Peters et al. etc.). To me, this weakness is serious enough to reject the paper, as the authors fail to properly position their contribution with respect to their natural field.  From the relative entropy or entropy-regularized perspective, the contribution of the authors, whose technical part is located in Eqs. (5), (6) and (7) could be described as performing entropy-regularized RL, but using an average over the n=5 previous policies rather than just the previous one. This characterization is much simpler than the one they propose, and if it happens to be too simplified, the authors could explain what are the differences and why they matter.  By the way, from the above perspective, the formal writing of the expectation in (5), (6) and (7) is partly wrong or at least lacking rigor. Again, since this is the main contribution, a much clearer and rigorous description is mandatory.  Also, the fact that using relative entropy improves exploration is now well-known, thus the empirical results are not surprising to me at all. An empirical comparison between the authors framework and other entropy-regularized methods could have delivered much more interesting messages.  Other weaknesses contribute secundarily to my negative evaluation about this work:  - Section 3.3 and 3.4 are full of un-principled tricks and hyper-parameters - the influence of those tricks and hyper-parameters is not properly studied - results in Fig.5 contradict the literature: the authors found that DDPG with OU noise outperforms DDPP with parameter noise, whereas several papers have found the contrary. I'm afraid the empirical study lacks a lot of evaluation rigor: no number of seeds is specified, statistical significance is not assessed, etc.  In the background section, the paragraphs are too short and not so well written, they do not help much.  Finally, the paper suffers from a few more local formatting or writing problems, but this does not contribute significantly to my negative evaluation: - Subfigs (a) to (c) could be above subfigs (d) to (f). - "sufficient enough" is redundant ;) - l. 48 to 52: two sentences that are quite redundant - l.92: an experience replay => a replay buffer?  typos:  l. 7: preventing => prevents l. 33: its simpliciy => their l. 113: compared with => to l. 129 eq. (4) => Eq. l. 263: of all of the models => of all models  References:  V. et al. Mnih should be V. Mnih et al. Many references suffer from the same problem.  Supplementary: the content of S1 should stay in the main text rather than being in an appendix