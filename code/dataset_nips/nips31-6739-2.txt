## After reading the rebuttal: I maintain my initial overall score: 7.   This paper proposes an unsupervised method to learn a warping distance  for unlabeled time series. In contrast to the typical handcrafted distance metrics, the learned metric is expected to automatically fit the target the data and capture the complex nature of the noise in the data. Though the method is performed in an unsupervised way, it employs the autoencoder to learn the hidden representations for paired time series and calculate their euclidean distance to determine their similarity. Based on the similarity information, the distance metric is optimized by minimizing the betaCV from a family of warping distances.  Strengths: 1. The method is novel in that it aims to learn a distance metric automatically in an unsupervised way. The proposed family of distances can be related to the typical handcrafted distance metrics, such as DTW, Euclidean Edit distance and so on. 2. The experiments on real datasets actually shows that the learned metric achieves competitive performance to traditional distance metric.  Weaknesses: 1. On the one hand, the paper attempts to leverage the representation power of autoencoders. However, it proves in Proposition 1 that the reliability (quality) of latent representations by autoencoders (the labels) does not affect the performance significantly. It seems that the autoencoders do not play an important role in the method.  I am curious about the experiments to show the effect of the quality of hidden representations by autoencoders on the performance of learned distance metric. E.g., would a poor autoencoders lead to a poor distance metric learned by autowarp?   