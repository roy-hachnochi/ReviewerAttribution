The authors propose a novel RNN ASR system that combines previously proposed simple recurrent units (SRU) and ifo-pooling. By incorporating these two changes, inference of the recurrent network can be performed in parallel over time for subsequent layer, reducing reloading of parameters into memory. In order to overcome the reduced performance from the change from more complex recurrent units to SRU's, 1-d convolutional layers are added between the recurrent units. The resulting system yields competitive performance with significantly reduced inference cost.  This paper presents an interesting approach to ASR in a memory constrained setting and is well written. The results are strong, however additional runtime comparisons with architectures used for performance comparison would strengthen the empirical evidence supporting the utility of the method.