This paper focuses on real-time strategy games, and presents a model to make predictions over the parts of the game state that are not observable, as well as predicting the evolution of the game state over time. The proposed model is based on a encoder/decoder architecture that integrates convolutional networks with recurrent neural networks.  This is an interesting paper with promising results. The most interesting part for me is that the proposed model seems to me a "starting point", and this opens up a very interesting avenue of research for the future. For example, the current module provides a prediction, but could it be used to provide a distribution over the possible game states, from where we can sample? This would be very useful for forward planning, for example. Also, could we feed a plan, and use the de-fogger as a forward model, of the execution of the plan? etc. So, in summery, very interesting work, showing a lot of potential!  Some specific comments:  - "To our best knowledge, the only deep learning approach utilizing replays of human games to improve actual full-game play is [17]" -> in "Evaluating Real-Time Strategy Game States Using Convolutional Neural Networks" by Barriga et al. they use deep learning to learn an evaulation function to be used in a game tree search framework for full game play in RTS games (in microRTS, not StarCraft though).  - "downsampled onto on a coarse spatial grid" -> "downsampled onto a coarse spatial grid"  - Section 4: this section is a bit foncusing to me, and I think it could have been written in a more clear way. For example, when describing the "two types of encoders", are both used in the model? [edit: this is clarified later in the experiments, but it shuold be clear from the start] or are they two alternatives that were compared?  - Section 5:   - "The full games, the prediction of" -> "In full games, the prediction of"?  - "Varying model sizes did not amount to significant gains, so we picked the smaller sizes for computational efficiency." -> what sizes were selected for final experiments?  - Concerning the baselines, the three first ones are basically the same exact ones used by Uriarte et al. in "Single believe state generation for partially observable real-time strategy games", so, this makes me think that if the last paragraph of the future work section is successful, the de-fogger could be used not just in RL, but also as a forward model in tree search algorithms.  - About the results (Table 1): I find it curious that with the ConvNet encoder, results seem to improve when increasing time (s)!! (Except for the Huber loss) Do you have an explanation for that? I would expect results to DEGREASE over time!   - Also, about the use of Huber loss: wouldn't it be more interesting to see error over time rather than average over the time dimension? i.e. see how error grows as the amount of time we are the model to predict into the future grows?  - Results show that incorporating the de-fogger into an existing StarCraft bot helps a bit, but it mostly hinders, since the existing modules are not expecting it. What kind of changes would be required into the bot to make it take full advantage of the defogger?  - I would have liked to see how performance degrades/improves when spatial resolution is changed. The current experiments show for g = 32 and 64. But what happens when you ask the model to do finer grained predictions? e.g. g = 16, or even g = 8? Does it introduce a lot of noise? 