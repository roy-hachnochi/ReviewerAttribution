The work builds on the technique of [3] (detailed in Alg 1) to conduct a set of experiments that — demonstrate the sensitivity of networks along certain directions largely affecting its classification accuracy. In fact, projecting the image onto a small subspace consisting of these critical dimensions is sufficient to explain most of the model’s accuracy. The projection along these dimensions naturally turn out to be strong “features” for an image to be classified appropriately and therefore, techniques that find adversarial perturbations smartly exploit these dimensions. This paper makes the important observation that the very dimensions responsible for a good accuracy also cause vulnerability of the model to adversarial perturbations.   I would like to know a more detailed response on previous work that claim to increase robustness to adversarial perturbations at negligible reduction in performance [29, 30] in this framework. What do the techniques proposed in these works correspond to in the framework studied in this paper ? Because — taking the view of this paper (and as mentioned in L238), it becomes infeasible to increase accuracy while increasing robustness to such attacks.   The main negative of the paper is that it is hard to read due to 1) convoluted writing and 2) sloppy notation. Some pointers are below and in general, adding sufficient cross-references to previously defined terms will increase readability. Also, the graphs need to be presented more clearly — for eg. by moving the legend out of the plot.  L16 — on one hand L156 — Algorithm 1, line 5 needs to be in two lines  Section 3 — Since the rest of the paper critically depends on this section and Algorithm 1, this section must be presented more clearly. (like adequate comments in the algorithm box and grounding sentences in the section back to lines in Alg 1).  Notation in the paper seems arbitrary. For example the set S_i is used to denote the subspace formed by the i-most positively curved directions and s is used to indicate samples from D in Alg. 1 (in the same section). Intuitively, one would assume s \in S and so, makes it a harder read.  Fig 3 —Is there any intuition for why curves for CIFAR-100 differ from the rest (positive curvature) ? 