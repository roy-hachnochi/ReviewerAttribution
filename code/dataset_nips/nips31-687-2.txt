This paper presents a Multi-Task based Residual Auxiliary block that modifies the output feature map of classical CNN networks (Resnet, ...) to improve it for an object detection application. The auxiliary tasks used here are optical flow and depth but the method is generic and other kinds of task may be used. This auxiliary block is a kind of feature-map auto-encorder driven by the auxiliary tasks.  The main idea is that using auxiliary tasks, we can improve the generalisation of the main detection task. The paper is easy to read and well-written. The residual Auxiliary block, that is the main contribution of the paper, is composed by light elements in order to reduce the cost and weight of the network. However, the authors don't give any information on this cost in the experimental part but they only give information on the mAP. It should be interesting: 1) to give this information and 2) to try more complex structures into the residual block in order to show if it possible to improve the mAP. Experiments show that the proposed MTN can improve MAp significantly on the NYUv2 detection dataset. It should be interesting to give information about the evolution of the loss during the training. Is the final loss of the detection lower when using ROCK? Comparinf the loss of the training and validation sets should also helps to understand id the residual block really helps to generalize.