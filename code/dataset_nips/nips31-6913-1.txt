Summary: This paper presents a generative rule-learning model that uses a two-stage learning process to first generate model structure and then assign features and values into the model structure. Two critical properties of the proposed approach are that it has an inductive bias to use few features and cluster discrete feature values to improve model support. Although performance on several datasets is close to the popular rule induction methods, the proposed method produces rules with fewer conditions and requiring fewer features.  Pros: - Bayesian, probabilistic approach contrasts with many of the deterministic methods of rule induction - Focus on using few features and clustering values is practical for explainability, and efficient evaluation. - Intelligent sampling approaches to improve scalability of complex inference Cons: - Does not concretely discuss scalability of the method w.r.t. features, values, instances, etc. - Ignores related work in structure learning and lifted inference in probabilistic modeling that has similar aims - Evaluation is restricted to a few, smaller datasets - could be more extensive  Quality: 3/5 - identifies a problem, introduces a novel solution, and tests it Clarity: 4/5 - Well-written and clear  Originality: 3/5 - Not entirely familiar with this subcommunity, but the ideas seem novel in rule learning, but structure learning work already employs many of the same ideas. Significance: 3/5 - Without better bounds and experiments on scaling, don't know if this is really a tractable model  Detailed comments: This is an interesting paper that uses a different approach from prior work on rule induction -- a fully generative model. The model itself seems a straightforward Bayesian approach to rule learning, but some elements such as feature clustering and efficient sampling from misclassifications are clever.  I have several misgivings about this paper. The most serious is scalability: is this a method that could conceivably be used in real-world settings where there are more instances, more features, many discrete options (or continuous values), and few training examples? The complexity of the inference suggests that this method could face many hurdles in those real-world settings.  The second issue I'd note is that this paper reminded me of the work in the probabilistic modeling community on lifted inference (see the tutorial "Lifted Probabilistic Inference in Relational Models" as a good starting point). The goals and techniques of this community, parsimonious models that maximize likelihood while bounding model complexity, seem very similar to this technique. Comparing against these approaches, in both theoretically and empirically would help contextualize this work more broadly. Finally, the experiments seem fairly constricted for the level of generality of this method. Classical rule  learning papers demonstrated performance on ~40 datasets, so limiting results to 3 datasets calls into question some of the generality of the approach. Additional experiments would also bolster claims of scalability.