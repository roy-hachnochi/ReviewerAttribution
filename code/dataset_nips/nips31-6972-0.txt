This paper tackles the problem of prediction of individual treatment effects given observed data and a small randomized trial. The unconfounded data can be used to estimate the effect, but the variance will be high, e.g., with importance sampling. So the authors reduce variance by including an estimate from the observed data, which no longer needs to be unbiased. I think the paper introduces an innovative approach that can be useful whenever unconfounded data is available. The experimental section is encouraging, except that I would have liked to see at least one other real-world dataset to show generalizability, and a comparison with baselines that they mention in section 3 (importance sampling and transportability ).   The catch, however, is that the effect of confounders can be expressed parameterically (linear in the current paper). I think this is a reasonable assumption, but the authors make a stronger claim: "strictly weaker than other assumptions". I suggest that the authors present a formal argument for this. The current justification in Section 4 is vague.   The other suggestion I have is in terms of expressing the main idea. It seems that the method is really a variance reduction trick---where a low-variance but biased estimate from the confounded data is used to reduce variance on the high-variance unbiased estimate from the confounded data. Maybe the authors can discuss this interpretation, and how this could lead to other derivative methods from this general insight?  