The paper proposes a feature selection/acquisition method to achieve better predction performance. The authors present a novel reinforcement learning framework for training the RL agent to select new feature or to predict.  In general, the idea of jointly minimizing the prediction error and feature acquisition cost is clear and convincing. The experimental results show that the performance of the proposed method is favorable. Nevertheless, there are still some concerns to be addressed.  1, Novelty. One of the contributions of this paper to the literature is the joint training framework for learning active feature acquisition model. I am wondering if they are the first one who use the RL agent for selecting features without a pre-defined classifier.  The proposed feature-level set encoding for sharing information between the learning tasks is designed as shared layers, and the set encoding method is from [4]. So, why the claimed encoding method is novel in this paper?  2, Presentation. The paper reads well overall, although some descriptions are not clear enough. For example, it's better to use the full name of reinforcement learning instead of its abbreviation RL in abstract.  In Section 3, the basic assumption here is that the feature vector is fixed-dimensional, and given in full (but possibly with missing entries), what do you mean missing entries? Does this mean some values of one feature vector are not available?  3, Experiments. The efficiency of the algorithm is also important for the  task, what is the running time of the proposed method and its components. The analysis of the algorithm limitations is encouraging, visual examples may need to support the authorsâ€™ arguments. 