The paper tackles a timely area of research, namely new approaches for time-to-event data modeling which is common in health data analysis. There is a large body of statistics literature on this topic and some recent ML approaches, such as DeepSurvival (Blei lab) and DeepHit (van der Shaar lab). The work proposes a multi-task model to consider competing risks, similar to DeepHit. The authors do compare with other methods, but I think these comparisons fail in two aspects: a) no comparison with a version of their method that considers each risk independently -- this comparison would be important to include in order to understand whether it is the flexibility from boosting trees or from the simultaneous modeling of multiple risks that leads to the improved performance. b) a comparison with DeepSurvival (from 2016, https://arxiv.org/abs/1608.02158) appears appropriate.  Apart from the limitations in the results part, I thought that the presentation of the methodology as a boosting method is not very clear. I consider myself an expert in boosting and miss a few important ingredients and explanations of the algorithm. a) what is the objective that is optimized by the proposed algorithm, b) how is the step size chosen (see Step 5 in All 1), c) is there any guarantee that the proposed algorithm converges to a minimum/maximum of the objective function. There is a lot of literature on boosting and how to these techniques are related to optimization, but there is very little mentioning of that work (except that it is very different from Gradient boosting). Without any analysis or justification beyond intuition of why the algorithm was chosen this way, it appears a bit too ad hoc.  Some details: * \tau is not defined in (2) * p(T<=t, Z=k|X) is used in the definition of F_k but not really defined anywhere. I'd think that such details should be described in Section 3, but I couldn't find them there.   AFTER AUTHOR RESPONSE: * The authors included a new table comparing the model against itself with separate causes. They were able to show that the results significantly improved by considering multiple causes together. (please include a statement how you determined "significance". I used a not quite appropriate t-test with the means and standard deviations that were provided with n=10 and all comparisons were significant at p<=5%). This addresses one concern I had about this work and I increase my score by one. * I still think that there is little justification for the algorithm. The optimization perspective can give justifications -- which the authors did not follow. Any other justification -- theoretical, analytical, empirical would be fine as well. As it stands the algorithm still appears ad hoc to me. So, no additional change in score here.