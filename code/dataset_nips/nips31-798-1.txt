The paper proposes to express the distribution of a real-valued univariate random variable as a tail deviation from the quantile function of a normal variate, called HTQF. This function consists of 4 parameters to specify the location, scale, lower excess tail, and upper excess tail. In a time series context, the paper models these quantities at time t in a time-varying fashion through an LSTM, using a window of L past observations (and higher central moments). Since the CDF of the HTQF model is monotonically increasing, the quantile crossing problem is avoided by construction. The model is trained by minimizing the set of pinball losses at the various quantiles of interest.  The paper is quite well written and easy to follow. The proposed form for the HTQF is interesting and appears to be a novel contribution worthy of a presentation at NIPS. The experimental validation on synthetic and real datasets is adequate, and the latter appears to show some improvement over well-known GARCH models. In addition to the pinball loss, it would have been helpful to provide coverage measures for the quantiles (i.e. in a properly-calibrated 0.1 quantile, 10% of the observations should fall below it; what’s the empirical quantile corresponding to the nominal model quantile? This would be akin to a Q-Q plot between the the realized quantiles and the predicted quantiles). This measure would also more adequately compare the behavior of various models across all quantiles, which are not systematically reported in the results.  Moreover, a small quibble would be that no model from the stochastic volatility family are represented, which are the other large family of volatility models in financial econometrics apart from GARCH.  The main issue that I have with the approach is that the specification of the excess tails takes a very constrained functional form, which limits its flexibility — it would be interesting to understand whether this leads to underfitting for the financial asset return series of interest. It is also obvious that this approach can significantly enhance time series modeling in many other areas beyond finance; I would be looking forward to a discussion of which fields would appear most suited to benefit from this approach.  Overall, I think that the issues reported above are fixable, and if so I would be happy to see the paper accepted.  Detailed comments: * Line 18: care ==> care about * Line 27: gaussian ==> Gaussian * Line 41: speak itself ==> speak for itself * Line 137: has ==> have * Line 236: Verity ==> Verify * Line 236: truth ==> true * Line 249: truth ==> true * Line 249: no matter it is on ==> on both * Paragraph 248-255: this analysis is sketchy and should be made more precise. 