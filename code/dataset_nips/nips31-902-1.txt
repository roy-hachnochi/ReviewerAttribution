The paper develops an analysis of semi supervised classification in a transductive context for linear classifiers and convex losses.  It shows that in most cases semi-supervised learning cannot be guaranteed to bring an improvement over supervised learning. This is a worst case analysis called “pessimistic” in the paper. This result is extended to soft labels. A characterization of possible situations where semi-supervised learning could be beneficial is also introduced.  The paper is well motivated and clear. It is well illustrated by detailed examples in the appendix.  My main concern is the worst case context of the derivations. The results are general, sure, but they are weak at the same time. The main results says that one cannot guarantee that a semi-supervised learner will not degrade the performance of a supervised learner for all possible target configuration of unlabeled data and at the same time have a better performance for at least one target configuration. As a worst case analysis, this does not take into consideration the nature of the problem, or the distribution of examples.  This is then quite far from any “real” situation. The conditions obtained for the characterization of favorable conditions are weak too.  Overall, the paper is correct and presents an interesting result, but this is a weak result.  Update:  I wouild like to thank the authors for the feedback, but there is no new argument there to change my opinion. 