This paper introduced a framework named adversarial information maximization (AIM) to improve the informativeness and diversity of conversational responses.   The framework (a) leverages adversarial training to enable distributional matches of synthetic and real responses, thus enhancing response diversity, and (b) optimizes a variational lower bound of pairwise mutual information between queries and responses to improve response informativeness. Experimental results show the proposed framework performs well.   The paper is generally clearly described. The proposed framework seeks to balance the diversity and informativeness aspects of conversational responses, which is a meaningful research problem, though I wasn't quite sure about the necessity of the dual adversarial learning objective introduced in Sec. 2.4. Below are some specific points.  It'd be great if the paper could provide justification on the effectiveness of the objective described in Eq. (3), where the source (S), target (T), and synthesized target (\tilde{T}) sequences are projected to the embedding space and the objective is to minimize the difference between cosine(S,T) and cosine(S,\tilde{T}). I wonder if it works better to project (S,T) and (S,\tilde{T}) to two embeddings and then minimize the cosine similarity between the two.   The physical meaning of \nabla_{\theta}\tilde{T}(S,Z) and the motivation of adding it to Eq. (4) perhaps could be more thoroughly explained.   I found the backward proposal network q_{\phi}(S|T) to be interesting. Given that the response (T) can be much shorter than the query (S), I'm also curious to know about what this network is expected to learn. Sec. 2.4 seeks to address this issue with a dual objective, but I feel it perhaps could be made simpler? Why not (a) calculate how likely a synthesized response (\tilde{T}) can be paired to a query (S), and then (b) divide it by the sum of such likelihoods over all queries of the corpus (or the current mini-batch), in order to estimate q_{\phi}(S|T).