The paper presents a generative model called Visual Object Networks (VQN), which models 3D shape and 2D texture. Loss for shapes L_shape and loss for textures L_texture are added. L_shape consists of loss for GAN and 3D geometry loss. L_texture consists of GAN loss and cycle loss from images and textures. Empirical evaluation shows the superiority to other existing models in several measures such as inception distance, human preference, and log-likelihood. Overall, the paper is well-written and well-organized. The only concern is that the proposed method is rather straightforward, and does not convey much insight to the NIPS society. Handling textures and shapes separately is also a limitation from the algorithmic perspective. Finally, more elaborate comparison to other models (including Generative Query Networks) may improve the paper. 