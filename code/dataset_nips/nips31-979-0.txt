This paper considers single-camera, single-target visual tracking where the target object can undergo large appearance changes. Attention maps helps visual tracking by selectively attending to temporally invariant motion patterns. The paper argues that existing tracking-by-detection approaches mainly use additional attention modules to generate feature weights. This paper proposes an algorithm consisting of feed-forward and backward operations to generate attention maps. The attention map is used as regularization terms coupled with the original classification loss function for training. The paper claims this is better than existing attention mechanisms used in visual tracking.   The paper lacks novelty and significant contributions due to the following. 1. Visualization techniques have computed the sensitivity of input pixels to loss function. So the technique does not seem to be new.   2. Using the attention map as regularization terms is somewhat interesting. However, the results are not much better than existing attention mechanism. As stated in the paper, the baseline tracker with reciprocative learning gain over the baseline vs the baseline with attentive feature scheme gain over the baseline are: 3.2% vs. 2.1% in distance precision metric, and 3.3% vs. 1.5% in overlap success rates.  3. The extensive experiments comparing [33] with proposed attention map with respect to many other methods in the literature does not seem to be very relevant.   There have been many papers on multi-target tracking, e.g.  https://arxiv.org/pdf/1604.03635.pdf, Online Multi-Target Tracking Using Recurrent Neural Networks https://arxiv.org/pdf/1710.03958.pdf, Detect to Track and Track to Detect  Multi-target tracking leverages state-of-the-art object detector. For two-stage object detectors, the proposal network acts like attention maps. For single-state object detectors, there is no need for attention. The authors might want to investigate whether attention map can reduce computation complexity in the context of multi-target tracking.   In summary, there are two key issues. One is whether attention regulation is novel enough or not. The other is whether performance improvement is significant or not. Unfortunately, the rebuttal does not address either of them. The rebuttal claims performance gain of +1.1% in distance precision and +1.8% in overlap success over the state-of-the-art methods is significant. The rebuttal just reiterates that they are the first to integrates attention maps as a regularization term into the loss function for end-to-end learning CNNs. 