* Writing and clarity - Some descriptions are unclear and hard to follow, e.g., L125-126. - The abbreviation MRCL is used before its definition (Abstract, Fig.3, L171). - How do you define the marginal distribution \mu in L73? Please clearly define -- the number of samples for a given X_t? Then, it's not a probability distribution. - In section 2, the authors assumed "a variety of correlated sequences" (L74). However, the rationale of OML in Eqn.3 is not sufficient to support the "correlated sequences". Even though consulting with Appendix B, the rationale is weak to persuade. Do you assume that the k-step online update in Eqn.3 can give optimal loss for RLN although k is smaller than the length of each session? And, what do you mean by "finding a model initialization and learning a fixed representation such that starting from the learned representation it has xyz properties (Appendix L379-380)"? - I strongly recommend the authors to move Algorithm 1 from Appendix to the paper after polishing Section 2 & 3.  * Related works  Missing related works make it hard to assess the novelty and significance of the proposed method. If it is possible, please do report the controlled experiments to compare state-of-the-art. Some parts of the comparison with the other methods should be mentioned in the paper to shape the position among the related works. The following papers (not exhaustively listed) are recommended to consider: 1) Meta-learning with Latent Embedding Optimization, Rusu et al., 2018 2) TADAM: Task Dependent Adaptive Metric for Improved Few-shot Learning, Oreshkin et al., 2018 3) Task-Agnostic Meta-Learning for Few-shot Learning, Jamal et al., 2019  * Evaluations - L209-210 says that training accuracy is the indicator for the amount of forgetting. However, Fig.3 shows the limited aspects of analysis on the catastrophic forgetting and how the models persistently maintain the information. Could you plot the progressive results of the accuracies? - There are only two experiments using sine waves and Split-Omniglot, which are both too simple to confirm its significance. More complex and realistic datasets should be tested, e.g., CIFAR100 (Krizhevsky, 2009), Mini-Imagenet (Vinyals et al., 2016), and Tiered-ImageNet (Ren et al., 2018).