The paper derives novel bounds for Smoothed Online Convex Optimization (SOCO) and a particular state of the art algorithm  on Online Balanced Descent (OBD), one in , showing its suboptimality, for the setup with (m-)strongly convex hitting costs and the squared l2-norm as movement costs. It also introduces two novel variants of OBD: G-OBD and R-OBD, and shows their optimality in terms of the strong convexity parameter.  The paper takes big steps towards understanding Smoothed Online Convex Optimization (SOCO) by addressing and solving various unresolved problems in it: - It provides the first non-trivial lower bounds on SOCO with (m-)strongly convex hitting costs and the squared l2-norm as movement costs. The bound grows as \Omega(m^{-1/2}) as m goes to 0. - It introduces two variants of a state of the art algorithm, Online Balanced Descent (OBD): G-OBD and R-OBD. R-OBD matches the exact lower bound on the above setup, and thus optimal in terms of the strong convexity parameter. G-OBD, on the other hand, has slightly less competitive ratio, O(m^{-1/2}), but on a broader class of problems. - It proves a Omega(m^{-2/3}) lower bound on the competitive ratio of Online Balanced Descent (OBD), a state of the art algorithm in OBD. This thus shows its suboptimality in terms of the strong convexity parameter. - The presented bounds imply that R-OBD can achieve dimension-free competitive ratio and sublinear regret simultaneously for problems with m-strongly convex hitting costs and the squared l2-norm as movement costs. (For linear hitting and movement costs, this was known to be impossible.)  The obtained results are strong contributions that improve our understanding of the topic and potentially help solving further problems in the area.  The subtleties of the results and the problems are essential, which automatically renders the paper hard to approach; however the authors did a really good job in highlighting the main details and guiding the reader through several layers of the problem. The summary of the main ideas were also very efficient in conveying the main challenges and ideas. Overall, it was an enjoyable read.  Minor remarks: line 179: "costs costs" -> "costs" Lemma 1: please quantify \beta. Lemma 4: this is a well-known property of convex conjugates 