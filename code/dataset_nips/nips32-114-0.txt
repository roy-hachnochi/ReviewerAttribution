This paper introduces a blind super-resolution technique, i.e. a method allowing to increase the resolution of an image without knowing the downscaling kernel.   Clarity : clarity is fairly good. It's just that sometimes some statements are raising questions which are answered later in the paper. It would be better to warn the reader that explanations are coming next.  originality : the proposed GAN allowing to estimate the SR kernel is new and tailored for the blind SR problem.  quality : the authors have rigorously presented their approach. The paper is technically sound. The only issue I see is that the performance discrepancies reported in the experimental section should be proved to be statistically significant.  significance : the results are significant (see previous comments on the contributions)  Remarks :   line 101 : The benefits of using a D-map as compared to a pixelwise output is not explained in details.  Line 117 : having a 7x7 receptive field is also possible because in other layers, the authors use 1x1 convolutions. This should be outlined in the text.  Line 130: the authors explain that using a single layer generator does not work because optimization is entwined with that of the discriminator which is non-convex. It should be mentioned here that an « over-parametrized » learned G can be anyway compacted to single layer kernel as will be done in 4.2.  Table 1 : please provide evidence that the reported PSNR discrepancies are statistically significant. I do not understand what synthetic dataset is used here (It is explained in the next subsection).  Reproducibility  : data and code will be made available but when or under what circumstances ?  Runtime : I don’t understand the comment that «  runtime is independent of image size ». If the image is larger, then there are surely more patches from which to learn and thus training epochs are probably longer.  UPDATE AFTER REBUTTAL:  I thank the authors for the relevant feedback they provided.   Concerning statistical significance, I agree that the reported indicators in the initial submission are indeed the usual practice in the SR (or image processing) literature, but I think the authors would also agree with me that this is a bad practice. I also agree that empirical standard deviation is not very informative because what we would like to know is how "concentrated" are probabilities around the empirical mean. I suggest bootstrap confidence intervals. The figure 2 of the feedback is also interesting.  About the Dmap, why is it computationally more efficient ? Is there a parallelization to be exploited ?  I am confident that the authors can easily address the other suggestions I made.   I maintain my score because it is already pretty high.