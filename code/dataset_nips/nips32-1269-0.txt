As mentioned, the paper sets out to model labor markets in which employers are either discriminating (i.e., hold misspecified prior beliefs about a minority group) or non-discriminating, workers are either high skill or low skill, and employers generate reviews of workers. The paper further models hiring decisions that take into account a mix of prior beliefs and reviews, exploring the implications of these dynamics as more reviews come in and employers' assessment changes as a consequence. The paper demonstrates that such markets will end up generating less welfare for the minority group, even as employers learn over time.  I expect my more expert colleagues will have a lot to say about this set up and the proofs. I found the set up reasonable and the findings rather instructive, but lack the technical expertise to evaluate them in depth.  I do, however, feel well equipped to assess the proposed mechanism. To minimize the effect on worker welfare, the mechanism aims to learn whether employers are discriminatory, given their response to workers, and then avoid matching minority workers to these employers. If employers are understood to be interchangeable from the perspective of the worker (i.e., the worker would be equally happy to accept jobs from any of these employers), the proposed mechanism can mitigate the effects on minority workers' welfare. But employers and jobs are rarely so interchangeable. A good deal of discrimination in labor markets arises from the belief that members of certain groups (e.g., women) are not suitable for certain jobs (e.g., executive positions). In the real world, the discriminating employers are not randomly distributed by occupation or role. A mechanism that aims to avoid pairing a minority worker with a discriminating employer would only be effective -- and justifiable -- if all jobs are equally attractive from the perspective of the worker. I'm not convinced that a platform would be able to develop a taxonomy of job types such that any job in a type is essentially interchangeable.