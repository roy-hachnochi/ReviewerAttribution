The authors present GENO, a generic optimization framework for solving classical machine learning problems, that can be expressed as  vectorized linear algebra expressions. The generic optimizer is based on quasi-Newton optimization, but can solve also constrained, non-convex and non-differentiable problems due to use of automatic differentiation, as well as a number of problem transformation methods.  The paper is clearly written, and easy to follow. Related work has been covered quite thoroughly.  The experimental comparison presented in the paper and supplementary materials is quite comprehensive with regard to number of compared methods, data sets and optimization problems considered. I found it quite surprising that a generic method can perform so well on such a diverse range of tasks, and I believe that the method will be of interest to the NIPS community.  Questions to the authors:  Since the main contribution of the paper is the solver software, what is the planned availability of this software - will it be made freely available under some open source license?  Can the solver accommodate for special structure in the parameter matrices (e.g. matrix A is sparse and mostly full of zeroes, product of two "thin" matrices", or A is a Kronecker product of two matrices)? In many scipy methods for example one can define a linear operator, that returns a matrix vector product rather than having to create a matrix explicitly.  Figure 1: the image caption could be a bit more informative. I'm quite familiar with the regularization path algorithm and have seen such plots before, but I still had to check the scikit-learn demo out to remind myself what exactly the axes and curves correspond to in the image. 