After rebuttal:  Having read the rebuttal and other reviewers' comments, I still think this is a strong paper. I don’t consider the novel contribution to be the disentanglement of representations, but rather the separation loss and interpretability, which they have done appropriate ablations for. A more thorough set of ablations on all of the different components would have been nice to see, but unnecessary in my mind, since they don’t claim their main contribution to be hypernets or disentangling.   Furthermore, they’ve validated (to a limited extent) on a real-world dataset, which was key to my high rating. That said, they could have gone much further in this respect, including addressing my point about needing to know the exact number of latent dimensions and how not knowing this would affect their method. I encourage the authors to consider adding this if accepted.  R2 does have a point about comparing to some non-RNN baselines, which would have made the paper stronger. The Dezfouli et al 2018 paper was using only supervised learning, and doesn’t consider other methods suggested by R2 like HMM (although it didn’t have the same goals as the current paper).  ======================================== Before rebuttal:  This paper introduces a new method of training a deep encoder-recurrent neural network in order to map behavior of subjects into low-dimensional, interpretable latent space. Behavioral sequences are encoded by an RNN to map into a latent space, which are then decoded and used as the weights (hypernet style) of a second RNN, which is trained to predict the behavioral sequences of each subject. The training loss includes a reconstruction loss, a disentanglement loss, and a separation loss. The separation loss is a novel contribution, and encourages the effect of the latents on behavior to be separable.   The analyses and figures are extremely well-done and clear. They show that on a synthetic dataset, generated by a Q-learning agent with 2 parameters, this method can recover latents that correspond to these 2 parameters in an interpretable way. Without the separation loss, this doesn’t occur. They further tested on a real-world dataset consisting of behavioral data from subjects with depression and bipolar disorder and healthy subjects. They found that one of the latent dimensions could differentiate between the groups, and further that the distances in latent representations between groups was larger than within groups, validating the usefulness of their approach.   The explanations were clear and at an appropriate level of detail. The figures are great, I especially found the off-policy and on-policy simulations to be illuminating and very nice. Along with the supplementary text, the experiments seemed quite thorough. However, I would have liked to see what happens when the number of latent dimensions doesn’t exactly match the number of parameters in the agent generating the synthetic dataset. For real behavioral data, we don’t know the number of relevant dimensions, and it’s not clear to what extent this method relies on knowing this.  The separation loss is quite novel. To what extent can it be generalized to considering not only separating choices, but also options?   Could the authors provide an intuition for how good the approximation in equation 10 is?   Very minor: please provide a citation for “... which is consistent with the previous report indicating an oscillatory behavioral characteristic for this group”. 