As the authors note, the idea of reasoning over both the design of an agent and its control policy is not new, with work in the robotics community dating back at least several decades. However, the large majority of recent work has focused exclusively on control in the context of a given design, with particular emphasis on policies learned via deep RL. Some recent methods have been proposed within the robotics and learning communities that revisit the idea of joint optimization, either via model-based trajectory optimization or model-free RL approaches. This paper continues in this direction by considering the problem of including the agent’s morphology as part of the design space, which poses interesting optimization challenges due the fact that the space is discrete.  The paper describes a framework for jointly optimizing over the space of morphologies and designs using RL (which is better suited to the challenges posed by the discrete-continuous space). Modifications to the morphology (attachment and detachment by individual links) are treated as part of the action space, with a policy that is aware of the dynamic structure of the agent.  As noted, the paper considers an interesting problem (joint optimization over a hybrid discrete-continuous design and control space) and describes an approach that seems sensible (essentially, treating the ability to connect/disconnect from an adjacent link as another action). I find this to be a valuable contribution. However, the paper leaves several open questions that make it difficult to draw conclusions about the effectiveness of this approach.  The paper provides few details regarding the specific nature of the architecture and the training procedure. Hybrid policies such as the one proposed have been found to be difficult to train, requiring careful thought about how one trades off between attachment/detachment and learning the control policy for the current morphology. Did the authors find the architecture to be similarly sensitive to this scheduling?  The training and evaluation consider environments that are not standard in the community. The need for a new environment is attributed to limitations of existing environments when it comes to modifications to the topology. This is unfortunate as this makes it difficult to judge the richness of the environment (e.g., are ground contact forces modeled? How about contact between limbs?). It is not clear why environments built around Mujoco or PyBullet (e.g., OpenAI Gym) would not allow for variations in the topology.  The paper makes vague references to “messages” communicated between limbs, but the nature of these messages is not clear (as is their relationship to the claim that limbs aren’t aware of other limbs).  The proposed framework is evaluated relative to baselines, however the baselines are weak. They include designs hand-crafted by the authors rather than design experts and the fact that the task is solvable with these designs isn’t sufficient to justify their choice. It would be more appropriate to consider a baseline that operated on random morphologies and one that employed Bayesian optimization (an evolutionary approach would be fitting). Given the relative small space of topologies, a random baseline would presumably perform fairly well.  I was surprised not to see a qualitative evaluation of the learned morphologies as well as the learned motion policies for the different settings.  The related work discussion is fairly thorough, with references to relevant decades-old work from the robotics community, which is refreshing. However, I would like to see a more thorough discussion relative to recent work on joint optimization of design and control and call into question the statement that work by Schaff et. al is “concurrent work” as it first appeared in January 2018. At today’s rate, 14+ months is hardly concurrent work.  ADDITIONAL COMMENTS/QUESTIONS  * It isn’t clear how much the controller on each link knows about the overall morphology. In lines 97-98, it is stated that each limb does not know about other limbs (though it has access to a sensor that indicates whether or not it is connected to another limb?), yet the controller on each limb reasons over the morphology. Aren’t these two things inconsistent.  * About which axis is the surface height grid projected?  * The distinction between using vs. not using messages is not clear as this would be a design decision at the outset.  * The paper should report the standard deviation of the reward at test time.  MINOR:  There are a few grammatical errors (e.g., lines 81, ) 