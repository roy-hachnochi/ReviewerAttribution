Originality:  I find this work to be original and the proposed algorithm to be novel. The authors clearly state what they contributions are and how their work differs itself from the prior works.   Clarity/Quality:  The paper is clearly written and is easy to follow, the authors do a great job stating the problem they consider, explaining existing solutions and their drawbacks, and then thoroughly building up the intuition behind their approach. Each theoretical step makes sense and is intuitive. I also appreciate the authors taking time to deriving their method using a simple convex function and then demonstrating that it is possible to extend the method to more general set of functions. At the end, the authors arrive at a quite simple objective function that produces unbiased estimates and is straightforward to optimize. In addition, the proposed objective  is well-behaved and allows to establish some theoretical guarantees on the convergence.  Significance:  The proposed method definitely has a potential to be an important step towards learning robust policies from offline data. This problem has wide practical applications in areas of robotics, natural language, medicine and more, where a lot of offline data has been collected over time. Being able to learn from such off-policy data and then maybe fine-tune the model on-policy would be a significant improvement.    Comments: Line 122:  It might be very hard to make sure these assumptions hold in practise, especially the coverage part, e.g. d^{\pi}(s, a) > 0 implies that d^D(s, a) > 0. How is this handled practically?  