While I acknowledge the novelties of the paper, as outlined above, I think the authors could have done a better job in presenting their results. Right now, the paper looks like a report of a series of tricks to perform better NN decoding of algebraic codes. What is the basic idea behind these tricks and why are they playing a major role in improving the performance with respect to previous methods, e.g. Nachmani et al.? I simply don't see an interesting framework behind this paper.   Also, in the experimental results, why haven't the authors provided comparison with the state-of-the-art decoding methods? E.g. for polar codes, the methods should also be compared with the list-successive -cancellation decoder.  Right now, the methods have a marginal improvement in themes of the error performance with respect to Nachmani's method. 