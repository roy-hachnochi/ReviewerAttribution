This paper brings the techniques of fast sketching and randomized embedding to total regression. These techniques have been extremely successful for giving fast input sparsity time algorithms for approximately computing solutions for linear regression problems. Directly applying these algorithms to total regression leads to much larger running times as compared to the "input sparsity" time established by this paper.   As a result, I think it's an interesting result for the Neurips audience, for a pretty basic problem. To the best of my knowledge, this is the first input sparsity time algorithm for this problem.  On the flip side, this problem is far less omnipresent compared to linear regression, and the techniques involved are the same as developed for linear regression.   The experimental evaluation is reasonable, but unimpressive. The scale of problems that the algorithm is able to handle is medium (~20k rows). The UCI datasets used are also on the smaller side.  Small comment - the figures don't have axis labels / units  - figure 2 is referred in the paper, but is only in the supplementary material - I am not sure I see error bars on Figure 1, though it's indicated in the checklist that they are present  Post-rebuttal: Thank you for your response. I had read your response, and I wish to revise my view of the significance/novelty of the paper. I'm upgrading my overall score to a 7.