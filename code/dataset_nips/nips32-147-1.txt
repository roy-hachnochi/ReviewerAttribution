I think this is a nice model and I like the clean analysis. The paper is easy to read and can be a good addition to the literature exploring connections between fair learning and privacy.  A couple of quick questions. I have read the Jagielski et al paper a while ago but the post-processing can be applied to any classifier, right? Furthermore, their setting can handle statistical parity, right? I would like the section regarding the connection to differential privacy to be a bit more detailed.