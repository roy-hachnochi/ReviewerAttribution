Originality: The work puts together ideas and formulations from various areas. I believe that this work is an interesting extension of the seminal work on CVaR-based RL by Chow and Ghavamzadeh, but I would not consider it as particularly novel. It mainly makes use of the Chow and Ghavamzadeh machinery and proposes an interesting but relatively straightforward extension. 2. Quality: I believe the work is technically correct, even though I was not able to go through all details. Prior works are properly cited and the authors provide proofs to their claims. 3. Clarity: The paper is based on a number of previous works, so it is not easily accessible to an audience without the necessary background. But I think it is clearly written and knowledgeable readers should be able to follow the paper. 4. Significance: Learning options is quite important in the RL context, and robust options have been studied recently [Mankowitz et al.]. Even though I do not feel that the present work advances the theory of robust options in some major way, it nevertheless provides an interesting framework for robust options that additionally incorporate the CVaR concept. Some practitioners may find such ideas useful.  UPDATE I have read the rebuttal and the other reviews, and I appreciate the authors' response to the points I raised. My overall feeling is that this is an interesting work in the field of reinforcement learning with robust options, and the experiments (old and new) look promising. With that said, all reviewers agreed that the novelty over Chow and Ghavamzadeh is not so significant. For this reason, I will keep my weak accept score, acknowledging that this a an above average submission but whose novelty is not particularly pronounced (at least in the present form of the submission).