         1. The main problem for me is that the paper promises a very real scenario (Fig. 1) of how a user can refine search by using a sequence of refined queries. However, majority of the model design and evaluation (except section 4.2) is performed with dense region captions that have almost no sequential nature. While this is partially a strength as no additional labels are required, the method seems suited especially towards such disconnected queries -- there is space for M disconnected queries and only then updates are required.          2. It would be good to have simple baselines that are modified suitably for multi-query retrieval. This would provide a deeper understanding of when the proposed method works better. For example,         (a) scoring each query separately and performing late ranking fusion (either scores or ranks);         (b) concatenating the query and performing retrieval through a typical joint text-image embedding.          3. Results on real user queries are most critical. In Fig. 1, the user queries seem very natural, but the simulated queries in Fig. 4 are not. It is not clear from the provided information, whether the users learn to create queries that just list the objects in the image, or have a more natural pattern of searching for the correct scene, followed by bigger objects/elements, and then their details.          Overall: I'm not convinced of the paper in it's current state, although it is quite borderline. Personally, when doing image search, I noticed that I'm mostly searching for images with a single big object. It is unclear whether users need to find images like those shown in Fig. 4 (middle) and would not rather search using terms like "London skyline", and refine with "Big-Ben tower" instead of vague comments like "water with shadows cast by building". Additionally, Google image search provides a few options based on attributes such as clipart vs. drawing / black-and-white vs. specific color tones / etc. This crucial aspect seems to be missing in the current paper.  ----------------------------- Post-rebuttal: The rebuttal does clarify some aspects about difference between user queries and dense captions (used during training). However, more examples and user queries would be required to fully ascertain that this is a viable option. There are a lot of todo experiments as well for the final version. I update my rating to reflect the score assuming these are incorporated into the final version.