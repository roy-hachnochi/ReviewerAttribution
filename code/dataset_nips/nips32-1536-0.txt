UPDATE: ======== After reading other reviewers’ comments and the rebuttal, I decided to raise my score by one point from 6 to 7. I am satisfied with the effort the authors made to address my two major concerns and I recommend to accept this submission in agreement with the other reviewers.  Overview/Contribution: ======== The paper proposes a dual variational autoencoder to generate synthetic training data to combat the limited data in heterogeneous face recognition. The synthetic data tries to preserve identity via identity preserving generation both in the image and embedding spaces while providing sufficient variation for the training data of the downstream recognition task. The authors claim an 18% improvement in TPR while FPR @10e-5.  Strengths: ========  - Most facial recognition tasks involve certain assumptions that constrain the task into homogeneous set of inputs. Heterogeneous face recognition (HFR) is an important task for many practical applications that is attracting attention recently. Learning heterogeneous face recognition with limited dataset by generating synthetic data is interesting.  - The choice of paired unconditional generation instead of image-to-image translation seem to promote inter and intra-identity diversity while preserving the identity.  - The semi-supervised HFR formulation with an added L2 loss component for the generated unlabeled pair could allow sufficient training of the network while implicitly learning the identity in the case of limited training data such as this HFR.  - Capturing the visual quality and identity preservation using FID and MD in addition to the recognition metric and the ablation of omitting loss components in the generation in Table I is interesting.  - Evaluating the method using multiple HFR datasets helps in drawing useful conclusion. This included near IR (NIR) and visual (VIS) pair and sketch and VIS pairs.   Weaknesses: ===========  - Although there are multiple datasets, the variation in terms of modality is limited to either NIR-VIS and Sketch-VIS. Other heterogeneous datasets with wide variations in resolutions, cameras and environmental conditions would have made the conclusions more stronger. As the task is HFR, more modalities would have been useful.  - In the formulations, there were ‘trade-off’ parameters both in the generation and recognition models yet their effect on the overall recognition is not fully explored. Ablation experiments exploring the effect of each of those terms would have helped to pinpoint from where the significant improvement was coming from.  Overall, the paper reads well and the task is relevant to NeurIPS audience. However, more datasets and more ablations could have helped especially when the major contribution of the paper is paired unconditional generation improves HFR. So, I suggest the authors add another dataset that is different from the pairing explored here such as pose and resolution pairing etc.