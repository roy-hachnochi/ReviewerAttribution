The authors propose a very simple approach to capturing the pictographic nature of Chinese characters into embeddings.  The goal in doing so being that such a representation captures semantic similarities perhaps obvious to the eye but difficult to learn from clustering the character IDs in a downstream task. Further, the authors provide insights into why previous approaches failed to see performance gains.  