The overall problem of integrating neural and symbolic methods via combining deep learning with deductive, inductive, and abductive logical reasoning is an interesting and important problem, as the authors discuss.  The framework that is introduced is interesting and novel and combines deep learning for perception with abductive logical reasoning to provide weakly-labelled training data for the deep-learning perception component.    The technique is fairly precisely defined but it was a little hard following all of the notation and equations.  It would have been nice to have a sample concrete problem as a example to illustrate the description of the notation and algorithm as it was being discussed in section 3.  Waiting until section 4 to see how this abstract formalism was grounded in a concrete problem was a bit frustrating.  I find the author's use of the name "abductive learning" for their framework overly broad and insufficiently precise, there has been a range of prior work on using abduction in learning.  You should give your work a more descriptive and specific title focusing on the issue of integrating deep learning for perception with abduction and deduction for providing it training data.  A lot of other existing work could be called "abductive learning" this term is too general.  Particularly, although the paper reviews a number of related works combining machine learning and abduction, there is a range of work from the mid-90's on this topic that is not mentioned, including:  Inductive Learning For Abductive Diagnosis, Cynthia A. Thompson and Raymond J. Mooney, In Proceedings of the Twelfth National Conference on Artificial Intelligence (AAAI-94), 664-669, Seattle, WA, August 1994.  A collection of relevant papers on the topic from this era is this book: P. A. Flach and A. C. Kakas, editors, Abduction and Induction, 2000. Kluwer Academic   This older work could be cited and discussed.  Some details of the method I found confusing and/or limiting .  When introduced,  the abduced knowledge Delta_c is described as a "set of first-order logical clauses" when eventually it seemed to be clear that these could only be ground literals, not general clauses.  The system for abductive logic programming can only abduce a set of ground literals as assumptions, not general clauses.  Therefore, the only symbolic knowledge it can learn is specific ground literals, not general quantified clauses (e.g. Horn rules).  The fixed knowledge, B, which apparently must be prespecified and cannot be learned or modified by learning, must be carefully crafted to allow the abducibles to represent the requisite symbolic knowledge to be learned as a set of ground literals.  This seems very limiting and requires carefully hand-crafting the actual symbolic knowledge B which cannot be learned.  How could B be automatically learned or revised?  The parameter M, seems like a fairly ad-hoc hyper-parameter which must be manually tuned for a particular problem.  How is this parameter set?  The test problem of visual equation classification seems very contrived and very toy.  It seems the knowledge based B had to be carefully crafted just for this specific problem and this knowledge cannot be learned or modified.   It would be good to show the actual clauses in B,  I would have liked to have seen application of the approach to a more realistic, real-world problem rather than this single, highly-artificial problem.  Overall, I am mildly recommending accept since I think integrating neural and symbolic learning and reasoning is a very important problem and, despite its limitations, the paper presents an interesting new approach for doing this.