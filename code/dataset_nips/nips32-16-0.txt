The methods appear to be new, but they are mostly a collection of pretrained components with minor novelty linking the visual and linguistic components. The submission appears to be technically sound, and the experimental results seem to validate the idea put forth. The analysis is lacking; all the results point to one thing, the effectiveness of the pretraining method for transfer learning. That is the one point, and it seems to be demonstrated, but there is little further discussion. The submission is clear enough, and it is organized well enough to make an easy read. The fact that code is available aids in reproducibility where one might be in doubt about reproducing form the paper alone. The results are not particularly surprising, and they do not seem particularly revolutionary. Rather they seem like a reasonable next step for extending BERT. This is not to say the results are not valuable, only to properly scope the importance of this singular work given that much similar work is likely. Others will likely make use of this work and refer to it in the multimodal setting. 