First, I would like to commend the authors on a very nice paper. I found the paper to be exceptionally clear and well-written. Moreover, the introduction provides a clear and thorough review of the related literature. The results are clean, and I believe are of great theoretical value.  Overall, I think this is a very nice paper. I only have a few comments:  1) In Remark 1 (lines 160-168), the authors state that "the DIGing algorithm can also be related to EXTRA [...] our technique covers that form of DIGing". I feel this is a misleading statement. DIGing is a fundamentally different algorithm from EXTRA in that it requires two communications through the graph in each iteration. In the DIGing paper (ref [2]), when the authors mention that DIGing is related to EXTRA, their precise statement was that if you choose the two mixing matrices of EXTRA in a particular way. i.e. W1 = 2W-I and W2 = W^2, then it BECOMES DIGing (note that choosing W2=W^2 means that you're communicating twice). Returning to the present manuscript, it is therefore meaningless to say that the new algorithm covers both EXTRA and also "that form of DIGing", since that form of DIGing is identically equivalent to EXTRA.  2) In the discussion that follows Theorem 2 (comparison to EXTRA in the case R=0), the authors claim that they provide a tighter bound on the stepsize mu than the bound in the original EXTRA paper (ref [1]). Again, I think this statement needs more qualifications. The two papers make different assumptions about the objective functions and therefore the results are not directly comparable. Specifically, the present paper assumes each J_k is smooth+strongly convex and that R is convex. Meanwhile, the result from the EXTRA paper only assumes that the global objective satisfies a restricted strong convexity property (the individual J_k need not). Since the present manuscript makes stronger assumptions than the EXTRA paper did, one would expect the bound to be tighter.  3) In the numerical simulations (Section 4), the authors state that PG-EXTRA is observed to converge linearly, but there is no theoretical guarantee that they in fact do. I am not familiar with PG-EXTRA, but since the proposed algorithm subsumes EXTRA in the R=0 case, does it also subsume PG-EXTRA in the R != 0 case? It would be worth briefly discussing this, since EXTRA and PG-EXTRA have such similar names and were developed by the same authors.