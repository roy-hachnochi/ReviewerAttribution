The results are very interesting, technically sound, and the paper is well written, in particular the proof sketch is very useful.   The main critical comment I have is that the results require the RIP constant to satisfy \delta = 1/sqrt{k}, where k is the sparsity. A sub-Gaussian random matrix satisfies the RIP of oder k with high probability provided that the number of measurements (or rows of the matrix A \in \reals^{n\times d}), n, obey:  n >= c \delta^{-2}(k log(d/s))  With \delta = 1/sqrt{k} as required by the theory, the number of measurements/rows of A needs to satisfy:  n >= c k^2 log(d/s)  I.e., the measurements need to be quadratic in the sparsity in contrast to l1 minimization, which only requires the RIP constant to be a fixed constant, independent of the sparsity, to succeed, and thus only requires the number of measurements to be slightly larger than linear.   Thus, the algorithm presented (or at least its guarantees) are highly suboptimal in the sample complexity. It would be important to prominently mention that (otherwise the title `optimal sparse recovery' is misleading). Also it would be interesting to add some numerical studies that show what happens when this condition is violated, to investigate whether the condition is an artifact of the theory or a property of the algorithm. For example, one could do phase transition curves (different to the ones in the paper, relating recovery performance k versus n) and compare them to lasso.