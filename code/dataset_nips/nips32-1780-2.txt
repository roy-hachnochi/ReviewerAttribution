Comments: 1. The audio quality and inference speedup are impressive. 2. In session 3.2 Length Regulator, the hidden states of the phoneme sequence are simply repeated, which is very much like what Gu et al. did in "Non-autoregressive neural machine translation". However, the advantage of attention-based sequence-to-sequence speech synthesis model is the soft alignments between phonemes and spectrograms. Empirically, the soft attention gives better prosody and more natural speech. Won't the hard alignments(rounding and repetition) hurt the performance of the proposed model? 3. In session 3.3 Duration Predictor, the proposed focus rate F has nothing to do with "measuring how an attention head is close to diagonal". Focus rate sort of measures the overall confidence of attention alignments, but doesn't constrain the attention alignments close to diagonal. Also, it's hard to understand the behavior of each head in multihead attention, and in many cases, the attention doesn't have any clear visual meanings at all. Then why diagonal alignments are good and what if there is NO diagonal alignments in multihead attention? 4. The title is improper. In TTS, "controllable" always means the prosody or pitch diversity under expressive settings. In session 5, the voice-speed control and breaks-between-words control are trivial to TTS models. It shouldn't be called "controllable".