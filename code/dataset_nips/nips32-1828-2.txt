It is overall a good quality paper. However, a few details could be improved.  1. Can the authors assign a name to their metric? It would help others to adopt it more easily.  2. Can the authors better categorize the tasks according to different aspects that the tasks can reveal about a system’s language understanding ability? Basically, is there a deeper motivation other than the chosen tasks are “more difficult”?  3. In terms of the reflection on a system’s language understanding ability, different tasks will have overlaps. Have the authors considered such bias in the overall metric?  4. Could the authors provide more dataset stats on WSC? The original test set is sometimes considered to be too small. How large is the test set size here?   ------------------------------- I thank the authors for providing such detailed responses, which have addressed all my concerns. Thus, I am increasing the score to 8.