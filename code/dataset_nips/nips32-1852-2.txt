I found this paper fascinating to read. I think this paper is quite strong, so my comments will be brief, aside from one recommendation (see Improvements) section that could potentially strengthen this work.   Summary:  This paper investigates the use of models pretrained on Imagenet that are used for transfer learning on medical applications. This is a ubiquitous practice, and this paper contains many (sometimes counter-intuitive) insights for the field of deep learning on medical images. Primarily, this work suggests that pretraining may be of little to no value for a sufficiently large (see improvements section for more) medical imaging dataset. Even more surprisingly, they find that relatively small models trained solely on the medical data are as good or better than large models like Resnet50 that are pretrained on Imagenet! I find this to be very surprising and exciting.   The rest of the paper is devoted to some very creative explorations to explain this key finding. I think this paper should be read by everyone doing medical imagining as it contains numerous pieces of insight and should make us all reconsider what best practices ought to be.   Originality Very original and creative paper. They underlying hypothesis (does transfer learning help in medical imaging)  Clarity An extremely well written and lucid examination of transfer learning in medical imaging. The presentation flow very smoothly from section to section and is easy to follow.   Significance  Very high significance not only to medical imaging, but also to computer vision as a whole.   Response to rebuttal: I have read the authors responses and found them suitable, and my score of 8 remains