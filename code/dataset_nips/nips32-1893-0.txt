The paper presents a neural network model for image registration, which generates an arbitrary displacement field to transform the input image in a way that matches the target. This neural network has several components, including a common feature extraction model that results in a 4D tensor with the correlations of local features from both images. The tensor is then transformed into a vector representation of the transformation, and later used to reconstruct a displacement field.  COMMENTS Overall, the work is relatively well presented and provides details to understand most of the formulation and solution. However, there are some confusing aspects that could be clarified or stated more prominently. * My understanding is that the components described in section 3.2 and 3.3 are the central contribution of this work. Section 3.1 describes a strategy used before by other researchers, as well as the loss functions, which seem to be standard and adapted for this work. Is this correct? * I found it difficult to understand the motivations behind these two components. While it seems reasonable to use them and the design looks coherent, no much discussion is provided about why the authors think this is the way of modeling the architecture. * The number of 4D conv-layers is not mentioned, so apparently it's only one layer. How critical is the 4D convolution in this architecture?  * The geometry of the filters (Sec. 4.1) does not match 4 dimensions: I assume a tensor with dimensions (w,h,w,h), while the size of the kernels is (3,3,3) with channels (10,10,1). Can you clarify? * I understand another interesting component of the proposed network is the displacement field predictor, which replicates the transformation vector n times, with n, the number of 2D points in the displacement field. I could not follow the continuity argument completely, and the smoothness vs complexity either. The authors say that they prove that spatial continuity is guaranteed, but the provided explanations don't seem to be a sufficient proof to me, unless I missed something. * The experimental results seem generally coherent, but the terminology does not quite match the conventions in the solution. More specifically, parametric and non-parametric transformations is something that was not mentioned in the formulation, and it is difficult for the reader to follow exactly what the authors mean. * The writing style needs polishing. In general, the ideas are well organized, but the text needs grammar improvements all around. The current version is distracting and makes it difficult to follow some details.  In summary, the paper has interesting ideas, but it still needs to improve quality of presentation significantly to be a robust submission.