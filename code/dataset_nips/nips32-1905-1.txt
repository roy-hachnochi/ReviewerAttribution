This paper is a fairly straightforward but sensible extension of  ROC/AUC to compare the quality of ranking across groups. xAUC is just the probability that a positive instance of group a is ranked above a negative instance of group b.   The paper is well structured and clearly written and I would expect these metrics to be widely adopted in quantifying fairness.   I have read the author response and comments from other reviewers. I am still of the opinion that this paper represents a significant contribution. I strongly argue that it be accepted.   I agree that this paper does not tell you when you should sacrifice accuracy to reduce xAUC disparity. However, I think is unreasonable to expect that it answer that question, as such an answer will be incredibly context dependent and will be based more on sociology, political science & philosophy than on machine learning. Almost no paper on fairness in ML would have been published if this was the standard.  I agree that there are too many papers in ML introducing new fairness metrics with very limited justification for them. But I don't think this paper falls in that category because:  1) They show how their metric helps clarify the Compas debate - which is a seminal example of fairness in ML,  2) Their metric is closely connected to (and a means for visualising) concerns relating to separation - which is one of the fundamental, widely discussed and used existing notions of fairness. From this point of view they are demonstrating a way of quantifying an existing fairness concept in the setting of ranking rather than introducing an entirely new (and disconnected metric).  3) This paper has done a substantially better job of clarifying the implications of their metric and how it connects with other metrics than most papers in this space. A clear understanding of the properties of a metric (as is given in Section 6) forms the starting point for the discussion of whether it is or not appropriate within a given context.