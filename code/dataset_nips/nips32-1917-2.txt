* Summary The authors study the problem of deletion efficient learning, i.e., given a dataset D and a model M, how to 'quickly' form the new model M' such that it is equal to a model trained on the dataset D' where some item has been removed? Here quickly means faster than the naive approach of retraining a model on the dataset D'. The paper contains a theoretical part and an empirical part. The theoretical part defines the problem and presenting two variants of the k-means algorithm that are deletion efficient. In the empirical part the authors investigate the performance of their algorithms and conclude that they are faster than the naive approach of retraining a model.   * Originality The authors state the concept of deletion efficient learning is novel, and based on this it appears that the ideas presented in the paper are new. Also, the two algorithms appear to the best of my knowledge to be new variants of k-means.  There is no separate 'related work' section in the paper, and I would encourage the authors to add a such, pointing to research that is (closely) related (such as the privacy-related matters mentioned in the paper). This would help the reader to better position the present work.   * Quality I think that the technical quality of the paper is good. The problem being studied is clearly defined and the notation is also OK. The two algorithms are presented in sufficient details in the main paper. Proofs are not presented in the main manuscript and I did not check proofs in the appendix.  I found the empirical evaluation OK, and I think it demonstrates the utility of the presented algorithms.  In overall, I think that this is a well-written paper that is also well motivated. However, I think that the authors might want to "downplay" the data deletion efficient learning in machine learning as a general concept, since the focus in the main manuscript (I did not check Appendix E in detail) is in fact only on deletion efficient unsupervised learning, specifially k-means clustering. If the authors have some relevant points concerning supervised learning methods, I think it would be very important to bring these forward in the main paper. This is due to the fact that supervised learning algorithms are much used in various domains and I think that the impact of this paper would be greater if deletion efficient learning in the domain of supervised learning would be discussed in more detail in the manuscript.    * Clarity The paper is well structured and the langauge is clear. The introduction is clearly written and provides a good motivation for the work. The experimental evaluation is also clearly presented. I found some minor typos:  - Sec. 3.2, paragraph 1: "as and independent" --> "as an independent" - Sec. 4, Datasets: "we run our experiments five" --> "we run our experiments on five" - Table 4: MNSIT --> MNIST   * Significance Summarising, I think that the ideas in this paper might be of interest to the machine learning community and can possibly spur new research.  * Update after Author Feedback I have read the author feedback. I find it good that the authors will try to include some more discussion concerning supervised learning in the manuscript, which I think will make this paper even better. 