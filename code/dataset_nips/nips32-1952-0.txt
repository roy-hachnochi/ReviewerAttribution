After reading the feedback, I am still not fully convinced that the results are significant, but I think the feedback makes sense. Therefore I've increased my score to 5 (weak rej). Here is the reason.   I think this is an interesting paper, and the observations are good to know. However, maybe because I am from theory community, I feel the results are not that significant for the following reasons.   1. If an empirical paper has significant results, I usually believe that they should provide better empirical performance, e.g., better test accuracy, running time, memory requirement, etc. This paper does not provide a better algorithm. The best mask they find has similar performance as the existing one.  2. Since this paper does not have better empirical performance, I tend to hope that it will give us better understanding of lottery hypothesis. However,  (a) First, all the experiments are run on small datasets, like MNIST/CIFAR, and not on large datasets, so it is not clear whether the claimed observation is universal.  (b) Secondly, it is not clear whether the presented observations are useful. For example, the authors show that LT is also valid on "magnitude increase" mask, and keeping the sign of initial value is more important and keeping the value. I agree those are interesting observations, but I don't know why these observations are important or significant. Is it for better pruning algorithm? But the authors say the performance is similar. Is it for understanding the training process of neural networks? But the authors did not mention any explicit connections, and I couldn't think of any as well. If LT becomes a universal algorithm that will be applied everywhere, then I think the exploration made in this paper might be valuable. But currently this is still not the case, as far as I know.   Therefore, personally I would not be willing to increase my score to weak accept/accept for this paper.   ---------------- Originality: this paper is doing ablation study on the previous lottery ticket paper. Therefore, the originality is limited.   Quality: this submission is purely empirical, and the authors use the plots to show their claims. The experiments are only on CIFAR-10 and MNIST, so not very convincing.   Clarity: I think the clarity can be further improved. There are so many different kinds of masks, and it seems to me that most of them do not work well. If that's the case, maybe the authors should consider remove some irrelevant curves, to make the plots easier to read. Moreover, it is hard for me to get the main message from the text.   Significance: I think the results are interesting, but I am not sure whether they are significant. For the first result, the outcomes of "magnitude increase" and "large final" look similar to me, and it is not clear what the authors want to show here. For the second result, keeping the sign of the original initial value looks very interesting, however I do not know what the indication of this observation is. For the final result, masking is training is a nice claim, but again, I do not know what is the message that the author wants to deliver. I feel this paper still needs some work on showing why the results are important.  