# Response to rebuttal  I would like to thank the authors for their rebuttal.   Overall, my opinion about the manuscript remains unchanged. Despite some drawbacks, such as the lack of results using more challenging datasets and/or more complex architectures, I believe the paper presents a well-executed empirical analysis that addresses some questions about the LTH, as well as raises some new ones, making it interesting for future work. Therefore I will keep my previous score, supporting acceptance.  # Summary  In this paper, the authors present an empirical study to investigate the recently proposed “Lottery Ticket Hypothesis” by means of ablation experiments.   In brief, “Lottery Tickets” (LTs) are sparse subnetworks which can be (re)-trained in isolation and yet achieve comparable or even better performance than the original, unpruned network. Prior work identified these LTs by first training the full network and then 1) selecting the (100-p)% weights with smallest absolute magnitude after training as weights to be pruned; 2) resetting the p% weights to be kept to their initial value; and 3) setting all (100-p)% pruned weights to zero and keeping them frozen to this value when (re)-training the subnetwork. In particular, prior work found step 2) to be crucial; if the p% weights to be kept are not reset to their initial value but rather randomly re-initialized, the (re)-trained LT is no longer able to perform comparably to the full network. All in all, prior work presented compelling evidence backing the “Lottery Ticket Hypothesis”, yet many aspects of these findings remained poorly characterized.  In this manuscript, a comprehensive set of ablation studies were performed to empirically explore additional degrees of freedom for each of the three steps above. Specifically:  1) Alternative criteria to select the set of weights to be pruned were considered, including initial magnitude, a combination of initial and final magnitude, magnitude increase and absolute difference between initial and final weight values. Additionally, “sanity-check” control criteria were also included, such as random selection and “inverted” versions of some of the aforementioned approaches.  2) Alternative ways to reset the value of the weights to be kept were considered, including random re-initialization, permuting the initial values within each layer and initializing the weights to constant values with a random sign. Additionally, alternative versions of each criterion guaranteeing that the sign of the resetted weights agrees with the sign of the initial weights were also included.  3) Alternative ways to select the values at which to freeze the pruned weights were considered, including freezing them at their initial value, setting them to either zero or their initial value depending on whether they moved towards zero or not after training the full network and “sanity-check” controls such as randomly setting them to either zero or their initial value.  The results of these ablation studies provided clear additional insight on the “Lottery Ticket Hypothesis”. In particular: 1) the phenomenon is not exclusive to the original criterion used to select the set of weights to be pruned; 2) resetting the kept weights to their initial value does not appear to be strictly necessary as reported by prior work, but keeping the signs identical seems to be crucial; and 3) pruned weights can be set to either zero or their initial value when the decision is informed by the dynamics of training in the full network, suggesting that masking pruned weights of small magnitude after training might work partly because it is somewhat consistent with the training dynamics.  Finally, the authors also introduced the concept of “Supermasks” by observing that LTs have better-than-random accuracy even before training the subnetwork, showing that despite being computed in crude ways, these masks can encode substantial information about the (supervised) learning task at hand.  # High-Level Assessment  The recent discovery of the “Lottery Ticket Hypothesis” has led to many unanswered questions of high relevance to the field, some of which this paper explored with a thoughtful and well-executed set of ablation experiments.   Despite still largely lacking a theoretical characterization of the phenomenon, I believe the empirical results reported in this manuscript would be of interest to the community and might pave the way to impactful future work.  The paper is very well-written, being generally a pleasure to read. Moreover, all aspects of the experimental setup are clearly detailed and seem reproducible, which is of particular importance in a paper with empirical results as its main contribution.  Because of all the aforementioned reasons, I am in favour of accepting the manuscript for publication.  # Other Comments  1. The main conclusion of Section 3 seems to be that as long as the weights to be kept are resetted to a value with the same sign as they had initially, (re)-training the LT will be successful. However, as shown in Figure 4, while this trend indeed seems hold generally, it can also be noticed that randomly re-initializing the weights can sometimes perform poorly even when the signs are respected (e.g. Conv4 and Conv6), as originally reported by Frankle & Carbin. Do the authors have any conjecture about why this might be the case? Is there something else essential for the “Mask-1 action" other than keeping the sign?  2. Regarding the optimization of “Supermasks” described in Section 5.1:  2.1 Given that the masks are stochastic, how are the LTs used at testing time? Are they substituted by their expectation, or is a MC estimate used instead (if so, with how many samples)?  2.2 Has there been any attempt to initialize the “Supermasks” prior to SGD-based optimization by, for example, making the initial value of m proportional to the scores of the “large_final_diff_sign” criterion?  2.3 Do the initial, frozen weights play a crucial role in these experiments? Can good performance be achieved if these weights were, for example, set to have constant magnitude with random signs?  3. Perhaps a natural extension of the different masking criteria introduced in Section 2 would be to consider the entire optimization trajectory instead of only the endpoints. Have the authors considered in any preliminary experiment to, for example, substitute the initial value of the weights in their criteria by the value of the weights after a few steps of training?  # Typos  Line 183: treaments -> treatments Lines 209 - 210: there might be a missing word