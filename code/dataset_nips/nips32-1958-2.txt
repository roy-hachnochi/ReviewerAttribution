The main contribution is the loss contribution metric. The metric is then applied to analysing deep neural networks. It is a challenging task to define a clear and interpretable metric that shows a new suprising perspective on the training of deep networks and the authors managed to do it. I believe that the experiments clearly demonstrate utility of the metric and the results are surprising. The paper is very well written. I was a bit let down that there is no novel practical tricks presented (see below for details). Nevertheless, the paper will be clearly of interest to the community, and I am quite optimistic that future work will bring more practical applications of the developed metric.  Detailed comments  1. Showing oscillatory-like behavior in training is not very novel. "Walk with SGD" (https://arxiv.org/abs/1802.08770) and "On the Relation Between the Sharpest Directions of DNN Loss and the SGD Step Length" (https://arxiv.org/abs/1807.05031) seem to already show a quite related dynamic in training. The first paper shows that the gradient oscillates (i.e. cosine is negative between subsequent iterations). The latter paper shows that there are directions in the weight space (corresponding to the largest eigenvalues of the Hessian) where training is unstable. What is novel, I agree, is that such a behavior happens on the parameter-level, that it is as dominant as shown, and how parameters switch between helping and hurting. It would be nice to contextualize prior work in a bit better.   2. Instability of the last layer was discussed by some prior work, e.g. https://openreview.net/forum?id=r14EOsCqKX. Freezing layers, especially the last one, is also not novel. In https://openreview.net/forum?id=r14EOsCqKX they also freeze the last layer.  3. The paragraph "Learning is heavy-tailed" could be made a bit more precise. For instance, how would refining the view of learning as a Wiener process alter the conclusions made by these papers? It wasn't very clear to me.  4. I would, though it is personal taste, remove exclamation marks. I think using them is not the best practice in scientific writing.  5. Experiments show on the example of the first layer that freezing a layer that hurts might hurt even more because other layers help less. This is not very intuitive. It also seems to limit applicability of the developed metric (if the metric shows layer hurts, we do not know if we should improve it or not). If possible, it would be nice to explain the result better.  Update  Thank you for the well-written rebuttal! I decided to keep my score. I would encourage authors, in case paper ends up rejected, to run experiments suggested by one of the reviewers and examine effect of skipping updates that are calculated to be negative, or any related experiment that would pinpoint the causal effect these dynamics have on the training performance.