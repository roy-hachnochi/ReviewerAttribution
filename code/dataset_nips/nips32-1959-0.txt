Originality:  This paper proposes a brand new dataset that is unique in that it contains images paired with text with bias labels (both noisy labels from source and also human labels).  The methods described are similar to existing distant supervision techniques though they use it for new analysis on this domain.  Quality:  The experiments seem sound to me.  They test on two different sets of labels and achieve consistent results that are reasonable (e.g. ocr performs better with logos).  I think there is room for them to add more analysis of the distant supervision technique and possibly include ablation of the approach to verify how much performance gains come from different components.  I was curious whether you verified how much performance differs with and without stage 2 of the training?  Similarly, is there a “sweet spot” in the amount of text data used helps vs. hurts during training?  Clarity: Overall, the paper was well-structured and easy to read, with only a few points that I found confusing.  I wanted to clarify about the Ours-GT model described briefly on line 242 because it was a bit ambiguously worded.  What do you mean by “ground truth text embeddings”?  Significance:  The dataset, itself, is a potentially high impact contribution.  The techniques and analysis are also interesting to read and indicate possible avenues for future research.