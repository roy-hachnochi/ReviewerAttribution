* summary: This paper makes a connection between Graph neural network (GNN) and some computer vision tasks. They introduce an adaptive GNN formulated as a label propagation system, which can be related to two CV operations: filtering and propagation. Their adaptive GNN is designed based on guided map, graph Laplacian and node weight. The guided map and node weight are associated with filtering and propagation diffusion task in computer vision, and kernel of graph Laplacian is related to the diffusion pattern in computer vision task. They applied their model for quotient image analysis (QIA) and designed various illumination editing tasks for faces and scenes.  * strengths:  - The main idea of relating the GNN to some CV tasks is really interesting.  - I like the way they narrate their work. After introducing their framework, they discuss how this model is a generalization of several models introduced for propagation diffusion and filtering.   * Notes:  - I think there was a lack of visualization or diagram in the paper. They could benefit from some pictures to make the main idea more understandable and easier to follow.  - It would be very informative if they could explain the intuition that why and how “the guided map and node weight determines whether a GNN leads to filtering or propagation diffusion, and the kernel of graph Laplacian controls diffusion pattern.”  - My main concern about the paper is the lack of enough experiments to show the efficacy of their propose model. They performed a qualitative experiments on a handful of images for the tasks of “face relighting,“ Illumination-Aware Face Swapping,“ “Transfiguring” as well as “low-light image enhancement.” They showed the results on a few images only. More importantly, there were not any qualitative experiments in the paper. How about post-hoc crowdsourced workers to rank the enhanced images; and then compare various methods together.  - In the experiments, I would explain in a few sentences how their images are semi-supervised.  - It would be very helpful if they could discuss the computational cost of their framework?  - There is a minor grammatical mistake in sentence “199 in in background, eyes and eyebrows, while preserve the information in facial region. The setting of”  - There was a question mark for Fig that needed to be corrected (I think it should be Fig 2). It is on page 7, last paragraph, second line.