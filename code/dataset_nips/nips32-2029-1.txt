The paper is thought-provoking -- especially in the way it identifies errors and then uses brute-force search to look for solutions that minimize distance in the compilation space. The method is not pretty, as the brute-force search through the high level language space could certainly be improved.  The paper throughout is frequently unclear and confusing to read. How do the two LSTMs for the left and right subtree children work?  How exactly is the error prediction module trained? The paper makes a distinction between functionally preserving the code, and also semantically preserving the code. In this context, program language semantics has a distinct meaning -- another word should be used and this concept clarified.  There are too many acronyms that make the paper difficult to read. e.g. LD for Levenshetin distance is not a common or well known acronym.  It would be useful for the authors to rescheck their answers on the reproducibility checklist. 