The submission proposes a model for time-series clustering. The model is a novel combination of several existing components: a) a deep recurrent auto-encoder using dilated RNNs, b) a spectral relaxation of the K-means objective and c) a self-supervision loss to discriminate time-series corrupted by random shuffling from the original ones. The model is evaluated on a common benchmark for time-series clustering and achieves superior performance to existing methods.  Overall I feel positive about the proposed method as the quantitative results look promising and using the spectral relaxation of K-means for deep clustering is novel and original. Nevertheless I do have some concerns about the submission in its current form:  1.) As far as I understand the time-series in the UCR benchmark are of fixed length for each category. In that sense there is no reason to explicitly model them as time-series but one could technically consider them as static vectors. Therefore one should compare the proposed method to an appropriate subset of the large body of recent work in deep learning clustering methods for static inputs (e.g. see [1] for recent overview).  2.) The submission has no discussion/analysis on how to treat the case if the number of clusters K is not known a priori, which is often the case for real world problems.  3.) The analysis and results in sections 4.3.2 and 4.3.3 are purely qualitative each evaluated on a single time-series clustering problem. It is not clear what general properties about the algorithm can be inferred.   Minor comments - The paper mentions sequence-to-sequence modeling multiple times, it should reference the original paper using deep learning for seq2seq [2]  - Typo in author name in line 119: Zhang et al. should be Zha et al.  References [1] Aljalbout, E., Golkov, V., Siddiqui, Y., Strobel, M., & Cremers, D. (2018).  Clustering with deep learning: Taxonomy and new methods.  arXiv preprint arXiv:1801.07648.  [2]Sutskever et al., Sequence to Sequence Learning with Neural Networks NIPS 2014  ———————————————————————————————  Given the author feedback, in particular the comparison with DEC and iDEC also on a separate, larger dataset, I am happy to increase my score to 7.