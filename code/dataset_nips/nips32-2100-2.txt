The paper improved a previous score-based blackbox attack "Prior convictions: Black-box adversarial attacks with bandits and priors" by leveraging gradients from substitute models. In details, they first train several reference models. When generating adversarial examples, gradients from one reference model will be randomly picked to calculate the search directions. Gradients w.r.t the input image will be approximated based on the calculated search directions. Finally, the adversarial examples are generated through iterative-FGSM/PGD.  The proposed method successfully improved the query-efficiency and failure rate of the Bandits-TD method. The improvement comes from the gradients of reference models. However, when training reference model on ImageNet, 75,000 images from an auxiliary dataset and all the images from the ImageNet validation set are used. One concern is that in reality, the adversary may not have access to such large amount of auxiliary images and validation images. Without those images, it will be hard to train a useful reference model thus cannot improve the query-efficiency of blackbox attack. It seems that such efficiency does not come from the method but from extra information.   Originality: the idea is not brand new. Works with similar ideas are available online, such as "Improving Black-box Adversarial Attacks with a Transfer-based Prior".  Quality: The method is technically sound and the evaluation is fair. But it is not supported by theoretical analysis.  Clarity: The paper is clearly written and well-organized. Adequate information and code are provided for reproduction.  Significance: Improving the query-efficiency of score-based attack is good but it depends on the availability of extra information.