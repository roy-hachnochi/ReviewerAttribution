This is a nice idea, a well-written paper, and should definitely be published. It is interesting for the NeurIPS community, because it presents a way to convert essentially arbitrary flow models into lossless compression methods. It is conceptually interesting, and there are plenty of potential applications.  My only criticisms are with the discussion and evaluation.  First, BB-ANS suffers from significant overhead due to the requirement to send auxiliary bits. The authors don't really discuss this sufficiently, and claim that it is negligible when encoding long sequences of i.i.d. data such as video. The reported overhead is between 1000% and 1200% of the code length, which is a lot even for video (one reason is that the first “intra” frame typically contains many more bits than the subsequent “inter” frames. Hence, to amortize 1000% of the size of the first frame could take hundreds or even thousands of subsequent frames). Overall, it would be honest to concede in the discussion that this is a shortcoming (but can of course potentially be worked around). Right now, it's up to the reader to work out that the auxiliary bits could be a problem in practice.  Second, regarding runtime, the authors state that “the compositional algorithm is only slightly slower than running the neural net on its own”. This may be true in terms of “wall clock” time, but what really matters is how many CPU/GPU cycles were actually utilized. This is what is of practical concern. It appears the authors here engage in a comparison of “apples to oranges”, since it’s quite plausible that the CPU has substantially more idle time for running just the flow model compared to running bits-back coding, since BB-ANS runs on the CPU. The authors need to report cumulative CPU/GPU times rather than wall clock time to be able to make a claim about computational complexity. For instance, if the flow model doesn’t utilize the CPU at all, the authors are effectively giving their method a significant amount of additional resources over the baseline.  EDIT: I thank the authors for their clarifications. Based on this, I’ll maintain my initial score.