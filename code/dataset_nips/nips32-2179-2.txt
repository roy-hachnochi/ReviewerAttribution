Limited novelty: The proposed approach is closely related to two lines of related work: 1) sg2im [4] which generates images from scene graph representations, and 2) semi-parametric image synthesis [3], which leverages semantic layouts and training images to generate novel images. The key difference to sg2im is the use of image crops in order to perform semi-parametric synthesis; however, in comparison to prior work on semi-parametric methods [3], as suggested by the authors (Line 82-83) the primary difference is the use of graph convolution architecture, where a similar graph convolution method has been introduced in [4]. Iâ€™d like to see more justifications from the authors regarding the technical novelty of this approach in presence of these two lines of work.  Limited resolution: My concern about the limited novelty is exacerbated by the fact that the generated images are still in low-resolution (64x64) as prior work [4], even though high-resolution image crops are used to aid the image generation process. In contrast, related work [3] is able to generate images of much higher resolutions, e.g., 512x1024, using their semi-parametric method (which was not compared in the experiment). Could the authors comment on the possibility of using this proposed method in generating high-resolution images? The experiment results could be much stronger if the authors can demonstrate the effectiveness of this method in generating larger images.  Crop selection: It is unsatisfying that the crop selector relies on pretrained models from prior work [4] to rank crop candidates, instead of jointly learned with the rest of the model. Is there a way to make the crop selector training as part of the final learning objective?  Relations of scene graphs: The model is trained adversarially with two discriminators on both object level and image level. However, there seems to be no training objective to ensure the pairwise relationships in the generated images to match the edges of the scene graphs. Is there any other learning objective that can ensure the consistency of the relationships between the scene graph and its corresponding generated image?  Figure 2: Is there a mistake in the caption description, which is inconsistent with the main text? Does the top branch generate the new image while the bottom branch reconstructs the ground-truth?