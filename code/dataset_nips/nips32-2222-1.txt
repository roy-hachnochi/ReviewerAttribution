- This paper is new and technically sound. The joint training nature differentiate this work from [12].  - The overall structure and title need some improvement. Before reading into Equation 1, it is difficult to understand what would authors mean by claiming line 32 - 36 in page 1 on the differences between this work and [12]. The claimed contribution is confusing, "Compared to existing lightweight design, the proposed... is more hardware friendly..." as many lightweight network designs are hardware friendly. The joint training or knowledge distillation idea did not show up in these claims. The same issue occurred in Figure 1. By simply reading the figure 1, it is difficult to know the core idea of this work.  - The result is significant as 1% on ImageNet is not trivial. This provides future studies with an empirical result on joint training of multiple classifiers. 