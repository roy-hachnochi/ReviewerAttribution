Originality: I think the specific teaching model proposed in the paper has never been considered in the literature.  Quality: Owing to time constraints, I only managed to check the proofs of Theorems 1 and 2; I think they are correct.  Overall, I think the quality of the main paper is generally very good, with very few typos.  Clarity: The paper is quite clearly written.  Significance: The development of a framework for modelling the teaching of multiple concepts to memory-limited learners is quite significant.  Minor Comments:  - Page 2, lines 67-68: Perhaps state what the acronym ACT-R stands for (just like other model acronyms used in the same sentence).  - Page 4, equation (5): Should this definition/notation be extended to the conditional marginal gain of teaching a _sequence_ of concepts at time t?  (On page 15, in the last equality before line 476, \Delta is applied to such a sequence.)  - Page 6, Section 4.2: Perhaps explain what a HLR memory model is in more detail.  - Page 9, references [8] and [22]: I suggest either spelling out the acronym PNAS in [8] or using the acronym PNAS in [22] (i.e., stick to only one formatting style).  - Page 10, reference [27]: "The Generalization of [`student's'] problem..."    - Page 14, line 449: Do we need to use the submodularity of \mu to show that g_i(\tau+1, (\sigma_{1:min(\tau,t)},\cdot)) \leq 1$ (if so, it might be helpful to mention this, since string submodular functions were not defined in the paper)?  - Page 14, line 460: "...denote such [a] case by..."  - Page 15, definition of conditional marginal gain of a policy: How is item i (mentioned in Line 468) used in the definition? It might be helpful to give an intuitive explanation for why, on the right-hand side of (12), one takes the concatenation of \sigma_{1:t} with \sigma^{\pi}(\Phi) (similarly for y_{1:t} and y^{\pi}(\Phi)); in particular, why does the sequence of items selected by \pi from t' = 1 to t' = t appear twice (once in \sigma_{1:t} and again in \sigma^{\pi}(\Phi))?  (Did I interpret the definition wrongly?)  - Page 16, inequality between lines 481 and 482:  I could not see why this inequality follows directly from Definition 2.  According to Definition 2, \omega_t is computed by taking the maximum over all (\sigma_{1:t},y_{1:t}) of the maximum expectation over all policies \pi with respect to (\sigma^\pi(\Phi),y^{\pi}(\Phi)); however, imposing the additional condition \Phi \sim (\sigma_{1:t},y_{1:t}) seems to reduce the value of E[f(\sigma_{1:t} \oplus \sigma^{\pi}(\Phi),y_{1:t}\oplus y^{\pi}(\Phi)) - f(\sigma^{\pi}(\Phi),y^{\pi}(\Phi))]/f(\sigma_{1:t},y_{1:t}).           - Page 16, inequality (17): Do we need to take the expectation of the second summand?    * Response to author feedback: Thank you very much for the detailed feedback. I am keen on following future work on this topic, especially any possible long-term experiments on language learning using the paper's algorithm. I will keep my current score.