 I have read the author response and other reviews and decided to keep my original score of 7.   Summary: The paper proposes a family of priors for GANs and VAEs. These priors are mixtures of Gaussians with a large number of components but which can be represented using few number of learnable parameters using tensor ring decomposition. This family of priors enable efficient marginalization and conditioning. The method is applicable to both discrete and continuous latent variables. The method is extended to conditional generative modeling; in particular missing values in the conditioning variable can be marginalized out. Experiments are conducted on CelebA and Cifar10.  Originality: The proposed method is novel to my knowledge.   Clarity and Quality: The paper is very well written and easy to follow. The experiments are somewhat satisfying. I would have liked to see comparison to works using richer priors. For example comparison to the VampPrior [1] for the VAE experiment would be useful. Furthermore, it is not clear whether the TRIP outperforms the GMM baseline solely because it has higher capacity. For example in the appendix it is mentioned that for the GMM the number of components used is 1000; I was expecting 128*10 number of components (128 dimensional latents with 10 gaussians for each dimension). See section 3 of the supplement.  Significance: For the VAE, I would deem this work significant if it was shown that this has the possibility to also help with latent variable collapse. For the GAN I would deem this work less significant as it relies on REINFORCE which is somewhat problematic due to high variance (this is rightfully acknowledged in the paper).   Questions and Minor Comments: (1) What happens when you use this approach to form the variational distribution in the VAE? (2) line 100: it is "log marginal likelihood" not "marginal log-likelihood" (3) For the GAN did you also use multiple samples from the prior as a GAN baseline? (4) Why not use 1280=128*10 for the GMM baseline in the gan model? That would be more fair to the baseline. (5) How do you select the core size m_k?   [1] VAE with a VampPrior. Tomczak and Max Welling, 2018.