# Overall This paper introduces a complex prior (TRIP) for deep generative models. TRIP has tractable marginal and conditional distributions and can produce an exponential number of mixtures of Gaussian with a small number of parameters. Overall, the paper is well written, the proposed technique is elegant and the motivation is clear. The main weakness is the experiment.  # Weaknesses - Some important related works are discussed in Sec.5 but not compared directly in the experiments. What is gained by TRIP vs autoregressive priors [12,13] or flow-based priors [15]? There are no quantitative comparisons between training the generative models with TRIP and with other advanced parametrized priors. - What is the computational cost of TRIP? Since TRIP introduces additional parameters for the prior and brings extra computation, it is worth knowing that how much it slows down the training.