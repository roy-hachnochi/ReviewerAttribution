This paper presents a novel idea to integrate logical knowledge with deep neural networks via logic graph embeddings. The proposed model aims at converting logic formulas to d-DNNF forms such that GCN can be utilized to learn a single embedding for each formula that could be trained through back-propagation. The logic embedder is then further used to improve the main task by incorporating a logic loss.  Overall, this paper is well-written. The proposed methodology is novel and interesting. The authors conduct extensive experiments on both synthetic and real-world datasets to demonstrate the advantage of the proposed model. It is clear that d-DNNF is preferred compared to other logical forms (e.g., general and CNF) from the experimental results. However, it is not too clear to me how exactly the model can be implemented from the descriptions. The detailed comments are the following: 1. Section 3.1 states that there are 5 types of nodes, but "IMPLY" is replaced with disjunctions in both CNF and d-DNNF forms. Should there be only 4 node types for these situations?  2.In section 3.2, how do you obtain the assignment embedding, e.g., p^q^...z? Do you initialize the embeddings for p,q,...z and then train them jointly? Do you treat the embedding of the topmost node as the formula embedding? Then what's the use of the additional global node mentioned in line 93? More details should be given in section 3.2 to illustrate how to compute q(f) and q(F/T).  3. In section 3.3, it is also unclear of how to compute q(h). Given a neural network, how does it contribute to the logic embeddings, i.e., what does those p_i correspond in this mapping?  4. The model separates the training of a logic embedder and the final target task. I'm wondering why not combine them jointly so that training loss can be propagated and the framework becomes end-to-end?  5. For experiments, what's the statistics of the synthetic dataset, besides the 3 different levels. (What's the number of training instances for each dataset?) For Figure 3(c), the performance pattern seems not normal. The proposed model has large gains for moderate dataset but less obvious in high dataset. Can you explain the reason? Moreover, the results for both synthetic dataset and VRP dataset are not too convincing when the authors only compare with different logic forms and treeLSTM. There are many neuro-symbolic methods, e.g., Logic Tensor Networks. It could be better to compare with those architectures.