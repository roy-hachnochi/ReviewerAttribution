Significance (6/10) ------------------- Minor insights like the fact that Bernoulli mixup seems to perform worse than linear mixup can be gained from this paper. Based on the results, I don't expect widespread adoption of adversarial mixup as a regularizer but the paper will nevertheless be interesting to some.   Originality (5/10) ------------------ The approach seems straightforward based on the ideas that exist in the literature.   Quality (6/10) -------------- The quantitative experiments seem reasonable and well executed. What's missing are comparisons with further baselines / better benchmarks. For example, it is not clear from the paper whether I'd want to use any form of adversarial mixing to regularize my classifier compared to or in addition to other data augmentation techniques or dropout, for example.  The interpolation results (Figure 1) are surprisingly poor, with not much semantic interpolation and a lot of the kind of ghosting artefacts expected from linear interpolation.  The authors claim that a "fundamental difference" between mixup and VAEs is that they "impose no constraint, at least not in the probabilistic sense." I disagree with this statement. In the extreme case of picking each latent dimension from the representation of a different image, you'd be generating independent coefficients just like in a VAE, except you'd sample from an empirical distribution instead of a Gaussian. That is, Bernoulli mixup introduces statistical independence assumptions, even if the authors don't present them as such. It would enhance the paper if the authors could formalize a connection between Bernoulli mixup and nonlinear ICA, and perhaps also explore the probabilistic interpretation of linear mixup.   Clarity (7/10) -------------- The paper is mostly well written and clear.  Please explain how the parameters of p = embed(y) are trained. Since the image is dependent on y only through the binary mask m ~ p, and this Bernoulli sampling step is non-differentiable, it is not clear to me how this embedding is trained.  The authors write that they "collect the highest accuracy on the validation set over the entire course of training". Please make explicit that you used separate validation and test sets to eliminate any doubt that the results are biased.  Before Equation 7, the authors write that these losses are optimized "in addition to their unsupervised losses described in Equation 3". The "min_F" in front of the loss in Equation 7 suggests that only these two terms are optimized with respect to F. This should be clearer.