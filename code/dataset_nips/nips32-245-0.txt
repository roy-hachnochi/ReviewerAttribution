In general, I like the paper: it tackles previously under-explored task and proposes a novel approach to tackle it.  The paper is well-written and easy-to-follow, however I suggest improving exposition of "graph context encoding" by providing more detailed explanations or preparing illustrations.  The overall approach appears to be novel to me. The main idea is to train a generative model of pixel representations that is conditioned on text embedding of seen and unseen classes. Later, authors use this model to train a classifier for unseen classes. As an additional step, authors demonstrate that pseudo-label technique can be used to further improve performance.  The experiments are conducted on two challenging datasets and quantitative/qualitative results appear to be rather convincing.  I am mainly concerned with the choice of baselines. Authors implement only a single baseline. In theory, it may be sufficient, considering that zero-shot segmentation learning appears to be a novel task. However, I wonder whether other classical ZSL learning techniques can be trivially adapted for ZSL segmentation and how they compare to the proposed technique. 