*After reading the rebuttal, I have increased my score, as the additional ablations, statistical tests, and results on an additional dataset were three key points in my review. Like other reviews, am a bit confused by some aspects of the ablation results (i.e., that reversing R and r makes a difference) and this point should be discussed in the revised version.  Originality: An incremental contribution with some insightful methodology - As noted in this paper, there a number of recent works showing how hyperbolic embeddings can be useful (e.g., for embedding ontologies, words, or used more generally in deep learning). This work demonstrates how these ideas can be successfully applied to multi-relational data, using methodologies closely inspired by recent work. Thus, conceptual contribution is useful but not particularly innovative. - While not being exceptionally innovative, the methodology is still insightful---especially the geometric intuition for the bias terms, the use of Mobius addition/multiplication, and the use of the Khs score to interpret the results.   Quality: Rigorous and correct, but the investigation could be more thorough - The paper is well-embedded within recent work, includes adequate citations, and the proposed methodology is sound.  - The empirical analysis was lacking due to their only being two datasets. Given that the performance trends were very different on these two datasets, it would seem natural to add at least one more dataset to further confirm the observed trends. For example, the Yago ontology (https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/yago/) would seem like a good candidate for another "hierarchical dataset" and a biomedical knowledge graph (e.g., http://snap.stanford.edu/biodata/index.html) would seem like a good additional dataset that is less hierarchical. The conclusions in the paper would be greatly strengthened by results on such additional datasets, especially given the differing performance trends on the two datasets that are currently examined. - The results using the Khs score are interesting but they could be made more thorough and rigorous by actually doing some statistical tests regarding the correlation between the Khs score (+ path length) and the performance difference between MuRE and MuRP. Table 2 is interesting, but as a reader I am left wondering how strong, consistent, and stable these trends are.  - The bias terms in the score function have a nice geometric intuition, but the other components of the score function---i.e., using a diagonal multiplication on the head entity and translation on the tail---are not as well-motivated. Presumably this score function was chosen after some empirical investigation, and I would expect that this score function performs better than ablations (e.g., only using the DistMult or translational parts). Some more motivation and/or ablation studies regarding the score function would improve the paper.   Clarity: The paper is very well-written and well-structured.  Significance: Incremental but insightful; useful to a niche community.  - The general utility of this approach for learning knowledge graph embeddings is not clear, due to the fact that performance gains depend strongly on the dataset. Given that improvement can only be expected in some datasets, combined with the additional complexities introduced by needing to work in a hyperbolic space, I do not expect this approach to have a significant impact on the general knowledge graph community. Additional results on more datasets and a high-quality code repo could make this work higher impact, however.  - This work will certainly be of significant interest to researchers working on hyperbolic embeddings, a relatively niche but growing community.   