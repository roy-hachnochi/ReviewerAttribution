Post-response update: Thanks for the response. It clarified my concerns about the data size but raised another issue of the method's utility being mostly in financial modelling, which limits the paper's impact in machine learning community. I'm then not increasing my score.  ----  The paper applies sparse stochastic variational inference to Wishart process inference, and also proposes low-rank and conditioned wishart for numerical stability.   The idea of applying SVI to Wisharts is good, but of little novelty since this work represents combining two well known techniques. The experiments do not highlight the full potential of the method: all datasets are so small that exact inference should be no problem. The method is applied to forecasting of future covariance, but the problem is not motivated. Why is this a meaningful issue to tackle? There is also no discussion of the resulting covariances. With SP500 one gets over 500 dimensional covariance. I donâ€™t see much benefit in modelling these, especially without sparsity.  The experiments show only modest improvements. The paper needs to show how the variational inference is necessary with large datasets with thousands to millions of points. The paper also should study how the correlation structures evolve, and why these are useful. The paper is well written, but the math notation is cluttered with lots of subscripts, and no distinction between vectors and matrices with boldface.   Given these deficiencies, this paper is not up to nips quality.    