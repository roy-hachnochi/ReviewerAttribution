This paper proposes a model for unsupervised time series modeling. The model consists of an encoder (for subsequences of varying length), a sampling strategy of triplet subsequences, and a loss function called the triplet-loss. The three samples are a reference sequence, a subsequence of the reference called the positive sequence and a negative sequence which is in no relation to the reference or positive sequences. The encoder maps each of the subsequences to their embedding and the triplet loss ensures that the embeddings of the positive sample and the reference are 'similar' to each other, while the positive and negative sample are 'dissimilar' to each other. The claim is that the learned representations capture meaningful features of the time series.  Representation learning is an active area of research but somehow embeddings for time series data have not yet enjoyed as much attention in the research community. Time series embeddings are useful because they can map time series data to fixed-length representations which can be used as input features for downstream tasks or for qualitative exploration of the data.   In a large-scale empirical study, the authors evaluate the time series embeddings on different tasks; classification, classification with sparse labels, and 'forecasting'. Evaluating time series embeddings is notoriously hard, especially since to quantify their quality a task needs to be defined. But for a given task (e.g. classification) the best model is simply a supervised model. It is intuitively clear that good embeddings are also useful for other tasks (e.g. clustering of the time series) but again it is difficult to quantitatively 'prove' that a specific embedding method would be preferable. Large benchmark time series tasks are only available for classification and not for other tasks.  The empirical study of this paper is quite extensive. I would have been curious to see performance on other tasks (though of course I understand there might be no benchmarks). I also would have been curious to see experiments that compare the embeddings of different encoders trained with the triplet loss.  This might help understand how much of the performance is due to the encoder architecture and how much is due to the triplet loss being a good objective. Similarly, it would be interesting to see the performance of the proposed encoder trained on a different objective, e.g. autoencoding or the 'forecasting task' from Section 5.3.  In Bagnall et al. many of the competitive methods are based on KNN (K-nearest neighbours). Have the authors tried (instead of using an SVM) doing the classification based on KNN? Are the distances in the embedding space more useful than DTW? An advantage would be that one wouldn't need any class-labels during training.  I would rate the originality of the work as medium (the encoder architecture and triplet loss come from other work, but how to best combine them requires some thoughts), with significance medium to high, as time series embeddings is an important topic. The work is of good quality (especially the extensive Experiments in a domain that is hard to evaluate) and clearly presented. 