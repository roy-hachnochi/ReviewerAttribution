Nice paper, and very clear presentation of the main results. Here are few suggestions for expanding your presentation:   1. The literature review needs to be broadened. In particular, you should discuss the work of Liu et al., JAIR 2019 (Proximal Gradient TD Learning), which analyzes two time-scale algorithms that include a proximal gradient step. The results in that paper show improved finite sample bounds over classic gradient TD methods, like GTD2. How do your results compare with those in that paper, and in particular, can your analysis be extended to GTD2-MP (the mirror-prox variant of GTD2, which has an improved finite sample convergence rate compared to GTD2.   2. Two time scale algorithms are somewhat more complex than the standard TD method, and Sutton et al. and others have developed a variant of TD called emphatic TD (JMLR 2016: "An Emphatic Approach to the Problem of Off-policy Temporal-Difference Learning") that is stable under off-policy training. How does your analysis relate to emphatic TD methods?  3. Your analysis is largely set in the context of linear function approximation, but of course, all the recent excitement in RL is over deep nonlinear function approximation networks. Does your learning rate adaptation scheme apply to nonlinear deep neural networks and have you done any experiments on such networks?  4. The presentation can be improved. Some of the main theoretical results (e.g., Theorem 1) would benefit from some simpler exposition. Rather than just state the exact theorem, it would help to add a sentence or two distilling the main implication into easier to parse language for those who want to get a gist of the main result. 