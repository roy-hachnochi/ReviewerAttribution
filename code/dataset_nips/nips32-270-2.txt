Positives: 1) I like the overall approach and the insight that when answering per-point queries, leveraging corresponding image-based features via reprojection should also help. Similar insights have been exploited in learning-based multi-view reconstruction works, but this approach is novel in context of single-view 3D reconstruction.   2) The paper is generally well written, easy to follow, and reports the desired ablations (though these do not necessarily support the claims, see below).  Concerns/Comments/Questions: 1) My primary concern (and the main reason for leaning towards rejection) is that the central contribution of using 'local features' does not help empirically. I am judging this in the setting with 'estimated pose' (and not known pose, as this is additional information that is hard to acquire at inference). Judging by Table 3, the 'global network' is slightly better than the proposed approach ('Two stream, est') in IoU, similar in CD, and slightly worse in EMD. This shows that using the additional stream with local features (if camera pose is predicted) does not necessarily help. Similarly, the improvement of 'Ours_cam' over Occnet is only marginal.  2) I am concerned about certain aspects of camera prediction: a) How are symmetric objects handled e.g. if a table is square, how can the network predict the true camera pose. b) What is the variation in camera poses? From what I recall, the data from Choy et. al. always has a camera pointing towards origin, and a fixed elevation and cyclo-rotation, effectively having only 1 degree of freedom. If this is indeed the case, this should make the camera prediction simple, and I feel that this approach would degrade more in settings with larger camera variation (e.g. actual 6D freedom) compared to methods that do not use explicit camera prediction. It would really help the paper if experiments in settings with larger camera variation are shown.  3) Some additional comments (not central to the rating): a) I am currently evaluating the paper only in context of results in settings without known camera, and previous approaches do tackle reconstruction in settings with known camera e.g. Kar et. al., "Learnt Stereo Machines", and have a similar ideology of propagating image features to voxels, and this paper would then need to compare to these. I would also strongly recommend renaming 'Ours'  to 'Ours + gt cam' and 'Ours_cam' to 'Ours', because currently method denoted as 'Ours' using extra information that baselines do not, and is not really tackling a 'Single-view 3D reconstruction' task as normally defined.  b) I am curious why 'One stream' with 'ground-truth' is worse that with 'estimated'?  ----- Overall, while the paper has an interesting central idea, the empirical results (in the setting with predicted pose) do not convince the reader that it is adds a significant additional value in terms of improving performance as the results (Table 3) are mixed, or at best indicate marginal improvement. ----------  Updates after rebuttal: I think the primary argument made in the rebuttal is that (in the setup with predicted camera) even though the quantitative results are only marginally better, the qualitative results are more impressive, and I think that is true. Additionally, the f-score metric reported shows slightly larger gains, and I'd overall be happy to increase my rating to marginal accept. That said, I really do hope the experiment with more camera variation would be added to the main paper as the authors promised in the rebuttal, as the current rebuttal experiment only shows that reprojection error is less, not that it helps in the downstream task.