I read through the rebuttal and peer reviewers' comments. I think the authors did an excellent job in addressing all raised concerns. Their responses are informative and convincing (with lots of new results as requested).   In particular, the authors were able to further eliminate the accuracy drop (by digging out and incorporating an existing technique). The proposed method seems effectitive in fine-tuning pre-trained models too, and works for different CNNs including the compact MobileNet.   I think this paper will attract profound interests from the NeurIPS community and generate a nice impact. I would like to vote for an acceptance.  ------------------------------------------------------  The main limitation of E2Train is currently its loss of accuracy: 0.1% top-5 looks nice; but 2% top-1 acc loss on both CIFAR datasets raise some red flag, even in exchange of 80% - 90% energy savings. I encourage the authors to discuss in rebuttal: Why the performance loss (seems the source is mainly PSF)? Can the accuracy be improved by simple tweaks? If not, what remedies are possible? etc.  Both experimental validations and verbal arguments are welcome.  The work immediately reminds of the ACl paper "Energy and Policy Considerations for Deep Learning in NLP". That one presented a first step toward raising awareness and quantifying deep learningâ€™s potential CO2 impact. Ever larger models are bound to gobble up energy saved by more efficient architectures and specialized chips. Then, in addition to resource-constrained scenarios, the authors (to their good) might also discuss their algorithms through the lens of reducing carbon footprint of training. Following that thought, it is meaningful to examine whether their algorithms can extend/scale up to even huger models, different hardwares (like TPU), or distributed settings.  Besides, I understand this work acts like a pilot study, and therefore standard classification experiments are probably the easiest to benchmark. However, it still would be nice to try at least one adaptation experiment from pre-trained models. Lastly, The paper layout is a bit too compact. Particularly, figures need re-work. For example, Figures 3 and 4 take some time to understand. The three arrows in Fig 5 are confusing.