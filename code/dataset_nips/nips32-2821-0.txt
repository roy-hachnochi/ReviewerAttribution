This paper studies online learning in the generalized linear contextual bandits where rewards are observed with delays.  UCB-based and Thompson sampling based algorithms are proposed, respectively.  Theoretical analysis of these two algorithm in terms of regret bounds are provided.    The problem is very fundamental and practical.  The proposed algorithms have theoretical perform and the theoretical analysis is reasonable.    It may be interesting to consider some real applications and test the performance of the proposed algorithms. 