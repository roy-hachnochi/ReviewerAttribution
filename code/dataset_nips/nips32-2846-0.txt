The paper suggests to do something that strains belief -- create an estimate of a face from a speech signal. Surprisingly, this is able to succeed in some regards! Ultimately this stems from the fact that speech production relies on face characteristics for aspects of the sound, a fact that has been known in that literature for a while.  The paper is thought-provoking and leads one to wonder what other reconstruction tasks might be possible across domains that seem unlinked.  The quantitative evaluation is a little tricky to do correctly. It would be interesting to see if there is a way to more directly compare, for example, see whether people are able to pick out which of the GAN faces was created by the model (given the human face), or have people choose which face is most likely to have created the speech signal they hear. This might support whether people have the same judgements as the GAN model.