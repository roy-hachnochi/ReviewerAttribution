Update: After reading all the reviews and the feedback my rating stays the same.  Note on visualizations: Please be aware that false colors (especially spectrum LUT) are problematic for people with color blindness. ---  Summary: The paper is about depth completion and uses 2D canonical correlation analysis to learn the relationship between color images and depth maps for depth completion. Inputs for this method are a sparse depth map and a color image. Similar to previous methods like "Sparse and Dense Data with CNNs", Jaritz et al. 3DV 2018, the proposed method uses separate encoders for processing depth and color. However, the proposed method separates the color image into a sparse part (masked out where no depth is available) and a complimentary part (masked out where depth is available) and uses a third branch during training. The three encoder branches process the sparse depth map, the complimentary color image and the sparse color image. The last branch, which processes the sparse color image is required for applying the new CCA-based loss during training. The CCA-based loss forces the network to extract features from color images that are highly linearly correlated with features extracted from depth images and vice versa. Besides the CCA loss, the method uses a reconstruction loss on the final depth output and losses to enforce smoothness and numerical range. The architecture uses a binary mask to focus the network on processing the pixels with information, which is inspired by "Sparsity Invariant CNNs", Uhrig et al. 3DV 2017 and "Segmentation-aware Convolutional Networks using Local Attention Masks", Harley et al. ICCV 2017. Finally, the features from the complimentary color branch and depth branch is concatenated and decoded to a dense depth map.   Originality: The idea to extend and use deep canonical correlation analysis for a depth completion framework is clearly novel and sets this work apart from previous methods. The network architecture itself is a reasonable combination of existing methods. The most notable changes are a cause of the CCA loss--the main contribution--which is good. The related work section on CCA provides many references and is especially helpful.   Quality: Overall the paper does a good job to explain the method and support the claims with experiments. The experiments are diverse and cover multiple different datasets. However, I think some results could be less significant than how they are presented.  For instance, the difference between using the complementary RGB image and the dense RGB image is quite small.  Adding information about the variance would help the reader to assess the importance of the different input configurations. Further some additional information and evaluation of additional configurations could improve the understanding of the experiments. See Improvements for details.   Clarity: There are some small issues with the writing that needs to be fixed but overall the paper reads well. The network for adapting the numerical range is just called "Transformer network", which is ambiguous. Giving a more specific name (maybe "range transform network") would avoid that. There are a few grammar issues.   Significance: In my opinion it is likely that future approaches for this task will make use of the CCA-based loss. The good results support the idea presented in this work and prove its significance. I vote for accepting this work.    Questions for the authors: Do you backpropagate to the parameters of the sparse depth branch from the 2D CCA loss? Which dataset was used for the results in Table 1? Were the networks trained for the specific input configuration in Table 1?  