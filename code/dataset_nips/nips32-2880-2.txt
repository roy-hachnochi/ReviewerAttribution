=== Post rebuttal === Thanks for addressing most of my concerns and adding experiments, and also great job at the added self-denoising analysis, I think it's a very cool application of the proposed measure! I'm updating my score from 4 to 6.  === Original review === The paper is very clearly written and has a nice mixture of formal statements with intuitive explanations and examples.  My main concern is with numerical experiments. There are 3 experiments: a) on a toy dataset to show that the similarity measure makes sense (and it does); b) on MNIST to show that one can use the proposed measure to speed up the training; c) on a dataset of satellite imagery to show that the proposed measure can be used to get insights about what's going on in the network and in the training process. However, the results on MNIST are not impressive at all (a tiny sped up on a very small dataset, and both methods converge to 80% validation accuracy, while on MNIST it should be around 98-99%). Also, none of the experiments has comparison against any baselines. At least the comparison against the perception losses (which is discussed in the paper to be similar but less justified, see lines 98-99) should be included. Experiment c) is supposed to show how to get insights by using the proposed measure, but I don’t understand what new knowledge/intuition about the network and the problem was obtained during the experiment. Similar to experiment a), experiment c) mainly just shows that the proposed measure makes sense, which is not enough to justify using it.  Some less important points  While theorem 1 is an interesting result and seem to motivate the (also very interesting) link to the perceptual loss (on line 98-99), it felt a bit left out: I’m not sure if this theorem was directly used anywhere throughout the paper. Not saying that it should be removed, but might be linked to other sections somehow?  There might be interesting connections of the proposed measure to Deep image priors [1] (which, similar to the satellite images experiment, has the flavor of “denoising based on similarity between patches”) and to cycle-consistency papers for semi-supervised learning, e.g. [2, 3], which is close to the Group invariance idea mentioned on line 197.  Calling the proposed measure “proper” compared to other measures seems a bit too far fetched.  Line 191, there seem to be forgotten absolute value in the denominator  [1] Ulyanov, Dmitry, Andrea Vedaldi, and Victor Lempitsky. "Deep image prior." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018. [2] P. Bachman, O. Alsharif, and D. Precup. Learning with pseudo-ensembles. In Advances in Neural Information Processing Systems, pages 3365–3373, 2014. [3] S. Laine and T. Aila. Temporal ensembling for semi-supervised learning. International Conference on Learning Representations, 2017.