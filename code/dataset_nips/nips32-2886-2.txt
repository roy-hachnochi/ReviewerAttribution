Edit after author response: I appreciate the model-based baseline and the frank discussion. I think the main pending question for this work is whether there is a reason to learn a model this way instead of with an explicit prediction objective. However, I think this is an interesting direction for exploration.  Overall this paper has an interesting idea and does some preliminary work to evaluate it. However, at this point the authors show only that it might be possible to do this, not that there is any reason one might want to. This is a clever paper and I would like to read a more complete version.  Originality This idea is fairly original, proposing to implicitly learn what is recognizably a predictive model of the environment without a prediction objective. I would be interested to see further exploration of this idea, and in particular a demonstration of cases where it has an advantage over explicit model learning. The most similar work to this is probably "The Predictron: End-To-End Learning and Planning" (Silver et al.) and the authors should include a discussion of the similarities.   Quality The main weakness of this work is in its experiments. The results shown in Figs. 2 & 5 seem unimpressive, and this work contains zero comparisons to any other methods or variants of the model. It is unacceptable that it does not include a comparison to explicit model learning. The results in Figs. 4 & 6 are qualitatively interesting but somewhat hard to interpret; they seem to indicate that the model which is learned is only vaguely related to ground-truth prediction. The comparison between architectures in Fig. 5 shows no significant difference; furthermore, without sharing the amount of data used to train the two architectures it is impossible to evaluate (as inductive biases will be washed out with sufficient data). The number of environment steps used may be computable from the number of training generations, etc in the Appendix but should be explicitly stated in the main body.  It is also clear that with an expressive policy which is able to distinguish between real and generated observations, there is no reason at all that the implicit "model" should need to make forward predictions at all. In that case the policy as a whole reduces to a recurrent neural network policy. It would be important to include a discussion of this limitation.   Clarity The writing quality in this work is high and I enjoyed reading it. However, there are a few details which could use elaboration: - All experiments should include the number of environment samples used. - The observation space for the cartpole example is not explicitly stated.   Significance Currently the significance of this paper is low-medium. It has a clever idea but it does not establish it well enough to motivate follow-on work by others.