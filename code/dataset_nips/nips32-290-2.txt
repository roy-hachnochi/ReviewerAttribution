Originality: The main novelty vs Bernstein and Sheldon (2018) [5] is handling the fact that regression models condition on the data, which is private, when accounting for the noise of the mechanism.  This is a valuable advance, though somewhat incremental.    Quality: The approach of accounting for mechanism noise in posterior uncertainty is extremely elegant (though the basic idea of that follows from [5]).  The proposed MCMC approaches are sensible, and the hierarchical normal prior formulation with conditionally conjugate updates is very clever.  Overall, I like the proposed ideas.  The experiments are the main weakness of the current manuscript.  The real and synthetic data both have only 2 dimensions, and the real datasest only has 46 data points.  While this data regime does have some real-world significance, it is not exactly modern.  I would like to have seen some larger-scale results.  The one posterior sample (OPS) method should also be used as a baseline (although I expect that the proposed methods would beat it, especially in this regime, due to its poor data efficiency).  There are probably several strong point-estimate private linear regression models in the literature which should ideally be compared to as well.  Clarity: The paper is well written and easy to read.  The only issue is that there is no conclusion section to wrap up, instead the paper simply stops (presumably due to running out of space).  Significance: The paper addresses an important problem (differentially private Bayesian linear regression, accounting for mechanism noise) and proposes elegant solutions.  Its significance would be increased if the experiments could demonstrate the methods efficacy in more realistic, higher-dimensional problems.