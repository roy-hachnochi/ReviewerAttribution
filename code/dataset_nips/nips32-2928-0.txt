 This paper proposes a sparse Gaussian MRF approximation for collaborative filtering applications.  The proposed approach builds on a previous approach known as Besagâ€™s pseudo-likelihood method for estimating a MRF under the auto-normal parameterization.  The proposed sparse approximation model, and learning algorithm, appear to be novel.  The learning algorithm is logically complex, although described reasonably well.  However, given the complexity of the learning algorithm, it would be helpful for the authors to provide a high-level summary of the learning algorithm, perhaps via pseudocode.    The experimental results shown in Table 1 and 2 are reasonably convincing, particularly regarding the training time speeds compared to the best performing baseline model.  However, the authors should describe exactly why their proposed approach is orders of magnitude faster than the MULT-VAE baseline, perhaps by discussing the computational complexity of training MULT-VAE compared to the proposed approach.  Additionally, it would be helpful for the authors to provide some explanation of why their proposed sparse MRF, which is a full-rank shallow model, is able to match or significantly exceed the performance of MULT-VAE, which is a deep nonlinear model.  Furthermore, is the comparison with the MULT-VAE model with 3 hidden layers fair, or is it possible to further improve the predictive quality of MULT-VAE by adding additional hidden layers?   Given the impressive training time performance and predictive quality, it seems likely that the proposed sparse MRF model could form the basis for future work that builds on this approach. 