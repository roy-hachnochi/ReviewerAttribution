Summary: This paper proposes a new Bayesian optimization strategy called TuRBO, which aims to perform global optimization via a set of local Bayesian optimization routines. The goal of TuRBO is to show good performance in both high dimensions, and with large numbers of queries/observations. This strategy uses trust region methods to adaptively constrain the domain, which using a multi-armed bandit strategy to choose between different local optimizers. A Thompson sampling approach is used to select a subsequent point given the multiple trust regions.  Comments: > My main criticism is that the empirical results don’t seem to go up to very high dimensions. In the empirical results, three of the four tasks are from 10-20 dimensions, while one task is in 60 dimensions. In some of the high dimensional BO papers listed in the related work, tasks are shown from 50-120 dimensions.   > It would be great to explicitly define or clarify what is meant by a “heterogeneous function”. There is a brief description involving reinforcement learning problems (in Section 1). However, I feel that this does not provide a clear description or definition of what the authors mean.  > Minor: the abstract has the line “the application to high-dimensional problems with several thousand observations remains challenging”. At first pass, the phrasing here makes it seem like you are defining “high-dimensional problems” as those with “several thousand observations”, while I think you actually mean the setting with both a high-dimensional design space and several thousands of observations. Re-phrasing this could improve the clarity.  > The overall acquisition strategy (described at the end of Section 2) is to concatenate the Thompson samples from all of the local models and choose the minimum. It therefore seems like this algorithm might be described as doing (“regular”) Thompson sampling over some type of approximate Bayesian model (e.g. some sort of piecewise model defined on independent and adaptively growing trust regions). Have the authors considered whether their procedure can be viewed as “regular BO”, i.e. standard Thompson sampling in a sophisticated model?  ---------- Update after author response ----------  Thank you for including a high dimensional (200D) result in the author response. This seems to show good performance of TuRBO in the large-iteration regime. I have therefore bumped my score up to a 7.