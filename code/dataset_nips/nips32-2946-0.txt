Originality: The work appears original to me, but it is not the first on GANs using temporal data. There is previous work on temporal GANs used to generate video sequences (Masaki Saito et al, Temporal Generative Adversarial Nets with Singular Value Clipping). This previous work also calls their approach TGAN, but appears to be different. It may be better to use a different name for the method presented in this work. It would be good to point out differences between the approaches.  Quality:  The submission appears technically sound to me, I didn't check every detail though. The evaluation uses a number of different approaches for comparison, all of which perform worse than the newly introduced method. From the description it sounds the approach is mostly used/useful for datasets with only small number of variates, but hasn't been used on eg video data. In terms of evaluating weaknesses of the approach, it may be interesting to do that.  Clarity: The paper is well written but clarity could be improved in several cases:  - I found the notation / the explicit split between "static" and temporal features into two variables confusing, at least initially. In my view this requires more information than is provided in the paper (what is S and Xt). - even with the pseudocode given in the supplementary material I don't get the feeling the paper is written to be reproduced. It is written to provide an intuitive understanding of the work, but to actually reproduce it, more details are required that are neither provided in the paper nor in the supplementary material. This includes, for example, details about the RNN implementation (like number of units etc), and many other technical details.    - the paper is presented well, e.g., quality of graphs is good (though labels on the graphs in Fig 3 could be slightly bigger) Significance: - from just the paper: the results would be more interesting (and significant) if there was a way to reproduce the work more easily. At present I cannot see this work easily taken up by many other researchers mainly due to lack of detail in the description. The work is interesting, and I like the idea, but with a relatively high-level description of it in the paper it would need a little more than the peudocode in the materials to convince me using it (but see next). - In the supplementary material it is stated the source code will be made available, and in combination with paper and information in the supplementary material, the level of detail may be just right (but it's hard to say without seeing the code). Given the promising results, I can imagine this approach being useful at least for more research in a similar direction. 