In this paper, the authors present a new generative model for time series data. The approach is based on GANs, with three key parts: 1) a supervised loss, 2) a reconstruction loss and 3) a joint training between the embedding and adversarial networks.  To my knowledge, the TGAN approach is novel. It has the potential to be widely applicable to many time series problems.  The paper is extremely well written and a pleasure to read. I commend the authors for explaining the technical details in a very clear manner. Figures 1 and 2 are particularly helpful at illustrating the key concepts of the paper.  The evaluation is very well done. A standard evaluation section for a GAN paper often only shows examples of data generated by the GAN model (e.g. images). This typical approach is very qualitative and it is refreshing to see the authors include quantitative results from different types of experiments. There could be minor quibbles with each type of experimental setup, but as a whole, the empirical evidence is compelling.  My main concern with the approach is that training GANs can be challenging. Does the training process for TGAN involve similar difficulties like mode collapse and having to give the discriminator more optimization steps than the generator during training? In addition, how sensitive is the performance of TGAN to parameters lambda and nu? Adding more parameters to an already notoriously difficult training optimization makes me nervous. The paper could be strengthened with a brief discussion of these issues.  Comments after author feedback ------------------------------------------ The authors have done a good job of addressing my concerns. My review remains the same and I still feel the paper should be accepted.