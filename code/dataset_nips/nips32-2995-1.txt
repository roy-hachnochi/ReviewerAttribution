The authors introduce a new way of embedding entities and relations into a R^n vector space via quantum logic. Quantum Logic provides the main framework by which they can show that, given an embedding that fits all the requirements, queries become a matter of taking the distance to a plane. Queries here are in the sense of description logic: set membership, containment, etc. The embedding is found through SGD with a loss function that represents all of the constraints the embedding needs to satisfy.  The authors did an excellent job of providing the necessary background and walking through the construction and to the experiments. There were a few times I jotted down a question to ask, and then found it answered in the next paragraph. The writing is clear, though if there was space it would be nice to expand a bit to help the reader follow the equations 4--9.  One question I didn't follow is how simple the operations in section 3 are. Is it trivial to intersect two subspaces, add two subspaces, and find the orthogonal complement of a subspace? Are the subspaces each represented with just a single 2d-dimensional vector, or is it more than that? Is it a span of a set of vectors, and these operations are trivial operations on those sets? Just looking for more understanding of the cost of these operations and the cost of representation in the space.  One question I had is how deep of an ontology of relations can be represented with n-dimensional space. Is it n, or something larger?  Can trinary or higher-order predicates be represented trivially by extending the space to R^3n for example, or does the entire technique support only unary and binary predicates?  The description of the experiments makes it sound like the baseline system hyperparameters were tuned on the test set. Can you verify if that is true or if it was done more carefully with something like cross-validation or a separate development set?  There seems to be a typo in Table 1 where the HITS@1 and HITS@10 results are the same for E2R. I'm hoping they are the results for HITS@1, but more likely are the actual results for HITS@10.  Line 289-290 made me remember that there are other reasons for doing an embedding of the KB other than as an approximation to doing logic reasoning. For logic reasoning, using a symbolic reasoner will perform better (as stated). However, there are other benefits of an embedding. For instance, it may be useful for prediction (as you show with the link prediction task?). Just to confirm: A symbolic logic reasoner would perform poorly on the two link prediction tasks, right? Because the link prediction is based on some unknown fuzzy properties of the entities and relations they belong to, not simply a reasoning task, is that correct? Another benefit, (not evaluated here), is that usually one can say something about relation and entity similarity based on closeness of their vectors. A qualitative evaluation of this property may also lend value to the paper. I think a brief discussion of the pros and cons of symbolic reasoning vs. embedded would be interesting, informative, and also strengthen the paper to point out the benefits of what you've done.  small typo: line 277 "predication" should be "prediction".  ** Update after author response: Thank you for answering my questions in your author response. 