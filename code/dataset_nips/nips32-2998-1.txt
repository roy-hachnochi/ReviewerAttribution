This work extends the problem of optimal best arm identification to the Markovian setting. Similarly to the iid case, each arm is still parametrized by a single parameter which can here be taken to be the stationary mean (exponential family of Markov chains), and a fair amount of structure is therefore assumed. For example the law of all arms is generated by the same Markov kernel (generator of the exponential family), and must be known for the algorithm to yield a priori guarantees and a valid stopping rule.  The paper is of theoretical nature, is extremely well written and uses proper mathematical formalism. Its structure is doctrinal, allowing the reader to understand the underlying family of distributions, the bandit problem, main developed tools, and parse the results efficiently.  Although the reviewer has no reason to doubt the results, a certain number of clarifications would be welcome here, especially with regards to Section 3.  P(S) is defined at L.92 as the set of chains (identified with their Markov matrix) that satisfy a collection of irreducibility and other structural properties that are tied to a previously defined function φ. However, in the statement of Theorem 1, P(S) is introduced prior to φ. This begs the question of whether Theorem 1 is as general as currently stated. If indeed there is a strong connection between the function evaluated on the chain and the transition matrix for the theorem to hold, it would be uncalled for the author to claim general improvements over the references at L.163-164.  In the proof of lemma 1, at L.373-374 the reader is referred to [Lax07], which guarantees existence of an eigenvector for the PF root that ’depends differentiably’ on the parameter, but also cautions the reader against the fact that not all such vectors might work. Is it therefore clear that the chosen u and v (where u sums to 1 and with v satisfying a prescribed inner product with u) are indeed sufficiently differentiable ?  === Minor comments ===  L.91 ’y_m’ should be y  L.135 ’the the’  L.166-167 The transpose notation is perhaps a bit too liberal here, as it refers to the adjoint of P in L2(π).  L.371 ’eigenvectors’  L.375 Missing a constant term in log P(x,y) (that will indeed vanish upon taking the derivative)  L.379 Last term should apply on x and not y.  L.380 The infinitesimal term in theta is sub-scripted.  L.387 Could you explain how dependence of this ratio in theta implies the ’Therefore’ ?  L.461 ’eigenvalue’  L.488 Can you add intermediary steps for the second equality ?  ==== AFTER REBUTTAL ====  The reviewer thanks the authors for their detailed answers.  As argued by the authors, concentration inequalities are handy tools,  but as such it is important for the reader to also quickly understand when they apply best, and when they don't. This coupling between φ and P could lead to a very interesting discussion and perhaps new insight. The reviewer keeps his score: an accept 7/10.     