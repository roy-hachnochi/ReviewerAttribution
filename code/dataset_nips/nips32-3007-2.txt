The authors provide a new sample complexity analysis for identifying a near optimal policy of a tabular MDP assuming access to a generative model. They provide a problem dependent bound compared to the worst case bounds present in the literature. The analysis technique is novel in the sense that their bounds depend on the gaps between the optimal action value function and value function of suboptimal actions. Similar bounds are well known in the multi armed bandits literature and shown to be derived from the proposed bound. I am not much familiar with the relevant RL literature and hence can not make detailed comments.  The bound improves over the previous results and a high level proof sketch is present in the paper. However, the paper refers to several lemmas present in the supplementary material which makes it a difficult read. Given the short amount of time I was not able to go through the supplementary material. But I assume that the proofs are correct.   One novel idea behind the proof is to make use of the variance of the optimal value function under the next state distribution, which effectively helps to improve over the previous analysis. I believe this new technique might be helpful to the community.  --------------- Post rebuttal update: The authors mentioned some ideas about numerically evaluating their methods. I confirm my original view and vote for acceptance.