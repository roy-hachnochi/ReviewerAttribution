1. This paper is mainly based on observations and empirical results. For example, the authors should provide more details in the regularization step of regulated QAT process in Section 4.1. If we simply clip the weights, then how is the convergence guaranteed? The authors should elaborate more on theoretical analysis. 2. It seems the paper is off the scope of NeuraIPS. The authors should consider submitting the paper to EDA conferences such as DAC. 3. In Section 5, it is not clear why majority-vote protection is better used under low error rate scenarios. 4. The experiment section is extremely vague. The authors claim that “We use the ImageNet dataset [3] (ILSVRC 2012) for model training and evaluation.” However, the only results based on ImageNet are in Figure 4(b) and 5(b). Are the results in Table 2 based on ImageNet or Cifar10? Additionally, are the models trained from scratch or finetuned? The accuracy curves in Figure 5 look strange to me. For example, the accuracy of SqueezeNet on ImageNet increases from ~10% to ~55% within 2 iterations and the accuracy of VGG16 on Cifar10 is already over 93% at epoch 0. 5. With a thorough look into the codes, I did not find the training module for the three selected models (i.e., VGG16, ResNet18, SqueezeNet) on ImageNet. The authors should provide a description of their codes.  Minor issues: 1. In Figure 1, the percentage row, shouldn’t the range be [-128, 128]? 2. There are many typos to be corrected. For example, in the last paragraph of Section 2, “mgeneral” should be “general”.