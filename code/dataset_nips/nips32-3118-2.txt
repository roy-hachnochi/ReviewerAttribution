Originality: The model proposed is quite novel. The teacher network uses recent development in reinforcement learning and applies in an innovative way to provide a curriculum for abstract reasoning task. While other curriculum learning works exist, this is one of the first to use it for challenging visual reasoning tasks. The related works regarding both abstract reasoning and curriculum learning are properly discussed and the authors do a good job of putting the proposed work in context of existing work.  Quality: The proposed method is well-motivated and technically sound. The experimental setup is also clear and shows that both of the contributions (the LEN model and teacher model) are independently effective for both RAVEN and PGM dataset surpassing existing art by a solid margins (over 10% for both RAVEN and PGM). I also appreciate the authors including several other competing curriculum learning algorithms as well as testing the proposed teacher model on a variety of algorithms. Overall, this a a good quality submission.  Clarity: The details are mostly clear. There are some minor writing issues. First, the use of past tense in abstract and body of text is unusual. E.g. "Table 1 illustrated such an idea..." instead of "Table 1 illustrates such idea". While it does not affect clarity, it reads odd. Most of the figures are blurry, I would consider using a vector graphics for revised version for better readability.   Significance: As outlined above, the paper has two main algorithmic contributions. The teacher model shows success for a wide variety of models and is likely to be adopted for other tasks as well. Similarly, a large improvement in challenging visual reasoning task is also significant. The authors introduce a number of small task-specific engineering changes, such as the use of  separate streams for processing "shape" and "line" features which are also likely to be useful to the community for similar visual reasoning tasks.  *** POST REBUTTAL COMMENTS ***  After carefully reading all other reviews, the author rebuttal and engaging in detailed discussions with other reviewers, I am happy to recommend this work for acceptance. The main merits of the work is in solving abstract reasoning datasets that have been independently studied (and duly peer-reviewed) to be a good proxy tests for the visual reasoning task. There is definitely valuable discussion to be had for how true that statement exactly is (as noted by R1). However, the authors of this submission should not have to defend the validity of community-established benchmarks. The author rebuttal also shows success in other tasks such as CLEVR.  My ratings is unchanged from before: An accept.  