This paper proposes a few practical tricks to accelerate the implementation of parallel SCD on NUMA architecture. I do like these practical implementation tricks. (I personally uses some of them before.) My concern on this paper is that the technical contribution of this paper looks weak to me. It might be not sufficient to support a publication in NIPS. I personally suggest that authors may consider selling this paper from the perspective of empirical study. For example, training a huge benchmark dataset in a XXX hours or minutes.  =========== after rebuttal ============  I would say that this paper is very different from the typical ones I reviewed in this track. I would not be upset if we decide to accept this paper, but I still have the following concerns that should be addressed before publication in anywhere.  The theory part directly applies existing paper. The implicit assumption is not clear. Without making appropriately assumption, I even do not think the theoretical result in the early literature can be applied.   I agree that this paper designs a few useful strategies to incorporate with the real system, which is very important to practice. Some of them are actually not new - people who implemented CD on the real system mostly used some them but just sell the paper more from the theoretical perspective. Authors should realize this.  This paper mainly uses Heish 15's paper as the bench marker for comparison. A better implementation was done in his 17 nips's paper "Asynchronous parallel greedy coordinate descent", which was not compared. Based on the makeup experiments, the speedup curve does not look very well. To my personal experience, it could be even better. Of course, it could be due to the difference on hardwares. Authors need to clarify this.