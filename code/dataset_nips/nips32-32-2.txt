The paper describes an elegant methodology to improves the performance of the very important and difficult task of depth and ego-motion estimation from monocular video. Experimental results validate the efficacy of the proposed methods. The paper is well organized and well written.  The paper would benefit from a more thoroughly study of the proposed methods: A mask for the photometric loss is proposed as a more efficient a simpler alternative to estimating optical flow. A natural question is how many milliseconds of GPU time does this save which isn't address. 