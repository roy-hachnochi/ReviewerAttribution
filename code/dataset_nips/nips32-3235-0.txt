The paper presents a spectral convolutional layer using feedback-looped filters and show how it can be used efficiently by means of scaled normalization and cut-off frequency. It is clearly written and easy to follow.  Introduction and walk-through on spectral convolutions is good and motivates the work. It would be nice to see how spectral methods compare to non-spectral ones, and if there is some interesting aspect that should be considered.   The method section could take more space to elaborate on 3.2 as it is key for the method as in this current form I am not sure it is sufficiently detailed and Alternatively details could be provided in the experimental setup section, as long as they are sufficient to grasp details of the proposed method.  Section 3.2 contains some details on initialization that should go in experiments, unless they are needed to explain something about the method. If so then please elaborate and explain better.  No ablation study has been performed with respect to the architectural choice of dense net. What is the difference in performance? Hope much would other methods, such as GCN, gain from just this architecture?  Section 4.5 should define better what are criteria for success, are dense clusters better than sparse ones for example? Figure 4 and 5 are not sufficiently explained to say anything relevant about the methods in my opinion. Please elaborate on this.  In introduction Shuman, cite [30], was first to propose convolution on graphs via spectral decomposition.   Overall I like the paper and the approach. Some polishing is still required and clarity should be improved.