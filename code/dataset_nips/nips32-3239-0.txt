- The paper presents a novel approach of getting attention at a given time by modeling infinitesimal change of attention as a continuous function. They extend the idea proposed in "Neural Ordinary Differential Equations" and implement in the MAC framework. They show that this proposed approach can get comparable performance by taking 1/3rd the steps.   - I enjoyed reading the paper and detailed experimental analysis. The paper is clearly written and the take-aways from the experiments are clearly outlined. I specially liked the qualitative analysis on interpretability by discussing chunkiness of attention maps, consistency across different seeds and the dynamics of the interpolation between different attention steps.  - The paper lacks discussion on the advantages of continuous attention mechanism instead of discrete attention mechanism such as Adaptive Computation Time [1]. Approaches like [1] has also shown reduction in computational complexity / attention steps while preserving performance.   - The paper also provides enough technical details (both in supplementary and main manuscript) for easy reproducibility. The code provided should also help in that aspect.   - The proposed method should help in building computationally efficient algorithms for visual reasoning. Additionally the proposed metric to measure focus drift for model might also be useful to reason about how the attention changes over time.   [1]Alex Graves. Adaptive computation time for recurrent neural networks. arXiv preprint arXiv:1603.08983, 2016.  Update [Post Rebuttal] Overall I thought that the paper is of a high quality. I found the idea using Neural ODEs in the MAC framework to model attention as a continuous system is definitely interesting.   After going through the discussion and additional experiments in the rebuttal, I believe that the authors gave further evidence on the significance of their work and the generalizability of the approach. Therefore, I am sticking to my original decision.   