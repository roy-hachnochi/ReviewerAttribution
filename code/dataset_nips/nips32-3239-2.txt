Post-rebuttal Comments: After reading the other reviews, the author's response, and the reviewer discussions, below are my thoughts: (P1) The direction of the paper is definitely interesting. (P2) However, I am not completely convinced that TLT is necessarily a good metric for interpretability. (P3) Given that the benefits of the proposed approach are mostly in TLT and with the above point, it is not clear if this leads to better interpretability.  On a side note, I would like to thank the authors for a strong rebuttal -- including experiments on GQA. However, concerns (P2) and (P3) still remain. Therefore, I am sticking to my score.  General comments: (G1) The paragraph explaining the relation of TLT to Occam’s Razor (L32-L41) sounds very philosophical without supporting evidence (either through related work or studies). Further, arguments for why TLT is a metric of interpretability is not convincing (L32-L41). There are no further empirical or human studies performed to established this clearly.  (G2) How does the system handle discontinuous attentions, where it makes sense. For instance, to answer the question: ‘Are there equal number of cubes and spheres?’, human would (i) find all the cubes (attention_cube), (ii) find all spheres (attention_sphere), and then compare their counts. Intuitively, attention_cube and attention_sphere needs to be discontinuous.   From what I understand, the ODE solver discretizes this sudden shift as an interpolation between two time steps (t=1 and t=2). If this is true, isn’t this in disagreement with the proposed idea of continuous attention change across steps?  (G3) A major concern is insufficient experimental validation. The proposed approach has similar performance as prior work. Most of the benefits are obtained on the TLT metric. With the problems in (G1), contributions feel not sufficiently backed with empirical evidence.  (G4) Additionally, the paper does not contain any experiments on any of the visual question answering (VQA) real datasets. Without these experiments, it unclear if models with proposed attention regularization across steps has benefits on real datasets (and therefore applications). This is another drawback of the current manuscript.  (G5) The manuscript does not talk about the additional cost of running the ODE solvers including run-time analysis and comparisons.  Typos: L44-45: Grammatical error in the sentence needs a fix.