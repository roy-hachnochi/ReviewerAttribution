The formulation in eq. 1 appears new. However, I am not convinced why minimizing the loss w.r.t. worst case distribution (in some epsilon ball) is a good idea (eq. 1). In this formulation, the task of classifier is made harder by having to model distributions that may be unlike the true distribution. Further, it is evident from experiments that when the epsilon is large, the method doesn’t work. Please comment on how the method is different from adversarial data augmentation methods for smaller epsilon. It is not clear to me how the second line of eq. 8 follows from first line and what Q_i are? Line 267, concludes that proposed method learns distributions closer to true distribution consistent with some claim in sec. 3. It is not clear which claim it is consistent with. Further, it is not clear why it would model “true” distribution. This is because, the generator is learned to model the worst case distribution within a epsilon ball of the empirical distribution and there is no reason for that worst case distribution to be the true distribution. In my view any closeness to true distribution is purely circumstantial. How does the method compare to data augmentation methods e.g. mixup or simple addition of noise to the training examples? This comparison is important because the proposed method can be viewed as a data augmentation method, where the generator acts as a learned data augmentor.  Other minor points Please change “Crap” in the title and paper to something more prudent e.g. “Bad” Line 62: demotes -> denotes Line 67: assumed to include For clarity (e.g. in eq. 3) it may be better to use some other letter instead of “d” to represent d(Q, P) Line 89: matrix -> metric 