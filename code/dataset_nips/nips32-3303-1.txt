As a caveat, I am not an expert in the literature surrounding low-rank reconstruction, and may not be entirely correct in my evaluation of the originality and significance of the contributions.  Originality:This paper builds upon previous work, in particular [62], which developed column-subset selection for low-rank approximation under the l_p norm. This paper expands upon [62], obtaining results for a broader class of functions and furthermore tightening and fixing some results from [62]. These expansions seem very valuable to the machine learning community. However, the authors may want to further motivate their work by providing specific examples of loss functions to which they extend previous theory, and which have found successful applications in machine learning.  Quality: This works appears to be of high quality. The authors provide the intuition behind their theoretical contribution as well as the motivation in a way that is very accessible; the results seem theoretically important, and I can imagine several implications for the machine learning field, for example in using low-rank approximations for problems that are prone to outlier data.  Clarity: This paper is somewhat clear, but could in my opinion be improved upon in a few ways that I describe in the relevant section. Overall, the authors guide the reader in understanding the motivation and reason for the hypotheses and class of functions that they investigate. Although I have not carefully read over the proofs, I understand the underlying reasoning of this paper.  Significance: This paper appears to be significant due to the importance of low-rank approximation and reconstruction in machine learning, from both a computational efficiency and memory usage perspective (among others).   *********** Post-rebuttal comments ***********   Based on the author rebuttal and reviewer discussions, I recommend the following for the camera-ready version if the paper is accepted:  (i) The issue regarding the choice of r in Algorithm 1 should be clarified. It seems that r simply indicates that the loop in Alg. 1 should be run until |T_r| < 1000k, and that the number of loop iterations required is O(log n); I recommend the authors make this fact obvious within the algorithm itself, for example by changing the first for loop to ''while |T_i| < 1000k''. (ii) Following Reviewer 2's review, I recommend the authors change the title. (iii) Similarly, I agree that the approx. monotone/necessary conditions have been proven to be *sufficient* but not *necessary*; the paper should be updated to clarify this.