Weaknesses:   1) There are 3 sources for similarities/transferabilities reported in this paper: attribution maps (the proposed method), SVCCA, and Taskonomy. The transferabilities of taskonomy have a practical value (they’re constructed and are shown to reduce the need for supervision through transfer learning), but Taskonomy’s method is computationally expensive. So, the gold standard is duplication of taskonomy’s affinity matrix, but with less complexity. Therefore I see the comparison between the transferability matrix by attribution maps and taskonomy’s (fig 4) valid and what the main point is. But I don’t understand why/how SVCCA vs attribution map’s similarity matrix comparisons (figure 3) are useful. What exactly is the value of SVCCA based similarity matrix? Why isn’t figure 3 comparing between attribution map’s matrix and Taskonomy’s affinity matrix (after being made symmetric)? As I said the practical value of task similarity has been shown for the taskonomy affinity matrix (Fig 7 of Taskonomy paper), so it makes sense to aspire to duplicate that, regardless of SVCCA.  In this regard the paper in L225-228 brings in a question to justify comparing against SVCCA: if similarity between attribution maps correlates with similarity between representations by a neural network. But as I reiterated, an absolute similarity between representations of neural networks dont seem to have any practical value unless that similarity is shown to mean transferability (which is what taskonomy affinity matrix does). So why this evaluated assumption is relevant, beyond the comparison with tasjonomy’s affinity matrix, is unclear to me.   2) Related to the above point, the paper seem to suggest attribution maps and SVCCA in the end yield similar task similarity matrices (Fig 3). Then why do the authors believe attribution maps is a novel method that is worth publication, if its final outcome is the same as SVCCA’s? Like the proposed method SVCCA also doesn't need separate labeled data, so supervision is not the advantage. If compute is the advantage, then it should be reported to be clear by how much the attribution maps are more efficient (though I dont find only computational efficiency as an exciting advantage, at least compared to not needing labeled data).   Overall, I think the role of SVCCA should be clarified in this submission.  3) The proposed method strictly results in a symmetric task similarity matrix (eq 1 and L174). This seem like a strong constraint and limitation, as the task transferability is not a symmetric property (ie if A transfers well to B, that doesn’t mean B will transfer well to A -- see Fig 7 of taskonomy paper). This makes sense when thinking of task transferability in an information theoretic manner. However, I’m surprised that Fig 4 shows that the symmetric task similarity matrix by attribution maps can be a good prediction of traskonomy’s asymmetric transferability relationships. Are the taskonomy’s top-k sources retrieved as-is from the Taskonomy’s affinity matrix, or are they forced to be symmetric beforehand? Overall, how limiting is the symmetry constraint (ideally reported quantitatively).   4) I didn’t quite find the attribution maps qualitatively intuitive (Fig 2). The attended areas of the image don’t seem to be related to the actual task (e.g. in 3D tasks the 3D worth pixels don't seem to be attended). Or there seem to be some clusters of attended pixels without a clear semantic meaning behind them. However, the resulting analysis using the attribution maps seem to work (sec 4.2), so quantitative value seem to exist. But as this state I fail to spot a qualitative value.   5) related to point 1 above, the analysis in sec 4.3 is more like a curious experiment and intuitive evaluations of the trends. As SVCCA (ie just similarity between representations) doesn’t mean transferability value necessarily, the trends in section 4.3 do not necessarily have a practical value. However, I still think having them is better than removing them, but I would clarify the observed trends don’t necessarily have a conclusive practical value.  6) Per Fig 4, it seems that the probe datasets other than taskonomy better predict the taskonomy transferability than the probe dataset based on taskonomy itself. This seems counter intuitive. How do you justify this?   7) The paper should cite and compare with the recent works that also attempt to duplicate taskonomy’s affinity matrix but with cheaper methods. E.g. “Representation Similarity Analysis for Efficient Task taxonomy & Transfer Learning”, CVPR19.  