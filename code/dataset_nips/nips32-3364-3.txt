LDMI: A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise:  This paper formulates a new information-theoretic loss function, which is based on determinant based mutual information (DMI). Their main contribution is that this loss is provably not senstive to noise patterns and noise amounts.  Pros:  1. The authors find a relatively new direction for learning with noisy labels. Namely, instead of designing distance-based losses, they try the information-theoretical loss. Based on this motivation, they design DMI loss, which is robust to label noise.  2. Related works: In deep learning with noisy labels, there are several main directions, including robust loss functions [1], reweighting trick [2], and explicit and implicit regularization [3]. I indeed appreciate authors survey them well. Note that, the authors may cite [4] in the regularization line due to its high impact.  3. The authors perform numerical experiments to demonstrate the efficacy of their framework. And their experimental result support their previous claims. For example, they conduct experiments on Fashion-MNIST, CIFAR-10 and Dogs vs. Cats. Besides, they conduct experiments on Clothing1M dataset [5].  Cons:  We have two questions in the following.  1. Settings: This paper still focuses on class-conditional noise (CCN) model. However, CCN model may not cover the real-world noise case. The current emerging noise model is instance-dependent noise model [6,7]. I am not sure whether this idea can be depolyed under this case.  2. Experiments:   2.1 Datasets: I think the author should conduct 1 NLP dataset instead of only using image datasets. 2.2 Baselines: Please add the results from reweighting methods like MentorNet [2]; Please compare your method with VAT [4].  References:  [1] Z. Zhang and M. Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. In NeurIPS, 2018.  [2] L. Jiang, Z. Zhou, T. Leung, L. Li, and L. Fei-Fei. Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, 2018.  [3] H. Zhang, M. Cisse, Y.N. Dauphin, and Y.N. Lopez-Paz. Mixup: Beyond empirical risk minimization. In ICLR, 2018.  [4] T. Miyato, S. Maeda, M. Koyama, and S. Ishii. Virtual adversarial training: A regularization method for supervised and semi-supervised learning. In ICLR, 2016.  [5] T. Xiao, T. Xia, Y. Yang, C. Huang, and X. Wang. Learning from massive noisy labeled data for image classification. In CVPR, 2015.  [6] J. Cheng, T. Liu, K. Rao, and D. Tao. Learning with bounded instance-and label-dependent label noise. arXiv 1709.03768, 2017.  [7] A. Menon, B. Rooyen, and N. Natarajan. Learning from binary labels with instance-dependent corruption. Machine Learning, 2018.