Summary:       The authors consider the task of predicting Y (the continuous variable is the most studied in this work ) given a set of features X by fitting a model. The aim is to provide uncertainties about the prediction. In the case of Regression, confidence intervals need to be estimated. Therefore, authors propose to use a pinball loss function with a quantile threshold tau, that in expectation is the tau-th quantile of the conditional distribution Y given X. Authors propose a variant called Simultaneous quantile regression when they uniform randomly sample the the quantile threshold tau to optimize for. This results in a simultaneous optimization of all quantiles through the randomized pinball loss.  I think the randomized version is novel although pinball loss has been used before. The authors demonstrate how a model trained using pinball loss helps in estimating the 95% prediction interval better than many competitors. Conditional Gaussian fitting with its variance providing estimate (although one of the simpler baseline) is the next reasonable close competitor. I find the numerical results quite exhaustive with many methods compared.  The authors then move onto the filtering problem (they call it epistemic uncertainty) when authors propose finding k orthonormal certificates c_i (each is a vector) that lies close to the null space or a subspace with very low eigenvalues of the covariance matrix of some high level feature vector in an already pretrained neural network. So essentially the score is the average of the sum of dot product between these certificates at the feature vector and evaluates to close to 0 for points lying in the training distirbution.   They show that if the features are Gaussian with some covariance, how the score is a pretty good separator of out of sample and in-sample points where out of sample has a mean shift and a different covariance.  They demonstrate by comparing it various methods for the filtering task how they get state of the art  or competitive with the state of the art on CIFAR-10, MNIST, Fashion-MNIST etc.. Out of samples are those data points in one half of the classes and in-sample are those samples belonging to the other half of the classes .  Authors further show numerical evidence of the SQR actually doing pretty well on detecting causal directions between a pair of variables. Although unrelated, it seems like the pinball loss is a good measure of complexity of a conditional distribution. Therefore, the direction with the lowest randomized pinball loss is chosen as the correct direction. Even here the empirical demonstrations are comprehensive.  Originality : Although the pinball loss is strongly motivated by prior work, randomized version of that simultaneously optimizing for all quantiles is novel and seems to have very competitive empirical performance on a variety of tasks.  The OC approach is very novel for the filtering task.  Quality:   Technically it is sound. However, given the formulation of Orthonormal certificate "approximately" tracing the null space of the feature covariances - whats the need for Theorem 1 ? It just solves the Gaussian case anyways and is not surprising. I think including the application of SQR for causality in the main paper would enhance the paper. Theorem 1 adds little and could be moved to the appendix as an intuitive formal justification for OCs.  Clarity:    The motivations behind OCs and SQRs are clear. However, the application of SQR methods to classification is not clear. So I have some questions here:  a) Lines 92-94  "When dealing with multivariate classification it is possible to proceed similarly (build one SQR on 93 top of each logit), or use calibration methods [29] to interpret softmax scores as aleatoric uncertainty 94 estimates" - If existing calibration methods like temperature scaling are to be used as in ref 29, where is the novelty for classification. Except the case of ordinal targets discussed in Appendix B, it is not clear what this one line "build SQR on top of each logit" means ? Why are there no systematic experiments for classification setup ? I find this is a wekaness of the paper. The authors might as well drop this and say that their method is meant for regression mostly.  b) Lines 165 - 67 says that when |x| goes to infinity upper bound goes to infinity, why is that an evidence that |C^T x| will also go to infinity. At least the point is not clear and the exact technical statement of the quantity going to infinity if the upper bound goes to infinity seems a bit awkward reasoning.   c) There is a lot of recent work on the filtering task of rejecting samples in the classification setting - https://arxiv.org/pdf/1705.08500.pdf, https://arxiv.org/pdf/1805.05396.pdf. Further there is some more work on uncertainty estimation (related to the SQR algorithm) based on observing confidences of the model during various snapshots of the training process - https://arxiv.org/pdf/1805.05396.pdf. These works must be cited and their differences discussed.  Significance:   Both problems tackled are real and very important. The new methods could act as strong baselines for future work.  The methodological novelty is also very interesting.  Weaknesses: I have listed weaknesses primarily in Clarity and Quality sections. Mainly, I am not sure of the authors assurances of being able to extend SQR to the classification setting. It seems only ideally suitable for regression and possibly when target is finite and ordinal.   Some key citations are missing. Since the authors did comprehensive evaluation on a large set of baselines and proposed novel methods, I would not press on new comparisons. However, they should discuss these recent relevant pieces of literature.  ***After rebuttal ****** The authors have reported a number of new experiments and their results. They have also adequately addressed my concerns. So I am fine with the current score. 