The proposed approach of combining copula and autoencoder as a generative model is quite novel. It has a superior performance to Variational Autoencoders and comparable to DCGAN ( one win and one loss) with modest gains in execution speed. Having said that, the comparison is based on only three datasets. Thus the results are not very conclusive.  Perhaps there needs to be a better notation for the numerator of formula 2. The mean and covariance given as subscript appear weird. It took me some time to figure out thats what it means.  In Figure 3, why does the graph for X1 versus X2 for C1 and C2 have circular contours? Shouldn't the contours be square since the model is nonparametric; X1,X2 have a uniform distribution over a square.  I understand that copula help generate more diverse images, but I fail to understand why they give sharper images? Is there a good intuition for that?  Figure 4: The caption says that the rightmost plot is a random sample of VCAE on MNIST and SVHN. How can there be a single sample for both SVHN and MNIST.  I couldn't find graphs similar to Figure 6 for MNIST and CELEBA. Why were they omitted?  The images in Figure 7 are too small to recognized the subtle points made by the author. It would be useful to have larger pictures in the supplement.   How can one objectively verify that VCAE is not memorizing the pictures in Fig 7? I've seen section D on interpolation in the supplement. Is that enough to verify diversity?  Please proofread the paper again; there are a few Typos and grammatical errors.