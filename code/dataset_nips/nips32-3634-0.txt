This is a good paper. The idea of using multivariate functions in order to perform better learning (distinguishing different distributions) is quite evident, especially when considering the fact that the assessment of the quality of the discrimination in the paper is expectation-related. It is an interesting and well structured paper. The statistical analysis of the Graph-based Discriminator classes is clear and informative and invites the follow up questions presented (closing down the gap in sample complexity, extending the expressiveness bounds for larger k).  A few other points regarding this paper: 1) In line 94 - You state that o(\rho) examples are sufficient for discrimination. I believe (even though this is early in the paper) that it would be clearer to state this size using the \epsilon and \delta confidence and accuracy parameters at this stage. 2) In line 229 - You write 'fix all coordinates'. It is possible that this phrase is ambiguous but my understanding is that you intend to fix only a single coordinate while all others remain parameters of the function (executing a reduction to k-1 gVC), While what I understand from the reading the phrase is that after fixing all but one coordinate we end up with a function which receives 1 parameter instead of k-1. 3) I would be very interested in seeing future work regarding different types of discrimination 'loss' (equation 1 in line 31) since the difference in expectations of distinguishing functions hardly seems the best tool for differentiating distributions using a minimal amount of tests.  Best of luck