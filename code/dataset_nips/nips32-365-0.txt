Comment on rebuttal: Thanks for addressing my concerns. I increased my score. By my comment on \lambda on table 1, I meant that the bottom of the table hides the bar not that the definition of \bar{\lambda} is not clear.  --------------------------------------------------------------------------------------------------------- The paper studies the problem of recovering block structure from a noisy tensor, which can be seen as a higher-order extension of stochastic block models. A least square estimator with good convergence properties is proposed together with alternating least squares implementation. Extensions are proposed to select number of blocks as well as model sparse data.   This is a well-executed paper. The formulation is clear and the flow of ideas is natural. Theoretical analysis and comprehensive experiments are provided. I did not check the correctness of the proofs.  I do have some minor comments though:  - L59: I believe by "fiber" the authors mean "slice". - L131: How do you know your estimator is "nearly optimal"? If this is based on equation (6) I would remove it and maybe mention later than equation (6) provides a *suggestive evidence* for optimality. - L230: Please indicate that this is *RMSE* rate and use big O notation to make it clear you dropped a term. - In sparsity experiment, it seems you are using \rho instead of p to indicate sparsity? Please fix that and specify the value of \rho (C norm) you used. - Also, in sparsity experiment. It does not make much sense to report baseline results. They do not add any information and only make the table more difficult to read. - In the description of table 1: the bar of \lambda is not clear.