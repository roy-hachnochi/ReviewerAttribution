The authors motivate the problem quite effectively and go into detail on the recall bias (that is, propensity of inference methods to penalize topic distributions significantly for missing document terms) of standard topic models. This is a useful observation that can motivate researchers to address this inherent bias. The authors propose a new topic model to balance precision and recall. This is done by introducing a Bernoulli distribution that controls word token generation through topics or through document specific word distribution. The authors note that this is similar to the SW model by Chemudugunta et al. The differences are that the SW model uses a weak symmetric prior for the Bernoulli distribution (\lambda) and uses a biased estimate for the document-specific word distribution. Experimental results measuring precision, recall, coherence, etc. demonstrate that the proposed model is significantly better on all metrics except recall (as one would expect). This is a significant result.  I have some questions that I would like the authors to respond/address: In my opinion, the differences between the proposed model and the SW model are not significant. For example, it is straightforward to convert a weak symmetric prior to a strong asymmetric beta prior in the current setting. Maybe the novelty is the way the document-specific word distributions are generated and the theoretical connection of your proposed model to the K-divergence. (ii) Secondly, based on the reasoning in lines 268-273, it looks like one other disadvantage of the SW model is its inability to explain generic words in the corpus. However, the same paper also introduces SWB model to address this issue. It would be useful to compare your model to the SWB version. (iii) It would be useful to see if the results in Table 2 are sensitive to \lambda. My understanding is that all of them use \lambda = 0.1.  The paper is quite well-written and the theoretical motivation for proposing the model is compelling. 