This work connects together the idea of using Wasserstein distance for cost functions in GANs to stabilize training with the recently introduced notion of quantum GANs. To someone with sufficient visibility into both the machine learning and quantum computing literature, this might be seen as a natural progression and tying together of ideas from existing works in a straightforward way. Admittedly, though, there may be very few such dual-field experts out there.   For quantum computing researchers, this work provides a method to potentially train larger-scale models on noisy machines than have been previously managed. To machine learning researchers, this work could be interesting because extends the familiar notion of WGANs to run on a new type of (available) hardware that can potentially model interesting intractable distributions.   The paper is technically clear. I did not spot any obvious flaws or scientific errors. The numerical results support the motivation and theoretical results of the paper (that training should be smooth and efficient).   The submission is clearly written and the argumentation is clear. I could follow the narrative of the work without any big issues, and extensive supporting material, proofs, and code are provided in the appendix for those seeking more concrete details. There were a few minor typos (more of a nuisance than any significant barrier to understanding). I would recommend that the authors go through an additional round of editing to polish it up.  This work builds upon previous work in a positive way, showing how existing training methods for quantum GANs can be made smoother and more robust, potentially allowing much larger models to be trained easier on noisy hardware.   Regarding significance, I would vote in favour of acceptance of this paper in NeurIPS because it is important for ML researchers to be made aware of advances and potential advantages of near-term quantum computing devices for machine learning. In particular, the ability to build generative models which can model and sample from otherwise intractable distributions---with the ability to run these models on currently available (or near-term) noisy quantum hardware---might be of general interest to the machine learning community and should be highlighted. Wider awareness of the current ideas in quantum machine learning could potentially lead to interesting breakthroughs and new bridges being built by experts from both sides. 