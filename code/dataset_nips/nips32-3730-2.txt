After reading the feedback from the authors: I am pleased to see that the authors have already managed to obtain much more convincing numerical results. I maintain my rating, and look forward to other applications of the Sinkhorn sorting operator in the future.   == The article starts with an equivalence between sorting and an optimal transport problem.  It leverages this equivalence to introduce a new generalized sorting operator, called Kantorovich sorting, and an entropy-regularized version called Sinkhorn sorting.  The latter is special in that it corresponds to a differentiable function of its input vector, as opposed to standard sorting. Consequently some uses of sorting operators in machine learning can then benefit from gradients, which would be unavailable with the standard sorting operator.  The paper introduces new fundamental objects, Kantorovich and Sinkhorn sorting operators (as well as CDFs and quantile functions), in a very insightful and elegant presentation (despite a number of typos, see below).  Applications to a variety of tasks, such as top-k loss, quantile regression, or soft quantile normalization, help to understand the potential use for machine learning. Nevertheless, the main contribution is of a conceptual nature, and while it is hard to anticipate where exactly the proposed objects will be most useful, they are clearly of interest on their own right, and very innovative.  The numerical experiments are a nice addition but it seems clear that the most fruitful applications of the new operators are yet to be found.  There are also some open questions about the choice of "m" and of the regularization parameter.  Overall I find the proposed manuscript to be very exciting.  It is very original and very clear thanks to examples and diagrams.  It can have far-reaching implications for a vast number of tasks in machine learning, despite the relatively modest advantages illustrated in the numerical experiments. There are a number of typos that can be easily fixed.