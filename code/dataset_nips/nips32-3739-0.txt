Overcomplete ICA (more sources than data) often becomes feasible after making a parametric assumption on the distribution of sources to make the computation of the likelihood feasible. The authors have proposed a method to estimate the mixing matrix without computing the likelihood. The proposed method is minimizing a distributional distance (MMD) between the generated and observed data when each source is produced by a nonlinear transformation of an independent noise. The generation procedure makes sure that sources are independent. The mixing matrix and the parameters of the generator of each source distribution are learned together.  Challenges: Identifiability:  The authors proposed the use of MoG as a parametric model for sources when the data is scarce. Such method has been extensively studied by [1] and [2]   It is not clear from the paper under which circumstances the proposed algorithm converges and if it converges to the true source distributions and true mixing matrix.  The main advantage of ICA method compared with Deep generative or inference methods is identifiability. Can you argue under which conditions the method become identifiable?  Regarding the sparsity regularizer, sparse coding has been extensively used to approach ICA and Overcomplete ICA problems [3, 4].  The use of GAN-based methods to solve nonlinear ICA problem was studied in [5].  Given these previous work, I think the proposed method lacks sufficient novelty for acceptance.   [1] Choudrey, Rizwan A., and Stephen J. Roberts. "Variational mixture of Bayesian independent component analyzers." Neural Computation 15.1 (2003): 213-252.   [2] Mehrjou, Arash, Reshad Hosseini, and Babak Nadjar Araabi. "Mixture of ICAs model for natural images solved by manifold optimization method." 2015 7th Conference on Information and Knowledge Technology (IKT). IEEE, 2015.    [3] Olshausen, Bruno A., and David J. Field. "Emergence of simple-cell receptive field properties by learning a sparse code for natural images." Nature 381.6583 (1996): 607.  [4] Doi, Eizaburo, and Michael S. Lewicki. "Sparse coding of natural images using an overcomplete set of limited capacity units." Advances in neural information processing systems. 2005.   [5] LEARNING INDEPENDENT FEATURES WITH ADVERSARIAL NETS FOR NON-LINEAR ICA   Update:  Thanks to the authors for providing a detailed answer to my questions. Even though some of my concerns still remain unsolved, I'd like to increase my score from 4 to 6.