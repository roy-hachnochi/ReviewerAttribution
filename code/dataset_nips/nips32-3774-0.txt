Update: Thanks for the feedback and I have read them. Yet I don't think it has convinced me to change my decision. For Q2, if the framework is general, the authors should have extended it more than one case. Otherwise, the authors should focus on PCA instead of claiming the framework to be general. For Q3 and Q4, I think the discussion on how to choose k and d is not sufficient in the paper. For Q5, my point is that the naive method (not PCA) will easily beat the proposed method, making the error criterion less convincing. I do like the insights of A1 though.   ---------------------- The authors developed a new robust dimensionality reduction framework called RSWL that adaptively learns different weights for different data points to achieve both robustness and sparseness. Here, the sparseness refers to that weights for the data points are sparse (which might be better clarified in the revision). Also, the authors applied RSWL to the PCA problem to develop a robust PCA approach called L3RL. Empirical results are provided to showcase the superiority of the proposed method.   I find the idea of learning different weights for different data points interesting and promising. The paper is well-written and the derivations seem to be technically correct. However, I have several concerns listed below:  1. The RSWL framework (7) does not seem to be well justified. Why squared loss for the regularization term instead of l1-norm or l2-norm? Does it work better in practice or it is because the closed-form solution (17) is only available for the squared loss? 2. The authors claim that RSWL is a general framework, yet they only applied it to PCA. How about other forms of the function $f$ other than linear?  3. Can the parameter k be chosen automatically, perhaps via some cross-validation methods?  4. How to choose the reduced dimension d?  5. In line 178, the authors mentioned that the error is quantified via a weighted loss where the weights p_i are learned by the algorithm. Is this fair? Because if it is fair, I imagine a naive method that assigns all weights (i.e. 1) to the data point with the smallest error would easily beat the proposed method.  6. For Figure 1, what is the baseline?  7. If I understand it correctly, the y-value at 0.85 in figure 2a should match corresponding reconstruction error in Table 2 (which is 6.65). Have I missed something? 