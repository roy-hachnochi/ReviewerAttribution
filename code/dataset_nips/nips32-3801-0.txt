post-rebuttal: Thank you for the clarification. My score remains the same.   -----------------------------   It is an interesting work that addresses the degeneracy of batch acquisition when using BALD as a score function. The methods proposed in the paper elegantly deals with the problem of redundant acquisition when using BALD in a greedy manner. I have a few questions and hope the authors can address them:  (1) Does this problem of redundant acquisition only happen when one uses BALD as the score? Intuitively I would think no, as if one uses any score function greedily, regardless of the contribution of the other samples selected in the same batch, one can still end up with a biased batch that can potentially harm training. If this is the case, then why are var-ratios and mean-std outperforming random? I guess it is a matter of batch size? Is there any intuition why this problem seems more serious when one uses BALD as the acquisition score?  (2) To me, Figure 4 really points out the problem and Figure 5 explains why we want to do AL in a batch manner (due to the computational cost). To avoid confusing though, I would suggest emphasizing that an AL algorithm is considered as good when the "accumulated accuracy" is maximized (Fig 4), as long as it is not at the cost of extra computational burden (Fig 5). Since simply just reading Fig 5 (and the description in the text), one could interpret it as BALD is better since it takes less "time" to achieve 95% accuracy.    (3) I'm not sure if I get the meaning of Fig 8. You can probably just randomly permute the RHS and it's going to look equally uniform. Likewise, you can also sort the bins for the BatchBALD's acquisition count, then for sure the difference between the max and min values will be contrasted. Perhaps sorting both of them will be more fair? I would also suggested printing some statistics measuring the dispersion (entropy, range, etc).   On a related note, why is it that they end up having different "datasets"? is it that the training set is not exhausted after all of the acquisitions?   (4) The section on "scope and limitations" seems a bit hastily written. For example, I don't get the intuition of why BatchBALD is expected to perform well if the test set is balanced, and not so otherwise. Will BALD also perform well if the test set is balanced? Please elaborate.   (5) What does the shaded area in all of the figs stand for? "1 stdv from the mean across multiple experiments"?  "over test set data points"?    (typos)  - line110: redundant "p(w" at the end? - line122: I think P_{1:n-1} is of shape c^{n-1} x k ? - line238: "Noisy" estimator 