Quality: Pros: Overall, this is a technically sound submission. I really like the proof of the submodularity of the proposed batchBALD acquisition function. Furthermore, the way to estimate that acquisition function using Monte-Carlo as well as the new efficient implementation are quite interesting.   Cons: My first concern is about the quality of the estimation in (10) when working with large acquisition sizes $n$. In particular, the number of overall possible configurations of $y_{1:n}$ is $n!$ (# of permutations)--will be extremely large when $n$ increases, while only $m$ samples were chosen. Although this was explained in app. C, it's still unclear for me about the difference between $m$ and $n!$.   Furthermore, the experimental results of the submission is not very compelling since they were only conducted on MNIST and its variants. It's would be more convincing if the authors can provide the results on at least one more benchmark data set in the field (e.g., cifar10).   Clarity: The submission is clearly written and well organized. However, it's unclear for me about the definition of data repetition. Does a data point x' duplicate the given data point x if x'=x, or these samples are closed enough? That relates to the Alg.1 as well as way to generate the repeated MNIST(sec. 4.1).  In particular, Alg. 1 can only guarantee that the new selected data point $x_n$ is different from the previous ones; while in repeated MNIST, a duplicated sample is generated by adding a Gaussian noise to a given sample.   Originality: The proposed BatchBALD is a novel extension of one of the most widely studied acquisition function in the Bayesian active learning with disagreement (BALD) framework [10], but targeting the selection of a joint (dependent) batch data samples to improve the data diversity. The paper also introduces the use of a greedy approximation algorithm as well as new ways to estimate the BatchBALD acquisition function.    Significance: The main contribution of the paper is to improve the data efficiency of the selected informative data points in BALD w.r.t both the diversity and batch size. The experimental results are quite promising.   Post rebuttal comments: I have read the author feedback carefully. Thanks the authors for providing insightful clarifications, especially for providing further  experimental results required for the score improvement. Also, based on positive coments/evaluations from fellow reviewers to the paper, I decide to upgrade my score for the paper to 7.