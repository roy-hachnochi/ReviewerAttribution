The paper is an original application of likelihood free inference to parameter estimation in a mechanistic model of the ribbon synapse. It is not super advanced on the inference aspects, but well executed and described. My feeling is that the community which would be most excited would be ribbon synapse neuroscientists, and they would be most excited about the results of the parameter estimation rather than the method itself. I'm not sure the neuroscience NeurIPS community at large would get that much out of the paper which is not already covered by existing (and more advanced) likelihood free inference papers such as ref [6] already cited in the paper.  A few questions: Is the linear filter really constrained to have a single form with a single stretch parameter? I would have assumed that given the discrete Gaussian or binary noise stimulus, it would be possible to estimate the full filter directly from data. Why is the filter constrained in this way?  It appears that the posterior over model parameters inferred via the method is a factorized distribution. What is the reason for leaving out the correlations? I would have assumed that it would be relatively straightforward, given that the distributions are all Normal? Is it because of the truncation applied to some of the distributions?  The acceptance criterion is to accept the best j particles. I wonder how well an acceptance criterion based on the loss value would work? Is it possible that the variance of the posterior is over or under estimated by the best j criterion? For instance, if more than j particles are within an acceptable loss value, then we would get an underestimate. And conversely, if the worst particles in the j best particles have unacceptable loss values, then the variance will have been over estimated.  