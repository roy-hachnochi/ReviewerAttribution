Summary: The paper proposes to use GANs in the LLP setting, where only the proportions are known per bag of covariates (say images), the goal is to create a classifier on the covariate level. Similar to the previous work in semi-supervised learning with GANs, the discriminator in this case classifies between the current classes and a new class for fake samples. Here, the loss function like the normal GANs uses two term, one for the supervision for the matching of the label proportion, the other for the adversarial training. The authors then proceed to analyse this loss function.  Originality: I have not previously seen the use of GANs in the LLP setting or the use of the lower bound approximation that allows for SGD on individuals. Also, I think the work done on analysis of the loss function is also new and interesting, however I am not an expert on GANs.   Clarity: I think the paper is mostly well written, however I have some comments and questions below.  Experiments: The authors compares their methodology to the current literature baseline that does not employ GANs, and also other baselines that are available for binary classification. In particular, they verify their algorithm on MNIST, SVNH, CIFAR10 and CIFAR100 for different bag size beats the current baselines. I have some question on experiments regarding the CIFAR100 experiment below.  Comments/Questions  1. Can authors give intuition on why the use of GANs would be beneficial in the setting of the LLP, the motivation was not very clear in the paper.  2. Since the discriminator constructed at the end is a K+1 class (including the fake data class) classifier, what do authors do for true K class when you use it?  3. How would the performance change if you were to use SGD on bags instead of individuals for LLP GAN? It might be an interesting experiment to run.  4. Is the current DLLP baseline implemented with SGD on bags or uses also the lower bound approximation? 5. Figure 3 seems to have unstable behavior during training, is this expected behavior? 6. In appendix Figure 1 for the multi-class case, the DLLP performance seems to massively drop from Bag size 16 to Bag size 32, this looks a bit strange, what is the reason for this? Related to this, recently I have come across another LLP paper [1] (arxived after NeurIPS submission), which also implements the baseline DLLP for CIFAR 10 and CIFAR 100, the performance for the same baseline seems to be a lot better in that paper. Can the authors comment on the differences in the experimental setting (architecture, training epochs etc)?   If the reviewers can clarify my comment and questions, I am happy and open to raising my score.   [1] Deep multi-class learning from label proportions. Gabriel Dulac-Arnold, Neil Zeghidour, Marco Cuturi, Lucas Beyer, Jean-Philippe Vert  Rebuttal: I have increased my score, as the authors have clarified my comments on motivation, and experiments. 