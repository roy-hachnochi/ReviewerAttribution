The paper studied loss functions for distribution approximation. It define various properties and prove different Theorems that show some nice inequalities with respect to these properties. Yet, the main punchline in the paper is missing. Why these properties are really important? I would expect to see a real example where the analysis made in the paper helps with. This part is lacking in the paper. So it is not really clear what is the applicability of the derived results.   Also the claim that only log-loss is used for learning distributions is not true. Unless I miss something, generative models are designed to learn distributions and they don't use only the log-loss. Where do they fit in the story? I think that giving them as an example and studying for example the earth moving distance and seeing what properties it gives etc. will make the paper stronger and clearer of why it is important.  At the moment, it is far from clear to me. 