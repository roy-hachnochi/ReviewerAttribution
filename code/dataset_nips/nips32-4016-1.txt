I have concerns about the following aspects of the paper:  (1) Related Work (missing citations and experimental baselines)  The paper unfortunately fails to cite or compare to other recent neural network architectures that exploit scale space.  For example:  Multigrid Neural Architectures Tsung-Wei Ke, Michael Maire, Stella X. Yu. CVPR 2017  Feature Pyramid Networks for Object Detection Tsung-Yi Lin, Piotr Doll√°r, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie CVPR 2017  Multi-Scale Dense Networks for Resource Efficient Image Classification Gao Huang, Danlu Chen, Tianhong Li, Felix Wu, Laurens van der Maaten, Kilian Q. Weinberger ICLR 2018  While these particular example architectures do not enforce scale equivariance, that actually makes comparison to them especially important.  We would like to know whether building in scale equivariance is actually a superior design.  Perhaps merely using multi-scale representations suffices?  (2) Novelty and presentation.  The mathematical exposition seems unnecessarily long, especially as it boils down to using dilated convolution in order to achieve scale equivariance.  This strategy for equivariance does not seem surprising and brings into question the overall degree of novelty.  (3) Depth of Experiments  By reporting only a few results on PCam and Cityscapes, against extremely simple baselines, it remains unclear whether the proposed design for scale-equivariance actually improves upon the state-of-the-art.  At minimum, I would expect to see performance reported on widely used benchmark datasets for semantic segmentation, such as PASCAL or COCO, where object scale is important.