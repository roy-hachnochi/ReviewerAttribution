Update:  I have reviewed the author feedback and was satisfied with some of the answers I have received. The motivation for the definition itself is still not clear enough to me (more specifically - its strictness) but I believe I can be patient and let the research of different but similar definitions be postponed to future work (as mentioned toward the end of the paper). Good luck.  Original review below:  The idea of the paper is interesting and discusses the fact that expected risk does not necessarily improve with larger data sets. It is clearly written and the points (and proofs) come across very neatly. On the other hand, the authors state that intuition would lead to the fact that the learning curve is monotonous. While it is an interesting discussion, I believe it is rather general to assume this and I believe that there are quite a few researchers that would put this statement to doubt. The analysis of the example distributions is interesting and clear, and the empirical results provide neat support to the proven theorems and examples.  For this reason choose to accept this paper.  The reason for my low acceptance score is that I believe the paper would have been more whole with more research of the exact conditions for monotonicity. The discussion that monotonicity is non-trivial is a large part of the paper which I believe could have been navigated towards the mentioned ideas. With further research regarding the conditions and the relation to PAC learnability (and combinatorial measures such as the VC dimension) I think this would be a very good paper.  One last point which I would like to address: the notion of monotonicity seems rather strict. Would the proofs hold if instead of monotonicity you would require convergence of the risk?  Best of luck