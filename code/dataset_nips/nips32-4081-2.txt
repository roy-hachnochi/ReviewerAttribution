Originality: it is difficult for me to assess the level of novelty of the ideas proposed in the work proposed in this paper. It seems to me that addressing the exploration problem using an additional planning strategy is close to what has been done in the Bayesian RL literature, in particular, Bayesian approaches doing planning in a Belief-augmented MDP.  Quality: it is difficult for me to assess the quality of the proposed approach (at least for its exploration performance). I could not see any empirical evaluation, nor clear theoretical statements (section 4. provides some more formal analyses, but without any claims (I mean Lemma, or Theorem) coming with proofs.  Clarity: despite the paper lists contributions at the beginning, I personally found the structure of the paper a bit complicated to follow. In particular, I found Section 4. strangely written: it proposes some form evaluations, but without structuring it in a sequence of Lemma and proofs.  Sometimes, the paper develops some intuitions starting from imaginary MDPs, for instance "For example, in an MDP with two states {s1, s2} [...] , a demand D[s1, a] > 1 can never be satisfied and will lead to an infinite exploration cost." These types of arguments could be formalised into lemmas or propositions.  Significance: the paper may be of interest for researchers interesting in sample efficiency of RL algorithm. However, the paper should emphasize more (and, perhaps, more quantitatively, including empirical evidence) how the proposed algorithm positions itself of the proposed approach regarding other algorithms.  *** Post feedback *** I have updated the overall score according to the feedback provided by the authors.