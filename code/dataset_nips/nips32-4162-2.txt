A new algorithm, competitive gradient descent (CGD), is proposed to solve for the Nash equilibrium of two-player zero-sum games. It is derived from the closed form solution of a local bilinear approximation to the game at each learning step. Given assumptions such as bounds on the player Hessians, exponential convergence is proven. CGD is compared to several other algorithms in the literature both empirically and based on mathematical form. A link to levels of intentionality is also made using the Taylor series expansion of the inverse. Finally, experiments fitting a GAN to a Gaussian mixture (bi-modal) distribution show CGD converges faster than other methods.  I believe the perspective of solving for the Nash equilibrium of a bilinear approximation is novel, however, an argument for the specific bilinear approximation proposed is lacking. Moreover, if the bilinear approximation were to retain the diagonal Hessian terms, e.g., 0.5*x^T (D^2_xx) x, the derived update becomes the standard regularized Newton method (based on a quick calculation): new preconditioning matrix from line 147 = [[I+eta*Dxx f, eta*Dxy f],[eta*Dyx g, I+eta*Dyy g]]^{-1} = (I + eta*Jacobian)^{-1}. This is regularized in the sense that identity better conditions the matrix for inversion. Therefore, the update presented on line 147 is nearly Newton's method applied to fixed point iteration, i.e., Delta = -J^{-1}F where J is the Jacobian. Theorem 2.2 requires eta*||D^2_xx f|| <= 1 -- does this condition arise because the diagonal terms in line 147 are replacing eta*(D^2_xx f) from Newton's method with identity? A discussion around these similarities would be helpful. It is known that Newton's method is attracted to critical points generally, not just minima (see "Identifying and attacking the saddle point problem in high-dimensional non-convex optimization"). By replacing the diagonal terms in line 147 with identity, CGD can avoid converging to some unstable fixed points -- does this prevent all failure modes? What are some of CGD's failure modes if any? Doesn't the requirement in Theorem 2.2 (eta*||D^2_xx f|| <= 1) suggest that a large enough step size, eta, may prevent convergence?  The work is generally high quality and clear, and many of the perspectives are original. I think the community would benefit from some of the ideas in this paper. The paper would benefit from a discussion of the weaknesses of CGD.  Main concerns: 1) CGD is very similar to Newton's method, but there is no rationale mentioned for dropping the diagonal terms of Jacobian. 2) No argument is presented for the specific bilinear form proposed as the fundamental local approximation to the game. 3) Complexity of inverting a matrix is dealt with using conjugate gradient but comparisons are done using "simple" GANs. Would this method scale well to higher dimensions? Do you believe there is a threshold at which the matrix inversion method becomes intractable? Have you tried CGD on more standard GAN tasks, e.g., MNIST, Celeb-A, CIFAR10? Do you expect problems at that scale?  Also, SGA [Balduzzi et al, 2018] was independently derived in "Global Convergence to the Equilibrium of GANs using Variational Inequalities" [Gemp et al, 2018]. This work provides a comparison similar to Figure 1 in this paper. It should probably be cited along with Balduzzi '18 and Letcher '19.