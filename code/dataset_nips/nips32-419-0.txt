The paper considers the problem of sketching in linear regression with symmetric norm loss functions. They provide a novel sketching method for generic symmetric norms that can provide a $d\text{polylog}n$ approximate to the underlying solution. This is an interesting result especially due to the fact that it generalizes the previous results in the literature. However, unlike other results in the literature (which mostly focus on $\ell_p$-norms and recently M-estimators), it can not provide a $1+\epsilon$-estimate of the solution (this is presented as a future direction in the conclusion section.) For the special case of Orlicz norm, the row sampling algorithm according to the Orlicz norm leverage score is a novel algorithm that can improve the previous results (in [2]). However, it should be emphasized that the Assumption 1. limits the applicability of the result. Specifically, due to the fact that the growth in function $G$ is sub-quadratic, this algorithm can not be used when the loss function is an $\ell_p$-norm with $p>2$. I understand that this a theory paper. However, in order to show the applicability of the algorithms I expected to see some experimental results to compare the time complexity and the quality of the estimate of the proposed algorithm with the previous results in the literature. The paper lacks providing experimental results which would have been very interesting for NeurIPS audience.