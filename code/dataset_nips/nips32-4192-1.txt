The paper considers a framework to coarsen (and/or sparsify) a graph via a probabilistic scheme that tries to preserve the spectral properties of the Laplacian pseudoinverse.  The authors demonstrate how this viewpoint can provide a 'unifying' framework from which the contraction of nodes (coarsening) as well as the removal of edges can be considered. I think this is a very interesting paper, even though I have a number of concerns as listed below.  Quality ======= Overall the claims the authors make are well supported. However, ocassionally their arguments feel a bit imprecise.  In section 3.2, for eq 5-6:  the authors argue that edges are uncorrelated  is a 'reasonable assumption, when one is considering a 'small fraction of edges'. There are several issues here: first, I feel their should be more explanation than a half sentence in parenthesis of why this should hold in such a limit. Second, they consider quite large fractions of edges afterwards (see e.g. Figure 2). Third it will certainly also depend on the position of the edges whether they are correlated or not. Some of these effects the authors account for themselves in their multi-step scheme when they discuss the merging of two important nodes and one unimportant node.  The algorithm the authors propose starts from the full graph and then eliminates edges. Now, if the argument is that the graph is too large to be kept in memory to start with, seems to be not a very good option, and at least slow down the first few iterations  -- is there any way to adjust their method to act more local or start from an empty graph? This would merit more discussion here.  What is the computational complexity of the algorithm?  Can the authors say something about the numerical stability of the Sherman-Woodbury-Morrison updates? In general I think these updates do not have to be numericall stable.  Sampling edges uniformly at random -- is this done for convenience or is there some kind of optimality associated with this sampling scheme? (e.g. in contrast in sparsification edges are also sampled according to the ratio of effective resitance and local weight)  The arguments put forward in the 'hyperbolic interlude' seem weak. There are many many ways to compare to graphs, and even if we accept that the relevant way is to compare the effect of linear operators it seems unclear how the authors end up with their particular distance (there also other ways to compare the angular distance between vectors). As the authors use exclusively this distance to compare their results to other methods this seems a bit like cherry-picking, in particular, since the other methods were not developed with this error metric in mind (and thus a claim that their method is superior based on this metric alone seems strange). I would suggest the authors show at least the comparison in the original error metric with the quadratic form. It would also be good it a comparison to more than one sparsification technique would be shown -- there are many more methods out there; and in particular those combined sparsification / coarsening techniques the authors cite themselves seem relevant for comparisions but are omitted.  Finally it would be beneficial if instead of just using some empirical graphs, the authors could use some synthetic graph construcitons in which they have a finer control about the properties of the graph to be sparsifieda / coarsened, such that we can see what are the relevant effects here. For instance the coarsening should work very well if the graphs have 'community structure' etc.  Optional suggestion: Some more discussion about the relationships of coarsening to community detection and formal model order reduction of LTI systems could also enhance the manuscript.   Clarity. ======== The paper is written quite clearly, overall.  I have several issues though:  The cost function (7) is meant to be optimized over what exactly? a single edge? In general I found the explanations in section 3.4 could have been more detailed.  In the section section 3.5., the authors state that one has to chose the 'appropriate pseudoinverse' but then do not say why their choice is appropriate. For the Sherman-Woodbury-Morrison for rank-deficient matrix -- please refer to the following paper: Meyer, Jr, Carl D. "Generalized inversion of modified matrices." SIAM Journal on Applied Mathematics 24.3 (1973): 315-323.  Originality. ============ The idea underpinning the paper is original, even though I feel the cost function the authors propose seems to be somewhat ad-hoc.  Significance ============ This is clearly a significant topic, in my opinion, as many graph based algorithms could be augmented by such a technique.  Conclusion ========== A good paper with some shortcomings that need to be adressed. Otherwise I think this is an interesting contribution.  [update post discussion]  After considering the authors' response and the discussion, I believe this could be an interesting contribution, provided the authors improve the paper as indicated in their response letter; in particular with respect to the clarity of the presentation.