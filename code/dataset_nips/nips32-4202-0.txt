The full paper is much longer and compressing it into an 8-page NeurIPS version makes for a terse read; I would advise the authors to summarize certain results so as to make the shorter version easier to read.  1. The discretization in (13) and (14) are given out of the blue. A derivation starting from (6) will be helpful.  2. Line 177: Theorem 1 should say “has _uniform_ local deviation orders”?  3. Section 4.2 is scant on details. It was not clear to me upon a first reading what the non-convex potential is, especially since Section 4.1 uses overdamped Langevin equation with constant diffusion for a strongly-convex potential.  4. Can you plot the dependence of W-2 with dimension in Figure 1? This will help ascertain the improved convergence rate numerically. Similarly, you should use the number of gradient evaluations as the X-axis in Fig. 1b. The SRK scheme uses three gradient evaluations whereas the EM scheme uses one.  5. How do you compute the MSE in Fig. 1c? Why does it increase with the number of iterations?