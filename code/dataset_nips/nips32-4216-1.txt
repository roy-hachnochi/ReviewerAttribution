This paper focuses on the video classification task, its goal is to speed up the inference of typically heavy video neural networks. The proposed method is a "cascade" like approach where one light-weight 2D CNN (e.g. MobileNets) scans through all frames, and an LSTM is employed to decide whether to apply a heavier-weight 2D CNN (e.g. ResNets) on each frame. The main innovation of this paper, is that opposed to previous work which are reinforcement learning-based, it proposes to use the Gumbel softmax trick which allows the whole framework to be trained end-to-end. Empirical results on FCVID and ACTIVITYNET confirms that such optimization process outperforms several RL-based baselines.  Clarity: the paper is very clearly written and easy to read. Originality: Although the proposed framework is not entirely novel (the high-level idea of skipping frames, and cascades have been explored by previous work on this topic), the optimization process is novel for this particular application (although explored under other scenarios) and shown to be critical by empirical evaluations. Significance: speeding up video classification networks is important for practical applications. However, the choice of using LSTM to aggregate temporal features may limit its practical application, as it has been shown by recent work that 3D ConvNets significantly outperform RNN alternatives on video classification benchmarks. This can also be seen from Table 1, where the uniform baseline is "unreasonably" strong compared with LSTM, on both datasets.   (Post rebuttal) The reviewer appreciates the authors' rebuttal which addressed my concerns. I keep my original rating and recommend acceptance of the paper.