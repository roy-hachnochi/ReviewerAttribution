Before getting into the review, I want to emphasize the high level of similarity between this submission and (Wang and Jegelka, 2017,  https://arxiv.org/pdf/1703.01968.pdf). I recommend reading the two papers side by side, since it is clear that this work was inspired by it to a high degree. I believe the comparison of the two works should be the central question of the review process.  (1) Quality: Is the submission technically sound? Are claims well supported by theoretical analysis or experimental results? Is this a complete piece of work or work in progress? Are the authors careful and honest about evaluating both the strengths and weaknesses of their work?  The submission is of very high quality. Max-value entropy search is well motivated, demonstrably works well in practice. The authors deserve credit for the careful, high quality experiments. Furthermore, the paper provides a theoretical guarantee on the performance, although I lack the expertise to properly judge the significance of this.  (2) Clarity: Is the submission clearly written? Is it well organized? (If not, please make constructive suggestions for improving its clarity.) Does it adequately inform the reader? (Note: a superbly written paper provides enough information for an expert reader to reproduce its results.)  The paper is an excellent read. It presents the algorithm in a structured way, with sufficient detail for reproduction. I would recommend it for reading to anyone interested in the general topic.  (3) Originality: Are the tasks or methods new? Is the work a novel combination of well-known techniques? Is it clear how this work differs from previous contributions? Is related work adequately cited?  As mentioned above, it is clear that this work was heavily inspired by MES (Wang and Jegelka, 2017).  This work does not adequately cite related works. My problem is that the way this submission puts it, 'our work is inspired by the recent success of single objective BO algorithms based on the idea of optimizing output-space information gain', might give the wrong impression to the reader. MESMO is the natural extension of MES (Wang and Jegelka, 2017) to the multiobjective domain. It also positions MESMO against PESMO and it compares/contrasts the two. This comparison might make it seem like the contribution is greater than it is in reality. On multiple occasion, the paper presents work without disclosing the strong connection to (Wang and Jegelka, 2017).  Examples: - Section 4, Equations 4.4-4.6. These equations literally come from (Wang and Jegelka, 2017). - Section 4 1) and 2), The algorithm this paper uses to approximate MESMO is the same algorithm as in (Wang and Jegelka, 2017). - Section 4.1 The theoretical result is analogous to Section 3.4 of (Wang and Jegelka, 2017).  Based on the arguments above, I will rephrase the question: Are the ideas in this paper novel enough to warrant a new publication over (Wang and Jegelka, 2017)? I would argue that they are not. The reason is that there does not seem to be a significant hurdle that this work needed to overcome in order to extend MES to the multiobjective domain. Both the formula for MESMO and the algorithm to approximate it extend to multiobjective problems. I cannot comment on Theorem 1.  (4) Significance: Are the results important? Are others (researchers or practitioners) likely to use the ideas or build on them? Does the submission address a difficult task in a better way than previous work? Does it advance the state of the art in a demonstrable way? Does it provide unique data, unique conclusions about existing data, or a unique theoretical or experimental approach?  The method is certainly interesting to practitioners. The work demonstrates the performance of MESMO on a variety of benchmarks and it consistently outperforms the baselines.  _________________________________________________________________________  After reading the author's reply, I decided to raise my score. I expect that the connection to (Wang and Jegelka, 2017) is properly disclosed in the revised version.  The paper is very well written but it has shortcomings in originality. The explanation for my score is that I think a practitioner might find this paper useful, but I don't expect it to have a large impact in the research community.  I think this paper is truly borderline. I do not have strong arguments for or against acceptance.