*Rebuttal* I thank the authors for addressing my comments and including the additional performance comparison. I will increase my score to 9.  *Summary* PyTorch is an open-source deeplearning library that strives to marry good performance, flexibility and usability. It is specifically designed for researchers with the goal to enable easy experimenting with new features. Through seamless integration in the Python ecosystem it enables the interoperability with other python libraries which makes prototyping easy for the user.  One may argue whether a systems/software paper, presenting the implementation details of a library should be published at NeurIPS, or whether it would be a better fit for USENIX or SysML. However, given the impact of the library in the research community I strongly support the publication of this paper at NeurIPS. PyTorch is specifically designed for the research community, thus of high interest to most attendees.   The library offers what a researcher needs to validate new ideas without large implementation effort. By being fully open-source and providing flexibility to the user, it enables the exploration of new features, including new models and performance optimizations. Thus, it has high value to the community and helps drive research forward.  [clarity] The paper is well written and easy to follow. It touches upon many challenges faced when implementing such a framework and gives some insights into its power and also its limitations.  *Comments*  I feel from the paper it is not clear whether PyTorch can run in the absence of GPUs. It says that it supports GPUs, but does it depend on the presence of GPUs?  My main criticism is that you claim that PyTorch offers performance comparable to the fastest current libraries for DL. But what are these libraries? In Section 6 you compare to MXNet and Tensorflow. I feel to support this claim a broader comparison to other libraries would be necessary, or at least some evidence/reference that Tensorflow and MXNet are currently the fastest out there.  *Minor comments*  - I think it is nice to have a dedicated publication for PyTorch so it is more clear in the future how to cite it. However I wonder how attribution of this open-source library is handled.  - The authors could try to tight the paper a bit more to the conference. There is only a single reference that has been published at NeurIPS and maybe there could be done a better link. - Line 87: remove ‘.’ 