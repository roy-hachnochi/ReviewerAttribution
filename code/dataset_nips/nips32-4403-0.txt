# Post-rebuttal comment  Thank you for your clear and convincing answers. I am updating my score from 7 to 8.  ---  # Originality  The main contributions are all original. While the take-home message of the study is in retrospect simple and obvious (== compute MDI importances on out-of-bag samples), the paper provides an original analysis that explains and justifies this modification of the computation of MDI importances.    # Quality  I admit not having checked in details the proof of Theorem 1, but this appears technically plausible given assumptions A1 and A2. Some remarks however: - I would have appreciated a controlled experiment where G0(T) can be computed exactly in order to empirically appreciate the (supposed) tightness of the bound. - Can you comment on the limitations of the results? More specifically, what if A1 and A2 are not satisfied? In real-word setups, A1 is very unlikely to hold.  While most related work is properly cited, a missing reference is Section 7.2.2 of (Louppe, 2014 https://arxiv.org/abs/1407.7502) which includes recommendations similar to those formulated at the end of Section 2 of this submission. The author identifies that "feature selection bias" is caused by the misestimation of the impurity decrease. More specifically, the estimation error of the (Shannon) impurity is inversely proportional to the number of samples in the node and proportional to the cardinality of the split variable. From this, experiments conclude that early stopping mechanisms (e.g., limited depth, larger leaf sizes, etc) are a simple and effective way to reduce bias towards noisy features. I find this submission to be consistent with this hypothesis and results, which is valuable by itself.    # Clarity  The paper is well written and usually easy to read, provided familiarity with this line of research.   # Significance  This work is significant and unique. It provides i) a better theoretical understanding of MDI importances and ii) a simple but quite effective recommendation to improve their practical use. 