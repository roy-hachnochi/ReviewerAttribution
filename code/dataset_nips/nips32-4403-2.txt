my perspective remains unchanged after reading the author response. my original review is below.  - "However, G0(T) is typically non-negligible in real data, "  how could one ever know this? it requires knowing the true distribution, which we don't know for any real data - please replace tables with avg AUC with figures showing scatterplots, jittered scatterplots, or beeswarms, so we can see whether the differences are meaningful - the proof of bias is nice, and then there is a claim that the MDI-oob is debiased, but no theorem stating that, and then not even a simulation demonstrating it explicitly.  please add to figures 1 & 2 the result from MDI-oob to at least provide experimental evidence for the debiased claim.  - the oob idea is nice.  in RF land, people have leveraged this before to get consistent estimates of uncertainty.  Brieman actually suggested it in his 1984 book, in chapter 3, it is called "honest sampling".  it was then seemingly independently re-discovered by http://proceedings.mlr.press/v32/denil14.pdf and http://www.jmlr.org/papers/v13/biau12a.html,  and used by wager in several articles, for example, https://projecteuclid.org/euclid.aos/1547197251, and then also in https://arxiv.org/abs/1907.00325 along with another trick to decrease finite sample bias.  i haven't thought about it carefully, though i imagine some of the theoretical work in those papers could form the basis of theory for your MDI-oob. probably for a future manuscript, i would recommend at least mentioning these kinds of works here. - one question i have is why couldn't one simply compute MDI on oob samples, without the new equation? i feel that needs clarification. - in the SHAP papers, they make a big deal about a few "properties" that SHAP has, that no other existing feature importance algorithms have.  i'd prefer in the discussion, rather than a paragraph summarizing the results, a discussion on this topic. 