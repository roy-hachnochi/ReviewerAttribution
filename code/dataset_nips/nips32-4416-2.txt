Originality: The contribution is original with related work clearly referenced.  Quality: The techniques used in the proofs seem sound. It would be interesting to have values for actual networks, for several quantities (see "improvement" part)  Clarity: The setup and theorems are clearly presented. Everything is well explained and the proofs are in the appendix.  Significance: The natural gradient is a promising way for optimizing and analyzing neural networks. This theoretical contribution for 2 layers ReLU networks is an interesting step toward a more general theory.