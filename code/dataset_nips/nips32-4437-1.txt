--- After rebuttal --- --- After rebuttal  The authors provided a numerical result for the case with unequal sample sizes. I hope they can provide the details (none in the response, probably due to space limit?) into the revised version as well since this can improve the applicability of this work. For example, how to implement the look-up-table in this case since sorting does not work now.  I'm still concerned with the computation of the inverse of Monge map mentioned in Section 4.2 with unequal case. It should also be addressed properly.  I think the idea of using project pursuit to find Monge map in high dimensional case is interesting, although it also inherits the issues such as existence and uniqueness from Monge's OT form. I raise my score and incline to accept this paper.  --- Original review ---  The authors considered a modification of the sliced Wasserstein distance algorithm to compute the Monge map between two sets of points. The novelty is in the application of existing projection-based dimension reduction methods (specifically, SAVE used in this work) to find in each iteration the projection direction that maximizes discrepancy between the (variance of) two projected sets. Numerical experiments show that projection directions selected as such yield faster convergence than the existing ones with random projections etc.  Some main comments:  1. The use of selected projection in sliced Wasserstein is interesting, and the computational efficiency looks promising. The reviewer only concerns that the Monge problem is often not well-posed as the Kantoronovich's formulation, and in many cases the Monge map does not exist or is not unique. It may not be that severe in this paper since the problem is basically to find the optimal matching between two equal-sized sets of points, which is a very special problem of optimal transport (OT). The proposed method does not seem applicable to the majority of OT problems considered in machine learning.   2. Could you explain in more details about the assumptions in Line 185-188? In Eq. (1) it appears that the response can be a nonlinear function f of the projected value. But the assumption 1 seems very strong and already excludes that possibility. Your algorithm only allows for the linear case as well. Will this affect your Step 2 in Algorithm 2, especially when the cost in the OT is not defined as (some power) of Euclidean distance?  3. The statements on complexity are a bit problematic: "Suppose that the algorithm converges after K iterations" is not a rigorous assumption for complexity estimate. The number of iteration K should depend on the accuracy of the approximation (e.g., K is a function of epsilon, the accuracy of approximation at the Kth iteration to the true one). From the experiments it does seem that K is proportional to d for the computed W distance to touch the true value, but it's not appropriate to claim K=O(d) when the constant is large and d is small like in your case.  4. It's not explicitly stated, but is \phi in every iteration of Algorithm 2 a permutation? What is the look-up-table in (b) of Algorithm? Is it just sorting?  Some suggestions/corrections: Line 29: Better use "\subset" instead of "\in". Algorithm 1 Step 3: should be $I_d$ not $I_p$. Line 196: it should be "... $y_{ik}$ and the $j$th and $k$th component ...". Line 200: it should be "c_l, c_u". Line 202: What is the subscript "p" in the big O? Line 296: The Table 2 with MNIST results is missing from your paper.