After rebuttal -------------------- Thank you for the rebuttal. Most of my concerns are addressed in the rebuttal to some degree. However, I am still missing a couple of details, e.g. - better justification of the sliding window "likelihood"  - a discussion of how the proposed inference scheme affects the exact posterior when they add factors sequentially rather than fitting all factors jointly - I still think that the LPF experiment would be much stronger if the authors had included a baseline method for comparison.   For these reasons, my score of 6 remains unchanged.     Summary -------------------------- The paper proposes a new model for analyzing dynamic functional connectivity (DFC). The goal is to estimate the dynamics of the second order moments from a set of non-stationary multidimensional time-series. The authors propose to first estimate a sequence of time-varying covariance matrices using a “sliding window”-estimator and then model these estimates using a factor model with Gaussian process priors on the factors. Rather than modelling the sliding window estimates directly, they model the matrix logarithm of these estimates using a factor model to ensure that the resulting covariance matrix is positive semi-definite at all times. The author further state three properties of the model: weak stationarity, the posterior contraction rate, and large prior support. They propose a sampling-based method for inference. The paper is concluded with two numerical experiment: a quantitative experiment based on a simulated data and a qualitative experiment based on real data (local field potentials from rats) but without any baseline comparison.   Clarity ------------------- Overall, the paper is well organized, well-written, and easy to follow. However, some aspects of the proposed inference algorithm is unclear and should be improved (see comments below) .  Quality ------------------------- The paper appears technically sound. The authors provided the source code for the proposed method.   Originality & Significance ------------------------------------------------ The paper proposes a novel way to analyze dynamic functional connectivity, which is an active area of research in neuroscience, and thus, the paper is likely to be of interest to the neuroscience community. However, the idea of parametrizing covariance matrices using the matrix logarithm map in general is not new.  Furthermore, the authors provide an interesting analysis of local field potential data from rats.  However, there are two issues that makes it difficult to asses the significance of the contribution: I) Some experimental details are unclear. For example, in lines 235-238, the authors state that the analyze data is for one particular rat out of five and they focus on 78 trials out of 200 trials. The authors should clarify how the subset of data is chosen, i.e. are the specific rat and the subset of trials chosen randomly before analysing the data? II) The authors do not provide any baseline results for experiment. The experiment would be more convincing if the authors included a qualitative or quantitative baseline.    Other comments -------------------------------- The authors should elaborate on the motivation for modelling the sliding window estimates rather than modelling the data directly. That is, \mathcal{D}(0, K_i(t)) in eq. (2) could be replaced with a proper likelihood.  In the past, several papers have shown that the estimating dynamic functional connectivity using sliding window estimators can be problematic [1, 2, 3]. Therefore, the authors should discuss if the concerns about the sliding window estimators also apply to their method.   How is the window size L and the taper parameter tau chosen? Can they be inferred from the data?  The paper [4] proposes a different Gaussian proposed-based model for functional connectivity. This work seems highly relevant, so the author should discuss and compare to two models.  The details of the inference scheme unclear. In section 3.3 the author states that they use the Hamiltonian Monte Carlo with No-U-turn sampler to sample the posterior distribution of the loadings and in Section 3.4 they describe how they fit the model using a Gibbs sampler. The author should explain the interplay between these algorithms more carefully. They could consider including an algorithm with pseudo-code in the supplementary material.   In line 162 the authors state that “... fit the new factor on the residuals”. Does this mean that all previous factors are kept fixed when adding new factors? If so, the authors should clarify how this affects the posterior distribution  The authors mention that they use 5000 MCMC (with 1000 warm-up) samples. However, sampling from GP and horseshoe priors can be difficult, so it would be beneficial to compute and state the standard convergence diagnostics for the MCMC chains, e.g. Rhat and effective sample sizes etc.    Minor comments -------------------------------- Line 83: The dimensions of Lambda seems to be flipped. Shouldn’t it be r x p rather than p x r? Line 111: The authors state that “\bm{u} maps a matrix to its vectorized upper triangle”. This seems flipped as well because K = Log(u(Y)), where Y is a q-vector.  Line 123: The following statement is unclear to me “The model posteriors are conditioned on difference observations despite sharing the same kernel”  Line 131: The author should probably state explicitly that (B)_kj = \beta_{kj}    References -----------------------  [1] Laumann et al: On the stability of bold fmri correlations. Cerebral Cortex, 2016.  [2] Lindquist et al: Evaluating dynamic bivariate correlations in resting-state fmri: A comparison study and a new approach. Neuroimage, 2014  [3] Hindriks et al:  Can sliding-window correlations reveal dynamic functional connectivity in resting-state fMRI? Neuroimage, 2016.  [4] Andersen et al: Bayesian Structure Learning for Dynamic Brain Connectivity, AISTATS, 2017 