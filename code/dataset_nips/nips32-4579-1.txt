The authors provide a simple method to create representations for graph in an unsupervised fashion. These representations are used in multiple prediction tasks.  The results are interesting in that this simple method works surprisingly well. However, it is not very clear whether these methods are broadly applicable (apart from the molecule domain) or if there are any conditions under which they may not work well. The baselines also look weak.   The authors refer to the Appendix. But I could not find the Appendix in supplementary material (only source code was available).  -- Update: After reading the author feedback My main complaint was the lack of comparison with MPNN and DTNN in QM9 and QM8. But, this was because I assumed wrongly that the supplemental material was not available. In the feedback the authors pointed out that the supplemental material was indeed available. The comparison with MPNN and DTNN is present in table S18 of the paper. Though they claim that a direct comparison with MPNN and DTNN is not fair because MPNN and DTNN uses 3d information, this table gives us an idea of how it fares with MPNN and DTNN. NGram XGB performs best in 6 out of 12 tasks. If we incorporate this result in Table 2 (where they claim that their method performs best in 9 out those 12 tasks), it will not significantly alter their claims of performance. In light of this, I will increase my rating. 