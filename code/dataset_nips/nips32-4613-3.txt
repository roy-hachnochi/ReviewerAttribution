In this paper, the authors present an approach to extract mechanistic insights from deep CNNs trained to recreate retinal responses to natural scenes. Specifically, the authors use a combination of model attribution methods and dimensionality reduction to uncover cell types from the CNN that explain nonlinear retinal responses to four classes of stimuli. The authors uncover mechanistic understanding of latency coding, motion reversal responses, and motion anticipation in the retina that fits with prior scientific findings and models. The authors uncover a new model for omitted stimulus responses that is better able to explain retinal responses than prior models and forms a testable hypothesis.  There are important limitations to the work presented here. The methods depend on artificial stimuli with spatial invariances and it is unclear that these methods will extend to more complex stimuli. The authors state that perhaps other stimuli could be reduced using PCA or similar methods but this paper would be more impactful if the authors demonstrated this or even discussed possible future directions in more detail.  Additionally, the authors mostly recreate known retina phenomena and mechanisms. They do yield a new testable model of OSR but since this is not tested yet, it is unknown if their approach yielded new knowledge about the retina. Providing some experimental follow-up on the scientific hypothesis generated by this work would be extremely impactful.   I think the paper should acknowledge and address these limitations/caveats more thoroughly - the work felt overstated at times.  Despite this, I think this paper is novel and significant. Moving the relatively new field of fitting neurons with deep networks beyond simply improving predictions to gaining scientific understanding is extremely important and this paper is a solid start to these efforts. It is encouraging the the deep CNN was trained on natural scenes and not specifically on the four classes of stimuli. The paper is well-written and relatively easy to understand.   Minor comments:   I disagree slightly with the emphasis that deep networks fit to neural responses must yield computational mechanisms matching intermediate computations in the brain to be useful. This is one particularly good avenue of research but deep networks predictive of neural responses could be used to find testable experimental phenomena (like those presented in this paper) through artificial experiments or to better understand neural computations at a more abstract level.  The paper is unclear whether the authors find the same 3 cell types to explain the responses for each stimulus - this is mentioned in the Figure 6 caption but is not emphasized elsewhere.  All figures should be larger for clarity. Figure 1 B-E are not very helpful without more explanation for readers unfamiliar with these concepts. The colors in Figure 2E are hard to distinguish - maybe use different colors or a wider range of blue shades?  EDIT: I've read the author response - it was thorough but did not convince me to change my score.