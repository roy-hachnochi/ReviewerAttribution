Originality: The proposed method is a novel dynamic loss re-weighting technique applied to VQA under changing priors condition, aka VQA-CP, where the train and test sets are deliberately constructed to have different distributions. The related works are adequately cited and discussed. While prior works have also focused on using knowledge from a question-only model to capture unnecessary biases in the dataset [25], the paper differs from [25] in some key aspects. E.g., the proposed model guides  the whole model (including the visual encoding branch) to learn "harder" examples better whereas [25] focuses on only reducing bias from question encoding.  Quality:  The proposed method is sound and well-motivated. The experimental setup is mostly sound and is on par with prior works. I have some qualms about absence of some common-sense baselines but that is not entirely the authors fault since the prior works have also failed to set a precedent. My another minor issue with the paper is lack of discussion of shortcomings / future work for the paper.   Clarity: The paper is very easy to read and the major contributions and background work is clearly laid out. The method descriptions are complete and contain enough detail to be able to reproduce.   Significance: The paper overall has a moderate significance. The proposed method is sound and is clearly demonstrated to work well for existing dataset. It is likely that the proposed method will be used in other bimodal tasks as well. However, common with existing works in this space, the algorithm is designed with prior knowledge about how exactly the (artificially perturbed) VQA-CP was constructed. Therefore, to me, it is slightly less significant compared to (hypothetical) alternative algorithms that propose a robust vision-language understanding rather than developing specialize algorithms just for "reducing" effects of bias on an specially constructed dataset. It is still a valuable contribution, just a very specific one instead of a true general solution.  *** POST REBUTTAL COMMENTS ***  As I said during my original review, I think that the "good results" obtained on VQA-CP alone is not *very* significant as there haven't really been carefully established baselines. I thank the authors for their rebuttal, which already shows that even the most naive baselines perform over 4% over the existing numbers. Again, I do not put the burden of this on the authors; but this is something the whole community has sort of ignored.   That being said, the improvements to the robustness by the proposed model is undeniable. In the rebuttal the authors also show that it improves robustness in VQA-HAT. Most importantly, the proposed method is an model-and-task agnostic de-biasing technique that I think will be useful to present to large community in NeurIPS.   After reading other reviews and author rebuttal, I am raising my score to a 7. 