This paper presents a technique for constructing a probabilistic deterministic finite automaton (PDFA) that can model a black-box language model such as LM-RNN. The main idea of the algorithm is to adapt Angulin’s L* algorithm to handle probabilistic choices with unbounded states of an LM-RNN by developing a notion of variation tolerance. The variation tolerance allows for comparing two probability vectors and clustering them if they are within a t-threshold. The goal is to construct a PDFA, such that for all prefixes the next token-distributions in the PDFA and the LM-RNN is within the variation bound. The paper presents analogous variation tolerance aware extensions to membership and equivalence queries in L*. The algorithm first learns an observation table that is closed and consistent, then constructs the corresponding PDFA using a clustering strategy, and finally performs an equivalence query using a sampling-based method. The technique is evaluated on grammars from the SPiCe competition and adaptations of Tomita grammars, and it outperforms n-gram and WFA (using spectral learning) baselines both in terms of WER and NDCG rates.  This paper presents a novel general technique to learn weighted deterministic finite automaton (WDFA) from a given weighted black-box target, and learns a PDFA for a stochastic target. Unlike previous approaches that use spectral learning or learn from sampled sequences, the presented technique learns PDFA in an active learning setting using an oracle by extending the widely used L* algorithm, which has some nice guarantees. The idea of using t-consistency for computing variations between probability vectors is quite elegant, and the idea of using clustering techniques to overcome non-transitivity of t-equality is also quite interesting. There is also a detailed formal treatment of the properties and guarantees of the returned PDFA in terms of t-consistency.   The paper is also nicely written and explains the key ideas of the algorithm in required details. One suggestion would be to add a small running example that might help clarify the extended L* algorithm a bit more (especially the step 2 of PDFA construction). It would also be nice to move at least the two theorems from appendix to the main text.  I was curious about the scalability of the algorithm. It seems it scales better than spectral learning based WFA learning methods based on SPiCe and Tomita benchmarks. But the LSTM network consists of an input dimension of 10 and hidden dimension of 20, which seems quite small compared to current state-of-the-art LSTM language models. What is the maximum hidden sizes the technique can handle currently?  Similarly, the alphabet size of upto 20 also seems a bit small compared to typical large vocabularies of state-of-the-art language models. It would be helpful to report the maximum sizes the technique can scale to currently, and that might help spur interesting future works to scale up the technique further.  It wasn’t clear whether for the results reported in Table 1, did the L* algorithm terminate before early stopping. If it didn’t terminate, what bounds on expansion time and suffix limits might be needed for full completion of L* algorithm on these benchmarks.  Since the equivalence check is being performed using sampling, the only difference between previous PDFA learning methods from samples would be that in this case the samples are being collected actively. Would it be possible to compare the presented L* based technique to also some of those previous PDFA reconstruction techniques that learn from samples?  Minor issues:  line 108: w^k \in S -> w_{:k} \in S line 165: algorithm reduce the number -> algorithm reduces the number line 193: prefix weight: -> prefix weight. line 336: The the -> The 