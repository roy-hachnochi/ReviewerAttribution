The paper presents a new attack on distributed learning systems. The threat model and targeted defenses are clearly explained, and the attack is explained nicely, with easy-to-follow intuition along with a more precise technical explanation. The properties of the proposed attack are strong: not only circumventing previously proposed defenses (and showing that some previous intuition is incorrect), but also being non-omniscient. The paper is a solid contribution.  Questions and areas for improvement:  The evaluation does not say whether the m=12 malicious workers are omniscient or not. If they are non-omniscient, it would be great to reiterate this. And if not, that seems like a serious issue: in that case, there would be no substantiation of the claim of a non-omniscient attack.  Line 80 says "in this type of attack, the attacker does not gain any future benefit from the intervention." This may not be true without additional context. For example, consider a scenario where a company attacks the distributed training of a competitor: in this case, there is clear benefit to performing the attack.  It would be interesting to see more discussion about where such attacks/defenses may be applicable in the real world, along with further elaboration of the threat model. In current practical uses of distributed training, are all nodes trusted? What future systems might be susceptible to such attacks?  Lines 215--221 discuss the situation when the attacker is not omniscient. In particular, the paper says that when "the attacker controls a representative portion of the workers, it is sufficient to have only the workers' data in order to estimate the distribution's mean and standard deviation ..." What is a representative portion?  It would be great to briefly summarize the threat model in the abstract (e.g. "percentage of workers are corrupted and collude to attack the system, but are non-omniscient and don't have access to other nodes' data").  Nits:  - Line 164: "(n-3)/4" should presumably be "n/4"? - Figure 1 is unreadable in grayscale (e.g. when printed); consider using different symbols rather than just colors (and perhaps make it colorblind-friendly as well) - Line 253: "the attack will go unnoticed no matter which defense the server decides to choose" -- this only applies for the known, particular defenses examined in this paper 