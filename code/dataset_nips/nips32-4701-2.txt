UPDATED REVIEW: I appreciate the extra experiments and clear explanation of them, and am happy to raise my score. I would have liked to see some discussion of the cost of flags vs. anemometers, but maybe this is in the "specific comments" that the authors say will be incorporated.  ================== Review summary:   The paper is well-written, the dataset and the experiments done are well explained and careful. I like this paper and definitely want to encourage this line of work, but I am on the fence about whether there is sufficient experimentation here to merit publishing at this stage.  Originality: The idea of estimating wind speed from imagery (video) is novel to my knowledge, and in my opinion is the main contribution of the paper. There is nothing novel about the model (CNN feature extractor with an RNN on top), but the authors don't claim there is, and based on the results it seems to perform well.  Quality: The paper is well-written, and the dataset and experiments seem to be well described and of good quality. In order to be a really high quality paper though, I would want it to convince me that this idea has practical merit - i.e. at a minimum I would want to see experiments with one other video, e.g. a different type of flag, or a moving tree. Clarity: I found everything very clear; one of the strongest aspects of the paper. Significance: Difficult to judge without more convincing experiments, but it is at least an interesting idea and the dataset is a solid contribution; overall I would say "medium".   - what about using auditory information and/or natural language reports of wind speed along /instead of the video? I would think this would be even cheaper than video, and making use of multimodal information would fit with the motivation to use 'existing' data in practical situations (e.g. drone delivery). This is just an idea, not a suggested improvement. 