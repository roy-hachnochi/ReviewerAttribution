Update:  I have read the author's response and the other reviews, and I maintain my score -- I think this a good paper. While I still wish the analysis was a bit broader (as described in my review), I appreciate that the authors expanded their AARI methodology based on the suggestions of reviewer #2.  --- Original review --- Originality: As mentioned above, InfoNCE-DIM was already described in detail in [25], the only addition this paper makes is using CPC-style linear prediction targets [24]. It does however seems to be performing quite well, so this combination is certainly worth documenting. Similarly, while the idea of using ALE ram state as ground truth is not new, there is value in creating an evaluation suite for representation learning.  Clarity: The paper is well-written in general. The method section (3.1) is very short, to understand/re-implement the method it's necessary to read and understand DIM [25] and CPC [24] papers, but maybe that's fine as much of the focus is on evaluation.  Quality/Significance: As self-supervised representation learning is becoming more popular again, it's important to have good tools for evaluating and inspecting these models, especially in contexts outside of image classification and vision. So I was actually quite excited to see much of the paper's focus being on AARI, and I encourage the authors to make the code and baselines included in the submission public and easy to use, should this paper get accepted. My main criticism with the paper is that the analysis and discussion presented in sections 5 and 6 is actually quite trivial. The main finding seems to be that generative models with an image reconstruction loss don't focus much on the small moving part of the screen which comprise much of the meaningful game state, while models with contrastive losses fare better in that aspect. This point is widely understood and easy to test even without AARI. On the other hand, there's a lot of interesting questions which would be more interesting to investigate, for example: - There are many self-supervised tasks with contrastive losses being suggested, from coloring, spatial arrangement, temporal prediction, etc. What are the strengths and failure modes regarding the learned representation? - Specifically, it's obvious why ST-DIM outperforms a VAE, but why is it better than CPC? Do the DIM patches make it less susceptible to distractors? And if yes, how can we show/test for this? - Does the AARI score translate into performance on downstream tasks ? Experiments which show this would strengthen the significance of the metric. Representation space which feel useful and semantically meaningful to human don't always translate into good performance, especially in RL. I encourage the authors to broaden the analysis with this type of questions.