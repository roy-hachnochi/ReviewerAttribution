Thompson Sampling with Approximate Inference =============================================  This paper investigates the performance of Thompson sampling, when the sampled distribution does not match the "problem" distribution exactly. The authors clearly explain some settings where mismatched sampling distributions can cause linear regret. The authors support their analysis with some expository "toy" experiments.   There are several things to like about this paper:  - This paper is one of the first to provide a clear analysis of Thompson sampling in the regime of imperfect inference. [High]  - This paper is very well written, and will help build intuition and understanding for this problem and field of research. [Medium]  - The authors support their claims through clear statement of theorems, experiments and do provide novel insights. [High]   In some places the paper could be improved:  - I do think that the emprical evaluations are overly "toy"... particularly the discussion of approximating Q_t, Z_t... this type of gross systematic mis-estimation seems like it would not occur from say "Bootstrapping" or some reasonably-updating posterior estimates?  - I don't think that the addition of additional noise exploration is really the "right" approach... although that is an interesting hypothesis. It seems like another solution that would "intuitively work" is to artificially expand the "prior" of the Thompson sampling procedure, but in a way that would concentrate away with data. I suppose this is something a little like the 50/t epsilon schedule though... so I don't hate that idea.  - I think that there is a thread of research on approximate TS in the RL-literature that is worth mentioning, of which "ensemble sampling" is one instance = "Deep Exploration via Randomized Value Functions" https://arxiv.org/pdf/1703.07608.pdf (or earlier ICML https://arxiv.org/pdf/1402.0635.pdf). In this, the authors show that an "approximate Gaussian" posterior can still satisfy the same regret bounds even on a mismatched Dirichlet posterior... (note that H=1 is the special case of the bandit) certainly this result is even less impressive than the Frequentist worst case guarantees of Agrawal etc. With this in mind, I do think it's a stretch to say Lu+VR are the only theoretical analysis of TS with approximate inference...The main reason I point to that work is the analysis in terms of "stochastic optimism", since that appears to suggest thatt a certain type of mis-estimation is more/less bad than others and it might be nice to connect to this alpha divergence!   Overall I really like the paper, it appears crisp, insightful and polished. Some of the comparisons and observations are slightly "toy", which is the only reason I won't push ratings even higher.