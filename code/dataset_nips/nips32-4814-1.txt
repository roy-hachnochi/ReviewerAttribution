Clarity: The paper was very well written, and the contribution was clear.  However, I think it would help if they make it more clear that which parts are standard bandit techniques and which parts are new. For example, they could explain more why adding fairness constraint makes the problem challenging and what is the new technique they are using and how much this technique is applicable to other constraints.  Originality/significance:  I think this paper is the first paper to come up with an algorithm that satisfies approximate EO at each round. However, I think the comparison to related work is not very clear. As they mentioned, one can also consider either of the following two notions to enforce in contextual bandit setting: For a fixed time horizon T, in the end, the algorithm satisfies EO (average False-positive over all rounds). At each round, each individual has the same probability of FP independent of the sensitive attribute. What is special about being fair at each round? Do you have a similar regret rate with (2)? They mentioned in the related work that (2) need strong assumptions, does your algorithm provide any guarantee at the individual level?  Quality: All the theorems in the paper are sound (I only check some of them in the appendix).