As I mentioned above, I consider the framework for Thompson sampling algorithms valuable, as it is easily implementable and allows for regret bounds with respect to a general class of policies. The analysis is also intuitive and not technically very difficult, combining ideas from posterior sampling that are now typically applied in Thompson sampling with characterizations of the Bayesian regret through the Bellman operator and concentration of parameter estimation. Proofs appear correct and formally written.  One thing I want to point out is that the length of the episodes, L, necessarily needs to scale as o(T^{1/2}) (that is, sub-square-root of the horizon) to get a sublinear regret bound according to the statement of the main theorem of the paper. In the analysis, it appears as though the sample counts that are used to establish concentration of the parameter estimate in episode $l$ to the true parameter are based on the sample counts at the start of the episode -- these sample counts are not tracked through the episode itself. So the analysis seems to be tightest when $L$ (which is the length of the episode) is very small, say a constant and not even growing in $T$.   My feeling is that considering the evolution of sample counts within episodes would make the analysis very delicate, but I am interested to hear from the authors about whether a more fine-grained analysis adds any value, and how difficult it may be to do. In particular, should I expect that the bounds in the main theorem are tight? Are lower bounds easy to prove?   I ask these questions because I am curious about how fundamental the episodic setting is and in particular how the episodic length affects a regret bound. Are longer and fewer episodes necessarily much worse for regret in simulation, as is suggested in the theoretical upper bound?  I already consider the results in this submission valuable, given that the restless multi-armed bandit problem is already very difficult and this is the first analysis involving learning the transition matrices that I have seen -- but concrete answers to these questions would make me consider raising my score higher.