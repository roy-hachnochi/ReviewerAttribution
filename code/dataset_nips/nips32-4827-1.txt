The results themselves form a nice study. The biggest problem I find is the impact. The studied network is neither convex nor concave but yet it is special (single-skip three-layer ResNet). It begs the question if the result can be extended to other networks, in particular without the skip connection, i.e., non ResNet.   I do not see any practical relevance. The result says in layman words "use neural networks instead of kernel methods," which these days everybody takes as granted.   Another big issues I have is with the exposition of the paper and the numerous grammar mistakes.   The exposition of the paper is weird. It is impossible to read the paper without continuously going back and forth. For example, Theorem 1 is using complexity before it is actually formally defined. In the same theorem, probability is used but it is unclear what really is random (the samples are random but this is not the origin of this probability).  I think a much better flow would be to define the quantities before being used. The two overview sections are kind of out-of-kilter. I'm not sure what a better flow would be but the current one definitely doesn't work well.   My 'below accept' rate is due to unclear impact and relevance of the results, and very poor exposition of the work with numerous grammar mistakes.   Minor comments (these are only a few of them; there are many additional grammar mistakes) 21: understood how  26: "from them" is incorrect 27: "to the optimization side" ??? 32: are kernel methods ... are defined 40: by random etc 