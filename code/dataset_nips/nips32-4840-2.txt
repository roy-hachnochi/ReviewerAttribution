The paper builds on the work in [21], which dealt only with SO(2). This paper adds multiple representations as a "multiview learning" problem and the bispectrum, which are nice additions and sufficient novelty.  The mathematics are technically sound and elegantly based on group representation theory. I believe more writing should be spent in explaining more background on representation theory and motivating the intuition behind it. Section 3, giving background on principal bundles, is very nicely written. The next section dives into irreducible representations, which I think the average NeurIPS reader will not be familiar with. A few sentences defining and motivating representation theory would improve the clarity. I realize that a full tutorial on representation theory is not practical. I have some familiarity with representation theory, but I was unfamiliar with Wigner bases and Clebsch-Gordan coefficients. Some more explanation (again, at an intuitive level) there would be helpful.  In a related point, I am having trouble understanding what you gain by incorporating multiple representations over using a single "best" representation.   I can see that the proposed work will be significant in cryo-EM and possibly in computer vision (accounting for transformations of objects being detected in images), but the applicability there is less clear.