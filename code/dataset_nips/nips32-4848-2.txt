This paper proposes to model fake news generation as a joint distribution over domain, date, headline, body, and author. In order to perform controllable news generation, the authors model the ability to generate any subset of these fields, given the other subset. To avoid modelling all possible permutations of these fields, GROVER assumes a canonical ordering of all the fields, and models generating one random subset given the other subset, in order. At training time, fields in news articles are randomly partitioned into two sets and GROVER maximizes the likelihood of generating one subset given the other. The underlying language model is a large Transformer Model similar to GPT (Radford et al).   The model thus trained achieves significant perplexity reduction in generation of news article body when conditioned on metadata. Perhaps quite surprisingly, human annotators rate GROVER generated propaganda higher in terms of style and overall trustworthiness than human written propaganda.   The paper then compares techniques for detecting fake news by trying to discriminate GROVER generated articles from real news articles (both from April  2019). The experiments show that GROVER models outperform strong BERT and GPT baselines in this task, perhaps unsuprisingly. The results hold when the generator size is larger than the discriminator size. The difference between performances of GROVER and BERT remain when the fake news articles that are fed to the training algorithm are sampled from smaller GROVER(-base or -large) while the test articles are from GROVER-mega.   The paper presents an explanation for why GROVER discriminators have the right inductive bias when compared with BERT. This is because the generation process explicitly takes word probabilities into account (and with nucleus sampling, avoiding generating words from the tail); the disciminator having access to these word probabilities can better model the generation process.  Originality 1. The work presents a new technique of incorporating metadata into account for neural text generation. While the process for sampling fields is simple, it is original and useful/ 2. The semi-supervised experiments for neural fake news detection are very well done and exciting. The setting where an adversary has access to a large neural net model and the verifier has access to a small one is quite original and interesting. cons: Minor: The paper uses describes GROVER's discriminative model being the best at identifying GROVER-generated fake news text as "counterintuitive" multiple times. It certainly doesn't help the early discussion and is not discussed as a "counterintuitive" find in the later sections. This finding certainly does not sound very surprising and should not be proposed as such.  Quality pros: 1. The techniques used in the paper are mostly clear and represent the latest norms in the community. 2. The studies in section 5.3 and 6 are quite useful in pointing out the effect of nucleus sampling on the accuracy of the discriminator.  cons: 1. Even though section 6 is titled "How does a model distinguish between human and machine text?", it actually does not meaningfully explain how the discriminative model distinguishes between human and fake news text specifically with a limited variance version. More below on the clarity of section 6.  3. It is unclear how there is "minimal overlap" between the discriminator and generator model as claimed in 181-183. Also unclear if the discriminator is initialized from generator parameters.   Clarity pros: 1. The paper is very clearly written and is appropriately supported by figures and colors.  cons: 2. Overall section 6 is a bit of hodgepodge of two ideas: how does GROVER detect real vs neural fake news and what is the inductive bias in GROVER that gives it an advantage over BERT. Disentangling these two ideas will make this section a lot clearer.  Significance 1. This is a very important and timely piece of work. The impact of the released model and released dataset is likely to be huge in the community. 2. The line of questioning around fake news detection and various artefacts around sampling distortions around neural text generation are both fertile grounds for future work.