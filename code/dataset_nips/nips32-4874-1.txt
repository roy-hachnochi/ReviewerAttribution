My comments mainly lie in the following perspective: 1. About \epsilon in Theorem 9. I think it may depend on the parameters of Besov space. As the design of both discriminator network and generator network depends on \epsilon, does this imply that the result is not adaptive, i.e., in order the achieve the minimax rate, we need to know \sigma_g, p_g, q_g? 2. Could the authors briefly summarize technical contributions of the paper? It seems that Theorem 9 mainly depends on the previous study of approximation ability of fully-connected ReLU networks.  3. GANs achieves minimax convergence rate over the Besov space, while the same rate can also be achieved by wavelet thresholding. This implies that if we consider Besov space and minimax rate, GANs cannot outperform wavelet thresholding. In order to demonstrate the superiority of GANs, especially in terms of image analysis, is it possible to study some more restrictive function classes other than the Besov space? This comment may be beyond the scope of the paper, but I do think it closely related to the study of statistical properties of GANs. ------------------------------------------------------------- Thank you for the response, which clarifies the adaptivity and theoretical contributions. My score remains the same.