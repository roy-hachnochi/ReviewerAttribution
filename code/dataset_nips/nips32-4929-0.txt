Update: I thank the authors for the feedback and the additional figure. I would gladly vote for acceptance of the paper.  ----------------------------------------------- The authors conducted the first large meta-analysis of overfitting due to test set reuse in the machine learning community. They surveyed a wide range of 112 Kaggle competitions and concluded that there is little evidence of substantial overfitting. I found the question very important to the machine learning community. The investigation is thorough that it covered a broad spectrum of datasets. The statistical methods used here are appropriate. And therefore, the conclusion is trustworthy. Also, the paper is well-written. I have a few suggestions, but overall, I think this paper deserves publication in NeurIPS.   1. For the overall conclusion, I think a more precise one would be: on the one hand, there is strong evidence regarding the existence of overfitting (p-values in Sec. 3.3); on the other hand, the extent of overfitting is mild (Sec. 3.1 and 3.2).  2. For the figures (Fig. 1, 2), there are too many things that it is a bit hard to parse. First, there are too many points. A common solution is to reduce the point size or make them transparent. Second, since the linear trend is apparent, I would suggest removing the linear regression line. Also, it would be nice to lay the points above the y=x line so that we can see them. Besides, the confidence intervals are missing for some plots, e.g., Figure 1.  3. It is important to investigate the covariates that are likely to cause overfitting. The authors mentioned that one reason might be the small test data size. Can the authors quantify this by plotting, e.g., the extent of overfitting against the testing data sizes across all competitions considered? It is also helpful to recommend a minimum testing data size for an ML competition to have mild overfitting.  4. Another aspect that people care about these competitions is that if the ranks of submissions are preserved between the public testing dataset and private testing dataset. Can the authors add some results on this?   Minor:  5. Line 146: I am curious about the subtleties.  6. Eq. (2): missing bracket inside summation.  7. One more related work on adaptive data analysis to include is [Russo et al, 2016, Controlling...]