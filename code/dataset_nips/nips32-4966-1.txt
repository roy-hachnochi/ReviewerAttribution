This is a very interesting paper on a highly pertinent question: how do neural cell type definitions align across different data modalities.  The figures all still look a little rough and need to be brushed up for publication.  l.80 E and D are limited to 'linear' transformations? Why is this? And how does that fitted to the, presumably, nonlinear MLPs used later?  The notation in section 2.1. is unnecessarily cluttered, please shorten and clean up. For instance, alphas can be absorped in the lambdas?  Please state clearly the difference to and novelty over citation [9].  Proposition seems trivial and unnecessary, it would seem fine to just say in plain text that this may happen. Moreover, I am rather confused by your complicated approach to the shrinkage problem as a trivial solution to the euclidean distances between hidden states. Would it not suffice to simply look at the L2 distances after normalization (i.e. dividing by the norm) or look at a normalized distance metric like cosine similarity? That would seem a much simpler solution than sections 2.2 and 2.3?  The crossmodal prediction tasks seem very interesting but I am not sure if I understood the details, could you explain the results a bit more? (e.g. what predictors are used, what is predicted?)  I am also a little uneasy about the clustering performed on top of the latent representations. How much is the latent geometry determined by the workaround (2.2.)? Is it surprising that is so regular and missing data fills in well? In unimodal cell type clustering there is a lot of uncertainty about the clusters and whether they are biologically meaningful. In this second stage clustering on the aligned latents it seems even more removed and harder to interpret whether this is actually something that falls in line with the underlying biology. Theoretically, should not the cell type identites be the ultimate latent (causal) factors that yield perfect alignment across data modalities â€“ modulo intra-type variability?