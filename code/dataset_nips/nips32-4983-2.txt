This is an empirical study to understand why over-parametrized CNN performs better than a Fully Connected Network. As fas as I know, on one did the same experiments before. The results suggested that the architectural bias is not necessary through all the training pass.  My key concern about this paper was the experiments. In the paper, it did on a realistic task (cifar), but the model looks small. It's unclear if the model has more parameters or more advanced architecture, does the conclusion still holds? It become even more suspicious, if we look at the results on supplementary material. One AlexNet, the accuracy is only 40%. How come AlexNet performs so bad? If I remember correctly, even FCN can reach 70% with carefully tuning. In another word, there are tons of CNN which performs good on Cifar-10, why pick AlexNet?  It's also unclear how the optimization approach affect the results. The paper use a smaller learning rate (0.01) to fine-tune. Is that sensitive or not? Also, it's unclear if the CNN also fine-tuned by this smaller learning rate. If CNN always use the constant learning rate, it doesn't looks fair to me.  The paper didn't cite "Do Deep Nets Really Need to be Deep?" which use a FCN to mimic a CNN.  Overall, I feel it's an interesting study but the experiments do not strong enough to support the conclusion.