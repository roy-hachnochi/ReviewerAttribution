The paper studies a novel method for making neural networks robust to norm bounded adversarial perturbations, in particular obtaining provable guarantees against perturbations in the L2 norm and empirical results showing that the networks are also robust to perturbations in the Linf norm. The paper is well written and the algorithmic and theoretical contributions are clearly outlined. My specific concerns center around the originality of the paper (distinction from prior work) and quality of some of the experimental results obtained.  Originality: The paper improves upon the analysis from Lecuyer et al and develops a training method for producing certifiably robust randomized classifiers that is novel as far as I know. However, it is unclear to me how much the paper improves upon the analysis of Lecuyer and what the main source of the improvement was. Further, there is more recent work by Cohen et al that appeared on ArXiv https://arxiv.org/abs/1902.02918 in February (and a revised version was later published at ICML). I understand that the authors may have missed this work at the time of submission, but since the paper was already online before the submission deadline and published soon after, I would appreciate clarifications from the authors regarding the novelty in the rebuttal phase. In particular, I would like to understand: 1) The developed certificates only apply to L2 norm perturbations. Can the authors' framework providing any guarantees for perturbations in other norms? 2) How does the certificate derived compare to that in Lecuyer et al? In particular, is the certificate always guaranteed to be tighter than the one from Lecuyer et al? If not, what are the regimes where it is tighter?  3) How does the work compare to that of Cohen et al? Cohen et al claim that their certificate is the tightest one can obtain for the L2 norm for binary classifiers given that the only information known about the classifier is the probability of correct classification under random Gaussian perturbations. Given this, how does the certificate derived by the authors compare?  Quality: The proofs of the mathematical results are correct in my assessment. The experimental results are interesting and indicate that the method developed indeed produces provably robust classifiers. However, there are a few issues with the experimental evaluation I wanted to clarify: 1) The authors mention that they multiply the confidence interval by 95% to obtain the corresponding accuracy. This seems very confusing to me. What accuracy is referred to here? If this is the accuracy in terms of the fraction of test examples certified to be adversarially robust, I find this a bit confusing, since the two probability spaces (sampling over the data distribution vs sampling over the Gaussian perturbations) are unconnected. 2) The improvements over PixelDP seem to come largely from the training method. (ie the blue curves are much above the orange curves in figure 1). What if the PixelDP bound was evaluated on the classifier trained by STN?  3) Table 1 is rather confusing. I assume the certified bound is the radius of the perturbation being certified. Why was this specific value chosen? Was it to maintain consistency with [17]?  4) Since obtaining certificates on ImageNet is a significant advance, I would advise the authors to include these results in the main paper rather than the appendix.  Clarity: The paper is well written overall and the details are clear and easy to follow.  Significance: I think