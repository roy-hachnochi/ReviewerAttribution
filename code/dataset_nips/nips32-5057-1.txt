Updated review: I thank the authors for their effort and time in addressing the authors concerns. I am happy with the provided clarifications and will keep my score as is.  --------------------------- In this paper, the authors tackle the important problem of feature selection. Moreover, they focus on deriving an interpretable feature selection method that can easily be combined to control the rate of false discovery. Both having an interpretable feature selection method as well as efficiently controlling the false discovery rate are important problems in themselves.  This paper proposes the Sobolev Independence Criterion, a criterion combining aspects of integral probability measures and gradient-sparsity penalties. The authors do a very good job in motivating the gradient sparsity regularization for SIC. While the first proposal of SIC is non-smooth and biased, auxiliary variables are introduced to mitigate the problem. Furthermore, the auxiliary variables have the convenient interpretation of being normalized importance scores for the features. Under a special class of critics (as considered in section 4), the authors show that SIC is convex and they prove the existence of a unique solution and the convergence of the perturbed SIC to the unperturbed SIC in the limit. To the best of my knowledge, the proofs provided in the appendix are correct.   Next, the authors combine SIC with deep relu networks and define the Boosted SIC using different random seeds. As an application of SIC false discovery rate control is proposed, and SIC is combined with holdout randomization tests and knockoffs. While the related work section is rather short, it is succinct and mentions the important previous work in the area. To improve this part of the paper a bit, I would propose to include a bit more detailed comparison of the proposed method with previous work (e.g. what shortcomings of previous methods are mitigated with SIC?).  At the end, an experimental evaluation of SIC is provided on both synthetic and real-world datasets. While not outperforming the competing methods on all instances of all datasets, SIC shows competitive performance. While there is a large diversity in the datasets considered, there is only comparison to 1 competing method in the two real-world datasets. I would advise the authors to provide comparison with further competing methods to strengthen the case for their approach.  Overall, this paper is very nicely and coherently written with a nice balance of motivation and details in the main text with the proofs present in the appendix. Furthermore, this paper makes as interesting and novel contribution to the field of feature selection with convincing experimental results. Thus, I recommend the acceptance of this paper.