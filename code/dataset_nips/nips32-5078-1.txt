The paper improves upon the main work from Yaida et. al by introducing a much more rigorous test for whether the chosen statistics indeed converge to zero. I think the authors introduction of the t-test and especially the improved estimators that take into account the temporal Markov Chain correlation is indeed great. The main text is very easy to follow and quite clear, with very clear idea and aim which the reader can follow. Several points of discussion:  1. I think a more important point though is that the authors should have plotted results with the learning rate adaptation of equation 9 for the comparison. From the variance tests and Fig.4 one can conclude that the newer test is better, but I think it is also important to measure to how much improvement in actual optimization that translates to?  2. There is an empirical analysis of the choice of the decaying constant (Fig. 3), however would be interesting to see similar plots for the confidence parameter (gamma in the paper) in the t-test interval construction.   3. On the comparison with ADAM it is claimed that it is "hand tuned". Given that SGM has decreasing learning rate schedule, there is no reason not to have run ADAM also with such cut-and-decay schedule and optimize it as well.   4. Any discussion on the higher order comparison rules from Yaida et. al would be beneficial.  5. It would be quite interesting to see if ADAM itself can benefit from SASA as well as how does the statistics of interest in the paper behave under ADAM in the first place.     Figure 4 is really confusing as there is no legend or explanations in the figure title on what the different curves actually represent - I was expecting two lines for the two tests in eq.9 and 10 but there are clearly 5 (one figure has a single red curve)?