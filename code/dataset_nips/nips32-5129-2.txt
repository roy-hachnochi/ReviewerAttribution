Update after author response: I would like to thank the authors for the detailed response which addresses most of my concerns, specifically those relating to the previously unjustified assumptions. In light of that, I am updating my score from 6 to 7. ------- In this paper, the authors propose a probabilistic model of human decision making in a collective scenario. The main proposal considers a simple binary decision-making task, and is based on updating the beta prior of each individual depending on the binomial observation likelihood of collective outcome. The modeling of the task as a POMDP follows naturally by considering the belief states. The authors also talk about higher level theory of mind models, and show that the results from the two experiments are better explained by the proposed model as compared to model-free reinforcement learning.  The paper considers a very interesting problem of collective decision making that has bearings on multi-agent models, cognitive science, game theory, etc. The initial development is straightforward and the results seem encouraging. However I had a few concerns and clarification questions about the model: 1. Equations 1 and 2 are only valid if all the other agents decisions are IID (Independent and Identically Distributed) with success-rate parameter \theta. This seems like a far fetched assumption since later we acknowledge that there are individual differences between the agents. How can we justify this IID assumption? 2. Another unsubstantiated assumption (related to #1) is that of every agent starting with the exact same prior. People will come into the task with different experiences and expectations and can’t be assumed to share those parameters. 3. The introduction of the decay rate \lambda is quite ad hoc. Maybe a similar effect can be induced in a more principled way by considering that the other agents adhere to the inferred strategy with probability p and revert back to the prior with probability (1-p). That way events in the past get discounted because it’s more likely that a catastrophic forgetting/reset happened. Is there a mathematical justification for discounting the pseudo counts in the beta distribution otherwise? 4. I was left very confused by the hierarchical model in section 2.3. For example, does line 155 assume all the other (level k-1) agents make the same decisions (a1 or a2)? I didn’t understand the decision making policies of the agents with different levels of theory of mind. It would have been really useful if the authors spent more time explaining this contribution, maybe saving space by being more concise when explaining the well understood beta-binomial updates in 2.1. 5. Line 218 is again a little unprincipled. If the priors are supposed to be beta, then we should adhere to that. A simple change would be assuming Beta (1,1) which is uniform and that will get "overwritten" by the observed data in a few iterations.  6. I am not convinced how easily the results can be reproduced since some of the details seem to have been left unstated. For example, how were the parameter optimized? Jointly using some Bayesian technique or grid-search? If latter, was it joint or sequentially for one parameter at a time? (Edit: I see that some of these are answered in the supplementary material. The authors should add that reference in the main text and can safely ignore my comment.)  Overall, I like the central idea of the paper but the proposal seems weakly motivated. There are several assumptions that I found unreasonable but that are not discussed. The central contribution of the paper is confusing to me and there is good scope for improving the presentation. All that said, the results, both experimental and model-fitting, are interesting and intuitive. Furthermore, overlooking the assumptions, the development of theory is reasonable. Based on these observations, I am mildly inclined for the paper to be accepted while acknowledging that there were parts of the manuscript that are still opaque to me.