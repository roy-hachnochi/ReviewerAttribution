As the topic of the this work is very interesting, I'm not frustrated by the presentation, which has a large space for improvement.  First, the motivation of the work is not so clear. Why is that an important concern to be able to poison a G-SSL model? The three references [1-3] provided seem at least a decade ago. Are they widely applied in modern security/privacy sensitive applications? Are there recent works bringing these techniques into consideration? Are the proposed methods applicable to recent techniques as well? Answering these questions may help to justify the motivation better.  The explanation of G-SSL and the formulation in 3.1 is very confusing. In particular, we need to understand what the subscriptions i,j, iterate over for. For example, in (1), do they loop over all labeled data? unlabeled data? or one labeled one unlabeled? Also, the description "the unlabeled data is then predicted through energy minimization principle" doesn't seem to bound any variables in (1) to the "unlabeled data".  For the formulation, capital $X_l$ and $X_u$ seem to indicate two sets of data points, rather than two data points. Then I cannot make sense of $X_l+\Delta_x$ in (2) (p3, L134). This confusion makes me unable to make sense about the threat model for the attack. Does it mean all data can be manipulated as long as the sum of the perturbation is small enough? or only a small group of instances can be perturbed? If the later, how these groups are chosen?  The experiments also have many presentation issues. The datasets are not explained at all, except mnist17. Although a reference is provided in the footnote, we require the paper to be self-contained.   In Fig 2, different $n_l$ are used for comparison, but not explained. I first find this notion in 3.5, in the summation of the constraint, without explanation. Does it mean the total number of labeled data?   Despite these presentation issues, I'm concerned about how should I interpret the hyper-parameters such as d_max and RMSE. Sure, RMSE 0.2 increases to 0.3. But doesn't mean very bad? Some real examples, and qualitative analysis may clarify this concern.  Last but not least, it's questionable how generic is the proposed unified framework. It seems to be applicable to only a specific form of learning algorithms defined in 3.1. These algorithms seem to require to construct a adjacency matrix from kernels, which may not scale well to large datasets? In Sec 4, it seems that datasets of more than 20,000 nodes are used, but I don't see details about how the G-SSL methods can handle them. Are they unlabeled data or labeled data? If my understanding of n_l is correct, then it seems that the G-SSL approaches can handle up to 2000 labeled nodes, which then can make sense. Again, all these details are very important to evaluate this work, but missing.  I do not check the proofs of the theorems line-by-line, so I have no comments over them.  Overall, I think this paper needs more work to resolve the clarity issue, and justify the motivation better.  Some minor issues: Thm 2 is refering a theorem ??. Shouldn't the input for MNIST be of dimension 28*28=784 (rather than 780 in Table 4.1)? Sec 4.4 says three approximate solvers are compared, but it's actually two presented. PageRank should be cited.