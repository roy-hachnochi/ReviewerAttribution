General comments / questions (see elsewhere in this review for contributions/originality/significance): - The paper is generally well-written and clear given the (at times) technical content. - The approach appears technical sound and I find the insight presented in section 3.1 (and proof in the supplementary) together with resulting algorithm quite interesting (and possibly useful in other domains). I’ve read through and haven’t detected any obvious flaws but I’d suggest to double check the technical proofs and assumptions (especially in the appendix). - Sec 2 seems a bit long compared to the new insight presented in Sec 3.  - The experiments appear relevant and mostly well-executed. My main concern is the perceived benefit of the two-step approach. It is especially difficult for a reader to quickly see the clear benefit of the 2-OPT (or any variant of it) when looking at the “real-world” HPOlib and ATO benchmarks. It would perhaps be relevant to further focus on and emphasise the robustness of the 2-step approach over alternatives. Also, given that a primary goal of the paper is to improve time complexity, not introduce a new acquisition function per se, I would perhaps have expected an more detailed empirical comparison of the time complexity among different multi-step (at least two) BO approaches (especially GLASSES) (possibly in the appendix). - The variance on the optimization traces for EI and LCB are often very small (despite a very non-smooth traces for e.g. 5d Ackley fig 2) or non-existent; any reason or insight into this?  Minor: - L 143: Define Q (I assume it is a typo or last-minute change in notation). - L 233-244; please check for minor typos; esp. l 238  - Figures are bit hard to read due to axis labels and markers etc being rather small; overlapping graphs etc. 