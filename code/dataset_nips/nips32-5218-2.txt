--------Update after the rebuttal------  I thank the authors for the rebuttal. However, it seems that some of the concerns have not addressed yet.   Firstly, it seems unclear that the optimization problem in 3.2 is formulated as metric learning, but the authors claim that their approach and NCA (even other Mahalanobis metric learning) is fundamentally different (except using the concepts of “in-class” distance or similarity). Indeed, Mahalanobis metric learning learns a linear transformation while the proposed approach learns a weight function. However, a weight function is a special case of a linear transformation when one forces the linear transformation in a diagonal matrix (I understand that you used a weight vector --- a special case of linear transform: diagonal matrix --- over a nonlinear Gaussian mapping). About the non-linear aspect, there is a rich literature about nonlinear metric learning (see the surveys of Bellet et al.’13 and Kulis’12). Therefore, it seems better if the authors can place their proposed approach in the picture of metric learning when claiming the novelty. Currently, I am not sure why the proposed metric learning is novel yet?  Secondly, giving a persistence image and using a grid to vectorize it, it is quite surprising that the grid size does not affect the performances of metric learning for classification tasks (following the rebuttal). Somehow, it seems to imply that weights for positions in the persistence image may not be so important in applications (comparing with the uniform weights). Additionally, I see that the authors indeed considered original Persistence Image (PI) as a baseline (line 262). However, it is unclear whether the authors employed Gaussian kernel for Persistence Image (which is a kind of uniform weight for the proposed kernel) or simply apply linear kernel with SVM?). In case, they use linear kernel + PI, I am not sure whether it can give information about the benefits of learning weights, but if they applied Gaussian kernel + PI, then I agree that they illustrate the importance of learning weights.  ---> In case, the authors have not considered PI with uniform weight WKPI kernel (or simply Gaussian kernel). It will be better to use this baseline to show whether the learning weight is necessary. (Note that this comment only raised from strange observations from your experimental results in the rebuttal, somehow grid size is not important which seems to imply that uniform weight may be good enough). Somehow, the importance of learning weight may not so convincing through your experiments yet (over the uniform weight).   Overall, I feel that although the submission may have some potentials, it still needs more improvements (e.g. above comments, and some of the previous comments such as more care for solving the non-convex optimization problem --- no comments from authors in the rebuttal yet --- it is not sure why the nonconvex optimization is quite easily solved (?), time consumption comparison for experimental results --- partly improved in your rebuttal). However, I appreciate that learning weights is indeed interesting for TDA applications and your empirical results showed some potentials. So, I leave the decision to the area chair.  ------------------------------------------  The authors proposed a weighted kernel WKPI for persistence diagrams based on persistence images and a sum of element-wise weighted Gaussian kernel. The authors propose to learn the weight in WKPI as a metric learning problem by using (stochastic) gradient descent (where the weight is corresponding to a node in a grid of persistence images). Therefore, the weight in WKPI is adapted to a given task (learned from training data). Additionally, the authors prove that (i) the proposed kernel is positive definite, which is quite straightforward from its definition, (ii) stability of WKPI-distance w.r.t the 1-Wasserstein by relying on results of persistence images. Empirically, the authors show that the proposed kernel WKPI obtains similar of sometimes significantly better results than other approaches in neuron and graph datasets.  The paper is easy to follow. The proposed WKPI obtains good empirical results for neuron and graph datasets.  Below are some of my concerns:  The authors motivate to learn the weight for points in persistence diagrams (in introduction). However, in the proposed framework, the weight is on the nodes of the grid in persistence image which is a vector-representation for persistence diagrams.   It seems that the grid of persistence images is a crucial parameter in experiments. How does it affect the performance in the experiments?  The proposed kernel WKPI is based on vector-representation of persistence images for persistence diagrams with L2 metric. There are many metric learning approaches for such kind of problems based on the Mahalanobis distance where one can not only learn the weight for each feature, but also can learn the interaction among these features. In that view, it seems the proposed framework is quite limited. (since the weight on persistence images is quite different to the weight on points in persistence diagrams)  The proposed optimization problem for metric learning is quite similar to Neighborhood Component Analysis (NCA) proposed by Goldberger et al.’2005. It seems better if the authors plug the proposed method in a general picture of metric learning and discuss its merit.  For the optimization in Section 3.2, it seems it is a nonconvex problem, it seems better if the authors give more care for initialization, local minima, saddle points etc. For the penalty (in footnote page 6), why is it in that form, what is an intuition (since it is quite strange for a regularization.)  In experiments, the authors compare WKPI with PWGK and SW in Table 1. It seems that the authors miss Persistence Fisher kernel (Le, Yamada’2018) baseline which is one of state-of-the-art kernels for persistence diagrams. From Table 1, other kernels without learning are quite comparative with the proposed WKPI. It seems better if the authors also illustrate the results of those persistence-kernel on graph data. It is a bit confused why the authors do not consider those kernel approaches as baselines for graph data.  It seems better if the authors show the time consumption comparison in the experiments. 