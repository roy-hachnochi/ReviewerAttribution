The author response addressed my doubts and questions to satisfactory and hence I raised my score. ------------------------------------------------------------------------------------ The motivation of this paper is good, while the algorithmic contribution is also solid and seems to have wide applications in many popular fields of machine learning. However,  I feel the paper being weak in several aspects:  Firstly, the discussion of the theoretical results are highly lacking: how does the  theoretical convergence result compare to the related state-of-the-art algorithms such as the ones in the cited papers [1, 5, 8, 9]?  How realistic is the bounded gradient assumption B_f ? (standard SVRG-type methods does not require bounded gradient).   In addition, the algorithmic idea of combining the stochastic variance-reduced gradient and primal-dual reformulation is not brand new [1, 5], but seems that the discussion of the relevance of these work is lacking.   The experiments are limited only for portfolio management optimization with very small datasets (d = 25, n < 10000), which is a bit frustrating in my sight. I would expect much larger-scale experiments, and ideally with some more applications such as policy evaluation [5] in reinforcement learning, which the proposed algorithm can be also applied. I wish also to see the experimental comparison of the very recent C-SAGA algorithm (Junyu Zhang and Lin Xiao. A composite randomized incremental gradient method. ICML 2019).  In short, I think the current version of this paper can be massively improved and wish to encourage the authors to continue working on this.  