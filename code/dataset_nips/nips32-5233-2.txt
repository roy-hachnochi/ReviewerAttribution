The authors have satisfactorily answered my concerns and I am happy to raise my score. The complexity comparison table is interesting and should be included in the final version.  ========= This paper studies a variance reduced primal dual gradient algorithm for solving strongly convex composite optimization problems (with a finite sum structure). The algorithm is shown to enjoy a linear rate of convergence, both theoretically and empirically, and the variance reduction structure has allowed for efficient implementation. The paper also provides a few convincing experiments on real dataset compared to state-of-the-art algorithms.  Overall, the paper has tackled a challenging problem with an efficient algorithm and the proof appears to be correct. Here are a few comments from the reviewer:  1. The complexity bound in Theorem 1,2 The theoretical convergence rate of the algorithms grow with the order of O(n_X (n_Y + kappa) log(1/eps)) - since both n_X, n_Y are large, it seems to be undesirable. Particularly, since the epoch size M has to be chosen at the same order as O(n_X), it seems that after 1 epoch, the algorithm would only improve its optimality of the order of (1 - O(1/n_Y)). May I know if this is the case?  In light of the above comparison, it seems that the algorithm in [8] (that is also compared in the paper) has a lower theoretical complexity for large n_Y,n_X, i.e., the latter only has a complexity of O( (n_X+n_Y+kappa^3) log(1/eps) ). Even though the proposed algorithm is demonstrated to be faster from the experiments, explaining such gap from an analytical lens is also important.   2. Strong Convexity in the Risk Adverse learning Example The risk adverse learning is given as an example in the paper and the numerical experiments. Yet it seems that the problem itself does not satisfy Assumption 4.1 required in the analysis. From (4) and the discussion that follows, we know that (4) is a special case of (2), where the latter is a special case of (1) with *g(theta)=0*. However, Assumption 4.1 requires g(theta) to be strongly convex, which is not the case here.  3. Related Reference The linear convergence rate result proven in this paper seems to be related to:  S. Du, W. Hu, "Linear Convergence of the Primal-Dual Gradient Method for Convex-Concave Saddle Point Problems without Strong Convexity", AISTATS 2019,  which studies the linear convergence of a variance reduced primal dual algorithm with only a non-strongly-convex + strongly-concave structure, whose primal-dual variables are linearly coupled. This is similar to a special case for the setting of (8), where (8) has a nonlinear coupling.