This paper presents a complete theoretical analysis of Principal Component Regression under noisy, missing, and mixed valued covariates settings. Equivalence between PCR and Linear Regression with covariate pre-processing via Hard Singular Value Thresholding is established. Several general error bounds are proposed under those settings. Overall, the paper is well organized, and the presentation is clear. Detail comments and suggestions are as following.  - For theorem 5.1, are there any ways of estimating the degree of corrupted error or mismatch error? Is there any threshold that these two terms will dominate the bound? - How will regularization affect the proposed theorem, will it helps reducing impact of the last two terms in theorem 5.1? - How would proposed theorems extend to generalized linear models, such as logistic regression, Poisson regression?  - Understand that the limitation of space, but it would be nice to have a simple experiment section even with synthetic dataset to help understand derived bound under each of these settings.  I have read author's rebuttal and I will keep my original scores.