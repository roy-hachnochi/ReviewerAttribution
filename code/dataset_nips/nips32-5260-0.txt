This paper provides a learning-to-learn approach that takes advantage of the information from the test set via a transduction learning setup. Although past meta-learning literatures evaluate the few-shot generalisation performance in an implicit transduction setting, this is the first approach that trains a network explicitly to learn from unlabelled test data. It conducts extensive ablation study on the type of conditioning features for the learnt cost function, and shows SOTA performance on Mini-Imagenet and Caltech-UCSD Birds 200 benchmarks.  The motivation and the algorithm of the paper is well explained. Figure 1 and Algorithm 1 are very useful to understand the proposed algorithm.  What is not clear to me is how the information of the entire target set used to predict individual test images. For every image, does the loss network computes features and adapt model parameters based on the information from that image alone or from all the images of the entire target set? I guess the latter setting may give better performance since the information of other unlabelled images is useful for the image of interest and the original MAML paper also used all the test images for transductive learning. In that case, it would be important to understand how the prediction accuracy depend on the size of the target set and if it generalises to a different size from the meta-training setting.  In the experiment section, the performance of SCA on Low-End MAML is not studied for the CUB dataset. It would be nice to show the results in order to show the generality of the algorithm under different settings.  ------- Update after feedback: Thanks for clarification on the test batch size. It would be nice to clarify it in the final version as I imagine the performance would depend heavily on the size of test set.