Strength: - The paper proposes an interesting and novel approach for transductive zero-shot learning. - The paper extensively evaluates their approach on three datasets under the normal and generalized Zero-shot learning setting showing strong, improving in most cases SOTA performance.  - The paper proposes a new evaluation setting which include distractors from unknown classes. - Extensive supplemental material with additional analysis and details. - Overall clearly written and easy to follow.  Weaknesses: 1. Experimental evaluation 1.1. It would be great to also include zero shot performance on ImageNet (this is most likely missing as there are not attribute annotations for ImageNet, but the approach does not seem to be limited to attributes for transfer) 1.2. It would be interesting to quantitatively compare to [31] and [34] as ablations of the author’s appraoch from which authors took inspiration. 1.3. The authors claim in the reproducibility checklist to have “Clearly defined error bars” and “A description of results with central tendency (e.g. mean) & variation (e.g. stddev)”, but they don’t, although it would be good if they had. 2. Related work 2.1. The paper misses to discuss (qualitatively and quantitatively) recent related work including [A]. [A] achieves higher performance on SUN. Similarly, DCN [18] is not discussed and misses in Table 3, although it is better than other prior work on CUB. 2.2. Not w.r.t. performance, but with w.r.t. transductive label propagation, [B] is relevant. 3. Clarity: 3.1. Calling splits “Proposed Splits“, although they have been proposed in [28] is a bit confusing. Better might be to refer e.g. as “pure” as in [B].    Summary and Conclusion: While the paper includes an interesting novel transductive approach for zero shot learning, with an overall solid evaluation setup and several datasets, the paper misses to compare (discussion and quantitative) to Neurips 2018 papers ([A], [18]).   References:  [A] Zhao, An, et al. "Domain-invariant projection learning for zero-shot recognition." Advances in Neural Information Processing Systems. 2018. [B] Transfer Learning in a Transductive Setting; Rohrbach et al. Neurips 2013   == Post rebuttal ==  The authors provided additional convincing results on ImageNet (and Sun) and promising to add missing comparison in the final version. Furthermore, the authors included more comparisons to prior work in the author response.  While I think this paper is sufficiently different with [34], I think the discussion on [34] could be further improved.   I agree with R3 that the "new setting" is somewhat adhoc, and it would probably be good to compare it to the open world setting but it is still interesting that this paper studies it, especially in the transductive setting.  I expect the authors include the results from the author response and I strongly recommend that the author release code (which is missing for [34]) to allow future work to build on and compare to this work.  Overall, I think the paper provides sufficient methodological and significant experimental contribution, including reporting Generalized ZSL Results. I recommend accepting this paper.  