In this paper the authors propose a novel deep architecture for predicting future video frames. This builds on a variational recurrent neural network and combines several novel features including a keypoint representation and a best of many prediction scheme. The authors validate this on several datasets showing improvements over competing approaches. Overall this is a reasonably good paper - most of my comments are relatively minor.   - It is hard to see how the keypoint construction approach actually imposes spatial structure. My feeling is that this should be very sensitive to initialization, but this seems not to be the case. Can the authors explain how this can be so?   - Some papers (e.g. ref [27]) suggests that adversarial training may improve prediction. Why do the authors not compare to that?  - Line 124: can the authors provide more intuition about why this should be the case? did the authors also try with the linkkng the two modules?   