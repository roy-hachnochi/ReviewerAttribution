The paper proposes a zero-order optimization method that avoids saddle points efficiently. This is a practically important problem since many of the practical problems are non-differentiable of it is too costly to compute the gradient. Previously published methods of this category are not efficient and scale as O(d^4) with respect to the number of dimensions. The proposed algorithm is is a medley of different finite difference methods combined to maintain converance and efficiency,  I really liked the related work session that covers many of the most resent works on the second-order defivative and dereivative free optimization. Generally, overall the paper flows very well and it a pleasure to read.  The problematic part for me is virtual lack of the experimental secion. The only real experiment is done in the two dimensional Rastrigin function, which is clear toy example. More importantly, this function is differentiable, which defeats the purpose of zero-order methods. In fact the paper only very briefly mentions the application of the zero-order methods (line 33-41). It is suprizing that none of these applications made it as a experiments for the proposed very practical algorithm.    