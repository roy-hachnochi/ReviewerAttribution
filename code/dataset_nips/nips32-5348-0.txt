This paper studies low rank matrix approximation with respect to the entry-wise L1 norm. The main result is a theoretical guarantee for the low rank setting where an arbitrary rank k matrix is additionally perturbed by a random matrix. The result shows how to obtain a O(k\log n + poly(k/\epsilon)) rank matrix with error less than that of the L1 norm of the random matrix. The random matrix is subject to a certain moment condition which is shown to be necessary as well. The paper further provides a heuristic method inspired by the theoretical machinery.  Strength:  *) Strong upper bound which improves understanding of column subset selection for L1 loss, along with hardness results on assumptions needed in the upper bound  *) The proposed method is conceptually simple, and indeed the paper evaluated a heuristic based on the proposed method  Weakness:  *) The empirical result only gives incremental improvement over prior methods on the two real datasets, especially for larger values of k (rank).  *) Discrepancy between the algorithm analyzed and the evaluated  More detailed questions:  *) Line 64-65, what is the order of the polynomial? Wouldn't a high polynomial dependency on \epsilon be less desirable as well?  *) How well do Algorithm 2 apply in the setting of equation (2) (i.e. when you are trying to compute the best rank-k approximation)? Could the same idea be applied to get improvement in that setting?  *) Algorithm 1 line 6: S -> Q?  Other remarks: the formatting of equations could be made better in the current format. 