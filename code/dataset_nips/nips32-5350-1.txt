The notion of combining unsupervised learning with supervised learning has a long history, but this paper takes an interesting viewpoint of assuming that randomly drawn images come from different classes.  Of course, the validity of this assumption is highly dependent on the number of underlying classes, but their equation 1 illustrates the rough scaling.  They then use data augmentation to ensure that similar images are assigned appropriately.  I found the work to be clear and well reasoned.  The most significant contribution would be the assumption that all samples are in a different class. This assumption is also a very strong assumption -- and they do not explain how a person might test this assumption on any particular problem where classes are not previously articulated (as they are in imagenet).    This makes the generalizability of this work uncertain.  I am not concerned about the relative performance as much as having the authors put more detail into justifying why this would work on data collected from, say, autonomous vehicles or social media or commercial satellites.  How would we estimate if "N << C"?