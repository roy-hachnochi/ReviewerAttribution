1. In the proposed training scheme,  training on the data points with pseudo labels is followed by finetuning the model only on the labeled data.  What will the model performance look like if finetuning on the labeled data is not used?   2. For the experimental results in Table 1, it seems only ResNet-12(pre) is used for the proposed method.  What about other backbones? E.g., 4 CONV, which is used in the previous literature.  Also, the comparison does not seem to include more recent approaches, e.g., RelationNet,  dynamic few-shot visual learning without forgetting, etc. It would be nice to see a more extensive comparison with the previous approaches.   3. The cherry picking step is composed of a hard-selection and a soft-weighting step.  What are the detailed statistics about how many unlabeled data points are filtered in each step? Also, what is the ratio of unlabeled data and the labeled data used during training?   --- After rebuttal  The feedback is satisfactory. I increase my score to 6.  