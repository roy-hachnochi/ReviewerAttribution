This work considers convex relaxation to the PCA problem and revisit two algorithms: matrix stochastic gradient (MSG) and l2 regularized MSG (RMSG) from the theoretical perspective.   For the Algorithm 1, it is not clear on how to choose T, the number of iterations.   For Theorem 4.1, it is a bit confusing that the upper bound will get large as the value of T increases. Note that T is the number of iterations. One would expect that a larger T should lead to tight bound.  For the numerical study, it is better to compare some existing methods to have fair evaluation of the proposed method.  