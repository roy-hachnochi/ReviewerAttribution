With both methods, they demonstrate similar performance to backpropagation on ResNet-18 and ResNet-50 architectures on ImageNet. To me, this is the biggest strength of the paper. There have been many proposals for learning algorithms that do not rely on weight transport (feedback alignment included), which have only been evaluated on toy tasks and on non-convolutional neural networks.   The only weakness I would say is if there were experiments with more architectures on ImageNet using their learning algorithm, either variants of ResNet (101, 152, etc) and outside of the ResNet family (VGG, AlexNet, EfficientNets). If that is difficult to do, is it because the hyperparameters to get this algorithm to work are more than those for standard backpropagation? If that is indeed the case, that should be made explicit in the main text of the paper.