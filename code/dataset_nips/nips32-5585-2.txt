The paper is a concrete work as theoretical work. The authors use overparameterized neural networks as Q functions, which should be inspired by the recent advance in this area. The convergence rate seems to be optimal to the problem, at least to my imagination.  The paper, however, lacks an experimental section to validate the convergence rate is tight or not, which is a pity. Or there could be some analysis to compensate for the experiments in existing papers, which should convey insight to wider society. The overparameterization assumption seems to be not practical in actual experiments, at least to my recollection, although I understand this is probably not a job for an RL paper to accomplish. Besides, the paper seems to have no conclusion section?   At line 37, the authors claim about solving the problem of infinite-dimensionality, nonconvexity comes from? could the authors elaborate a little more for the technical difficulty in the specific function?  In algorithm 1, what is the criterion for line 5 and 6 to converge? or is it only one gradient descent step?