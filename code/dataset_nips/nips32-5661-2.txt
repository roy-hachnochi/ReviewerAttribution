Originality: this is in my opinion a quite strong point of the paper, that nicely bridges two different theories and brings an interesting interpretation to rejection samples and their nature within the learning theory.   Quality is good, even if some typos remain here and there (L114,L156,L200,L272)  Clarity: the authors often speak of assessing the uncertainty associated to a sample, however what they provide is a scalar-evaluation allowing to assess an overall confidence we can attach to a given instance being properly classified (and then possibly rejecting it according to our policy). We remain far from a full assessment of the uncertainty as would give a calibrated probability distribution or a gradual conformal prediction (that would go from the null set to the totally empty one). It could be useful if authors were clearer about that from the start.  Significance: from the paper, I had the feeling that theorems 1 and 2 are quite direct trasnposition of known results, while theorem 3 is kind of obvious (if every horse give me more than m times my money, then for sure a uniform bet on them will make me win without needing any saving, and if I cannot win more than one by betting on any of them, it is of course better to keep my money). So it could be argued that those main results are in fact expected. Would authors agree with that? This said, I think the bridges that are made are sufficient in significance by thmeselves.