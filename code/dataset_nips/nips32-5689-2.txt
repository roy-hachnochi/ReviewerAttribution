-------Comments added after the rebuttal------------- 1. Prop 1: Thanks for clarifying the implication of proposition 1. Please add a discussion to the paper. 2. The differences between the implemented algorithm in [1] and the algorithm in this paper should be clearly mentioned in the paper. " slightly different condition to discard candidate vector" -- it would be better to be specific and add the details.    ----------------------------------------- I think this is a good and well written paper. There are several interesting results (see above). There were few issues with the writing and I have some general questions.   1. In the abstract and in several places in the paper it has been written that "this is a generalization of linear and combinatorial bandits". It would be better if it is clarified everywhere that this is only the pure exploration version to avoid confusion.   2. (not a drawback) I am curious whether the bounds derived in this paper can lead to any new insight or better problem dependent bound for the cumulative regret problem in linear bandits.  3. It would be better to give direct references to the results used in the "review of least-squares" section even though the results are fairly well-known.   4. I actually did not understand the significance of proposition 1. What does it justify? A bit more discussion will be helpful.   5. Can you clarify whether the only difference between the version of [27] used in the empirical section and RAGE is the greedy rounding procedure? in light of "We remark here that in our implementation of the X Y -Adaptive allocation, we follow 267 the experiments in [27] and allow for provably suboptimal arms to be discarded (though this is not 268 how the algorithm is written in their paper). "  6. It would be great if a real dataset or experiment can be identified to try these algorithms out. It would be great to see the performances of the various algorithms where the linearity assumptions are not exactly satisfied. For example one can find the optimal parameter from a training set in one of the datasets used to evaluate linear bandits. Then on a separate validation set, these algorithms can be tested on whether they can identify the above parameter. 