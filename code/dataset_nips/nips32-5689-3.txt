I find the new transductive setup well-motivated and interesting.   Still, I wonder if this setting is really harder than pure exploration in linear bandits. Indeed, the lower bound derivation (and the complexity quantity) follow very closely the one obtained in the linear case. This makes me wonder whether any algorithm for pure-exploration in linear bandit could be extended to best arm identification in the transductive setup.   Still, the authors propose a specific algorithms that is not just an extension of an existing one (at least not that I noticed), and perform an original analysis (that I did not check in details).   The main theoretical claim of the paper is that in the linear setting, where several pure exploration algorithms have recently been proposed, they achieve proposed a sample complexity upper bound that is the closest to the lower bound. My only concern about the paper is that I am not completely sure about this claim.   Indeed, the paper [30] kind of claim the same thing. Yet in Section 4, the upper bound obtained in this work is not even mentioned: the LinGapE algorithm is "ruled out" of the pool of good algorithms because it needs to select each arm once. Still, it could be that in a regime of a moderate number of arms, the upper bound obtained in [30] is better than the one obtained in the present paper. I agree that the upper bound in [30] is less explicitly related to the lower bound than the one in the present paper, however a fair comparison would for example numerically compute the two upper bounds to juge which one is closer to the lower bound.   In Theorem 2 we have a multiplicative factor of c * \ln(1/\Delta_\min). First, it would be nice to specify the value of c in the statement. Then, \ln(1/\Delta_\min) can actually be very large, especially with 15000+ randomly chosen arms in dimension 2 as in the experiment reported in Figure 1(b).   To summarize, without the ln(1/\D_\min) this paper would be a strong accept due to the new framework + first optimal algorithm for pure exploration in linear bandit. Without it, the reader needs to be further convinced of the actual improvement in the theoretical result for the linear case.        