This paper describes an approach to semi-supervised learning for object detection in images. The authors propose two consistency losses (one for localization base on MSE, and the other for classification based on JS-divergence between predicted class distributions). This consistency loss is applied to original and horizontally flipped versions of labeled and unlabeled images during training. The hypothesis being that any predicted, localized objects should be invariant to flipping. The proposed loss can be incorporated into a variety of state-of-the-art object detection architectures and consistently improves downstream performance (with some caveats). Experimental results are given on PASCAL 2007 using unlabeled data from PASCAL 2012 and  MSCOCO.  The main selling point of this work is the simplicity of the proposed regularization and its applicability across architectures.  However, there I have two main concerns with the work:   1. Datasets. Although PASCAL 2007 is a venerable benchmark dataset for object detection, it is definitely showing its age. Moreover, the PASCAL 2012 dataset has the same class distribution as PASCAL 2007, and MSCOCO has significant overlap. The authors clearly acknowledge this (and split MSCOCO into two distributions for experiments). However, *both* PASCAL 2012 and MSCOCO are highly curated object detection datasets, and semi-supervised learning for object detection would be far more convincing if the "unlabeled" data used were sampled from more arbitrary sources.   2. Comparison with Self-supervised Sample Mining (SSM) [8]. The comparison with SSM in Table 4 seems to indicate that it does not share "the same drawback as self-training" as stated in the related work. Since the results of the proposed consistency-based approach are very similar, a deeper analysis of the differences and advantages should be provided. Why should one prefer consistency over SSM?  POST REBUTTAL: The authors touched on all of my concerns in the rebuttal. Though I still think the work would be significantly improved using less curated sources of unlabeled data, the paper is solid and the results on PASCAL 2007 convincing.