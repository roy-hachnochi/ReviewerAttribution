This paper is clearly original since it provides a new proof of a well-known result (Catoni's bound, recovered up to constants), a new definition of flatness (h-flatness) of the landscape where the posterior concentrates and a new PAC-Bayes bound associated to the notion of flatness. This paper is a nice theoretical contribution to the PAC-Bayesian theory of learning. The details of the proofs, that are technically sound (use of symmetrization for deviation inequalities, theory of shifted empirical process, duality formula for the kullback-Leibler divergence, peeling with respect the values of the KL divergence), are deferred to the Appendix and condensed arguments of proofs are written in the main part. However, the comparison of the new bound (Theorem 4.3) with Catoni's bound remains at rather heuristic level. Indeed, it is proved that the new bound is not worst than Catoni's bound, but it is only assumed and not clearly demonstate that the new bound can actually be stronger than Catoni's bound in favorable cases. I have also a question in mind about the scheme of proof exposed in Section 3. To bypass the suboptimality of the bounded difference inequality, the paper advocates to use control by Rademacher quantities directly in the deviation inequalities. But what about Talagrand's type concentration inequalities for the supremum of the empirical process, that would allow (classically through a peeling argument) to take into account the localization of the variance of the classes (KL neighborhoods). This is the classical way to produce fast rates from empirical process theory, so I wonder if some adaptation could be worked out here in the PAC-Bayes framework? This paper is essentially well written and well organized. The notations are carfully introduced and many references to existing, connected works are provided. However, I have three remarks concerning the presentation, that are rather minor. Constant c does not appear in display (11) (that refers to Lemma A.2 in the supplementary file), on contrary to what is anounced (l. 158: "as long as c>0"). This should be fixed. Also, l. 175-176, the sentence that begins with "For fixed $h>0$ [...]" is unclear to me and should be rewritten. Finally, I think that Display (25) could help the reader to understand the notion of flatness if it would be placed right after Remark 4.2. I think that the proof of Proposition 3.1, the new bound of Theorem 4.3 and the definition of flatness provided in Definition 4.1 are interesting and important theoretical contributions, successfully investigating the links between two major lines of research, Rademacher complexities and PAC-Bayes bounds. 