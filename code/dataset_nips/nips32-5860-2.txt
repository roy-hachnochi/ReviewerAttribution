[Edit after the author feedback]:  I thank the authors for addressing my comments during the author feedback. I have read the authors' response as well as the other reviews. The authors' response, especially the updated attack results on \ell_{\infty} adv trained models (Table B), addresses my concerns on the effectiveness of P-RGF. Overall, I think this submission is interesting and provides an efficient and effective adversarial attack approach. I am happy to raise my rating.  ==========================================================  Summary:  To improve attack success rates and query efficiency for black-box adversarial attacks, this paper proposed a prior-guided method which is able to better estimate the gradient in a high-dimensional under the black-box scenario. Theoretically, this paper establishes the optimal coefficient of the proposed algorithm. Empirically, the proposed algorithm can use fewer queries to achieve higher attack success rates compared with previous approaches.  Pros: - This paper derives the optimal coefficient, i.e., $\lambda^{*}$, in the proposed algorithmic framework, which makes the algorithm more efficient and effective. Also, the algorithm is simple and easy to implement. - The proposed attack framework is general and is able to incorporate various data-dependent prior Information. - The empirical results demonstrate the effectiveness of the proposed method, especially when attacking defensive models.  Limitation & Questions: - As described in Table 1, it seems that the improvement over the RGF method is not significant. - As adversarial training, like [22], has been shown to be an effective approach to defend against adversarial attacks, it would be better to add the attack results on adversarial trained defensive models to section 4.3, such as attacking models trained by adversarial training ($\ell_{2}$ model with $\epsilon = 0.5$).