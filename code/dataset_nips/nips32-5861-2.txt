The paper is clear but some parts could be improved, for example the authors refer to scalability issues for GCN in the sense of stacking multiple layers but the term refers to scalability wrt size of the input.   The authors focus on a very specific instantiation of graph convolutional networks, namely GCN, and to spectral methods. How does the method compare to approaches based on the more general message passing paradigm that can implement both local and global computation? Laplacian smoothing is not necessarily an issue there.  Why is the graph defined using edges and adjacency? Isn’t it enough to have either one? Please explain.  At the end of sec 2 it is said that Chebyshev polynomial constitutes a spectrum-free. The method does not require the computation of the eigendecomposition, however the resulting method still behaves as spectrum-based.  Experiments are very thorough and show that the proposed method achieves good performance in all the proposed tasks. However the section is quite short and should be expanded for better clarity. For example, it is not specified what column is the usual data-regime (not decimated setting) used for each experiment.  Future works in this current form is not very useful. I’d consider some rewrite of section 4 and 5 to make space for better motivation and explanation of results.