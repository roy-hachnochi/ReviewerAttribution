Detailed comments on the contributions:  Contribution 1: The learning model consists of an autoencoder that is based on the Transformer. The latent variable z of the autoencoder is supposed to be fed to a classifier that is trained separately and that will guide the autoencoding process.  Questions: If the classifier C is used to change z and so its parameters are kept fixed, how is it insured that this classifier has the optimal set of parameters as z is changed?  The idea of “control of degree of transfer” seems a bit not well-grounded to me… Language is complex, and I find it hard to draw a parallel between fine-tuning one weighting parameter in an objective function and an effect on the output where, as I understand what you mean by it, certain words will change in, e.g., intensity? [e.g. funny -> hilarious]…   Contribution 2: By way of its design, the model allows (at least conceptually) to handle multiple attributes effectively for transfer.   Experiment/Section 4.2: The authors choose the most straightforward experiment. Given how strongly the authors claim their model to be performing in previous sections, it would’ve made sense to evaluate the model on cases that are bit more involved. Another challenging dataset is the one introduced by Ficler and Goldberg 2017 (full title later in the review) in which they do multi-field conditioned generation. That dataset has 5 fields that the author could use to further investigate their model’s performance.  Contribution 3: The authors perform extensive experiments against 8 previous models. The experiment seem quite comprehensive in terms of competing models. Given the strong performance of the model (surprisingly in almost all of their test cases as in Table 2), the authors could've chosen some more involved qualitative validation in Section 4.2 as noted above.  I'm also hesitant regarding some of the conclusions regarding transfer control. In my opinion, the contribution of these results (e.g. Figure 2) is the performance trends they show the model to exhibit when the parameter is tuned, but this is not a general indication of the impression that the paper is trying to give regarding the effect of fine-tuning that weight parameter [the actual control of word usage]. ------------------------------------------------------------------------------------  Clarity: The paper reads very smoothly and is an enjoyable read. The model is explained clearly and the paper is well-structured.  The description of Algorithm 1 is useful. However, I find it crucial that the author also explain how the two components of their model interact with each other. This is missing and I think it's crucial. If the paper is accepted, given the extra space, I encourage the authors to further explain that [other than the fact that they're trained separately].  Intro: What does this mean? “this may undermine the integrity” Intro: At this point of the paper, it's unclear what the notion “degree of transfer” means. It should be clarified in the intro.  Table 2: The way numbers are bolded vs underlined is confusing. Bold is usually used to highlight the strongest performance, whereas the authors use the underlining to point to strongest performance. I encourage the authors to bold the strongest numbers for the Captions dataset for the corresponding (competing) models and keep the underlining to indicate that this is their numbers.  If the paper is accepted, given the extra space, I encourage the authors to explain better their "Automatic Evaluation" results of Section 4.1 drawing parallels between the trends in numbers and the way they are explained in the body of the section. ------------------------------------------------------------------------------------  Additional references:  Since the authors mention at the beginning of their “Related Work” section the notion of transfer of style as a whole (not attributes) [specifically in Lines 61-62], these are possible references that could be added for that: 2012: Paraphrasing for Style  2016: Stylistic Transfer in Natural Language Generation Systems Using Recurrent Neural Networks 2017: Shakespearizing Modern Language Using Copy-Enriched Sequence-to-Sequence Models 2018: Evaluating prose style transfer with the Bible  Not transfer per se but relevant to generation of texts conditioned on specific attributes (the paper I mentioned above): 2017: Controlling Linguistic Style Aspects in Neural Language Generation ------------------------------------------------------------------------------------  Typos and other comments: Line 51: fluent* Line 55: capable of* controlling* Line 85: edit* Line 116: language modelling* Line 129: “representation that conforming to the target” -> “representation so that it conforms to the target” Line 136: editing the* latent representation  Line 141: “z’ that can be identified as the target attribute y’ ”. I understand this to mean that z’ is the target attribute y’… I think what you’re trying to say “ z’ that leads to the identification of target attribute y’ “?   Order of papers in References is off at some point (e.g., Smola et al appearing at [1], Van Der Maarten at al. appearing at [18] and not towards the end…) 