The need for the transformer network in the encoder is not clearly explained.  Can you achieve better disentanglement by discouraging perspective code from predicting appearance code?  Would Wasserstein auto encoder be a more powerful framework than VAE?  Below are two related papers: 1. Unsupervised Part-Based Disentangling of Object Shape and Appearance Dominik Lorenz, Leonard Bereska, Timo Milbich, Bj√∂rn Ommer  2. Unsupervised Disentangling of Appearance and Geometry by Deformable Generator Network  Xianglei Xing, Tian Han, Ruiqi Gao, Song-Chun Zhu, Ying Nian Wu; The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019, pp. 10354-10363  ----after author feedbacks--- The authors provided results on more datasets, dSprites and CelebA. The authors also clarified their contributions with respect to related papers (transformations in related papers are not invertible and hence do not correspond to proper group actions). The authors also commented on WAE vs. VAE. My main concerns are addressed to my satisfaction.   Therefore, I am happy to increase my rating to 6. The reason that my rating is not higher is that, the framework is rather straightforward technically. For more technical depth, the authors should consider analyzing the use of inverse transform in encoder from a mutual information perspective. This key contribution needs to be backed up by rigorous theoretical analysis. 