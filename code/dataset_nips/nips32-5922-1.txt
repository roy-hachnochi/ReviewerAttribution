 =Summary=  The paper propose a method for correcting the bias in the outcomes of pretrained deep generative models. Given data from a generator distribution and the real distribution, the paper uses importance reweighting to up/down-weigh the generated samples. The importance weights are computed using a probabilistic binary classifier that predicts the identity of the data distribution. Experiments are shown on several tasks to show that the importance reweighting improves the task performance.  ----  =Originality= Medium. The importance weighting using binary classification is a well-known technique. However, its usage in pretrained generative models is interesting.  =Quality= Medium. The experimental section is well-written and the paper clearly points out potential drawbacks.  =Clarity= Low-Medium. The paper is in general easy to read. However, some design choices can be explained better. Please see detailed comments below.  =Significance= Medium. The proposed scheme can be a good addition to a deep generative model practitioner's toolkit. The framework has some stark limitations (e.g., the requirement regarding joint support of the real and generated data), as also pointed out in the paper. But it is still a useful addition to the growing literature on deep generative modeling research.  ----  =Detailed comments and suggestions=  - Lines 135-143: It is not clear what the corrective measures proposed here do on an intuitive and theoretical level.  For examples, given very high and very low importance weights in a minibatch (corresponding to real and generated data), how does normalization help in terms of obtaining the "true" importance weights?  - Similarly, are there any guidelines on when to apply each of the above corrective measures and how should the hyperparameters be selected?  - Line 161: It is a bit surprising to see that the binary classifiers are calibrated by default, given that deep models are known to be very prone to miscalibration (https://arxiv.org/pdf/1706.04599.pdf). How precisely is miscalibration measured (e.g., via expected calibration error as described in the reference above)?  - Line 168: For computing the reference scores in Table 1, how precisely is the real data split? Is it a 50-50 split?  - Line 129, 304: The reviewer appreciates the fact that the paper is quite open about the potential limitations in the proposed methodology.  - One limitation that is worth mentioning is that the proposed method cannot be used to generate new unbiased samples.  - A question inspired by the closely related work of [45]: Ignoring the mode-dropping phenomenon of GANs (that is, assuming that the real and generated distributions have joint support), would the proposed importance weighing mechanism be obsolete if one were to train the GAN for a very long time?   -------  = Update after the rebuttal =  Most of my questions were addresses in the rebuttal. It is good to see the plot showing that the models are already well-calibrated. It would perhaps be helpful to add the plot (or at least the reference by Danescu-Mizil and Caruana) in the final version so that the readers are aware of 1)  the potential for miscalibration and 2) the fact that these models are in fact well-calibrated. 