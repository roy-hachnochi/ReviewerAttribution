The paper presents a method for constructing neural network architectures that have build-in theoretical guarantees of Lyapunov stability - meaning that the equilibrium will be in the origin and for any initial condition, the network will produce trajectories that converge to the equilibrium. The method is evaluated on the N-link pendulum and video generation problems.  The methodâ€™s significance comes from two different reasons. First, Lyapunov stability for the system is very difficult to prove with classical methods. Second, deep learning methods are largely empirical, without theoretical guarantees, limiting their applicability for life-critical system. This paper presents a method for learning autonomous dynamics that is guaranteed to be Lyapunov stable, without having the classical toolset.   This methodology is original and potentially very useful for many applications, beyond classic controls and videos. For example, protein folding, robotics, weather predictions, material design, etc.  The quality of the paper overall is good, although it varies. The theoretical potion is solid. The contribution is clear, well-motivated, and structured well. The empirical validation is somewhat lacking in quality. While the authors are commended for exploring two very different domains (classic controls and video generation), the empirical validation is missing some key elements. For example: - It is not clear how the method would perform on a system without equilibrium, or for that matter the link in the upright initial position. - How do the learned and ground truth models perform in the presence of noise? - Details about the training are missing:    1. methodology for gathering the training set;    2. why the convex network has 60 layers (and in the previous example, it contranied 100 neurons per layer);    3. system info is missing in both examples (equations for the pendulum with the damping factor and reference to the video dataset for the video prediction dataset).   4. Figure 5: Over how many initial conditions was the Figure compiled? Please show error bars.       In addition, that authors should include and discuss the following related work: Learning Stabilizable Dynamical Systems via Control Contraction Metrics, Singh et al. WAFR 2018 Continuous Action Reinforcement Learning for Control-Affine Systems with Unknown Dynamics, Faust et al, Acta Automatica Sinica, 2014  The presentation of the paper is excellent. The authors make a theoretical paper very easy to read, and logically introduce one step at the time new notation and the elements of the method. Some minor comments:  - Lines 59-60: stating that those conditions are sufficient but not necessary is more clear. - Line 113: What differentiable tools. Please cite? - Line 132-133 - Please, either prove or remove the claims. - Line 145: is V is -> if V is  - Line 167: The fact the V -> The fact that V - Line 192: angular velocity \theta -> angular velocity \dot \theta - Please go through the math and use standard notations for vectors (vs scalars).  Overall, strong potential theoretical result, with lacking supporting evidence as how well it really works in practice.  -------------------------------------------------- Update after author response: Thank you for the response and clarifying the points. The paper presents a strong theoretical contribution, and I leave the score unchanged.