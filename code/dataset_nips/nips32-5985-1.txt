Originality: This work is an application of the much explored idea (partition functions, belief propagation, dynamic programing, etc.) that sums/max operations on functions whose variable dependencies decompose into a tree-like structure and can be carried efficiently via recursive procedures and caching. The paper makes a small contribution over the work of Guy Van den Broeck.  The quality of the work is solid. The proofs, in particular, are very clean, and mostly amount to rearranging multiple summations of products. Definitions and statements are precise. Great job!   The clarity of the writing and explanations is very good in general, but the paper is, at times, too concise in its explanation, making it easy to read only for people previously exposed to these topics.  From the theoretical point of view, the significance of work is modest, since the results are not surprising, and are of similar flavor as ideas regarding how to efficiently compute sums/products of functions. The push to bring circuit theory, from the theory of computation field, to ML is laudable, and important. However, from a practical point of view, most technology seems to be driven by continuous and inexact methods (training NNs, etc.), not by discrete and exact methods.  From a practical point of view, the significance is unclear. The data-sets used are very small and simple. Also, it would be good if the authors compared their technique with methods other than imputation methods, and small data-sets. Maybe compare against some sampling methods to estimate the moments.