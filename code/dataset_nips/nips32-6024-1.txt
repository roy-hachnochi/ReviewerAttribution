I really like the first contribution of the paper. However, I still think this work lacks the experimental part.  As I know, most of the recent work on the central (\epsilon, \delta) DP-ERM has experimental study such as [1-6]. So I think in order to say that their method of DP-batch SGD, they should provide some experimental study in order to say the improvement.   [1] Towards Practical Differentially Private Convex Optimization. [2] Differentially Private Empirical Risk Minimization Revisited: Faster and More General.  [3] Privacy-Preserving ERM by Laplacian Smoothing Stochastic Gradient Descent [4] Renyi Differentially Private ERM for Smooth Objectives [5] Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization [6] Efficient Private ERM for Smooth Objectives.  ------------------------------------ -------------------------------------------------------------------------------------------------  After the rebuttal I change my rate to accept. However, I still want to see some empirical performance of the algorithms. 