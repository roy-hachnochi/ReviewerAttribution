Originality: This work builds upon previous work but derives several results that are interesting in their own right, including moment bounds for determinants and adjugates of random matrices.  Quality & Clarity: This paper is extremely clear and easy to read, which contributes significantly to its quality. The results are carefully proven and explained, and the proofs are easy to follow.   Significance: the ability to recover the inverse of a large matrix through distributed averaging and without bias has many important applications to machine learning problems, as the authors point out.   ----- Questions ------ - Would it be possible in certain of the ML scenarios mentioned, to take advantage of the determinantal weights by sampling subsets of size k that yield high determinantal weights?  - Do you know if the identities derived in Section 2 can be generalized to other elementary symmetric polynomials?