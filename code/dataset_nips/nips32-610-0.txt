Originality: While the components of the algorithm (i.e., message passing, attention, graph-embeddings etc.) are not new, this particular combination is novel, and required a nontrivial effort deploy effectively.  Quality: The work is technically sound, and the evaluation criteria are robust and extensive (though I am curious how this compares with MAML style metalearning techniques).  Clarity: The paper is fairly clear, but could be improved considerably with code for implementation.  (There are also a handful of minor spelling errors throughout).  Graph-based methods and message-passing (in particular) are relatively uncommon, thus providing more detail could only help the traction of the work.  Significance:  The work seems significant (as evidenced by the clear advantage on the provided baselines), but I will admit to a small amount of bewilderment at the sheer number of separate ways in which people have chosen to test few-shot metalearning systems.  This is partially the community's fault (for failure to align on a clear baseline), but it would help it the authors spent a bit more time contextualizing their choice of baseline.