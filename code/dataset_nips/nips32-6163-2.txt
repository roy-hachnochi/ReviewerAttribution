The idea is original, the paper aims to improve a simple element-wise sum of context representations as in GQN. The key idea is based that there should be a consistency between the viewpoints, i.e. for a given pixel we can cast a ray from the pinhole camera, then from a different viewpoint this pixel colour should lie somewhere on the casted ray (yet can be occluded). The output of the model should then depend only on the relevant features, i.e. for a given pixel only on the rays that pass though it.   The overall network and attention mechanism (Fig2 and Fig3 b) is complex and have some extra unexplained engineering. I did not understand the approach properly from the descriptions. For example is e^k aggregated for all observations, or separate, is the attention mechanism looking at all of them together? Where z_i variables come from, seems these are not specified. In Fig2 it is unclear which operations are done per observation and which across all. In Fig3b, what is d, what is its value any why? Why e^k dim is 2 times h' and one time w' if h/w (height/width) of an image should be symmetric?  Regarding the results, the EGQN results on the new datasets are much better than GQN. This is especially visible in Fig6 where only EGQN gets the colours and letters of the box correctly. Similarly, EGQN performs well on disco humanoid, and GQN performs poorly. The original datasets are very simple and here the results are similar, only sm7 is more challenging from the original ones are here the performance is again much better.  Fig8 ground truth is the same as the last column of the context, and predictions are different, it seems GT is incorrect.  Would be good to explain each variable in the caption of each figure, not only in the main text.  The evaluation is only one table with 2 rows. Would be good to show other measures, and for this table, the presentation could be richer, e.g. show violin plots with std/median depicted too.   Surprisingly exemplary images are not given for all datasets at least in the supplement.  Fig4: What is +1.254 on top of 3 plots meaning?   Fig4 minimum y-value looks suspicious -- why is the value constant for 4 datasets and then for the 3 other ones?  The method is interesting overall but evaluation seems to be not adequately explored, visualised, and presented or even provided. There are some issues raised that hopefully will be explained in the rebuttal.