This paper concerns a repeated multi-unit auction, where a collection of items are sold to bidders each round.  The seller uses past bidding behavior to learn how to set a reserve price for the auction.  The buyers are aware that the seller is learning, and might participate multiple times, so they might change their behavior to affect future prices.  The authors propose a differential privacy (DP) approach to this problem.  They show that if the seller maintains their data about the bidding history in a DP way, then truthful bidding each round will be an approximate equilibrium for the agents.  If the seller also determines the allocation and payments in a DP manner, then it is possible to get the stronger guarantee that exact equilibrium behavior is "close to" truthful bidding, leading to approximately optimal revenue.  There is a lot to like about this paper.  The problem of repeated sale to forward-looking bidders is an important one, and a hot topic in the intersection of microeconomics and learning theory.  Differential privacy is a natural tool to bring to bear on this problem.  The authors do a good job of explaining the connections between DP, known DP algorithms, and their various incentive properties.  My main concern is the incremental contribution over Liu et al. (cited as [27]).  Paper [27] solves a nearly identical problem.  The main difference is that [27] learns an *anonymous* reserve, which is optimal only when the agent distributions are identical; this paper extends their approach to Myerson auctions with per-agent reserves.  While this is an important extension, the difference between the papers is not discussed at all aside from a cursory mention.  Indeed, from a technical perspective, all the ideas from this paper seem to be present in [27] also, so the impression is that the marginal technical contribution is very minor.  The paper would be *much* improved with a thorough discussion of what new ideas/techniques were needed for this extension.  A more minor issue is the modeling choice that exactly one bidder from each of the n populations is present in each round.  Is this necessary?  It feels very artificial.  As far as I can tell, the results would go through if agents are instead selected each round from an aggregate population of size N, divided into n sub-populations, and the sub-population of each agent is publicly observable.  I.e., sometimes there might be 2 agents from one population and 0 from another.  I find this model more natural; do the results carry over to such a setting?  Overall, I find the paper hard to judge without a detailed comparison to [27].  I think the extension to optimal auctions is important, but as far as I can tell the main body does not contain much content about the new ideas/techniques needed for this, and mainly goes over ideas already present in [27].  In its current form, I think the paper is a marginal case.  [Post Author Response] The proposed paragraph describing how the paper relates to [27] would be very helpful.  Though I think it's important to clarify the distinction from [27] not just in terms of problem setup, but also techniques after having reduced to the underlying DP problem.  In general, I am convinced post-rebuttal (and having seen the other reviews) that the technical contribution relative to [27] is above the bar.  I have raised my score.  I do still encourage the authors to emphasize the technical proof  differences from [27] (e.g., in the way joint DP is established), as this is currently hard to see from the main body of the paper. 