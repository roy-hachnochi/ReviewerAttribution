The paper is overall well-executed.  To my knowledge this approach, while intuitive, has not been explored in detail before.  My primary comment is that several important strands of related work are omitted.  First, there is a line of work that illustrates why the utility-approximate guarantee is a weak one.  In particular, after the McSherry-Talwar paper, people realized that while differentially privacy limits the loss from truthful reporting, it also limits the gains.  So there may well be obvious, yet individually small improvements that could undermine the mechanism.  To counter this, a stronger guarantee like bid-approximate is needed.  Papers in this line include [35] (which is currently only mentioned in passing, “Is Privacy Compatible with Truthfulness” by David Xiao ITCS 2013, and “Truthful Mechanisms for Agents that Value Privacy by Chen et al. ACM TEAC 2016.  Second, there are some other recent approaches to this problem other than those cited.  See “Selling to a No-Regret Buyer” by Braverman et al. EC 2018 and references therein.    Third, there are papers looking at applying differential privacy to advertising systems, one of the examples where this paper is relevant.  These include “PriPeARL: A Framework for Privacy-Preserving Analytics and Reporting at LinkedIN” by Kenthapadi and Tran and “A Practical Application of Differential Privacy to Personalized Online Advertising.”