This paper studies zero-sum Markov games in the context of linear quadratic systems. Despite the non-convex non-concave nature of the objective, by exploiting the specific dynamics/structure of the linear quadratic systems,  the authors propose three nested gradient algorithms with theoretical guarantees. Specifically, they prove global convergence with sub-linear rate and local convergence with a linear rate. They also support their claims with empirical evidence. In the experiments, they compared their proposed algorithms against the simpler variants of them, namely alternating gradient and gradient-descent-ascent (for which convergence analysis is not available in the literature).   ************************ + The paper is overall well written, and sufficient background is provided.   + They have clearly distinguished their work with other theoretical works on min-max problems.   ************************  Regarding Figure 1, in the theoretical analysis, is the performance ordering of the three methods (gradient, natural, and Gauss-Newton) explicitly shown?   The main limitation is the (direct) applicability of the proposed algorithms to general RL problems. Does the analysis/insights of this work extend beyond LQ systems? It would be interesting to empirically evaluate the nested gradient type algorithms on some general continuous control problems.   In terms of Optimal Control contributions, I am not familiar enough with the literature to assess the novelty of this work. 