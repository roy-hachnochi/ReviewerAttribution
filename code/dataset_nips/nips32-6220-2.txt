Learning graphs from data is an important problem finding many practical applications. This paper contributes by a new regularization strategy that employs spectral constraints of graph Laplacian. The resulting algorithm appears to be novel and technically sound. However, I think this paper will benefit significantly from major revision making the practical relevance of the proposed approach clearer: 1) The authors originally suggested four different spectral constraints but only one of them (k-component graph) was actually evaluated. Implementing and evaluating more than one constraints in this framework could help understand the nature of this strategy. 2) The resulting algorithm has been evaluated on synthetic data sets and two real-world data sets. Evaluation on real-world data sets has been done only based on `visual inspection’. Neither objective criteria (e.g., the BIC used in [14]) nor user study aggregating subjective user opinions have been employed for real-world data sets. Two-dimensional visualizations of clustering results on two simple data sets does not seem to effectively demonstrate the usefulness of the proposed algorithm. Minimally, the authors should provide an intuitive discussion on what practical relevance can `k-component graph’ have for graph learning. To summarize, the current reviewer is not sure if the results on these simple data sets reflect the actual performance of the proposed algorithm on challenging real world problems.   Minor comments - The authors should discuss how `k’ should be determined in practical applications. - The proposed framework does not actually enforce the spectral constraints. Instead, the authors replace the hard constraints with soft spectral regularization term that simply measures the squared Frobenius norm from a matrix (in a spectral decomposition form) that satisfies the constraints (the third term in Eq. 8). Quantifying the violation of the original spectral constraints in this scenario could help. Alternatively, the possibility of `having sufficiently large beta’ could be substantiated in terms of the optimization trajectory.  - After rebuttal: Thanks for the rebuttal. I increased my score to 6. My main concerns were 1) implementing and evaluating only the k-component graph case among other constraints that the authors suggested; and 2) assessing the performance only based on visual inspection. I think the rebuttal addressed some of my concerns.  Suggestions for improvement: 1) I would suggest including the results corresponding to Eq. 6 and Eq. 7, convincingly demonstrating the `general' utility of the proposed spectral regularization framework or alternatively, remaining focused on the k-component graph (including the 1-component graph) case and adjusting the title and main claims accordingly. 2) The experiments could be significantly strengthened by evaluating objectively the resulting algorithm in the context of real-world applications that the authors mentioned in section 3 of the rebuttal, e.g., semi-supervised classification. 