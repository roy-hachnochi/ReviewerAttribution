Significance and originality : There is a huge number (and it's growing) of small variations of settings for pure exploration in MABs, and this paper adds to them by changing the notion of regret in thresholding bandits. The algorithm LSA is quite similar in form the APT of Locatelli et. al . That said, LSA is well motivated (with the optimisation problem), and the authors provide a well-rounded analysis of the problem with non-trivial methods, which is always interesting for experts.   Quality and clarity : The paper is quite complete and thorough, answering spontaneously many natural questions (e.g. illustrating how the uniform sampling algorithm behaves, how to tune alpha, ...). Almost all mathematical operations are well-motivated, which is a pleasure for the reader, and the mathematical statements are followed by insightful comments. The experiments are quite complete too and seem to honestly show that their algorithm behaves well in practice.   There is however a caveat: the theoretical dependence on \alpha is a little worrying, as the lambda_i's depend themselves on \alpha. Therefore, Remark 2 is not completely clear, and the claim of instance optimality is not properly proven. I do not think this is a bad problem, but it should be clarified. In general, I have a feeling that the exposition in Section 4 could be improved, as it confronts very suddenly the reader with some heavy notations that hinder readability.  All in all, I think that this is a strong contribution, currently with an exposition problem in a critical part of the paper.  Some typos :   l32 : z_i = 1 iff \theta_i \geq 1/2 overall the description of the problem seems weird to me, why not just say we want to predict whether \theta_i \geq 1/2, without talking about the z_i  ? l.90 : why is that ?  l.162 : “Note that this is all AN algorithm can do […]” (the AN is missing). Why is this ?  l.170 : approximates P_c^\star well l.173 : I think you mean max ?  l.174 :  function on x <- function of x l.182 : value <- values l.203 : alpha = 1/ 20 <= alpha = 1/10 ? l.206 : demonstrated <-  proved, or stated ??  l268 : MOSS is not asymptotically optimal in the usual sense, although it is minimax optimax.  l302 : the delta’s in the definition of H are not the delta's in the TBP  l332 : the celebrated Hoeffding’s  maximal inequality <- Hoeffding’s celebrated maximal inequality l.408 : applies <- apply to  l454 : performing THE uniform  Post rebuttal edit.  The setting and the algorithm are interesting. However, the issue I find critical, about optimality, has not been answered properly in the author feedback and I maintain my score. To me, this is a potentially strong but incomplete work as long as the regret bounds are not more readable/comparable to lower bounds. 