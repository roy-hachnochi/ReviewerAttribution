The work discusses how mis-identifying causal relations can create issues with imitation learning. They show experimental data to support the claim, propose new algorithm to overcome the problem and propose new benchmarks to test the problem and solution. I think this is a very important work that can open a new directions for imitation learning and should be accepted.  Detailed remarks: 1) I am not that familiar with causal inference so I am not sure if the algorithm proposed is a good way to identify causal structure, but it makes sense to me and seems to work well empirically. 2) Regarding the GAIL baseline - I think one can explain part of the reason GAIL is successful using causal reasoning (if you get the wrong cause the state space distribution would be different and "caught" by the adversary) and discussed in the paper. 3) In Fig. 11 I would like to see the intervation curve continued to be sure it doesn't converge to a lower state in the end, even if it is higher sooner. 