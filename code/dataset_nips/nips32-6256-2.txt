This clearly written and highly novel paper describes a critical gap in the causal inference literature. While inference methods have advanced, our evaluation techniques have not. As the authors show, this means that our ability to predict which methods will translate successfully to practice is limited.  The paper contains a thorough survey of inference methods and evaluations, which i have not seen before. This is a valuable contribution to the literature. While the paper is not perfect (see improvements section), I believe the significant novelty and potential impact on the community outweigh these weaknesses and that it is a significant contribution. Figure 2 is especially striking.  Questions: -The authors discuss the significant limitations of synthetic data. However, only simulations using the target structures (e.g. DAG) seem to be considered. What about  using domain specific simulation systems?  These are totally independent of the methodological assumptions/approaches. Do you believe the results would be closer to interventional measures?  I appreciated the responses to the reviews, and maintained my high score as the weaknesses pointed out by the other reviewers will be addressed in revision.