The submission studies the meta-inverse reinforcement learning problem, which is clearly motivated. Specifically, the submission includes a latent variable into the AIRL. To solve the achieved deep latent variable model, a new estimation method is proposed to approximately optimize the objective function.   The work is very complete with a new model, a corresponding estimation method, theoretical supports, and convincing experiments.  One minor issue:  Authors mentioned that the model is related to a unified graphical model (line 55) in the introduction, which,however, is never mentioned in the main part. 