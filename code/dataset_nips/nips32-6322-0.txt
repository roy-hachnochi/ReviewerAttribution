While mostly I was able to understand the contributions, and comparison with the related work is reasonably well-written, I think that the organization and the quality of writing could be significantly improved, as summarized below.  a. The main statistical result, Theorem 2, is stated in a very concise manner in the main text. For example, for me it is unclear how $\alpha$ in Assumption 1 influences the result (I guess the ``constant'' C actually depends on it, as well as on some other parameters).  b. The structure of the paper could be significantly improved. In particular, discussion of the results and motivation for the estimator are somewhat scattered throughout the text, appearing before the estimator is introduced (see, in particular, lines 29-30, 52-55).  c. There are numerous typos, see, e.g., lines 6, 42, display under line 45 (missing subscript of $\inf$), display (4), 92, 101, 177 (missed $\nabla$), 179 and mild stylistic error (``touched'' in line 94, ``order $O(\cdot)$'' and ``at most $O(\cdot)$'' throughout, etc.)  Regarding the significance of the contributions and mathematical quality of the paper, I see the following issues.   a. First of all, Assumption 1 (Weibull-type tails of the design vector) is relatively weak, and the distrubution robustness of the novel estimator is quite limited. It would be interesting (and more useful in practice) to consider finite moment assumption on the design. I expect that using Huber-type M-estimators, or median-of-means, one can obtain statistically optimal rate $O(-2/(d+4))$ in any dimension (see lines 111-113), perhaps even without explicit  Wasserstein regularization, and under finite-moment assumption. This would be in line with the recent parametric results (see, e.g., S. Minsker. Geometric median and robust estimation in Banach spaces), as well as with the empirical results obtained in Sec. 3. Algorithmically, the Huber-loss criterion would result in a quadratic program rather than a linear one.  b. While the authors claim that their estimator does not depend on the a priori bound on the size of the gradient of the target function (see, e.g., lines 79-80), such dependence indirectly appears in the constraints of their optimization problem. Also, it is not entirely clear why they impose logarithmic scaling of the gradient.  On the positive side, I would like to emphasize the technical quality of the paper, in particular, the proof of Theorem 3 which features a somewhat non-standard chaining argument. 