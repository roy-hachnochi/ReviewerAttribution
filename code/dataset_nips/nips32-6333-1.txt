**** I thank the authors for the response. My concerns have been partly addressed and thus I will increase my score. However, the submission would benefit from a round of clean-up: clearly state how each approximation step works and how well this works, the relationship to existing methods, and add some existing benchmarks (if possible) as this is key for community adoption/acceptance.   **** Originality: The formulation of the sample selection as a feasible region selection seems sensible. The proposed IQP and greedy algorithms seem sound. However, it is unclear how well these actually work theoretically in high dimensional space and when the buffer size is large. The interpretation of the proposed surrogate function as maximising the diversity of the samples in the replay buffer is interesting but begs the question that there is some similarity between the proposed methods and existing coreset selection algorithms, for example: the K-center algorithm in "Teofilo F. Gonzalez. Clustering to minimize the maximum intercluster distance", or more recent coresets algorithms in "Bachem et al. Practical coreset constructions for machine learning".  Quality: It is challenging to judge whether the proposed method actually performs well in a more realistic continual learning setting, due to the difference between the experiments considers and existing benchmarks. The number of random runs considered is also quite small and that the result tables do not include error bars (it would be better to convert these tables into figures, as it is much easier in general to understand the real difference between methods -- there are more than just one single bold number). It is not clear how well the empirical surrogate work in high dimensions, or that how accurate the proposed greedy strategy is. It would also be interesting to have a more in-depth discussion/comparison to existing methods such as coverage maximisation as briefly mentioned on line 72. The paper seems to criticize methods that combine episodic memory/experience replay with parameter based regularisation (in the intro) -- but isn't the final algorithm considered in this paper a form of such algorithm? [the line is pretty blurred, but the buffer can be used for objective/gradient regularisation or replay as discussed in 3.6].  In general, I also feel there is not enough high level picture on how the algorithms are derived and to glue different subsections together, which makes it hard to read. The claim in the conclusion "efficient and constantly outperforming other selection strategies" seems very strong given the mixed performance of both IQP and greedy in many tasks considered.  Clarify: The writing is clear, in general. However, there are presentation styles in the experiments that make things quite hard to read to me. For example, the tables are not in order, the subheadings in 4 and 4.4 are hard to read/look strange. In figure 2, what is "200D log scale". Line 129: "this exact in 2D with figure 3"?.  