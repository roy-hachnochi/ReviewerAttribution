The paper presents a successful audio attack on a commercial grade Automatic Speech Recognition system - Alexa. To my best knowledge it is the first time it was successfully performed, and so claim the authors.  What is worth emphasizing is that the attack is performed fully in the real world. An actual piece of music is recorded and played using actual speakers. It interferes with the word "Alexa" spoken by a human to a physical Alexa device. The device is placed in a reasonable distance from the speaker and the distracting device in a physical room. The authors provided an actual video recording of the experiment taking place, which I find very valuable and working very much in favor of the acceptance of the paper for NeurIPS 2019. The authors claim the attack was a black box attack, but they relied heavily on the works of Panchapagesan, Gao and others to work out the adversarial signal, leveraging the work of those on "reverse engineering" Alexa's algorithm. The authors themselves admit, the gradients of a real Alexa can be expected to be similar to those of models of Panchapagesan and Gao, so I would it call it a "gray box" attack. What I find most valuable about the paper is: 1) It works. Plain and simple - the adversarial music played by the authors in the real life setting makes Alexa not wake up to "Alexa" command spoken clearly and audibly. 2) Video is provided, and it demonstrates that a physical meter was used to measure the levels of audio signal and the voice of the speaker, contributing to the credibility of the result. The task of building real-life attack on Alexa was nontrivial, and I like the approach presented. Instead of reinventing the wheel the authors cleverly leveraged the existing results to come up with an efficient pipeline that lead to the desired outcome.  I find the discussion provided by the authors not entirely convincing. The adversarial signal does not sound that musical to me (and I happen to be a progressive-metal guitar player). This is subjective, of course, but I do not think that many people would be deliberately listening to that type of sounds for entertainment. It was generated from a synthesized guitar track (why not a real guitar?), yet it sounds more like surrealistic steel drums/handpan to me, so the adversarial perturbation was very significant. The transients are really boosted here. Also, the perturbing signal is quite loud. mp3-s are mentioned, and indeed, lossy compression is very relevant here. The whole goal of the lossy compression is to leverage psychoacoustic effects and "hide" the compromises from the listener. It would be really interesting, if the adversarial signal could be made sound more pleasing to human ears using similar techniques. Maybe some mp3-inspired constraints on Projected Gradient Descent? That could be a fascinating theoretical research topic. Overall however I find the experiment very valuable and I am recommending the paper for publication at NeurIPS 2019.