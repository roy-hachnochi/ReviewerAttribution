Thanks for the author feedback. I am happy that the gap in regret bound is closed. However, it seems like the issue of parameter-free algorithms are not addressed. References [12,13] uses the SW-UCB as sub-routine to derive parameter-free bandit algorithms, it is extremely interesting to see what would happen if D-LinUCB is employed in such manner.  -----------------------------------------------Original Comments---------------------------------- The paper provides an intuitive analysis for the D-LinUCB algorithm, which can attain a dynamic regret bound of order O(dB_T^{1/3}T^{2/3}).  It also delivers solid experimental results on the proposed algorithm. The paper is also well written in general.  But some questions remain:  1. It seems like the current algorithm is only optimal w.r.t. B_T and T, but not d, the problem dimension. It is proved in [5] and [12] that the lower bounds for K-armed and linear settings are O(K^{1/3}B_T^{1/3}T^{2/3}) and O(d^{2/3}B_T^{1/3}T^{2/3}), respectively. So it is worth checking the source of this gap.  2. It is shown in [12] that one could build a parameter-free algorithm for non-stationary linear bandit setting on top of the SW-LinUCB. It is thus expected that the D-LinUCB algorithm could also be enhanced accordingly. Is there any specific reason that hinders the flow? If not, what would be the parameter-free dynamic regret based on D-LinUCB?  3. It seems like the discounted linear regression estimator is not entirely new. In  [1] B. Keskin and A. Zeevi. Chasing demand: Learning and Earning in a Changing Environment. In Mathematics of Operations Research, 42(2), 277â€“307, 2016.  Similar type of estimator is analyzed for the 2-dimensional dynamic pricing setting. It is thus worth doing a thorough literature search to make sure all prior related works are properly credited.  4. At the end of paragraph 2 of Section 1.2, the dynamic regret bound is O(d^{2/3}B_T^{1/3}T^{2/3}). 