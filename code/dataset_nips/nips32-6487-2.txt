[Post-response comment: The response addressed most of my comments. In particular, the gap in the analysis is due to my mis-reading the formula, and the response convinced me. However, the paper overall looks incremental, so it is a paper nice to have, but its acceptance seems to be depending on the quality of other papers.]          The paper studies the bandit combinatorial optimization problem and improve the lower bound of the problem from $\Omega(\sqrt{dk^3T/log T})$ in the prior work [8] to $\Omega(\sqrt{dk^3T})$, removing a factor of $1/\sqrt{\log T}$. This makes the regret dependency on T and k, d tight up to a logarithmic factor. The analysis is built upon prior work [2,8], with the major innovation being a design of new distribution of loss vectors (given in Eq.(8)) that leads to a better lower bound.         The design of distribution of the loss vectors looks nontrivial to me, and there are some involved technical analysis to make it work. However, there seems to be a gap in the analysis: In the derivation sequence between line 248 and line 249, I do not understand the last equality (after the inequality). It does not look to be true to me, since it is true only when the first time of the LHS of the equation, (P'(i)-P(i))/P(i) is set to zero, but this is not the case. With this gap, I am not sure how the rest derivation should proceed, and thus I am left with some doubt on the correctness of the analysis, although I feel that it should be amendable. I would be happy to raise my score if the authors could clarify this issue and fill this gap in the analysis.         Beside this gap, I feel that the authors in general did a good job in explaining the problem, and in explaining the inuition and the idea of the analysis. The results look nice, in tighting up a regret bound, and in proving a potential useful distribution of loss vectors for future analysis. Therefore, I feel that the paper is worth to be published.          