The bound is a bit harder to deal with because it is formulated as an oracle inequality, and this introduces additional complexity in terms of tuning (quantization and union bound). The paper also includes some empirical evaluation, which I didn't find particularly strong. An interesting part here would be a synthetic evaluation, however it is somewhat "fixed", in a sense that it does not vary relevant parameters of the experiment to show sensitivity of the variance proxy (and it's merits against another empirical Bernstein type of bounds). For instance, this can be done by varying the Bayes optimal predictor. Therefore it is impossible to judge whether the bound is empirically tighter compared to the prior work. Also, it is unclear how far we are from the ground truth --- Bayes error in the plots would definitely help.  Finally, comparison to another PAC-Bayesian literature that introduces algorithmic stability ideas is missing. For instance: Rivasplata, Omar, et al. "PAC-Bayes bounds for stable algorithms with instance-dependent priors." Advances in Neural Information Processing Systems. 2018.  == Post-rebuttal comments  I would like to thank authors for their detailed response. Promised improvements will definitely make the paper better.  There was also a number of issues raised during the discussion (see comments by the meta-reviewer).  I agree that at the moment, the paper perhaps has too many "moving parts" and their effect should be ideally studied separately (that is, the effect of the "half-samples", biasing, new Bernstein-style bound). The work would be much more solid if this would be the case. If the paper is not accepted at this time, this is the main point for improvement.  As for the conventions, I also agree with the meta-reviewer that "un-expected" indeed sounds a bit strange, and this could be changed regardless of acceptance.  