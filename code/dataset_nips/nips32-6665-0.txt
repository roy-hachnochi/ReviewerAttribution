Originality: The robustness verification methods presented in the paper is new and interesting. The authors provided a fair list of related work and compared the existing methods with their method in the experiment section.   Quality: The paper provides a complete presentation of three verification methods, 1) verifying the robustness of a single decision tree, 2) verifying the robustness of a tree ensemble using existing algorithms for finding k-cliques, and 3) a fast and approximate method for estimating a lower bound on the robustness. The theoretical claims and their proofs make sense to me. Overall the empirical evaluation is well designed and convincing. I only have two questions:  1. What are the ensemble sizes for the models trained on the datasets presented in Table 1 and 2? 2. How much does the parameters T and L effect the running time?  Clarity: This paper is well written and well organized. The authors did a good work on describing the objective of their method, and provided a fair amount of introduction on the background and related work. It would be desirable if the authors consider releasing the source code of their method, which is not provided with this submission (though pseudo code is provided in the appendix).   Significance: The robustness of the tree models are attracting increasing attention due to their popularity in the real-world applications. This paper presents an effective method for quantifying the robustness of tree ensembles. Empirical evaluation shows that the proposed method can provide evaluation in seconds per example, which is often order of magnitude faster than the existing methods. Overall I think this paper is valuable for the practitioner for evaluating the robustness of the tree ensembles.  ---  Update: The authors clarified my questions. I also found the answer to measuring the feature importance (a question from Reviewer #2) could be a very good addition to the text. Overall, I maintain my original assessment that this is a good submission.