--- Review update: The authors clarified the details of the ablation study in Figure 5, so now I am convinced that the proposed updates to the decoder architecture constitute a significant improvement. Therefore, I am increasing my score to 7. ---  The authors consider variational autoencoders with hidden variable $z$ in hyperbolic space. Intuitively, hyperbolic space is suitable for learning hierarchical representations. The exponential growth of surface with radius allows locating an exponential number of leaves of a tree on an equal distance.  In the concurrent work, Nagano2018 considered analogous models. The submission has two principal differences. First, it studies a different type of distribution on a hyperbolic plane as a building block of VAE. Second, it uses a particular “hyperbolic” layer in the decoder. The former leads to better results for one of the tasks in the experimental section, but the paper does not study the effect of the layer.  In general, the paper is well-written and technically sound. The claims are supported by thoroughly described experimental results. However, the use of hyperbolic spaces is motivated by two-dimensional illustration. How does the analogy between trees and hyperbolic spaces work beyond two-dimensional case?