*********After author response********** I thank the authors for their response. The response addressed the clarity issues I raised.   While I understand the high-level intuition that tail-averaging allows larger step sizes by reducing the variance, the authors could do a better job by making this intuition clear in the paper and supporting it by a quantitative relationship between tail-length and step-size. Therefore, I still keep my evaluation. **********************************************  Originality: While there are many previous analyses of least-squares learning in Hilbert spaces, the finding that tail-averaging overcomes saturation is novel and interesting, providing deeper understanding of the role of averaging in SGD.  Quality: I didn't go through the appendices, but the analysis and proofs in the main paper are well-supported and sound. The experiments support the theory well.  Clarity: The paper is clearly written in general and Section 3 provided a nice intuition, but I find several small spots that confused me (see the entries 2-6 in the "improvements" part).   Significance: The paper seems to suggest the use of tail-averaging instead of full-averaging in practice, but the reason for using averaging in the first place is to allow larger step sizes. The paper seems not clear about why tail-averaging allows larger step sizes than no averaging, making the result less significant.