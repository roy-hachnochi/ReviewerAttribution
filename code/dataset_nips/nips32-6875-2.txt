This paper proposes a new image data-augmentation approach that adds class-dependent noise to the features (instead of input images). The idea of augmenting in the feature space is new and intuitive. The surrogate loss looks reasonably sound. The paper is well written.  I have major concerns about the experimental results. In particular, the reported performance of the baselines looks much weaker than those in other papers. E.g., from [12] table.2, Wide-ResNet-28-10 on CIFAR10 has 3.9 top-1 error rate; while in the present paper, it's only 4.81 for the base model and 4.30 for the proposed approach, both of which are weaker than the base model in [12]. The same observation applies to other settings (different base models and datasets).  The empirical comparison is mainly with other "robust losses", such as focal loss, etc which can be seen as "implicit" data augmentation. How about other popular data augmentation approaches, such as those proposed in [6, 12, etc] which perform "explicit" data augmentation?  The paper claims the proposed approach brings little additional computational cost. Doesn't the computation of covariance matrices for each data instance (Line.6 in Alg.1) cause more computation? What's computation complexity, and how does it affect the run time empirically?  Line.185: lost --> loss   