1). First of all, I don't think it's a good way to represent each node with a dirichlet distribution leading to a positive node embedding. It's quite different from traditional real-valued embedding methods and I assume positive embedding representations will directly reduce semantic information compared to real-valued. So if there are any other positive embedding methods, please refer them to illustrate the relation to the proposed method.  2) . As mentioned in the article, the proposed SDREM propagating information through neighbors works in a similar spirit to the spatial graph convolutional network (GCN) in a frequentist setting. But as far as I am concerned, GCNs that have already been applied, will not only consider neighboring information in graphs, but also propagate each node embedding to a deeper representation through a fully connected network. Different from traditional GCNs, the proposed SDREM only summarizes the entire neighboring node embeddings with the learned weight, so please provide a conceptual comparison between the proposed SDREM and GCNs as described in [1].  3) . Similar in experimental parts, the authors give a comparison with GCN as described in [2], but why not compare with the improved version in [1]?   4) . There are some other related work [3], which has a similar structure with SDREM, please give a comparison on model aspect and it will be better if you can list quantitative comparisons in experiments.  5) More test details should be shown. The relationship between nodes is needed during the training process. I don't understand how to do the test.  6) The latent representation pi is interpretable as node iâ€™s community distribution, however, the number of communities K in each layer keeps the same in SDREM. Could the authors give the reasons?  7) why not model R_ij as a Bernoulli distribution ? This is more in line with the Bayesian model.   After all, the authors introduced a Bayesian framework by using deep latent representations for nodes to model relational data. And it's a quite novel model although there are many places to improve.  [1]. Kipf, Thomas, and Max Welling. Semi-Supervised Classification with Graph Convolutional Networks[J]. In ICLR, 2017.  [2]. Diederik P. Kingma, Danilo Jimenez Rezende, Shakir Mohamed, and Max Welling. Semisupervised learning with deep generative models. In ICLR, 2014.  [3]. Hu, Changwei, Piyush Rai, and Lawrence Carin. Deep Generative Models for Relational Data with Side Information. In ICML, 2017 