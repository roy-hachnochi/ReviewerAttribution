***** I thank the authors for the response. I have also read author reviews.  My concerns have been partly addressed and I will change my score to reflect this. My major remaining concern is the incremental nature of the work that should be discussed more in the text, i.e.: how each component of the algorithm/architecture has been used before. That said, there are values to combining existing works and showing that this works better. It would also be great if some claims that are not empirically supported are removed from the paper. *****  Originality:  As far as I know, the combination of several continual learning strategies proposed in this submission is new. However, it is not clear to me each of these strategies on its own is a novelty. For example, a special case of the objective function has been used by iCaRL (as noted on line 255). The modification in this paper is the phi term that balances the regularisation term and the prediction loss. I feel this is hardly a "novel controller". The use of core-set points or examplar replay is not new -- this is however not discussed in the main methodology. The paper also suggests that previous methods fail in some continual learning aspects, but note that these previous methods can also be combined like done in this paper.  Clarity: I think the paper is generally well written. There are however hyperparameters in the proposed approach that should be discussed.   Quality:   + The paper stated that the proposed random search is better than reinforcement learning or genetic algorithm based methods, but did not provide any experiments on this. Maybe in terms of parallelism and time efficiency, this makes sense. But running multiple training routines in parallel is also expensive.  + as stated above, it would be good to understand which component of the proposed method contributes to the performance gain, e.g. maybe coreset points are already sufficient for all the gain seen.  + network size and capacity: it would be good to have a comparison to previous approaches that dynamically add capacity to the network. The random path selection strategy here does this when M is large, so it would not be fair to criticise other methods (line 98). As seen in Figure 4, increasing the network size improves the performance significantly.  + I think the stability-plasticity dilemma is well-known in the continual learning community and is somewhat over-emphasized in this submission. Most existing continual learning algorithms are actually trying to balance these two aspects of learning and provide either an objective function or a network architecture or both that deal with such issue. The proposed method falls into this category.  + the regularisation term in eqn 5: Is this a valid KL divergence (due to the log)? How is the temperature t_e chosen?  Clarity: The paper is well written in general. The experiments seem extensive and thorough. Line 127: remarkably -> unsurprisingly?  Significance: The paper attempts to address an important and challenging problem. The proposed methodology seems interesting and the results show that this works well in the class-incremental learning setting in continual learning. However, it is a hybrid approach that involves many moving parts and it is unclear which one should be adopted by the community. Whilst the experiments show that this works, it would be good to know if this also works on non class-incremental learning settings that are typically tested by other continual learning work, and that all contributions claimed in the intro are supported by empirical evidence.