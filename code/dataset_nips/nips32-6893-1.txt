This paper studies minimax optimization problem. The target function g(x,y) is assumed to be smooth, i.e., it has Lipschitz gradient wrt (x,y). Two cases are considered: (i) g(x,.) is concave for any fixed x; g(., y) is strongly convex for any fixed y; (ii) g(x,.) is concave for any fixed x; g(.,y) is nonconvex for any fixed y. New algorithms with improved convergence rates are proposed for solving problems in these two classes.   In general, I think the results are important. My main concern is that the paper lacks numerical illustration of the performance of the proposed algorithms, and that the authors didn't give any practical examples that satisfy the assumptions of the models. If these can be done, the paper will be much stronger.   == after author's rebuttal ==  My main concerns are well addressed by the authors and I am willing to increase my score. 