Overview:  This paper proposes a Bayesian algorithm to aggregate the labels in a crowdsourced application.  The authors consider the standard Dawid-Skene one coin model, in which each worker j is associated with parameter p_j, which represents the probability of the worker correctly assigning a label.  In the Bayesian setting, the authors assume that the parameters p_j’s follow a Beta distribution.  Computing the exact posterior distribution is computationally difficult.  Therefore, the authors use variational approximation in which the posterior distribution is assumed to have a product form.    Even with the variational approximation, parameter inference is computationally difficult.  Therefore, the authors propose to perform a single coordinate descent step as opposed to an expensive coordinate descent step.  The authors derive bounds for error rates.  They also demonstrate the efficacy of their methods on both synthetic and real-world datasets.  Strengths of the paper:  The paper is tackling the classic problem of aggregating labels in a crowdsourced application.  The paper is focusing on speed.  The algorithms proposed are fast and simple to implement. Plus, they come with theoretical guarantees on the bounds for error rates. The fact that the theoretical bounds are close to empirical error rates is impressive.  Weaknesses:  The paper has the following main weaknesses:  1.  The paper starts with the objective of designing fast label aggregation algorithms for a streaming setting.  But it doesn’t spend any time motivating the applications in which such algorithms are needed.  All the datasets used in the empirical analysis are static datasets.  For the paper to be useful, the problem considered should be well motivated.   2. It appears that the output from the algorithm depends on the order in which the data are processed. This should be clarified.   3. The theoretical results are presented under the assumption that the predictions of FBI converge to the ground truth.  Why should this assumption be true?  It is not clear to me how this assumption is valid for finite R.  This needs to clarified/justified.  3. The takeaways from the empirical analysis are not fully clear.  It appears that the big advantage of the proposed methods is their speed. However, the experiments don’t seem to be explicitly making this point (the running times are reported in the appendix; perhaps they should be moved to the main body).  Plus, the paper is lacking the key EM benchmark.  Also, perhaps the authors should use a different dataset in which speed is most important to showcase the benefits of this approach.  Update after the author response:  I read the author rebuttal.  I suggest the authors to add the clarifications they detailed in the rebuttal to the final paper.  Update after the author response:  I read the author rebuttal.  I suggest the authors to add the clarifications they detailed in the rebuttal to the final paper.  Also, the motivating crowdsourcing application where speed is really important is not completely clear to me from the rebuttal.  I suggest the authors clarify this properly in the final paper.