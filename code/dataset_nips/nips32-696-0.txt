The paper proposes to use multiple meta classes, each of which which are defined to be partitions of the original classes, to create a classifier that is more robust to label noise. The idea is that, while some of the original labels may be incorrect, they are more likely to be correct in the new meta classes. Furthermore, given enough overlapping meta classes, it is possible to infer the original class by meta class membership. In practice, the authors use meta classes that are binary partitions of the original class space, which are constructed by clustering on subsets of features from a classifier trained on the original noisy labels. This is a nice idea, and experiments show that it works well.  Originality: the idea here is novel (as far as I know) and innovative, going beyond an incremental contribution. Related work is adequately discussed.   Clarity: overall, the paper is quite clear and provides a sufficient level of detail. Some minor language errors remain, but very readable for the most part.  Significance: interesting idea, advances the state of the art, likely to be interesting for others working in the area.