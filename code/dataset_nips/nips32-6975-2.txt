The authors consider the problem of clustering a set of lines in R^d. The goal is to minimize the k-means objective: given n lines L in R^d find the best set of k points c1,...,ck in R^d so as to minimize sum_{l in L} min_{ci} dist(ci, l)^2.  This a clean, nicely motivated problem. The authors provide a coreset construction (namely a small size summary of the input so that any alpha-approximation for the summary yields an alpha(1+epsilon)-approximation for the entire input). This implies the first (1+epsilon)-approximation for the problem with running time nd exp(poly(k)) together with a streaming algorithm with similar running time and memory size 2^{poly(k)} log n. En route to the result the authors provide a bicriteria approximation algorithms: namely a solution that contains O(k (log n dk log k)) centers and whose cost is at most 4 times the cost of the optimal solution with k centers. I think the paper introduces a couple of new techniques and new ideas and make a significant progress on the problem. The ideas behind the approaches (sampling to estimate the location of the center, sensitivity sampling, bounding the VC dimension, merge and reduce, etc.) are not completely new but proving that they indeed work for the case of line clustering is a challenge and a good result.  The experiments are ok and seems to indicate that the algorithm is competitive (see comments below though).  I think the results are interesting, I recommend acceptance.   Comments: - You are saying that you have a deterministic algorithm for the coreset construction, yet the theorem says the opposite. - There are various typos here and there, please check carefully. - Why using EM + kmeans++ and not simply k-means++? - How did you compute the optimal solution? - It seems to me that for getting an offline (1+epsilon)-approximation, one may be able to combined your lemmas on sampling (say Lemma 6.3) together with [A Simple D^2 -Sampling Based PTAS for k-Means and Other Clustering Problems] by Ragesh Jaiswal, Amit Kumar, Sandeep Sen so as to obtain an improved running time of nd 2^k. 