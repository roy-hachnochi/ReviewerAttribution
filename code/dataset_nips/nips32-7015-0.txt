- Authors explained a gradient-based attack which can be used as a standard task to test the robustness of machine learning models.  - The paper is well-written and problem statement is clear and concise.  - There are major algorithmic and empirical contributions in this paper.  - At each step, they solve a constrained quadratic program through an iterative gradient-based algorithm in order to find the most promising optimization step. After each step, the adversarial example Lp distance from the clean input example get smaller.  - Authors approach, compare to previous work, only needs one hyper-parameter to tune (trust region) and as long as the boundary between the adversarial and the non-adversarial region can be described by a differentiable equality constraint, it is straightforward to extend it to other norms. 