The proposed problems by the authors is interesting. Essentially one is looking for dimensions according to which the target variable becomes monotonic.  The writing of the paper requires attention, and it suffers from the conference format. Most of the algoritmic side of the paper is pushed in the appendix, and the explanation of the algorithm is barebone: - it is not clear whether the problem is NP-hard or is it tractable. - Algorithm 1 requires integer programming, do you do this in practice, or is the algorithm just the theoretical construct? - Ignoring the relaxation of v_k, the authors do not prove that Algorithm 2/3+4 actually solves the same thing as Algorithm 1.   Specifically, the objective in Eq. 10 is not properly explained, and how it is linked to Eq. 5. - Line 343 in Appendix seems incorrect: The new objective should be sum (1 -    F_i)^2 + sum F_i^2 which is not a linear objective, note that F_i may be real   numbers even if target is binary.  This seems to be problematic for Lemma 1.    The experiments should be improved. Additional benchmark dataserts would add more credibility. Also, the chosen baselines should perform relatively badly for the chosen data: 1. Based on Figure 1, the decision boundary is not linear which puts SVM at disadvantage. 2. barebone k-nn with (probably) high-dimensional data suffers form curse of dimension. A better comparison would be a decision tree and k-nn with feature selection/dimension reduction.