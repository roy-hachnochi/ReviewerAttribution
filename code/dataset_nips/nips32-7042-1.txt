originality: the idea is very interesting, even though with heavy assumptions. Authors did explain the impact of each assumption, but it is still a very limited setting.   quality:  1. the technical results are sound, but authors should state full assumptions for each theoretical results (such as Proposition 1).  2. One can view the work is closely related to some hierarchical tree/latent tree learning algorithm. It seems that the major different the latent variables can have arbitrary relationships. Author should explain in more details that how does the proposed algorithm compare with many latent tree algorithms? In Experiments, authors should also compare with these algorithms.  3. the consistency result of the algorithm is missing: is it sound or complete? 4. Does the method find an equivalent class of the graphs or the true graph?  5. what is a reason to choose noise term so small, with fifth power? It seems the algorithm could suffer from high noise?  Clarity: the paper is well written, although one would wished that the authors should rely less on the supplementary materials and provide more intuition/explanation on proofs of the theorems. The examples are good.   Significance: the idea is worth to pursue further and will have potential big impact.    ===== I have read the authors' response. It would be interesting to see how the latent tree methods perform on the real dataset, since Figure 5 is basically a latent tree. 