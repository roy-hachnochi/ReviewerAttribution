Positives  The paper is well-written and includes a through literature review.  The following paper is also very relevant to the submission: Shrivastava, Ashish, et al. "Learning from simulated and unsupervised images through adversarial training." Proceedings of the IEEE conference on computer vision and pattern recognition. 2017.  Novelty of the method over [44] is not major. Still, I believe no one has shown that computing flow on simulated data and using it for training improves over RGB only (although the improvement is quite marginal).   Simulation pipeline proposed in the paper seems to be quite useful. It improves over the previous approaches that used simpler compositing operations.  Negatives  My main concern is about the generality of the method: 1. It only applies to video data which is a major limitation.  2. Using only simulated data (flow only), accuracy is still very far from the state of the art. The method requires additional information from RGB images in the form of 2D keypoints to improve the result (In fact 2D keypoints only has almost the same performance). This network is trained using supervised data. This is not coherent with the claim of the paper that the method completely relies on simulated human data.  My second concern is whether the method is a viable solution for sim2real problem. Flow only is only marginally better than RGB only (105.6 vs. 100.1) which introduces a doubt about motion computed using simulated data being a viable solution for sim2real problem.  Overall, the paper has good points but I believe the negatives mentioned above weighs more. I encourage the authors to address the concerns above.  ------ Revision after rebuttal: Going over my review, together with other reviews and rebuttal, I think the paper deserves a marginally above average rating which I will revise.  Nevertheless, I stand by my original review points, particularly about the generality of the method: 1. To clarify, one of the limitations I stated is requiring the motion of the humans and/or camera, not only application to video. Compared to many of the methods that the paper is compared against (e.g. in Table 1, Martinez et al., DANN or HMR), this is a limitation. There is no question about working on video data being an important problem. 2. I agree that the paper is not trying to hide it is using real data supervision for keypoint detection. However, this fact still weakens the main claim of the paper which is “… motion can be a simple way to bridge a sim2real gap”.  I appreciate that the paper presents an optimized pipeline which combines real and synthetic data to obtain a good 3D human pose estimation result, however in my opinion “… motion can be a simple way to bridge a sim2real gap” is a strong claim that is not strongly supported by the experiments presented in the paper. In addition, as also noted in the rebuttal, I would recommend the paper rephrases some of the claims about simulated data such as in abstract: “…  on par with state-of-the-art methods trained on real 3D sequences despite training only on synthetic humans from the standard SURREAL dataset”.  