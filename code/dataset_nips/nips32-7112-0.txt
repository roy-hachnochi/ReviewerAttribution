In this paper the authors present a kernel based frame work using stein estimators to fit normalized densities. This framework is quite general and covers several existing estimators. They also prove nice theorems on the finite/asymptotic behavior of the estimator as well as how it approximate other estimators. Finally they present evidence that this framework estimates better than the standard score matching on some nastier toy datasets, heavy tailed and nonsmooth.  Overall the contribution of the paper seems very much worth publishing although this topic is very much outside my area of expertise, so I cannot be sure how it fits into existing literature, or how novel it is.  My main issue with the paper is that it is very technically dense, perhaps unnecessarily so. As someone outside the field I felt like the mathematical exposition could be significantly decompressed for the introduction of their framework (Section 2.0) with some additional intuition and leading provided for the reader. To compensate one could omit, shorten, make more vague, some of the content in Sections 2.1-3.2. For example Theorem 1 would definitely benefit from hiding more of the details under the hood, i.e. in the supplement. It would be better if the paper was more readable and made it clear what additional details can be found in the supplemental section for the very interested reader. If this were improved I could see giving the paper a 7 or 8.