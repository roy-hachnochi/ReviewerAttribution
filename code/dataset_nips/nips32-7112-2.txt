Update: Thanks for your feedback and additional experimental results. I still suggest accept.  ============  As far as I know, it seems original that the work focuses on leveraging a flexible metric (e.g. information geometry) into probability discrepancies. I did not go through the proof so I do not know the validity and the difficulty in adapting existing results (e.g. [21]), but the results seem reasonable. The provided results also cover a wide range of considerations on the proposed discrepancies.   Issues: * On generalizing the metric in discrepancies, the authors are recommended to discuss the relation between DKSD and the Riemannian kernel Stein discrepancy proposed in Liu & Zhu (2018; arXiv:1711.11216). * In Eq. (2), what does it mean that m is a diffusion matrix? Does it have to be symmetric positive definite? Referring to the operator in Theorem 2 of [21], if m is taken as the sum of the covariance and stream coefficients, it could be any matrix. Does the considered operator have this generality? * For DKSD and DSM to be discrepancies constructed by Stein's method, the corresponding operators need to satisfy Stein's identity. I noted that the identity for DKSD is provided in Line 120, but did not find the one for DSM. * Why the matrix-valued kernel considered in DKSD has to be in the two forms? Is it possible to extend the results to a general kernel? The corresponding vector-valued RKHS theory is known, e.g., [C. Micchelli & M. Pontil, 2003, On Learning Vector-Valued Functions]. * For the experiments, is it possible to make the experiments more related to the theoretical analysis? For example, analyse the failure of SM in estimating symmetric Bessel distributions, or compare DSM with SM to demonstrate the benefit.   The presentation of the paper is basically clear, and I appreciate the notation system. Here are some additional concerns. * In Line 76, "Stein's identity" is referred before its definition in Line 80. * Unexplained abbreviation "SDE" in Line 90. * The authors could use another symbol for the dimensionality of \theta instead of m. * Possible typos:  Line 177: "probality" -> "probability"  Line 214: no subject in the sentence  Line 283: "his" -> "This"