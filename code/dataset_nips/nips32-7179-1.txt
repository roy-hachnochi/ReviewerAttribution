In this paper, a primal-dual online learning framework is proposed to deal with the online within online meta-learning problem. This setting is important in practice since it can be used to model the life-long learning scenario naturally. Comparing to recent advances on this topic [1][2][3], this paper proposes an alternative primal-dual view, providing a more general algorithmic framework and more refined theoretical results. The contribution is somewhat significant to this point for providing novel tools for future researches.  On the other hand, as the primal-dual approach is classical for online learning, I expected deeper insights for thinking meta-learning under this perspective instead of a direct application of the theoretical tools. The discussion towards this direction is limited unfortunately. It seems that the proposed approach is more a theoretically guaranteed solver for classical objectives instead of a novel view of the original problem. While overall, I still think the paper proposes a good alternative to previous works thus I lean towards acceptance.  Further comments: In the current version, the discussions of the related work are put in the supplementary materials. I strongly suggest putting them back in the main paper, especially for the overview of the other works under the online-within-online scenario for better comparison.   [1] G. Denevi, C. Ciliberto, R. Grazzi, and M. Pontil, Learning-to-learn stochastic gradient descent with biased regularization. ICML 2019. [2] C. Finn, A. Rajeswaran, S. Kakade, and S. Levine. Online meta-learning. ICML 2019. [3] M. Khodak, M.-F. Balcan, and A. Talwalkar. Provable guarantees for gradient-based meta-learning. ICML 2019.  ------ after rebuttal  The author response does not change my evaluations very much. The main contribution lies in proposing the theoretical analysis of the online-within-online meta-learning setting from the online primal-dual framework, which is a good alternative comparing to related work. 