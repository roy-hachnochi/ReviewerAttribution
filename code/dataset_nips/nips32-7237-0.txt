The writing up to page 4 is very wordy and I believe could be more succinctly written. First of all, I am not entirely sure why the problem of sampling from sub collection of sets need to be repeated twice in the paper.  In addition, the paper should clearly state that the new sampling strategy can be embedded in the existing LSH method to achieve unbiased query results.  Nevertheless, the algorithm does seem interesting - the key bottleneck of  estimating the degree of a particular point (basically the number of distinct  buckets that contain it) is identified and there are interesting solutions based on existing work in this paper.  Section 3 - line 161 states the union of $G$ but $G$ is a set of sets. I can see that the part after the equal sign does make sense. I see that there are similar notational mistakes throughout the paper.  Section 4 - line 226: what is $x$ and its relationship to $p$?  Section 5 - Please clarify the following experiment setting: "Our data set contains the first 10000 points in the MNIST training data set..." Does choosing the first X points in the dataset help reproducibility? I am not sure why randomization was not used. Also should comment the distribution of the classes in the dataset that was used in the experiment. - Comparison is largely in terms of quality of the query results. Could the authors comment on the querying time and time-accuracy tradeoff?  Originality - The sampling framework seems novel. Quality - The paper overall has average quality and somewhat incomplete experimental results. Clarity - The paper could be re-written to deliver the message more succinctly because some definitions are repeated throughout the paper. Significance - The problem/framework the paper discusses is of practical importance but because the paper is more empirically oriented (although the authors may disagree and do provide proof sketches in the appendix), it should provide more compete experimental results.