## The continuous Bernoulli: fixing a pervasive error in variational autoencoders.  ### Summary  The authors propose a new single-parameter distribution with support on the open interval (0,1). This distribution is the result of properly normalizing a Bernoulli distribution when we allow the random variable to take values in the continuous interval (0,1) rather than just in the discrete set {0,1}. This so called "Continuous Bernoulli" distribution belongs to the exponential family and have several nice properties like reducing to the classic Bernoulli distribution in the limit. In the experiments, the authors apply it as the likelihood of a VAE to model image datasets where the intensity of the pixels are normalized between 0 and 1. Previous work in the literature have model this incorrectly by using a Bernoulli likelihood, and so the authors show that using a proper distribution (the propose continuous version of the Bernoulli distribution) improves the performance.  ### Details  The motivation of the paper is simple and the exposition is clear. In addition, it is really well-written which raises the quality of the paper. Some sentence however should be slightly tone down (just a minor).  The main idea of the paper is to propose a new distribution which is simply a continuous version of the Bernoulli distribution. This is done by assuming the same functional form of the Bernoulli distribution and then computing the right normalization constant in closed from. Surprisingly, and to the extend of my knowledge, this distribution has not been previously proposed in the literature.  The authors provide a through analysis of this new distribution computing the pdf as well as the first moment, showing that it belongs to the exponential family, that it is amenable to the re-parameterization trick and that in the limit it converges to the classical Bernoulli distribution (among other properties).  One derivation that it is missing and I thing it is pretty important in better understanding the properties of a distribution is the moment generating function that has closed form (see at the bottom the derivation).  In the experiments the authors, the authors apply it as the likelihood in the VAE and use it to model an image dataset where the support is bounded. This was previously done by incorrectly using the Bernoulli distribution ignoring the fact that the observations were not binary but rather continuous values between 0 and 1 after renormalizing the pixel intensities to fall in this interval.  They show that the propose continuous Bernoulli distribution outperforms the VAE with Bernoulli, Gaussian and Beta likelihoods. Maybe, the weakest point of the paper is that the fail to further analyses why the Beta shows a worse performance. The Beta distribution is a more flexible object that the proposed distribution in that it has two parameters and that can model multi-modal distributions. Given that, I would expect to see a trade off between the two distributions (not one outperforming the other in all situations). The Beta distribution have the advantage of being more flexible, but at the same time it would be more prone to over fitting due to a higher number of parameter. Additionally, the beta distribution is tricky to optimize due to the gamma function in the normalization constants, and maybe the proposed distribution has a better behavior. This analysis is missing in the paper.  Despite this, the paper is well-motivated, they propose a simple approach to a prevalent problem in the previous literature and has a significant novelty by introducing a distribution that despite its simplicity, and to the extend of my knowledge, has not been proposed before.  ## Moment generating function  Just applying integration by parts you can get that the MGF = \frac{2 \tanh^{-1}(1-2\lambda)}{2 \tanh^{-1}(1-2\lambda) - t} \frac{\lambda \exp(t) + \lambda -1}{2\lambda-1} (for \lambda \neq 0.5). 