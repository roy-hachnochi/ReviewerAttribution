The paper deepens our understanding of the relationship between differential privacy and theory of stochastic processes. The main reason for exploring the connection is refined analyses (also known as "amplification theorems") of iterated mechanisms, which is of great relevance to the ML community. If early differentially private mechanisms targeted one-shot queries, learning problems call for iterative versions of DP mechanisms.  The paper builds upon a recent work by Feldman et al. on privacy amplification-by-iteration where the main technical tool was a statement between closeness of distributions over Banach spaces. The submission generalizes this result using the measure-theoretic language of Markov operators and their properties. While, by itself, this new approach does not not change the underlying mechanism, it does lead to stronger guarantees in the case of strong convexity, and paves the way for more interaction between these areas of research.