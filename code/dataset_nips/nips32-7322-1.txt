This paper introduces a methodology to build and train the neural network that acts like an external memory module through meta-learning. The central idea of building such model is that the memory module has to be updated fast so that it can remembers from writing the contents even for a one shot, therefore they use meta-learning strategy.   Q1.Is there any intuition that proposed model has better performance than NTM, which had also trained from episodic training? I wonder if it's better because the model is applied on quite recent meta-training (MAML), or its advanced network modeling.   Q2. The experiments and their results are not intuitive to understand. I expect to have the algorithmic tasks conducted in NTM, but they give novel tasks they made even without comparing with previous works. Also, some pictures are too small to read. Are there any comparison for memory-based networks?