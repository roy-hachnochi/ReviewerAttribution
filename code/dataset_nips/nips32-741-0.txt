EDIT: Thanks to the authors for addressing my questions in the rebuttal. I have read the other reviews and will still recommend acceptance. I want to emphasize that addressing the clarity concerns of all three reviewers will improve the impact of an already strong result.  Quality: The paper is of high quality and the proofs seem mostly correct. A few comments:  - I would suggest that the authors consider putting Figure 1 into the main body of the paper. It will help give readers a sense of the gains that are practically possible.  - Eq (14) of the Appendix, should this be eta instead of eta_t? - Eq (22) of the Appendix, x_i should be capitalized, I believe. - Line 108, "f_t's are iid", I'm not sure what this means since f_t are not random variables.  Originality: The algorithm itself is primarily an application of SAGA as an inner loop, but the analysis is original and the observation that the constants can be balanced in an appropriate way is original.  Significance: As mentioned in the contributions section, this contribution is significant for two reasons. (1) the algorithm may be used in practice, assuming the hyperparameters can be reasonably tuned, and (2) the assumptions and proofs are of independent interest.  - My only concern with the current results is that the only example given is Bayesian logistic regression, for which a specialized method already exists. It would be nice if the authors could comment on other possible scenarios.  Clarity: The draft could use some work with the presentation. While the writing and notation are generally clear, I think the authors could make a few changes that might make the paper easier to read for a broader audience.  - A great deal of space is taken to discuss how this algorithm and the results compare to the complexity of other results in the literature. Obviously this is a central contribution and should be given good real estate, but I think the authors could condense this discussion to a single section, instead of distributing it across multiple sections. This would free up space to discuss the intuitive content of the results and algorithms.  - I would spend a bit more time in the introduction explaining in more intuitive terms the information that this algorithm exploits and why that information is sufficient to recover these results. This should give readers a clearer sense how the assumptions prevent non-degeneracy without strong convexity.