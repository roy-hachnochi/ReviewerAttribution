 <Summary> Given an image set of which images contain a single target category object at near the center, the submission presents a neural network method that can discover a fixed number of landmarks in an unsupervised way. The basic idea of this work is to leverage the learned knowledge of the source network pre-trained with a source object category to discover the landmarks of a target object category.   To this end, the proposed landmark estimation network is designed in a simplified way of Progressive networks [29]. All the activations obtained from each layer of the pre-trained fixed source network are transformed by respective 1x1 convolution layers (i.e., linear transform in Eq. (1)). The last convolution layer is modified to output the pre-defined number of the landmark for the target object. Then, all the linear transforms are trained by backpropagation with the unsupervised task loss, landmark conditional image generation [13], on the target category data. The number of parameters is significantly lower than training the whole network from scratch, because only the linear feature transforms are trained while fixing the source network.  The proposed model is largely based on [13], so the authors reproduced [13] and used it as the baselines, called Scratch and Fine-tuning. The authors showed the proposed method outperforms the fine-tuning baseline. The authors' hypothesis is due to fewer degrees of freedom by the small number of parameters to optimize than [13].  The paper is written clearly, and the experiment shows the effectiveness of the proposed method. However, the authors fail to provide understandings of the proposed algorithm's behavior and failure cases that would contribute a lot to get informative takes. Due to this missing piece, it is a bit vogue where the performance gain actually comes from and how stable the algorithm is.   <Missing discussion> - Strong assumption: the proposed approach is based on a strong assumption that useful intermediate activations for the target object can be linearly spanned from other categories activation; in other words, for a target object, there exist effective convolution filters constructed by the linear combination of the specifically trained filters for a source object. The authors overlooked mentioning this point.  - Category dependency: Also, there could be some other source-target cases that may fail to represent each other by the linear combination. However, the authors failed to demonstrate the effects according to the categories.  Currently, the source network is trained for the human pose (16 keypoints), and the target network is adapted to different object categories. Most of the evaluations are done on the "human=>face" case. The cases of "human=>{cat head, shoes}" are only demonstrated by consistency measure in Table 3 and Figure 3, which does not truly assess the landmark accuracy (will be discussed further in the below comment).  These only show very limited generalization across the category.   <Evaluation> - Taxonomy; as mentioned above, there must be effective relationships between different category pairs. Showing varying performance and knowledge transferability would be critical evaluation in this submission due to its technical contribution point on adaptation.  - The proposed method requires to have a pre-trained landmark detector for a different object category a priori, which is pre-trained in a fully supervised way. Thus, the system would largely depend on the quality of the core network. While this is the case, the authors do not provide any study to understand dependency. The comments in <Improvement> sections would be relevant to get better understand the proposed method. Please see <Improvement>.   - L250-251 and Table 2; I found that the authors' interpretation of these lines is good. But if the 3D rotation of the landmark in the LS3D dataset is the factor that cannot be handled by all the methods, then the LS3D errors reported in Table 2 is not reliable to be interpreted because large dominant outliers will dominantly contribute to errors. Thus, what we can parse from the reported error is that the models just do not work. So, in this case, it would be more interpretable to measure the errors only for visible landmarks, rather than measuring overall landmarks.       - Landmark consistency against random similarity transform is interesting, but not strong evidence of outperforming. For example, in an extreme case, if the network always produces average landmarks regardless of any input, then it will have the perfect consistency. Thus, this metric alone cannot be used to argue accurate landmark detection.      