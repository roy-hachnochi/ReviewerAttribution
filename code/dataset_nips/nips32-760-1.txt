 This paper formulates a new problem and proposed a reasonable algorithm. However, I am not totally convinced the current jointly optimization is significantly better a two steps approach of (1) first do adversarial learning and then (2) compress the model by pruning and compression.  As shown in Figure 2, the performance of the proposed method is almost the same as the two step approach (adversarial learning + pruning).  Moreover, the current paper could be improved in the following aspects: - eq (3): what about the non-conversational layers?  - line 128-line 133:  it is not clear what "the nonuniform quantization" means, and how it leads to the equation between line 132 and line 133.  - eq (4): in this paper f^adv seems to be limited to PSD attack. I wish to see results of other adversarial learning.  - Table 1: all the networks here are relatively small, for which the compression seems not very important. Is it possible to provide experiments for large neural networks?