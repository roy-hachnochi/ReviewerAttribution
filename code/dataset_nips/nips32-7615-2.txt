The proposed method is somewhat interesting for data imputation. It seems to be a good choice if one wants to imputation missing data at random locations. This is also empirically validated in the experiments.   In addition to data imputation, the authors proposed several other motivations for their proposed method. However, I have several significant concerns   The claims in the introduction are questionable. For example, “unsupervised learning in general is an exponential amount of supervised learning problems” seem overly audacious, and needs justification. There are many similar unconvincing statements that should either be justified or downplayed. There is certainly much more to be desired from unsupervised learning, such as learning meaningful features that benefit downstream tasks, or data visualization. It is not clear how the proposed approach benefit these common accepted use cases of unsupervised learning.   I am not convinced by the arguments of the benefit of learning the conditional distribution. For example, why should the entropy have anything to do with our ability to model a distribution? (line 154) A standard Gaussian distribution can have higher (Shannon) entropy than the complex distribution over natural images, but it is strange to claim that the latter is easier to learn/model.   I'm not sure I get the significance of the theoretical analysis (section 4.2-4.3). For example, for section 4.2. Does this provide any additional insight compared with standard minimax distribution analysis of GANs? The notation is also sloppy (notation such as C_b is not even defined). The same holds true for section 4.3. It is not clear what all the probabilities are, are they conditional probabilities? Joint probabilities? The notation leaves a lot of room for guessing. In addition, since the objective (eq 1) is stanfard GAN and not f-GAN, it is not clear where the KL comes from. Therefore, I am not confident that these analysis are correct (but maybe it is because I didn't parse the notation correctly).  Experiments: The experiments are okay, the authors show that the proposed approach is able to impute missing data. The difference from GAIN is minor, but the proposed method performs slightly better. In fact, the contribution of a superior imputation method is the major argument I am judging this paper on (because of my previously mentioned concerns on the other claimed contributions), but it is only briefly explored with simple experiments showing small net improvement.   The experiments on semi-supervised learning is unsurprisingly un-par with other generic deep generative model based methods.   Writing: The non-technical part of the paper is reasonably well written and clear. However, the theory sections are harder to understand because of ambiguous/unclear notation.   Small points: Typo: line 80 a \in {0, 1}  ->  a \in {0, 1}^n   -------------- After rebuttal The authors provide additional experiments on imputation. Combining with the original experiments, I am fairly convinced that the proposed approach is good for data imputation.    I'm still not convinced that "learning good features" is a significant benefit of the proposed method. More experimental validation (downstream task performance and visualization) would be necessary to prove good feature learning performance. For example, in Table 1 of the rebuttal, the performance seem far from state-of-the-art methods.   Nonetheless I am happy to improve my score by 1 because of the convincing imputation results.