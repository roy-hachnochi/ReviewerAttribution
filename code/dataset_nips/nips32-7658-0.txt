     The authors propose a method to trade-off "computational costs" and "model fit" when learning a Sum-Product-Network (SPNs) represented as an Arithmetic Circuit. An SPN is a compact representation of a probabilistic model over discrete random variables with finite domain. The proposed method involves an SPN learner that is restricted to binary random variables. In practice, this requires to convert continuous variables into categoricals (e.g., using binning), and categoricals into binaries. While SPNs can handle missing data, they do are typically black-box models where the structure is learned.          Computational costs are defined in terms of costs per arithmetic operations, memory/caching costs, as well as costs for feature computation. In particular, the authors assume that the feature costs might be defined over groups of features, e.g., generated by a single sensor. The made choices to define costs are plausible and rather straightforward.          Model fit is measured in terms of identifying a distribution's mode, i.e., predictive performance of a maximum likelihood estimate. While the authors include datasets for density estimation in the experiments, they still focus on predicting one of the attributes rather than estimating the density of the whole data.          While the proposed approach can be applied to a large and important class of problems, the title and introduction slightly overstate its applicability. The method does not address a general probabilistic model, e.g., stated as a Markov network or a probabilistic program. The significance of the work is moderate.          The main contribution, besides defining hardware-related costs, is a heuristic to identify a set of SPNs at the Pareto frontier of costs vs. performance. The heuristic performs a backwards feature selection, where features are greedily removed such that the ratio of accuracy and costs is maximized. The removal is performed by pruning a previously trained SPN using an existing SPN learning algorithm.      While empirical experiments confirm the effectiveness of the proposed search heuristic, the method is similar to backward feature selection sequentially selecting features that least affect the performance-cost ratio. The overall scientific contribution to the field of Machine Learning is minor.          The pseudo code in Algorithm 1 is, in parts, incorrect: a_{ca,j}, acc_{ca,j}, cost_{ca,j} should be outside of the S-loop; \alpha_{select} etc. should be outside of the j-loop. Also using \notin for two sets, F_{ca,j} and F_S, is imprecise; this should be F_{ca,j} \cap F_S = \varnothing. Finally, \argmax_{F \notin F_{ca}} is ambiguous as there might be many F that are not element of F_{ca} (which is, strictly speaking, a list of sets). I assume, this should read j^* = \argmax_j CF(acc_{ca,j}, cost_{ca,j}), \alpha_select = \alpha_{ca,j^*}, and F_{rm} = \F_{ca,j^*}. Overall, I find the pseudo code not very helpful in its current form. Figure is slightly too small.    