1. What is the role of learning in the tasks being studied in this paper? The paper shows results on planning problems. If I understand correctly, these problems can be solved exactly if appropriate state estimators are trained (to check on the state of different objects, such as, if the cabbage is cooked or is raw). Thus, to me it is not clear as to what is the role of learning in solving these problems? If the problem could be solved exactly using appropriate classical planners, why should learning be used here at all? The paper argues in its text that symbols need to be hand-defined in classical approaches, but as far as I understand, they have also been largely hand-crafted in the proposed learned approach. It will really help if: a) the authors can provide intuition as to what they hope to learn in the different networks they are learning? b) the authors can provide qualitative and quantitative evidence that the networks are learning something non-trivial? b) provide an explicit experimental comparison to a completely classical planning algorithm to solve the problem at hand?  2. The current experiments in the paper are geared towards showing that learning inside a planner scaffolding is better than without. However, the experimental setup chosen is in some sense biased towards problems that can be solved within a planner scaffolding. There are very clear symbols that need to be manipulated in order to get to the right solution, etc. Learning based solutions may be more attractive in settings where symbols may be fuzzily defined, hard to define, or hard to exactly extract out from raw sensory inputs. It will be great if the authors tried the proposed technique in such experimental settings, such as where data comes from more realistic settings.