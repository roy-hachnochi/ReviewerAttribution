*** Update after the rebuttal *** I believe the authors have provided a strong rebuttal, including a table with new results. However, the composite likelihood approach (CL) is a substantial part of the paper and I'm very concerned about whether it helps at modelling dependencies at all. There is a single composite weight in Equation 1 in the main paper, which comes out of the ELL term in Equation 6 in the supplement, i.e. all the resolutions have the same weight. This weight is fixed (using the proposed estimate) before carrying out variational inference. This means that all the components in the ELL term are weighted equally, hence I do not understand the claim that this is a way to "model the additional dependency of the observation processes". In the new table of results, MR-GPRN w/o CL and MR-GPRN w/ CL are essentially the same, which further supports my point about the CL approach not providing any additional benefit. The authors will need to discuss this as (in my view) the proposed CL+VI approach for modelling additional dependencies is either wrong or counterintuitive.  ****  ### Summary ### This paper develops Gaussian process-based methods for multi-resolution multi-task regression problems, i.e. problems with data collected at multiple resolutions and also with multiple outputs. (i) The paper proposes a flat GP method that builds upon the Gaussian process regression networks (GPRNs) of Wilson et al [30] by extending it to handle multiple resolutions through a composite likelihood model. (ii) The paper also develops a deep GP method based on GPRNs and mixture of experts. Experiments are presented on synthetic data and one real dataset concerning the estimation of air pollution levels in London.   ### Originality ### The paper is mainly a combination of existing ideas, with regards to multi-output problems (using the GPRN of Wilson et al [3]), modelling dependencies in the likelihood (using a composite likelihood approach) and flexible and efficient modelling and inference for GPs and deep GPs [11, 24]. I do like the exploration of composite likelihood approaches for modelling dependencies across different modalities (e.g. resolution, outputs, etc). I have seen this before for structured likelihood settings, e.g. when using a pseudo-likelihood approach. However, the paper falls short in demonstrating that such approaches are worthwhile when compared with the natural approach of using latent variables.  In other words, the benefits of the composite likelihood approach are unclear as a comparison with a baseline that uses the same GPRN-type model but without a composite likelihood is not provided. See more on baselines below.  ### Quality ###  - I believe the paper is technically sound, although there are some details that make the reader wonder whether there is something inherently wrong or the confusion may be caused by a lack of clarity or typos. For example, in Equation (1) and algorithm 1, only a single composite weight $\phi$ is used. I am not very familiar with the literature cited here but it looks like a single composite weight would not make a difference. One way to think about it is that this weight will come out of the expectation across multiple resolutions (during variational inference) and provide nothing with regards to modelling dependencies. Can please the authors clarify/explain what is going on?  - Another reason (perhaps related to the above) for concern is the baseline used. My understanding of VBAgg [12] is that it is a method proposed for handling aggregate data, for example when the inputs are observed at a higher granularity than the output, and it is not really a multi-resolution method. A better baseline would be to consider a GPRN-type model where the resolution is seen as another context and where the GPRN parameters (e.g. weights) are now tensors. This would really help us understand what the composite likelihood is bringing to the game of modelling dependencies across resolutions. This is perhaps what the method is doing so it would probably materialize to not having the composite weights. In any case, the paper does need a multi-resolution baseline so it is unclear why there is no comparison with this (e.g. using [6] and simple extensions to multi-task). Similarly, other multi-task methods can be evaluated.   - Additionally, with regards to the composite weights, is there any theoretical justification to first estimating the GPRN parameters using MLE so as to estimate the composite weights, and then fixing these to estimate the posterior of GPRN parameters using variational inference? It seems rather ad-hoc. Why not estimating everything under a single (e.g. variational) framework?  - I see some inverse Hessians in the algorithm yet the computational complexity reported does not seem to include this. Can the authors please clarify?  - Only point prediction metrics are used. Please report (estimates of) test likelihoods.   ### Clarity ### - The paper is well structured but, at times, it becomes really difficult to follow what's going on. This is particularly true for the DGP model (section 4). I strongly suggest to the authors to pass this trough someone else (with a background in GPs) and they will realize I am probably right. For example, in line 131 it is very unclear what the GP is on as it seems that the kernel is computed on two different spaces? P(X_a) is not even defined. Why the notation P_a,k^{(1)} if the (1) is not used for anything?  - Table 2 right: It shows that actually VBAgg is the best when using MAPE but the proposed method MR_DGP is bold. why? This is also not even discussed in the text.   - The abstract needs some work: it refers to shallow GP mixtures. GPRNs are not really mixtures in the probabilistic sense.  It is unclear what "naturally handle biases in the mean" means, also mentioned in the text. line 8, information-theoretic corrections: this is not even discussed in the text. line 10 and in the text: what is hyper-local?  - In line 126, the subscript $m_k$ for the MoE does not make sense. The sum is over k, so why the subscript?  - There is no composite likelihood in Eq (4) so the DGP model is not really an extension of the GP model. This is a shame as it would be interesting to compare both.   - What happened with the notation $Y_{a,n,p}$ in Eq (4), there is no $p$ here?  - Why is there a superscript in $X_^{(k)}$? why $X$ depends on k here?  - line 88: replace n with N    ### Significance ###  Since the models are a combination of existing ideas and no new inference methods are proposed the significance of the theoretical/algorithmic side is low. The proposed method can have a high significance in the practical side but a better evaluation considering more datasets and more suitable baselines must be done. 