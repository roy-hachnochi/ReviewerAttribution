Review Update: The author did a better job of explaining how the PPSWROR sketch, SumMax sketch, Sideline data structure, and gamma threshold work together in Algorithm 3 in the rebuttal.  ------------------------------------------------------------------------- -- Summary -- Massive datasets contain elements represented as key, value pairs. The task is to compute statistics where each key is weighted by a function of its frequency. The paper specifically focuses on concave sublinear functions to mitigate the effect of keys with high frequencies.   The paper designed a composable sampling sketch for any concave sublinear function while requiring space near to the desired sample size. The stochastic PPSWOR sampling and the auxiliary SumMax sampling sketch support generating a sample of keys whose expected weight is equal to the key's true weight.  Naive Approach: 1. Aggregate all data into a table of keys and their frequencies. 2. Apply function f to frequency values 3. Estimate statistics using weighted sampling scheme  Probability Proportional to Size and WithOut Replacement (PPSWOR): 1. Sample keys in proportion to their frequency 2. Estimate statistics using function f * Requires space equal to the number of distinct keys