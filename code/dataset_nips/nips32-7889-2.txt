Summary and Contributions From a practical perspective, the problem studied here is interesting. The authors tackle the problem of recommendations for a special kind of items that are associated with phases in a user's purchasing behaviour (i.e. items that users only buy rarely, like a TV, a new phone, furniture, movies etc.). Here, a play of an arm triggers a state change for a period of time (users most likely do not want to watch the same movie again immediately). Mapping this to a bandit setting, the authors aim to solve the a MAB problem where, after each play of an arm j, the expected reward of j start changing over time according to an unknown function f_j drawn from a GP of known mean and kernel, until a maximum time z_max, after which the expected reward remains constant. The authors propose using d-lookahead regret as a proxy for the classical measure of regret (which is prohibitively expensive to compute in this setting) and show that it is indeed a good approximation (the approximation is arbitrarily close as T\to\infty). Additionally, the paper introduces the d-lookahead UCB and Thompson Sampling variants and analyse their regret proving scaling of the order O(sqrt(KT\gamma \log(T))) where \gamma depends on the GP kernel and takes values from O(log(T)) to O(T^{1/(1+\nu)}log(T)) for Matern(\nu) kernels.  Overall I find this paper interesting but wonder whether some of the assumptions hurt the practical significance of the work. The GP kernel will not be known in most real-life scenarios - would the uninformative prior be sufficient? z_max being the same for all arms seems a bit unrealistic. Would it be possible to relax this assumption? Another questionable assumption that I think also needlessly complicates the problem is the fact that the decision maker is forced to play an arm each round (normally, web services are not forced to display ads, for example). Having the ability to pass on playing at some round would allow for easier planning ahead since now, there is more independence between arms.   While I have not checked the proofs, in my opinion the paper is very well written and I particularly like the result on d-lookahead regret being a good approximation of the full horizon regret. I like this metric and think it's a great proxy for this setting. I appreciate the authors comparing their algorithm's performance to several baselines, including the common sense UCB-Z algorithm. The authors also provide a section on reducing the computational complexity of their algorithm.  Despite some questionable assumptions, I can see this paper representing a solid starting point for further work on this setting, I therefore recommend accepting this paper.  =========== Post Rebuttal =========== I have read the author's reply and am satisfied with the clarifications.