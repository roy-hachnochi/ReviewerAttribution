[Update after feedback round: since the authors did not have the chance to respond to my issues, my review should perhaps be down-weighted a bit. I have read the other reviews and the author feedback and was pleased to see that nonetheless some of my issues were (partially) addressed, in particular another experiment with slightly more complex dynamics (maze with walls). I think that the VI scheme derived in the paper is promising and that there are fairly straightforward ways to speed up / approximate the matrix inversion to improve scalability of the method at least to some degree. Nonetheless I personally think that the paper would benefit from a another round of revision, after which it could potentially be a much stronger paper. To me, the main hurdle for this is a comparison against the Gibbs-sampling version of the method. The paper should address the following questions: (I) why derive a VI scheme in the first place, where does the Gibbs-sampling method fail (scalability? performance? data-efficiency?), (II) the VI scheme makes additional approximations (e.g. mean-field) - how do they affect the solution class (theoretically and empirically), how does training of the model behave (local optima, mode-seeking/-covering behavior, convergence behavior), (III) an empirical comparison of the same questions as (II) but compared against the Gibbs-sampling method. Paired with a larger-scale experiment and perhaps a comparison against another method (as a bonus), I think that the paper would be very strong (particularly, as the authors point out, since the method is quite broadly applicable).]  The paper addresses the problem of inferring “structure” via hierarchical probabilistic models in discrete domains. Structure refers to higher-order statistical regularities which can be expressed as priors and hyper-priors in hierarchical Bayesian models. In the discrete domain this typically leads to intractable inference or overly simplistic models that cannot capture complex higher-order regularities because of overly restrictive independence assumptions. The paper builds on previous work to alleviate this problem via the introduction of Polya-Gamma auxiliary variables. While the previous method allowed for efficient approximate inference via blocked Gibbs sampling, the main novelty of this paper is to introduce a suitable parametric model for the approximate posterior and derive a corresponding variational inference scheme that allows for closed-form expressions. Additionally, the paper derives (closed-form) update equations for an EM-style scheme for tuning the method’s hyper-parameters. Empirical results are shown on a toy grid-world domain for: imitation learning and system identification (learning of transition-dynamics) under both, a fixed random policy and a policy produced by a planner that takes into account the learned transition dynamics. The method is also evaluated on a “Queuing Network Modeling” task (121-dimensional state-space, 2 actions).  The paper addresses a very important and timely problem: learning of higher-order statistical correlations in discrete MDPs (and related problems such as contextual bandits). While I think that the particular approach taken in the paper is very promising, the current manuscript has some shortcomings such that I currently vote and argue for major revision of the work. My main issues are (I) quality and extent of the experiments. (II) insufficient discussion of related literature and shortcomings/restrictions of the presented method. I appreciate that the authors show a number of different applications and I would be excited to see convincing results in favor of the proposed method and therefore want to encourage the authors to take the time to improve the manuscript.  Detailed comments: 1) Experiments: the comparison shown in the experiments (“Dirichlet”) is ok as a naive baseline, but not enough as a serious competitor method. As a minimum the (block Gibbs) sampling version of the method should be included and it some discussion/results on strengths and weaknesses of the two variants (does the VI version run faster in terms of wall-clock time, is it more sample efficient, does it generalize better, …?). Given the small size of the toy domain, other (brute-force, or inefficient sampling-based) methods could potentially be included as well, but it would be OK to dismiss them by showing results on a larger-scale task where competitor methods can no longer be applied. Another competitor for comparison in Fig 1 would be the Dirichlet estimate with (a) copying the action-distribution from the nearest observed neighbour state or (b) taking the average over all observed neighbour states within a certain radius.  2) Larger-scale experiments. Why were there no experiments with larger state-action spaces and non-trivial dynamics included (at least grid-worlds with walls, and other non-trivial tiles)? Currently it is hard to judge whether this was simply due to a lack of time or because the method has severe scalability issues. Very convincing experiments would be e.g. on simple video-game domains, (which naturally have a low-cardinality discrete state- and action-space) - simulators for such experiments are publicly available and comparison against other approaches would be easier.  3) Literature: there is a considerable body of literature on (hierarchical) inference in latent-variable models that is barely mentioned. E.g. in the language domain, topic models are mentioned but dismissed as “not discussing the problem of decision-making”. Can some of these methods be straight-forwardly be applied to the tasks/domains shown in the paper - it seems so, since the model in the paper is not explicitly used for decision-making. Please correct me if I’m wrong and discuss this in greater detail. Hierarchical inference for discrete-variable models is also discussed in the literature on Bayesian deep (reinforcement) learning and hierarchical representation learning with deep networks - importantly, these models are also optimized via variational inference (ELBO maximization), however under different approximate distributions (the emphasis is on differentiability, rather than closed-form expressions). What are the advantages/disadvantages compared to the presented method (scalability, data-efficiency, …)? I am of course happy to also see non-deep-neural-network approaches, but this literature must be discussed in order to put the method into perspective. See e.g. [1] for lots of up-to-date pointers to literature.  [1] https://duvenaud.github.io/learn-discrete/  4) Shortcomings of the method and implications of the simplifications/approximations. Please discuss the implications of the mean-field approximation for the variational distributions, beyond simply stating the mathematical form. The same applies for restricting \theta to be a scale parameter (line: 165) - ideally compare empirically against no restrictions and doing the full matrix inversion numerically (particularly since the experiments are on small domains), or against using a low-rank matrix factorization. Finally, please discuss the implications of using a square-exponential kernel - would it for instance still be suitable in grid-worlds with walls, or other situations where simple Euclidean distance of states is not indicative of the “generalizability” of state-dependent action-distributions.   Originality:  Medium - the derivation of the VI scheme and the EM scheme is interesting and novel, but replacing a sampling-based ELBO optimization with a VI-based one is a rather straightforward idea.   Quality: Low - while the derivations are well-presented and sufficient detail is given, the experimental section lacks comparison against important methods. Some ablation studies and sensitivity-analysis w.r.t. Hyper-parameters would have been nice and results regarding larger-scale applications are crucially required to judge the significance of the approach. The literature-discussion lacks important parts.  Clarity: High - the paper is generally well written. The only important improvement is a qualitative/informal discussion of some of the restrictions/approximations, such as the mean-field approximation - though the mathematical statement is sufficient in principle, adding one, two sentences would not hurt.  Significance: Currently low - the method could potentially be quite significant, but this needs to be shown with experiments that compare against other state-of-the-art methods and larger-scale experiments. It remains unclear whether the same results could have been achieved with the sampling-based approach and where the advantages of the VI approach lie. 