UPDATED post rebuttal:  Thanks to the authors for addressing all my points. I am raising my score to seven.    The authors begin by noting that many existing object detection pipelines include a step on 'anchor assignment', where from a large set of candidate bounding boxes (or "anchors") in a generic image frame, the one that best matches the ground truth bounding box, as measure by IoU, is chosen to be the one that is usedÂ for training, ie the object detection and bounding box regression outputs for that anchor will be pushed towards the ground truth. The authors note that for objects which don't fill the anchor well (slim objects oriented diagonally, objects with holes, or occluded objects) the best anchor according to this IoU comparison may be actively bad for training as a whole.  The authors propose "learning to match", ie producing a custom likelihood which promotes both precision and recall of the final result (making reference to terms from the traditional loss function). For each ground truth bounding box, a 'bag of anchors' is selected by ranking IoU and picking the best n. During training, a different bounding box is selected from this bag for each object, for each backwards pass. Which one is chosen depends on the current state of training - as demonstrated in Figure 4, the confidence gradually increases for certain anchors. The Mean-Max function means that at the start of training, many of the anchors in the bag will be selected, but over time a single best one will come to dominate.  I do not have the relevant background to confidently assess originality / quality / significance in this subfield. The results seem impressive, to do a drop-in replacement of the loss function and get multiple percent increases on difficult categories (figure 5 right) with negligible impact on other classes is a good result. Figure 6 is a nice result as well. All necessary experimental details seem to be present. The paper seems to be well written, and for those working with these kind of models I'm fairly confident that trying out these changes would be simple, given the information in the paper.  Minor points:  * L16: the citations given for algorithms which incorporate anchor boxes includes [5] and [6], which are R-CNN and Fast R-CNN - neither of these papers includes the term 'anchor', I believe that first came into that line of work as part of Faster R-CNN.  * In the figure 1 caption, (top) and (bottom) would read better to me than (up) and (down). * L145: "The anchor with the highest confidence is not be suitable for detector training" - remove the extra word "be" * Algorithm 1 - the anchor bag construction is implied to happen on every forwards pass - but if it just depends on the IoU between the anchor and the ground truth bounding box, presumably this could be done once before the training loop and cached? * Algorithm 1 - "super-parameter" - I'm pretty sure I have not come across this term before, and google search says "did you mean hyperparameter"... * Algorithm 1 - Backward propagation - I think it's way more standard to do something like $\theta^{t+1} = \theta^t - \lambda \nabla_{\theta^t}L(\theta^t)$. You are presumably not solving the exact argmin problem, and it takes approximately as much space to write. * Figure 4 - Firstly, I would recommend noting in the caption that the laptop is relatively low contrast and encouraging readers to zoom in. I am viewing in color and it was on the 3rd pass through the paper that I realised the green bounding box does actually capture the laptop very well - I basically didn't notice half the laptop and it's easy to assume that this is some kind of failure case where it's incorrectly focused on the cat. Given this realisation, I'm still not sure if this image shows as much as it could - obviously there is progression to the right as the center anchors get redder, but I don't really know what actual spatial extent those anchors represent. It's also unclear why more than these 16 were not represented (the minimum anchor bag size that is mentioned is 40) - presumably the confidence goes really low much further away, but could we then see this? Perhaps it might be more interesting to show, in separate images, the actual anchor extents for the final most confident and least confident. My intuition is that one of them would clearly have a better IoU with the true bounding box, but the eventual higher confidence one would focus more on the pixels that are a laptop - am I right about this? * L172 - I am intrigued as to why this value for a bias initialization (presumably the rest of the convolutional biases are initialized at zero as normal). Can you provide some justification as to why this formula is used? I would also recommend not using $\pi$, as that already has a well known scalar interpretation.     