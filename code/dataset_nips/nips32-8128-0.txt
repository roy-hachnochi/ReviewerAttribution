- Originality: the contributions are original and provide new insights.  - Quality: one can discuss what way is the best to approach the problem, but the road taken seems sound. Details below. - Clarity: the most interesting parts are in my opinion not described well enough. I have a feeling that one could provide simple and intuitive explanations of the main idea which would improve readability. - Significance: the problems considered are relevant and the solutions could prove useful. The present paper seems to be a step towards such solutions.  Detailed comments: The paper works with soft interventions only, and at the end of the paper the case of hard interventions is mentioned. It says that hard interventions can change the skeleton of the graph, and this is not handled by the present paper. Is it correct that the soft interventions considered should always have the same set of parents in the interventional graph as in the original? This would seem very restrictive.  I'm curious about the choice of using MAGs to represent the interventional distributions. The abstract goal of the paper is to describe equivalence classes of graphs that are more fine-grained than the standard ones, in this case by using interventional equivalence as well. The abstract goal seems to be the same as that of nested Markov models which are also more fine-grained models in which constraints induced by interventional distributions are employed (though all of these constraints are necessarily identifiable from the observational distribution only). I think the paper would benefit from including a comparison between the proposed methods and the nested Markov models. This leads to another question. In the nested Markov models, ADMGs (not MAGs) are used as graphical representations of partially observed causal systems. I believe this choice was made because the MAGs throw away some causal information by insisting on using at most one edge between each pair of nodes. To give an example, we can consider the graphs in Figure 2. In the MAG (even without the auxiliary F_x node) there is directed edge from X to Y (because X and Y cannot be separated, and X is an ancestor of Y). This means that when looking at the MAG, it would seem that when intervening on (X,W), the value of X actually matters for the distribution of Y. However, knowing the underlying causal graph in (a), this is not the case. It could indicate that MAGs are actually throwing interesting information away (they of course encode the independence structure, but not necessarily that of the interventional distributions). You could also formulate this as saying that even if an algorithm learns the I-PAG completely, this doesn't provide complete causal information. To take the example in Figure 2, if I understand correctly, we have access to the interventional distribution from intervening on \{X\} and this shows that X is not a parent of Y (condition on W), however, this information would never be in the output when learning equivalence classes of MAGs.  The learning algorithm is described very briefly (I acknowledge that the page limit probably also is to blame for this), and this makes the paper unnecessarily difficult to read. As far as I can understand, the interesting part happens in Algorithm 3, Lines 7-11, and I would suggest describing this in more depth. If I understand correctly, we are basically testing separation between intervention nodes and non-intervention nodes by testing whether there is some set (of non-intervention nodes) such that the conditional distribution of Y remains the same between different intervention regimes. This seems like a simple idea, and one worth communicating early in the paper.   At the end, the reader could be left wondering how much more information is gained in the algorithm. More information is definitely required as input to the algorithm, as we also need interventional distributions. The example clearly shows that it is possible to obtain more information. If Rule 9 is the only real gain of the algorithm, it would seem that we could just employ that one directly on the output of the FCI algorithm using the observational distribution. Again, if true, this could offer a more intuitive explanation of the crux of the matter.  I'm not sure I understand Definition 5 (Augmented MAG). There seems to be no requirement that the augmented MAG is maximal (i.e. unseparable nodes are adjacent) which is different from MAGs. Is this an omission? In Line 248, it says that something was established, but that seems to be by definition.  Minor comments: In Line 118-120, some form of faithfulness seems to be assumed. In Line 100 it says that randomized controlled trials are also called interventions which I don't think is true. Some times people say that interventions can be thought of as generalized randomized controlled trials. I'm not sure what you mean by that sentence. In Lines 118-127, I would suggest adding some references, e.g. to the paper showing completeness of FCI, etc. In Definition 2, the notation [k] has not been introduced. In Lines 200-201, 'since augmented' -> 'since the augmented' Algorithm 2: 2^V is the power set of V? In line 9 in Algorithm 3, it looks like I, J is set to the same thing, maybe write 'I,J is s.t. (I,J) = \sigma(i)'. I think this would be more easily understood.   EDIT after response from authors: I thank the authors for providing answers to my questions and concerns. This clarifies central parts of the paper in my view and I've updated my score to reflect this.