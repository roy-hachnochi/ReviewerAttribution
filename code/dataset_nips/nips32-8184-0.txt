Post author response: I thank the author(s) for their response and commenting on my discussion points. As those would need additional work, I for now keep my original score: this is a solid paper. ----------------------  Clarity: The paper is very well written and generally easy to understand, given the technical nature of the contribution. While the proof for Lemma 4 & 5 is described very well in the main text, it would be helpful to have a short explanation how this is used to achieve Lemma 6. If necessary, I suggest to drop the proof of Lemma 3 from the main text as this result is standard.  Quality: I have verified the proof in the main text and individual lemmas in the appendix. All results that I checked appear to be correct.  The authors do discuss the main limitations of their analysis but it would be nice to discuss the following points at least briefly: - The authors chose the setting with time-dependent dynamics which is a little less common than the default setting where dynamics and rewards are identically distributed across time steps within the episode. Would the current analysis be able to go through even if samples are shared across time steps? I suspect it would be difficult to achieve a tighter bound in H (e.g. due to Lemma 8) but I wonder whether the same bound can be proved. - How does this setting for \beta affect the empirical performance of the algorithm. To what degree does it make the algorithm conservative compared to empirically tuned parameters? - This is an expected regret bound (given any fixed true MDP) but is there any indication that a similar analysis would not yield a high-probability regret bound or PAC-style bound (as in [11] after adjusting k --> n_k(h,s,a) in beta)?  Originality: This is the first worst-case analysis for RLSVI and even though it might not yield novel insights beyond the analysis itself, is an important technical contribution. The proof relies to large parts on existing strategies (which is not surprising) but contains novel technical insights such as lemma 5.  The paper does discuss the relevant links to existing literature but it would have been helpful to give a more direct comparison of the result here to the lower bound and upper bounds of other algorithms (e.g. OFU based methods) in this setting.  Significance: I think this is a solid technical contribution to the field and even though it is not surprising or particularly tight, it is absolutely non-trivial and still an important result. As mentioned in the introduction of the paper itself, worst-case analyses of randomized algorithms in the RL setting are far from trivial and so this relatively simple analysis has a good chance of being used as a template and improved upon in future work.    Minor:  - Line 361: hat M_k \in Mcal_k  should be \notin - Line 264 missing closing )  