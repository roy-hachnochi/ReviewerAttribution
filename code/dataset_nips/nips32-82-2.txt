  This work studies the problem of selecting a hypothesis from a class of hypotheses that is close in TV-distance from an unknown distribution P that samples are drawn from, with the added constraint of DP.  The overall algorithm is the exponential mechanism, but some care needs to be taken in selecting the correct score function.    The paper needs a lot more explanatory text to help the reader understand the intuition.  Some things are defined with no explanation, such as \Gamma(H,H’,D).  The paper dismisses in a footnote the issue that p_1 and p_2 can be evaluated exactly, because they can be estimated to arbitrary accuracy.  How does an error in p_1 or p_2 propagate through the analysis?  Overall I think the paper tackles an interesting problem and uses standard DP techniques to solve it.  There are many different applications that the paper points out to show the impact of this result.  The paper would benefit from a thorough proof reading with more explanations to improve the writing.  This could all be fixed.   Comments:  - "indepdently" on page 2. - Should cite the various constraints studied previously in hypothesis selection on Page 1. - Lots of terms are used before they are defined, like DP, \alpha-cover. - The variable “d” is overloaded in Section 1.1 (refers to VC dim and I assume the dimension of the Gaussian distribution). - Preliminaries just state lots of definitions, with no explanatory text. - In Definition 3, how to define d_{TV}(P,\mathcal{H}) when d_{TV} is only defined over distributions.  Also missing a \hat{H} in the d_{TV} bound. - Footnote on page 5 refers to H_j, but should this be H’? - Proof of Lemma 2, is H_j and H_k supposed to be H_1 and H_2? “probablity” on page 6 - In the Applications of Hypothesis Selection section, the notation O(x)^d is used.  Is this supposed to be O(x^d)?  ###  I have read the author feedback and will keep my score unchanged.