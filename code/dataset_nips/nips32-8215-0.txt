In this paper, the authors present a multi-state Dynamic Recurrent Neural Network architecture and training framework for Brain Machine Interface (BMI), including incorporating scheduled sampling and testing diverse neural features as input. The authors robustly analyze this model in comparison to other prior modeling frameworks on human posterior parietal cortical activity (PPC).   This paper is of an impressive quality, containing rigorous and methodical analyses showing clear and significant improvements of their model. The authors compare to twelve baseline models and investigate many aspects of the modeling framework, including single-day vs multi-day performance, generalization of single-day training to other days, the reliance on amount of training data, the optimal preprocessing of neural feature inputs, and  generalization of the models over time with different styles of retraining. The paper was very well-written, with most choices and details clearly explained. I also appreciated that the authors showed examples of the regression performance (Figure 4) instead of just reporting summary statistics.  However, I do not think it is stated explicitly enough exactly which parts of the model are novel vs novel in the BMI setting vs pulling from prior BMI literature.  The paper could benefit from an expansion of the background section of the Introduction and a citation to a “conventional DRNN” method. The authors did include a description of all baseline models in the Supplementary Material but I still think a more concise description of differences from the most similar previous model (presumably F-DRNN) in the main text would benefit readers. Also, what makes this method multi state?   Additionally, this paper applies these methods to a novel brain region, posterior parietal cortex. Other than briefly stating this, the authors do not further discuss PPC or include any analyses or citations about how the decoding performance differed from that of more traditional BMI brain regions such as motor cortex data, which causes this contribution to be much less significant.  Some questions:  Does watching the cursor move for 3 minutes constitute a trial?  Why is there a disconnect between figure 7 and the rightmost point of figure 8? The DRNN and Deep-DRNN have significant differences in figure 7 but in figure 8, when trained similarly on 20 days, they perform similarly.  Is there an intuitive explanation as to why the more complex model is doing worse (Deep-DRNN vs DRNN)? It doesn’t seem a clear case of overfitting based on the training days plot.  EDIT: I'd like to thank the authors for their thorough rebuttal. I am now even more confident of my high score. 