Originality: This work is innovative in generalizing markov decision process to multi-view scenarios. The authors have clearly distinguished their work from the state of the art and similar works.  Quality: The submission is technically correct. The claims made in the paper that multi-view RL using policy transfer between views can achieve convergence faster has been adequately demonstrated. The works reads like a complete piece of work and the authors have performed thorough experiments to demonstrate the claims. They did discuss the case where the proposed solution did not better the competing method, providing justification on why that would be the case.  Clarity: The paper skips over a lot of derivations and only a person who is very familiar with MVRL would be able to understand it without supplemental document. Otherwise, the paper is well written. However, without the supplementary material, it would be hard to replicate the experiments.  Significance: The work seems relevant and significant to advancing the state of the art in reinforcement learning. There are increasing number of scenarios where multiple sensors sense the same environment. Therefore, multi-view RL is definitely going to be a hot topic of research.