** I have read the author response and my opinion remains the same.**  This paper uses imitation learning to solve the compiler auto-vectorization problem. It trains an agent to mimic the optimal solution generated by an integer linear programming solver. It outperforms production-level compiler LLVM in the experiments.  Originality: The novelty is incremental. This paper directly combines well-known techniques and does not make any new contribution from the machine learning perspective.  Quality: The experiment results look promising but it lacks detailed explanation. Only two figures were provided. Some case studies of the learned policy and more detailed results (more tables and plots) are expected. The claim "The learned policy runs faster then goSLP's ILP solver" is not backed by any experiment results. The author needs to provide a wall-clock time cost comparison of different methods.  Clarity: The paper is clearly written and well organized. All required background is provided. The only drawback is that there is no mathematical description of the used algorithms such as GGNN and DAGGER. The author should provide these descriptions to make the paper accurate and clear.  Significance: This paper shows a successful application of imitation learning for compiler optimization. It is a good trend for the compiler research community to use more intelligent data-driven machine learning algorithms.  Overall this is an okay paper with limited novelty. The evaluation part definitely needs more experiments and result plots.