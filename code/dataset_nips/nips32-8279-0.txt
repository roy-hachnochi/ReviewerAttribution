*** Update after the rebuttal *** I thank the authors for their clarifications and additional results.  A good result from this rebuttal exercise is that the authors now report test likelihoods, which I think should always be reported in GP papers. It will be great if the authors can be a bit more explicit about the additional contributions with respect to the previous work [11,26]. It is OK to focus on the engineering effort and experimental evaluation as the main contribution of the paper. The paper will also benefit from reporting error bars on all the results. ****  This paper develops a method to scale up exact GP regression (under the standard Gaussian noise assumption) to a very large number of observations. The paper does not provide new theoretical developments or a technical contribution. The implemented method is based on the work by Gardner et al [11] and by Pleis et al [25]. The paper is well written and structured and it is clear in terms of the claimed contributions, i.e. using the previous developments to provide a practical implementation that can scale up GP regression. From this perspective, there is not much to comment on the technical part as there are not really new insights here.   From the practical perspective, the paper provides two interesting conclusions: (i) that for the benchmarks studied, exact GP regression can indeed benefit from using all data and (ii) inducing-variable approximations are somewhat limited by the number of inducing variables and by the main assumption in the approximate posterior.  In terms of clarity, it would be helpful if the authors can clarify the differences between SGPR and SVGP (line 220) as both methods reference 16.  ### Significance The main question is whether these practical contributions are sufficient to deserve publication at NeuriPS.  Although I find the above insights interesting, I guess perhaps NeurIPS is not the best venue for this work. There is also one major flaw in the evaluation of the method: most GP researchers (and certainly the NeurIPS community) are interested in the full predictive distribution so I believe a thorough evaluation of the predictive variances must also be presented. These days, the ML community has plenty of flexible non-probabilistic supervised learning methods and those are not even mentioned here.  