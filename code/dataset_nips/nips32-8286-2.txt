---------------------------------------------------------------------------------------------------------- Post-rebuttal update: ================ I thank the authors for the clarification. After some discussions with the other reviewers and the AC, I've decided to increase my score to lean more towards an acceptance. I do believe, however, the current version of the paper is sub-par in term of presentation. Please add comparison with Aboleth, along with other missing information that I had mentioned in my original review, and please fix all the formatting issues.  I do hope that given sufficient work from the authors in preparing the camera-ready version, this paper could be more like a proper scientific paper, instead of a description of a software toolkit. ----------------------------------------------------------------------------------------------------------  This article describes an extension of TensorFlow (TF) called "Bayesian Layers" (BL) which abstracts the variational inference implementations (e.g. sampling, reparametrization trick, and KL-divergence calculation) inside the API itself. These layers are constructed in such a way that they maintain the compatibility with the pre-existing API in TF. The resulting layers are therefore maintained compatibility with the pre-existing layers in TF. This allows users to stack together variational and vanilla layers together when building their models. Some examples provided by the authors include the variational versions of fully-connected, convolutional, RNN, and Gaussian process layers. The article shows that these layers can be used as drop-in replacements for the existing deterministic layers in (possibly any) existing models to enable uncertainty quantification, which is very important in real-world systems. Furthermore, the authors demonstrate that the proposed layers scale well to a particularly large model with 5 billion parameters.  I like the idea of having an easy way of building BNNs. Especially, having a painless way to turn complex, deterministic models (like what people use in NLP or CV) to Bayesian ones is very appealing. Even more so because the real-world systems nowadays cannot quantify their uncertainty, giving rise to many safety issues. So, I think there is a big real-world potential for this toolkit.  Having said that, I have the feeling that the proposed toolkit is a bit too similar to the existing toolkits such as Aboleth (https://github.com/gradientinstitute/aboleth). Indeed, the authors cite Aboleth as the most similar toolkit to theirs. However, there is a lack of comparison between BL and Aboleth, thus it is difficult to know what makes BL special and original. Furthermore, when comparing BL with Pyro, the authors mentioned that BL could use more recent estimators such as Flipout and deterministic VI. I think this could be a strong point for BL, but the authors did not do any follow-up on this feature.  While BL hides away the pain of implementing VI, it makes the toolkit inflexible. For example, I am under the impression that only VI with Gaussian prior and variational posterior (with diagonal covariance) is supported. While Edward can be used on top of BL for more advanced inference, it is still not clear to me how easy this would be and whether the usage of BL with non-Gaussian priors and posteriors could be done easily. Perhaps the author could clarify further on this point.   For the experiments, I think it is really great to see that one can use the proposed toolkit to turn a large, complex model into a Bayesian one. But, I think an additional comparison with the respective vanilla deterministic model in term of training time and memory overhead would be important. I also think the claim in Figure 9 that the performance of BL scales linearly is not warranted as there are not enough data points to draw that conclusion. That is, there is a lot of uncertainty on how does the performance curve look like between x=128 and x=512.  The overall writing of the article is clear, although some questionable terms such as "tensor-dimensional" are being used here and there. I appreciate the authors for showing codes describing the usage of BL. However, the presentation of those codes could be better, as they often overlap with each other and cross the page boundary. Another minor point that I would like to bring up is that in the x-axis of Figure 9, the number 8 and 32 are too close together and makes it confusing at a glance.  Finally, I would like to mention again that I really like what the authors proposed in this article and hope that it could have a big impact on real-world systems. However, ultimately, I think this article's scientific significance is low, as the nature of this article is a description of a software toolkit.