The authors apply an actor critic algorithm to the task of learning to solve algorithmic/program induction tasks. The model uses an LSTM and embeddings of program states and actions, with a shared policy and value network. During rollouts, MCTS is used as an improvement operator. Following prior work on curriculum learning, the authors check the validation error periodically and adjust using this the task regiment, increasing in difficulty over time.  The authors validate their approach by training to learn how to sort, and solve a Tower of Hanoi problem, they demonstrate that using a recursive solution, it is possible to train a policy to solve either of these tasks without full trace supervision. 