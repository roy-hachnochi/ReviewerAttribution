The paper is clear, and makes efforts to highlight the behavior of the proposed algorithm (value of the regret bound for some specific settings, experiments measuring the impact of the metric).  The comparison to other settings may still be enforced. Typically, I would appreciate knowing the theoretical upper-bound of the regret of Approx-Zooming-With-No-Arm-Similarity.   In the experimental part, I would also appreciate the comparison to include some state of the art algorithms. What would be the empirical results of a gaussian process-based bandit? It would also be interesting to have results on datasets used by other contextual/similarity-based bandits (except that these datasets use a context in R^d).  Finally, it's surprising to have a context space of dimension 1. Extending the algorithm to R^d setting seems strait-forward. It would explode the time before sub-partitioning, but would it have more disadvantages? Would the R^d setting be more difficult to analyse?   __________________________ # POST REBUTTAL  I thank the author for their precise and clear rebuttal. It strengthens my positive opinion wrt. the paper.   Regarding Gaussian process-based bandit, I was expecting a gaussian process per arm, but the version requiring an oracle access to a metric among the arms would also be informative wrt. to the efficiency of sub-partitioning.  Regarding dimension-d context, given its necessity for most applications, the more the paper includes results wrt. that setting, the better. I understand experiments may not be conducted in the limited timeline, and the regret bound in the rebuttal gives a preliminary answer to the impact of dimension. The next step could be to also give the regret bound with dimension-d context for both concrete examples: finite types, and Lipschitz wrt. continuous arm metric space.