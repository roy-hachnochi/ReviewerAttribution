The relationships of many real-world networks are complex and go beyond pairwise associations. Hypergraphs provide a flexible and natural modeling tool to model such complex relationships. The authors propose HyperGCN, a novel way of training a GCN for semi-supervised learning on hypergraphs using tools from spectral theory of hypergraphs and introduce FastHyperGCN. They conduct some experiments on co-authorship and co-citation hypergraphs to demonstrate the effectiveness of HyperGCN, and provide theoretical analyses for the results.  Strength: 1. The paper proposes 1-HyperGCN and HyperGCN using the hypergraph Laplacian and the generalized hypergraph Laplacian with mediators. FastHyperGCN is proposed for fast training, which computes the hypergraph Laplacian matrix only once before training. 2. HyperGCN is applied to combinatorial optimization such as densest k-subhypergraph problem.  The paper is well presented and easy to follow, but it can be further improved by addressing the following potential issues: 1. The experimental setting is a little unclear. The training/test split ratio of the dataset is not reported in the paper. 2. HyperGCN should be compared with GCN models since GCN models are also designed for the semi-supervised task and can be easily applied to hypergraphs.  3. There are a few typos in the paper such as “Cora co-citaion” in line 203.  