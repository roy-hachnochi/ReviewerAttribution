The authors did an outstanding job in addressing "where to learn" "how to learn" "what more to learn" and clearly established the novelty of their method. Their work opens the door to solving more sophisticated optimization using L2L.  The uncertainty-aware loss fits the goal of the exploration-exploitation tradeoff, that was popularly researched in Bayesian optimization and RL (but not so much yet in L2L). I also like the intra- and inter- particle attention modules, that add to the explainability whether particles are working collaboratively or independently.  A clear conclusion could be drawn from their Rastrigin experiments, that population-based L2L outperforms gradient-based meta optimizers including (Andrychowicz et al., 2016). The meta optimizer then outperformed a very recent SOTA method (Cao and Shen, 2019) in the real protein docking  application.     