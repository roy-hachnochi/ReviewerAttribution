ORIGINALITY: The authors present a framework for multi-task learning on aggregated data, i.e. data that has been averaged over time and/or space. The key contribution is to consider a *multi-task setting*, in which correlated aggregated data is jointly modeled and each task can have a different likelihood function. As such, the paper seems to be a relatively straightforward extension of the work of Moreno-Munoz er al. 2018 (Multi-output GPs when outputs have different likelihoods) by the work of Smith et al. 2018 (GPs for aggregated data in the single-output case). This combination is (to my knowledge) novel and relevant.   QUALITY: Technically, the method seems sound and supported by the experiments, although the latter are partially presented in a manner that doesn't make them easy to follow. There is a clear setting when this method should be used (different kinds of correlated, aggregated data), but there is no assessment of weaknesses of the method.  CLARITY: The paper is well organized, partially well written and easy to follow, in other parts with quite some potential for improvement, specifically in the experiments section. Suggestions for more clarity below.  SIGNIFICANCE: I consider the work significant, because there might be many settings in which integrated data about the same quantity (or related quantities) may come at different cost. There is no earlier method that allows to take several sources of data into account, and even though it is a fairly straightforward extension of multi-task models and inference on aggregated data, it is relevant.   MORE DETAILED COMMENTS: --INTRO & RELATED WORK: * Could you state somewhere early in the introduction that by "task" you mean "output"?  * Regarding the 3rd paragraph of the introduction and the related work section: They read unnaturally separated. The paragraph in the introduction reads very technical and it would be great if the authors could put more emphasis there in how their work differs from previous work and introduce just the main concepts (e.g. in what way multi-task learning differs from multiple instance learning). Much of the more technical assessment could go into the related work section (or partially be condensed).  --SECTION 2.3:  Section 2 was straightforward to follow up to 2.3 (SVI). From there on, it would be helpful if a bit more explanation was available (at the expense of parts of the related work section, for example). More concretely:    * l.145ff: $N_d$ is not defined. It would be good to state explicitely that there could be a different number of observations per task.    * l.145ff: The notation has confused me when first reading, e.g. $\mathbb{y}$ has been used in l.132 for a data vector with one observation per task, and in l.145 for the collection of all observations. I am aware that the setting (multi-task, multiple supports, different number of observations per task) is inherently complex, but it would help to better guide the reader through this by adding some more explanation and changing notation. Also l.155: do you mean the process f as in l.126 or do you refer to the object introduced in l.147?    * l.150ff: How are the inducing inputs Z chosen? Is there any effect of the integration on the choice of inducing inputs? l.170: What is z' here? Is that where the inducing inputs go?    * l.166ff: It would be very helpful for the reader to be reminded of the dimensions of the matrices involved.    * l.174 Could you explicitly state the computational complexity?     * Could you comment on the performance of this approximate inference scheme based on inducing inputs and SVI?  --EXPERIMENTS:   * synthetic data: Could you give an example what kind of data could look like this? In Figure 1, what is meant by "support data" and what by "predicted training count data"? Could you write down the model used here explicitly, e.g. add it to the appendix?    * Fertility rates:     - It is unclear to me how the training data is aggregated and over which inputs, i.e. what you mean by 5x5.    - Now that the likelihood is Gaussian, why not go for exact inference?    * Sensor network:    - l.283/4 You might want to emphasize here that CI give high accuracy but low time resolution results, e.g. "...a cheaper method for __accurately__ assessing the mass..."    - Again, given a Gaussian likelihood, why do you use inducing inputs? What is the trade-off (computational and quality) between using the full model and SVI?    - l.304ff: What do you mean by "additional training data"?    - Figure 3: I don't understand the red line: Where does the test data come from? Do you have a ground truth?   - Now the sensors are co-located. Ideally, you would want to have more low-cost sensors that high-cost (high accuracy) sensors in different locations. Do you have a thought on how you would account for spatial distribution of sensors?  --REFERENCES: * please make the style of your references consistent, and start with the last name.  Typos etc: ------------- * l.25 types of datasets * l.113 should be $f_{d'}(v')$, i.e. $d'$ instead of $d$ * l.282 "... but are badly bias" should be "is(?) badly biased" (does the verb refer to measurement or the sensor? Maybe rephrase.) * l.292 biased * Figure 3: biased, higher peaks, 500 with unit. * l.285 consisting of? Or just "...as observations of integrals" * l.293 these variables 