The paper considers learning a specific type of latent variable model from conditional independence relations, a latent polytree network.  The paper shows that when the underlying network has a tree structure and when certain degree conditions are met for the latent variables, the latent variable model can be exactly recovered.  They show the degree conditions are complete in the sense that when they are not met, there is a polytree network with fewer latent variables which satisfy the same conditional independence relations.    An algorithm is provided for learning latent polytrees when these conditions are met.  In general the paper is well written.  The results are novel, sound, and theoretically interesting.  The paper doesn't provide much motivation for the approach so it's difficult to gauge the significance. It's not completely obvious what a realistic scenario would be where you can assume both a tree structure and the given degree conditions on the latent nodes, but don't already understand the exact latent structure. No motivating examples were provided and there are no empirical results.