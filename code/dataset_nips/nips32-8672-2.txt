This paper addresses an interesting problem in word embedding: given a downstream *WORD-task* and its evaluation metric g, which subset of solutions of the original word embedding (WE) learning problem is performance-invariant to g? And can we improve WE's performance with respect to g?   Originality and Quality: The paper's analysis is relatively novel and insightful. To answer the raised questions, the paper considers a rather special linear case:  Latent Semantic Analysis (LSA) with the specific inner product metric g = <*, *>. The author provides a mathematical analysis about which transformation groups {C} to a WE solution V* will stay performance-invariant with respect to g and the reasoning given is solid. The author also conducts an investigation about the non-invariant transformation groups and discuss some of their mathematical properties (although not all of them are necessary).  In a word, Section 2 and 3 spark some deeper understanding of how a transformation on an existing WE solution will influence (or not influence) the g in WORD-tasks.  The writing is good and easy to follow.  Weakness: (1) Section 4.2 is a bit short and weak. Before reading this section I was expecting something like a more general solution rather than some short discussion about the existing special and simple method. (2) It would be great if the author could give further analysis (or at least a )that how the variance of different word embedding solutions may influence the performance in more complex *NON-WORD* tasks (not just word similarity measurement using <.,.>) as they are much more popular scenarios in practice.  