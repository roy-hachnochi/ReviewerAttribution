This paper presents solid theoretical work that is well written in clear, at least to the extent that is possible for a dense topic. It address relevant questions about generalization error for random projection combined with quantization and provides useful insights after each results. The choice of simple but meaningful models for which a broad set of people are likely to have decent intuition, also makes the work more accessible.  The paper is not without its shortcomings however. Most of which I cover in section 5 below. That being said I struggle with one of the key assumptions in the paper which is the fact that we can normalize all the data to the unit circle. The author(s) justification is that it is a “standard preprocessing step for many learning algorithms”. This certainly has not been my personal experience, as opposed to say mean/variance or min/max normalization. For high dimensional data I can conceive this transformation to be a reasonable choice, but I definitely feel it requires more than a passing mention. It either needs established references or a separate analysis, potentially empirical, of how this affects performance. 