This paper proposed a variant of gradient checkpointing algorithm that recursively applies checkpointing to derive a O(log n) memory cost for general computational graphs.  First of all, I do believe that the general treatment of tree decomposition for computational memory optimization is valuable. Although some of that was also mentioned in the previous works (e.g. the tensorflow gradient checkpointing blog-post). It is helpful to have papers to formally summarize the algorithms.   The authors uses “materialization” (comes from database systems) while most existing works uses gradient checkpointing (a terminology in AD). I think it would be helpful to clarify the relations of these terminologies to give readers a better context, as they are essentially the same thing.  Given that recomputation trades computation for more memory, the authors should also list the additional computing cost besides the memory usage -- given that the recursive algorithm pays additional computing cost to save memory. I am not sure if we want to go as far as the recursive approach to pay the additional computing to save more memories -- given the sqrt(n) time cost might be good enough for many cases. Some discussion around computing cost vs memory would be helpful.  Can the current algorithm be adapted to take a memory constraint into consideration to minimize the amount of compute needed for a memory constraint? 