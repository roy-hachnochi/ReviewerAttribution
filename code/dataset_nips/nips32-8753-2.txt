The paper concerns itself with whether it is feasible to use a pretrained language model as a universal decoder. To this end, it proposes an approach to forcing a pretrained language model to output a particular target sentence, by essentially adding a bias vector to the pretrained LM's hidden state at each time step. The paper shows that for sufficiently large pretrained LMs it is possible to optimize with respect to this bias vector such that a held-out target sentence can generally be decoded (using beam search) with high accuracy.   The paper is easy to follow, and the idea of a universal decoder is compelling (and likely to be on the minds of many NLP people), and so I think the results presented in this paper will have an impact. At the same time, the question of whether it will actually be practical to have a universal decoder remains unanswered, since (as the authors partially note) it is unclear whether a pretrained LM can generate text that is sufficiently different from that on which it was trained, it is unclear whether an encoder can mimic the optimization with respect to the z's (though it seems reasonable to be optimistic about this), and it is not clear whether the finite capacity of the z vectors will end up being a practical issue, especially for generating longer sentences.  The experiments are largely convincing. However, although it isn't completely clear, it sounds as though the beam search is carried out assuming the true length T, which may lead to an overly optimistic numbers. Similarly, it would be good to establish whether larger beams ever decrease performance (as they often do), which might be another reason for caution.     Update after response: thanks for the out-of-domain results and the beam search experiments. These results are certainly encouraging, and I continue to recommend acceptance.