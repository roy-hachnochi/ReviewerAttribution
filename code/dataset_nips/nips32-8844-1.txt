Overall the paper focuses on theoretic analysis of the expressive powers of RNN's in terms of generating a desired sequence, but does not provide any implementable strategies to improve over existing algorithms in terms of avoiding vanishing or explosive gradient.  Another concern is that ``generating desired output sequence'' may not be directly related to the generalization capacity of RNN in terms of predicting future signals, and so it would be more desirable if the analysis can bridge this gap.