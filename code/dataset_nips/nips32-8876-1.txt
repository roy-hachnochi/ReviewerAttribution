This paper studied an important problem regarding the representation power of GNN when learning graph topology. The paper first introduced graph moments, a key indicator for characterizing the random process of graph generation. Then they showed that a particular variant of GNN with linear activation function and graph filer D^{-1}A has issue in learning degree of a graph.  They further pointed the cause of the this limitation due to permutation invariant and then proposed a new modular GCN design. Some theoretical analysis is also provided regarding the graph moments. Some cases study are shown to justify the claims.   In general, this paper studied an important problem - understanding the power of GNN regarding its representation since GNN area has been fast growing in recent years. However, there are severe limitations of this paper:  1) It looks to me that authors try to use GNN for graph generation, which graph moments plays a key factor for characterizing this process. Authors pointed out a particular GNN variant with linear activation function and graph filter D^-1A as well as no node attributes has limitations in learning graph moments. However, this particular choices failed does not mean no GNN can do it. Especially, the chosen GNN variants seems like a very uncommon one.   2) Authors tried to connect the failures of a GNN variant in learning graph moments with the property that GNN needs to enforce node permutation invariant. And it seems to me that A_hat  =  D^-1A caused this issue. However, I have no idea how this conclusion is obtained. Not to mentioned that no GNN paper used D^-1A (but using D^-1/2AD^-1/2), why D^-1 A is associated with node permutation invariant. In fact, the node permutation invariant is typically enforced the node aggregation function (well discussed in GraphSAGE paper).   3) In lines 181-182, authors listed three popular GCN modules and which papers used them (GCN, graphSAGE, and GGNN). However, I did not see these papers used these three different graph operations, instead they only used f3 = D^-1/2AD^-1/2. I am a little supervised how authors get this conclusion. For the proposed GCN module, I did not see why these designs can help learn graph moments. Also, this design is just a simple variant of original GNN and I did not see any novel thing here. These designs have been used in many applications papers.   4) The experimental evaluations are weak. They are many graph generation papers in the literature both from conventional literature and recent GNN papers. But I didi not see any baselines there. 