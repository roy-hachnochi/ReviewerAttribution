1. Mentioning some solid motivations and practical usage of rotation and translation invariant latent variables would be helpful.  2. Not very clear where the MLP in Figure 1 is inserted within the VAE? A diagram of the overall architecture would be useful.  3. The method description is a bit too high level and sparse. Would be great to have some key implementation details.  4. Is Gaussian approximation appropriate for theta (i.e. angle)?  5. For the MNIST experiments, were three spatial VAEs built, one for each (transformed) MNIST dataset? How sensitive are the results to the choice on prior values, e.g. what happens if use the same value for prior on theta? Also, is setting D to 2, 3, and 5 reasonable? Based on just ELBO, seems like using higher D will do the trick. Hence, need to show usefulness of rotation and translation invariant latent variables.  6. All the nicely aligned images in Figures 4 to 6 are great, but what exactly can we extract from these? Some quantitative evaluation, and again demonstration of usefulness are highly needed.  ------ My comments have been satisfactorily addressed especially the point regarding quantitative evaluation. I have thus raised the score.