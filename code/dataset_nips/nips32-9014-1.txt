- Overall the paper provides a creative new approach to learning/inference for Markov random fields and provides a thorough empirical study of its behavior. The writing is very clear and notation is precise. - The approach draws inspiration from a variety of existing work and ties together ideas from both classical graphical models work and modern deep MRF learning. The key idea is to use an inference network that approximates the factor/variable marginals of the MRF and to obtain its parameters by minimizing the (approximate) BFE by gradient descent. This inference technique can be incorporated into learning via a saddle point min-max problem. The gradient based learning algorithm alternates between updating the parameters of the MRF are to minimize the negative log-likelihood and updating the parameters of the inference network to maximize the negative BFE. The simplicity of this approach and the fact that the inference network can be some GPU-friendly deep net makes this potentially faster than LBP. Although the resulting algorithm provides no bounds on the partition function (akin to LBP), its results suggest that it is a promising solution. The paper plays a nice trick by enforcing a local consistency constraint via a penalty term on the node marginals in order to maintain an algorithm that is linear (instead of quadratic) in the number of factors. - The experiments suggest that the approach is more efficient (computationally) than LBP and that it often learns to predict more accurate marginals than learning with other approximate inference algorithms (e.g. LBP, mean field). The paper explores approximations of both the fully-observed and partially-observed (i.e. marginal) likelihood. The Ising model experiments are carried out on synthetic data on models for which comparisons to exact inference (by variable elimination) are tractable. The RBM experiments compare on the UCI digits dataset with recent work on Neural Variational Inference (Kuleshov and Ermon, 2017). The HMM experiments explore both directed and underdirected equivalents of HMMs that include neural factors (a la. Tran et al.) and evaluate on a odd (i.e. 30 tags instead of 45, short sentences), but previously used POS tagging setting on the Penn Treebank -- this permits comparison with other VAE approaches on directed HMMs. - While the pairwise MRF doesn't reduce the generality of this approach, does doing so have potentially negative impacts on runtime? That is, might one prefer working with some (slightly) higher-order factors for some efficiency gains in the inference network? - It would be great if the statement on line 134-136 were expanded upon in the supplementary material. What would it look like to optimize in that subspace? Are there cases where it might actually be a good idea (even if more complicated to do so)? - Empirically, how well does the penalty term succeed in enforcing local consistency? - How important is using gradient descent (as opposed to say batch SGD)? That is, does learning become unstable if you are not amortizing over the training set? - Missed citation: In line 166, the paper notes "Second, we emphasize that...its gradients can be calculated exactly, which stands in contrast to much recent work". Stoyanov et al (AISTATS 2011) "Empirical Risk Minimization of Graphical Model Parameters Given Approximate Inference, Decoding, and Model Structure" presents an alternative LBP-based solution that also computes exact gradients of an approximate system. - Why are the inference networks different between the Ising and RBM experiments? Did the transformer or biLSTM perform better/worse on or the other? - Somewhat disappointingly the paper never mentions what hardware was used.