The paper focuses on the memorization capacity of ReLU networks. For 3-layer FNNs the authors tighten the bounds by some carefully constructed parameters to fit the dataset perfectly. As they point out, some related works focus on shallow networks and it could be hard to apply the analysis to more practical networks. The authors provide a lower bound for memorization capacity of deeper networks, by using a set of 3-layer FNNs as blocks in the proofs. To the best of my knowledge, the result is novel.  The paper is structured clearly and easy to follow. I enjoyed reading the paper. 