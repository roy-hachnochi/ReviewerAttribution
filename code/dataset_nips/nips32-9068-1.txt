POST REBUTTAL UPDATE: I thank the reviewers for their detailed rebuttal. I agree with the argument for CCA usage.    Artificial neural networks – both feedforward and recurrent – are increasingly being used in neuroscience as hypothesis generators. That is, networks are trained on cognitive-like tasks, and then aspects of the artificial network are compared to biology. Despite the increasing usage of this approach, there are very few systematic efforts to understand the “rules of the game”. The present contribution is thus a very timely systematic investigation of which aspects of trained RNNs are variant and which are invariant. Specifically, the authors compare a “tensor” of (architecture * task * analysis method). They conclude that network geometry, as assessed by CCA is highly architecture dependent. In contrast, fixed point topology is mostly task dependent.  Major comments: 1. The tasks used seem to have only one possible solution strategy, and thus the topology result could be somewhat trivial. Is that indeed the case? Can different tasks break this? 2. CCA assumes linearity. RNNs are nonlinear. Did you try a nonlinear method? Minor comments: 3. Related work and line 60-61 “theoretical clarity… completely lacking”. While there is very little theory, there is some that could be relevant [1]–[3]. 4. Page footer is NeurIPS 2018 5. K bit flip-flop. Input statistics (rate) are not specified 6. MDS graphs (e.g. figure 1D) : Perhaps I’m missing something, but I expected to see the same distribution of points colored differently in the left and right parts of the panel. The text says that you used a similarity matrix between all networks to construct the MDS space, and then projected to 2D. This should give a scatter of uncolored points, that you can later color according to tanh/relu or architecture. 7. Figure 1C : axes labels, colorbar – either on the figure, or in the caption. Are the networks ordered according to clustering? According to MDS? 8. Figure 1E the graph looks undirected, which is misleading. 9. Line 211, Figure 2F : “systematic differences” : Are there error bars? Is this reproducible? If so, can you hypothesize on mechanisms or implications? 10. Line 238 “that THE all” 11. Figure 4 : Was this effect similar for all configurations (task,architecture,unit type)? Or just relu/tanh in the contextual integration task?  [1] A. Rivkind and O. Barak, “Local Dynamics in Trained Recurrent Neural Networks,” Phys. Rev. Lett., vol. 118, no. 25, p. 258101, Jun. 2017. [2] F. Mastrogiuseppe and S. Ostojic, “Linking Connectivity, Dynamics, and Computations in Low-Rank Recurrent Neural Networks,” Neuron, vol. 99, no. 3, pp. 609-623.e29, Aug. 2018. [3] F. Mastrogiuseppe and S. Ostojic, “A Geometrical Analysis of Global Stability in Trained Feedback Networks,” Neural Comput., vol. 31, no. 6, pp. 1139–1182, Apr. 2019.  