The authors propose the first end-to-end learning model for protein interface prediction, the Siamese Atomic Surfacelet Network (SASNet). The novelty of the method is that it only uses spatial coordinates and identities of atoms as inputs, instead of relying on hand-crafted features. The authors also introduce the Dataset of Interacting Protein Structures (DIPS) which increases the amount of binary protein interactions by two orders of magnitude over previously used datasets (DB5). The results outperform state-of-the-art methods when trained on the much larger DIPS dataset and are still comparable when trained on the DB5 dataset, showing robustness when trained on bound or unbound proteins.  The paper is very well written and easy to follow. The problem is well characterised and the contributions and differences with state-of-the-art methods are very clear.   Originality: This work is a novel combination of well-known techniques. It combines Siamese networks with 3D convolutional neural networks and minimises the binary cross entropy loss, as opposed to minimising the Euclidean distance as in classical Siamese approaches.  This work is clearly separated from previous works and the contribution is well explained.  Quality: The claims in the paper are well supported by experimental analysis. There is no mathematical notation or definitions in the paper, however the architecture of the model is well described. The authors also mention that their method lacks scalability as they can only train on 3% of the data but show how the performance would keep increasing as the data size increases.  Clarity: The paper is very well written and organised. It is very easy to follow and gives detailed information about the model. The problem is very clear and the contribution well defined.  Significance: This work does not require hand-crafted features since it is an end-to-end framework. The method modestly outperforms competitors, but the authors show that there is a lot of room for improvement that could originate from the sheer amount of data.  Other comments: • For figure 2-E the 3D representation of the surfacelet is a bit confusing, since it seems like it is just a projection of the surfacelet in 2D, but that is not the case from what I understood when reading. No depth is depicted in the second cube in the figure. A more appropriate 3D figure could improve the understanding of the representation. • I believe that the second column in Table 3 should be DB5 trained instead of DB4 trained. Numbers are the same as Table 2 where performance was calculated from training on DB5. It could be possible that the reported number is the performance on the validation set from DB4. • In section 5.1 authors define CAUROC as the median per-Complex AUROC. Is this only used for the test set? In the caption of Table 2 the mean and standard deviation is reported across training seeds, but CAUROC is the column name.  • The same problem happens for Figure 3 where the label for the y-axis is CAUROC but what we see there is the Mean AUROC and standard deviation. • For figure 3 it would be nice to see the CAUROC for the test set, so that the plot reaches 0.9 as reported in the results. Also, for the grid edge size, it seems like 27 should provide a more robust choice given the very small deviation. • 194: “we use a siamese-like networks where we…” should read: we use Siamese-like networks, or we use a Siamese-like network. 