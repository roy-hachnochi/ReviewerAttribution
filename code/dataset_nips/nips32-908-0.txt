This paper asks how a player should exploit knowledge that their opponent in a repeated game is using a no-regret learning algorithm.  Prior work has studied this question in Bayesian settings, such as when the learning player is a buyer and the rational player is a seller.  This question extends the ideas to a non-Bayesian setting.    In general, the rational player can guarantee the first-mover Stackelberg utility in the game.  That is, being rational against a no-regret learner is worth at least as much as going first in a Stackelberg game.  If the learning is using a "mean-based" learning method, the rational player can obtain even more utility.  I like this paper.  The question of how to strategize vs a learning agent is a very hot topic.  The result that the rational player can guarantee their Stackelberg utility is quite easy to prove, but is a nice conceptual result none-the-less.  The authors also show that certain learning guarantees (no-swap-regret) prevent the rational player from getting more than this, which says something interesting about the use of no-swap-regret methods in competitive environments.  The result about improving on Stackelberg utility against mean-based learners is very similar to Braverman et al (2018), but applying these ideas in the non-Bayesian setting is a solid marginal contribution.  Overall, this paper makes a solid conceptual contribution in a hot area.  The marginal technical contributions are not especially deep, but on net the paper would be a good fit for NeurIPS.  I think the paper is a good candidate for acceptance. 