The paper titled “Exploring Algorithmic Fairness in Robust Graph Covering Problems” deals with the shortcomings of traditional and even state-of-the-art graph covering solutions that result in biased node coverage. The implication of which in the real world could be the marginalization of some minority group, negligence towards a social sector etc. Therefore, even though the paper is theoretically sound and mature, it has some excellent real world applications. This is discussed in precise details later in the review.  Briefly, the authors consider a network or graph of nodes/vertices where each node belongs to some group (race, gender etc.). The problem is to select a subset of the nodes that the authors call “monitors” (since they encompass neighboring nodes) along with the possibility that a fraction of them will fail to exist and thus the coverage by the failing nodes will be diminished. The success case is when a node is selected to be a non-failing monitor then that node’s neighbors would be covered by that node. The final objective is to maximize the coverage in the worst case scenario subject to a given fairness fraction (which is fixed by the authors) across the groups of nodes. If one considers the nodes to be people and neighboring nodes of a particular node to be friends, this essentially turns the graph into a social network and that is exactly the path the authors took to analyze the algorithm and methodology where groups are different ‘races’ of people in a community homeless shelter.  Significance: The significance of this algorithmic methodology is very high as this paves the way for future researchers to adopt this approach since the proposed method is dataset independent. The implications of the embedding fairness constraints in a graph covering problem can be applied in epidemiology, fairness in media coverage, resource allocation, benefit disbursals in large scale corporations, only to name a few. This is possibly the strongest impact of the paper i.e. the openness of the approach to a variety of domains.  Originality: Considering the originality, the paper is undoubtedly quite unique since it amalgamates a well-studied problem in computer science (graph covering) with group fairness constraints. This is further propounded by the authors since they very legitimately discuss the importance of this work using a social network dataset of a homeless shelter which has multiple races, genders etc. and show how the node coverage of such groups fail to be fair using existing graph covering algorithms. In terms of impact of the real world, the authors also mention suicide monitoring, landslide assessment – that are of high significance in reality.  Besides the applications, the algorithmic approaches are also truly original. What stands out is the analysis of the problem where the authors first solve the problem of unfair node coverage in a social network by imposing a fairness constraint (by specifying that a fixed fraction of members of every group must be covered i.e. a lower bound – termed as RCfair in the paper) and then further analyze the problem to transform it into an MILP for the simplicity offered by Bender’s decomposition (termed as Theorem 1 in the paper).  A laudable work, in its own regard is the solution approach of a robust optimization approach for fair graph coverage i.e. Problem 3 using a two-step method. Then the authors reformulate it into Problem 4, which is a K-adaptability counterpart problem. But the authors do not stop there and simply solve the max-min-max optimization subject to several constraints; rather they take another leap to analyze it again to reformulate the same problem further into a moderately sized MILP. Therefore, the authors take three formulations on the same problem – which effectively shows the depth of analysis from the researchers. This is praiseworthy. To be more specific, the final reformulation (Theorem 1) i.e. formulation of an MILP makes the solution of the problem much simpler (if not fully tractable) and using the observation of symmetry in the solution space, the authors present a practically feasible solution to the problem presented.  Clarity: In terms of clarity, the authors have handled a complex problem in a very clear and comprehensible manner from the very beginning of the Abstract till the end. There are some minor caveats to the clarity which will be discussed in detail in Part 5 (Improvements) of the review.  The authors introduced the problem in plain terms, before moving on to explicitly discuss the impact and application of the theoretical aspects of the research before delving in the algorithmic detail. This approach in clarity is exemplary. More paper should be like this. It should be noted that the clarity and simplicity of the language at the beginning of the paper do not take away any merit of the algorithmic and theoretical work presented in great detail in the latter part of the paper including the Appendix.  The organizational flow of the paper is also as vivid as it could be, given the complexity of the problem that is discussed.  Right after the introduction and literature review, the authors presented the formal formulation of the problem i.e. fair and robust graph covering problem. First, the authors formally introduced the problem where no fairness constraint is involved in the graph covering scenario as an optimization problem (called Problem RC in the paper). Then, the authors moved on to define the problem that is unique to this paper, which takes the group fairness into account (termed as RCfair). After formally formulating the problems and right before presenting the algorithmic solutions and approaches, the authors also defined the Price of Group Fairness (PoF) in Section 3 – which was aptly put in the right place. Here, authors discuss two type of PoF – deterministic case and uncertain case. In the first case, the authors assume that all monitoring (covering) nodes will survive whereas in the latter (uncertain) case, the authors defined the problem so that a particular number of nodes will fail with a given probability distribution. Both the cases are clearly defined in equation 2, Proposition 1 and Proposition 2. After all the formulations have been completed at this point, the authors moved on to the core solution approach(es) in section 4. Here, it should be noted that the authors should have indicated that the formulation of PoF and an extensive analysis of Section 2 of the paper is also presented in the Appendix. This would let the reader know that the theoretical proofs are also available. A list of all rooms for improvements are enumerated in Section 5 of the review.  It should also be noted that the authors very clearly discussed any and all assumptions that has been made. For example, in Assumption 1, the authors present the average complexity of the probability of the existence of an edge from one to another among the same group as the inverse of the size of the community. The author(s) also discuss the reasoning for their assumptions. For example, the reasoning for Assumption 1 (mentioned above) was due to the “homophily” phenomenon in sociology. This is splendid in terms of clarity and transparency from the author(s).  However, there were minor instances where there are some improvements of clarity. One such example is the range of lines from 280 to 283. It is not clear as to why the time limit was set to 2 hours. Was it for practical purposes or something else? It would have been better if it was clarified.  The Appendix section is praiseworthy because it tackles every proposition, lemma and proof presented in the original paper. It is also done in great attention to detail. While there are some minor rooms for improvement, the Appendix is splendid.   Some more rooms for improvement on clarity is given in section 5 (Improvements) of the review.  Quality: The algorithmic formulations are very clearly presented – from problem formulation to reformulation into different schemes and the final solution. At the very start of the solution approach, the authors very clearly state that the solution will be done in three stages and also provides rational behind it i.e. the discontinuity of the objective function and the fact that it is non-linear, which they later reformulated into a linear problem by relaxing some constraints without losing the effective merit and significance.  The paper has impressive intellectual merit in the reformulation of the original problem using sound mathematical proofs and equations. For instance, in section 4, the authors reformulated the original problem into a two-stage robust problem in problem 3. Author(s) also showed a brief proof showing the equivalence of the original problem (RCfair) and problem 3 (which is a linear objective function). Next, the reformulated problem (problem 3’s objective function) is turned into a K-adaptability counteract problem and the authors generated K number of candidate covering schemes in the first stage and after revelation of the nodes that indeed does not fail (which is not known apriory), the best candidate is chosen. All of these processes are very clearly defined and expressed in detail in high quality of intellectual merit.   Then the authors presented possibly the most notable contribution to the problem i.e. the reformulation of the original RCfair  problem into a moderately sized MILP. This follows from the previous reformulation of the K-adaptability problem (problem 4) – hence the flow remains coherent in the paper. This is presented using Theorem 1. Even though the mathematical formulation is clear and correct, it would have served well in terms of clarity to define each and every coefficients presented in Theorem 1. As such, a short explanation of the variables and coefficients in Theorem 1 in 2-3 sentences would remove the necessity to move to go on to the Appendix and the codes since the paper is so well written otherwise.  Following the reformulation into an MILP, the authors very clearly the utility of Bender’s decomposition in solving the problem. Moreover, one of the best contributions and observations of the paper is to notice that the solution space has a very useful symmetry i.e. all permutations of a set of feasible covering schemes are also feasible. They used this information to tackle the combinatorial explosion of solutions. Finally in the results section, firstly, the performance (coverage) of the approach is compared with several other approaches which showed its superiority in the cases where the candidate schemes (K) were 2 and 3 vs. Greedy approach and DC approach (along the lines of 17% and 24% respectively). Secondly, the authors compared the solver time between standard Bender’s decomposition and Boosted Bender’s decomposition (using the available information of symmetry to relax the problem). They showed significant speedup in convergence towards feasible solutions holding one group constant while varying the size of another group. In a different metric (Table 2), the authors showed the improvement of their approach in terms of coverage percentage along with PoF over the same dataset that was introduced in the motivation i.e. a social network of a homeless shelter as they varied the number of nodes that have an uncertainty level of failing, compared to exact optimal coverage and greedy heuristics. Hence, the results were clearly illustrated to portray the strength of the work.  It should be noted that the author(s) very honestly concur that in certain cases, the memory ran out which is reasonable. Even though it is understandable that the first formulation is intractable, there could have been a brief explanation of this along with the reasoning for memory overflow for K=2,3.   