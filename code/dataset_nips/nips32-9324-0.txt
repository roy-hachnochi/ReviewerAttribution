Detailed Comments:  Originality:  To the best of my knowledge, the distributional optimistic approach to approximating the likelihood function, based on constructing an uncertainly set and picking the most likely distribution in this set, is a novel and interesting idea. The idea borrows from the robust optimization community as well as the principle of optimism under uncertainty and is intuitively appealing.  Clarity:  The paper is for the most part written well and is well organized.  Quality/Significance:  To the best of my knowledge, the mathematical analysis and proofs are correct.  The paper importantly demonstrates that for several important choices of uncertainty sets (e.g., KL and Wasserstein divergences), the optimistic likelihood formulation reduces to a convex optimization problem. Moreover, in the cases of KL and Wasserstein, the paper shows that applying this technique within the ELBO problem for posterior inference has good theoretical asymptotic guarantees. The above two classes of results on reformulations and asymptotic properties are the  most important results to establish for this type of methodology, and it appears that the paper does a good job in establishing these results.  Finally, while the numerical experiments are largely illustrative on toy datasets, they do also provide some justification for applying this methodology for posterior inference.