<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!--><html lang="en"> <!--<![endif]-->

<head>

	<meta charset="utf-8">

	<title>Mark Silberstein, Professor | Publications   </title>

	<!-- Google Analytics -->
		<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

		ga('create', 'UA-164543670-1', 'auto');
		ga('send', 'pageview');
		</script>
	<!-- End Google Analytics -->
	  
	<meta name="description" content="">


	<link rel="shortcut icon" href="https://marksilberstein.com/wp-content/themes/acsl/img/favicon/favicon.ico" type="image/x-icon">
	<link rel="apple-touch-icon" href="https://marksilberstein.com/wp-content/themes/acsl/img/favicon/favicon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="https://marksilberstein.com/wp-content/themes/acsl/img/favicon/favicon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="https://marksilberstein.com/wp-content/themes/acsl/img/favicon/favicon-114x114.png">
	
	<link href="https://fonts.googleapis.com/css?family=Roboto:400,500,700" rel="stylesheet">
	<!--<link href="https://fonts.googleapis.com/css?family=Comfortaa:400,500,600,700&display=swap" rel="stylesheet">-->


	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- libs css -->
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/bootstrap/css/bootstrap-grid.min.css">
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/animate/animate.css">
	<link rel='stylesheet' href='https://marksilberstein.com/wp-content/themes/acsl/libs/smartmenus/css/sm-core-css.css' type='text/css' />
	<link rel='stylesheet' href='https://marksilberstein.com/wp-content/themes/acsl/libs/smartmenus/css/sm-clean/sm-clean.css' type='text/css' />
	<link rel='stylesheet' href='https://marksilberstein.com/wp-content/themes/acsl/libs/jquery.mmenu/jquery.mmenu.all.css' type='text/css' />
	<link rel='stylesheet' href='https://marksilberstein.com/wp-content/themes/acsl/libs/jquery.mmenu/hamburgers.css' type='text/css' />
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/magnific-popup/magnific-popup.css" type='text/css'>
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/jquery.keyboard-focus/w-i.css">
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/swiper/swiper.css" type="text/css">	
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/jquery-nice-select-1.1.0/nice-select.css">
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/remodal/dist/remodal.css"> 
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/libs/remodal/dist/remodal-default-theme.css">

	<!-- custom css -->
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/css/fonts.css" type='text/css' />
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/css/main.css" type='text/css' />
	<link rel='stylesheet' href='https://marksilberstein.com/wp-content/themes/acsl/css/sm-menu-cs.css' type='text/css' />
	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/css/media.css" type='text/css' />

	<link rel="stylesheet" href="https://marksilberstein.com/wp-content/themes/acsl/style.css?ver=1.62">

	

	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/modernizr/modernizr.js"></script>



</head>

<body >


	<header>

		<div class="top_bg">
			<div class="container">
				<a href="#main" id="scroll" style="display: none;" class="contains-image" aria-hidden="true"><span>Go Top</span></a>
				<a class="skip-main" href="#main" >Skip links to main content</a>
				<div class="header_wrapper">


					<div  class="ms_logo"  >
													<a  class="contains-image"  id="logomark" href="https://marksilberstein.com" >
								<img src="https://marksilberstein.com/wp-content/themes/acsl/img/title-mark-silberstein.png" alt="Welcome to Mark Silberstein website!">
							</a>
						

					</div>
					<div  class="hdr_other_logos_wrapper"  >
						<div class="holr1">
							<div class="tf_logos_wrap">
								<div class="tc_logo">
									<a href="https://www.technion.ac.il/" target="_blank" class="contains-image" id="tchlogo"><img  src="https://marksilberstein.com/wp-content/themes/acsl/img/logo-technion.png" alt="Logo of Technion"></a>
								</div>
								<div class="hd_sep bee">
									<img  src="https://marksilberstein.com/wp-content/themes/acsl/img/logos-separator.png" alt="">
								</div>
								<div class="ee_logo">
									<a href="https://vee.technion.ac.il/" target="_blank" class="contains-image" id="eelogo"><img  src="https://marksilberstein.com/wp-content/themes/acsl/img/logo-ee.png" alt="Logo of EE"></a>
								</div>
								<div class="hd_sep">
									<img  src="https://marksilberstein.com/wp-content/themes/acsl/img/logos-separator.png" alt="">
								</div>
								<div class="acsl_logo">
									<a href="https://acsl.group/" target="_blank" class="contains-image" id="acsllogo"><img  src="https://marksilberstein.com/wp-content/themes/acsl/img/logo-acsl.png" alt="Logo of ACSL"></a>
								</div>									
							</div>
						</div>
						<div class="holr2">
							<div class="hdr_icon_wrap">
								<div class="icon1">
									<a href="https://marksilberstein.com" id="ich" class="contains-image">
										<img src="https://marksilberstein.com/wp-content/themes/acsl/img/menu-icon-home.png" alt="">
										<div>Home</div>
									</a>
								</div>
								<div class="icon2">
									<a href="https://marksilberstein.com/contact-us/" id="ieml" class="contains-image">
										<img src="https://marksilberstein.com/wp-content/themes/acsl/img/menu-icon-e-mail.png" alt="e-mail">
										<div>Contact Us</div>
									</a>
								</div>
							</div>							
						</div>
					</div>
				</div>
			</div>
		</div>

	<div class="menu_wrapper" id="main_nav">
			<div class="main_nav">
				<div class="container">
				<div id='mobile-menu'></div>
				<!-- Mobile menu toggle button (hamburger/x icon) -->
				<div class="mobile-menu-toggle">
					<button class="hamburger hamburger--spin" type="button" aria-label="Menu" aria-controls="navigation">
					  <span class="hamburger-box">
					  	<span class="hamburger-inner"></span>
					  </span>
					</button>
				</div>

					<!-- Main menu -->
					<nav id="navigation">
						<div class="main-menu-wrapper" id="main-menu-wrapper">
							
							<ul id="main-menu" class="sm sm-clean" ><li id="menu-item-644" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-644 menu-item-home first-menu-item"><a href="https://marksilberstein.com/">Home</a></li>
<li id="menu-item-29" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-29 menu-item-about-me "><a href="https://marksilberstein.com/about-me/">About Me</a></li>
<li id="menu-item-32" class="menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-14 current_page_item menu-item-32 menu-item-publications "><a href="https://marksilberstein.com/publications/" aria-current="page">Publications</a></li>
<li id="menu-item-462" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-462 menu-item-talks "><a href="https://marksilberstein.com/talks/">Talks</a></li>
<li id="menu-item-463" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-463 menu-item-students "><a target="_blank" rel="noopener noreferrer" href="https://acsl.group//team/">Students</a></li>
<li id="menu-item-464" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-464 menu-item-prospective-students "><a href="https://marksilberstein.com/prospective-students/">Prospective Students</a></li>
<li id="menu-item-1407" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-1407 menu-item-teaching "><a href="https://marksilberstein.com/teaching/">Teaching</a></li>
<li id="menu-item-28" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-28 menu-item-undergraduate-projects "><a target="_blank" rel="noopener noreferrer" href="https://acsl.group/research/">Projects</a>
<ul class="sub-menu">
	<li id="menu-item-468" class="menu-item menu-item-type-custom menu-item-object-custom menu-item-468 menu-item-ongoing "><a target="_blank" rel="noopener noreferrer" href="https://acsl.group//research/">Ongoing</a></li>
	<li id="menu-item-469" class="menu-item menu-item-type-post_type menu-item-object-page menu-item-469 menu-item-past last-menu-item"><a href="https://marksilberstein.com/undergraduate-projects/past/">Past</a></li>
</ul>
</li>
</ul>
						</div>
					</nav>

				<div class="header_icons"></div>
			</div><!-- container -->
			<div class="menu_bottom_line"></div>
		</div>
	</div>

	</header>



		
		<main id="main">

	        						

				<!-- .content -->
				<div class="container main_content_wrapper">
					<div class="page_main_content">

						<div class="pheader_wrapper">
							<div class="h1hdr_line_wraper">

								<div class="h1mp1">
									<h1 class="h1mp11m">
																				<span class="h1mp32 h1c2">Publications</span>
									</h1>
								</div>
							</div>
						</div>

						<div class="clearfix"></div>
						<div class="editor_content">
							
							<div class="publ_all_wrapper">

							<div class="res_all_wrapper">

								<div class="rsm_main_wrapper">
									<div class="rsm_wrapper">
										<label for="prys">By Year: </label>
										<select class="n_sel yrsel" id="prys"><option value="2020">2020</option><option value="2019">2019</option><option value="2018">2018</option><option value="2017">2017</option><option value="2016">2016</option><option value="2014">2014</option><option value="2013">2013</option><option value="2012">2012</option><option value="2011">2011</option><option value="2010">2010</option><option value="2009">2009</option><option value="2008">2008</option><option value="2006">2006</option><option value="2004">2004</option>						</select>
									</div>
									<div class="publ_menu_opt"><a href="https://marksilberstein.com/publications/?mod=1">By Research Area</a></div>
								</div>

								<div class="clearfix"></div><div class="publ_content_wrap"><div class="ra_mpart_wrap"> <h2 id="2020">2020</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1438"><span class="pbl_akr">[WACI]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/05/Putting_Bugs_in_Your_DC_Might_Actually_be_a_Good_Idea_WACI.pdf" target="_blank">Putting Bugs in Your Data Center Might Actually be a Good Idea</a></span><div class="pbl_nstring2"><a href="#" title="abstract" data-remodal-target="modal1_1438" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Putting Bugs in Your Data Center Might Actually be a Good Idea"></a><div class="remodal" data-remodal-id="modal1_1438" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Putting Bugs in Your Data Center Might Actually be a Good Idea</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Data centers of cloud providers hold millions of processor<br />
cores, exabytes of storage, and petabytes of network bandwidth.<br />
Research shows that in 2019, data centers consumed<br />
more than 2% of global electricity production, where 50% of<br />
consumption targeted for cooling infrastructures. While the<br />
most effective solution for thermal distribution is liquid cooling,<br />
technical challenges and complexities make it expensive.<br />
We suggest using living spiders as cooling devices for data<br />
centers. A prior work shows that spider silk has high thermal<br />
conductivity, close to that of copper: the second-best metallic<br />
conductor. Spiders not only generate spider silk but maintain<br />
it. Recruiting spiders for the job requires no more than inserting<br />
bugs to the data center for the spiders to catch. This<br />
solution is effective, self-sustaining, and environment-friendly,<br />
but requires solving a number of non-trivial technical and<br />
zoological challenges on the way to make it practical.</p>
</div></div><a title="video" href="https://www.youtube.com/watch?v=8V1DyzX8JMA&#038;t=2901"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for Putting Bugs in Your Data Center Might Actually be a Good Idea"></a> </div><div class="pbl_astring"><span class="pblempta">Alon Rashelbach</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1106"><span class="pbl_akr">[EuroSys]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/02/eurosys20-final310.pdf" target="_blank">Autarky: Closing controlled channels with self-paging enclaves</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1106" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Autarky: Closing controlled channels with self-paging enclaves"></a><div class="remodal" data-remodal-id="modal0_1106" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Autarky: Closing controlled channels with self-paging enclaves</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{ autarky20eurosys,
<br>authors={ Orenbach, Meni and  Baumann, Andrew and  Silberstein, Mark},
<br>title = {{Autarky: Closing controlled channels with self-paging enclaves},
<br>booktitle={ Fifteenth European Conference on Computer Systems, Heraklion, Greece},
<br>series= {EuroSys ’20},
<br>year= {2020},
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1106" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Autarky: Closing controlled channels with self-paging enclaves"></a><div class="remodal" data-remodal-id="modal1_1106" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Autarky: Closing controlled channels with self-paging enclaves</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>As the first widely-deployed secure enclave hardware, Intel SGX shows promise as a practical basis for confidential cloud computing. However, side channels remain SGX’s greatest security weakness. In particular, the “controlled-channel attack” on enclave page faults exploits a longstanding architectural side channel and still lacks effective mitigation.</p>
<p>We propose Autarky: a set of minor, backward-compatible modifications to the SGX ISA that hide an enclave’s page access trace from the host, and give the enclave full control over its page faults. A trusted library OS implements enclave self-paging policy.</p>
<p>We prototype Autarky on current SGX hardware and the Graphene library OS, implementing three paging schemes: a fast software oblivious RAM system made practical by leveraging the proposed ISA, a novel page cluster abstraction for application-aware secure self-paging, and a rate-limiting paging mechanism for unmodified binaries. Overall, Autarky provides a comprehensive defense for controlled-channel attacks which supports efficient secure demand paging, and adds no overheads in page-fault free execution.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{ autarky20eurosys,
<br>authors={ Orenbach, Meni and  Baumann, Andrew and  Silberstein, Mark},
<br>title = {{Autarky: Closing controlled channels with self-paging enclaves},
<br>booktitle={ Fifteenth European Conference on Computer Systems, Heraklion, Greece},
<br>series= {EuroSys ’20},
<br>year= {2020},
<br>}</div></div><a title="slides" href="https://www.eurosys2020.org/wp-content/uploads/2020/04/slides/310_orenbach_slides.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Autarky: Closing controlled channels with self-paging enclaves"></a> <a title="video" href="https://www.youtube.com/watch?v=Jkgx3Pai2Yo"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for Autarky: Closing controlled channels with self-paging enclaves"></a> </div><div class="pbl_astring"><a href="https://shmeni.github.io/" target="_blank">Meni Orenbach</a>, <a href="https://www.microsoft.com/en-us/research/people/baumann/" target="_blank">Andrew Baumann</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1098"><span class="pbl_akr">[SIGCOMM]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/pdf/10.1145/3387514.3405886" target="_blank">A computational approach to packet classification</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1098" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for A computational approach to packet classification"></a><div class="remodal" data-remodal-id="modal0_1098" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">A computational approach to packet classification</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{Rashebach2020SIGCOMM,
<br>author = {Rashelbach, Alon and Rottenstreich, Ori and Silberstein, Mark},
<br>title = {A Computational Approach to Packet Classification},
<br>year = {2020},
<br>isbn = {9781450379557},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3387514.3405886},
<br>doi = {10.1145/3387514.3405886},
<br>booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
<br>pages = {542–556},
<br>numpages = {15},
<br>keywords = {Packet Classification, Virtual Switches, Neural Networks},
<br>location = {Virtual Event, USA},
<br>series = {SIGCOMM ’20}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1098" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for A computational approach to packet classification"></a><div class="remodal" data-remodal-id="modal1_1098" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">A computational approach to packet classification</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Multi-field packet classification is a crucial component in modern software-defined data center networks. To achieve high throughput and low latency, state-of-the-art algorithms strive to fit the rule lookup data structures into on-die caches; however, they do not scale well with the number of rules. We present a novel approach, NuevoMatch, which improves the memory scaling of existing methods. A new data structure, Range Query Recursive Model Index (RQ-RMI), is the key component that enables NuevoMatch to replace most of the accesses to main memory with model inference computations. We describe an efficient training algorithm which guarantees the correctness of the RQ-RMI-based classification. The use of RQ-RMI allows the packet rules to be compressed into model weights that fit into the hardware cache and takes advantage of the growing support for fast neural network processing in modern CPUs, such as wide vector processing engines, achieving a rate of tens of nanoseconds per lookup. Our evaluation using 500K multi-field rules from the standard ClassBench benchmark shows a geomean compression factor of 4.9X, 8X, and 82X, and average performance improvement of 2.7X, 4.4X and 2.6X in latency and 1.3X, 2.2X, and 1.2X in throughput compared to CutSplit, NeuroCuts, and TupleMerge, all state-of-the-art algorithms.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{Rashebach2020SIGCOMM,
<br>author = {Rashelbach, Alon and Rottenstreich, Ori and Silberstein, Mark},
<br>title = {A Computational Approach to Packet Classification},
<br>year = {2020},
<br>isbn = {9781450379557},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3387514.3405886},
<br>doi = {10.1145/3387514.3405886},
<br>booktitle = {Proceedings of the Annual Conference of the ACM Special Interest Group on Data Communication on the Applications, Technologies, Architectures, and Protocols for Computer Communication},
<br>pages = {542–556},
<br>numpages = {15},
<br>keywords = {Packet Classification, Virtual Switches, Neural Networks},
<br>location = {Virtual Event, USA},
<br>series = {SIGCOMM ’20}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/02/A-Computational-Approach-to-Packet-Classification-Long.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for A computational approach to packet classification"></a> <a title="video" href="https://dl.acm.org/doi/abs/10.1145/3387514.3405886"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for A computational approach to packet classification"></a> <a title="code" href="https://github.com/acsl-technion/nuevomatch" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for A computational approach to packet classification"></a> </div><div class="pbl_astring"><span class="pblempta">Alon Rashelbach</span>, <a href="https://sites.google.com/site/orirottenstreich/" target="_blank">Ori Rottenstreich</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p782"><span class="pbl_akr">[USENIX Security]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://www.usenix.org/system/files/sec20-oleksenko.pdf" target="_blank">SpecFuzz: Bringing Spectre-type vulnerabilities to the surface</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_782" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for SpecFuzz: Bringing Spectre-type vulnerabilities to the surface"></a><div class="remodal" data-remodal-id="modal0_782" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">SpecFuzz: Bringing Spectre-type vulnerabilities to the surface</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@Inproceedings{SpeckFuzz20UsenixSec,
<br>author = {Oleksii Oleksenko and Bohdan Trach and Mark Silberstein and Christof Fetzer},
<br>title = {SpecFuzz: Bringing Spectre-type vulnerabilities to the surface},
<br>booktitle = {29th {USENIX} Security Symposium ({USENIX} Security 20)},
<br>year = {2020},
<br>isbn = {978-1-939133-17-5},
<br>pages = {1481--1498},
<br>url = {https://www.usenix.org/conference/usenixsecurity20/presentation/oleksenko},
<br>publisher = {{USENIX} Association},
<br>month = aug,
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_782" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for SpecFuzz: Bringing Spectre-type vulnerabilities to the surface"></a><div class="remodal" data-remodal-id="modal1_782" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">SpecFuzz: Bringing Spectre-type vulnerabilities to the surface</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p><span style="color: #000000; font-family: 'Lucida Grande', helvetica, arial, verdana, sans-serif; font-size: 13.608px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">SpecFuzz is the first tool that enables dynamic testing for speculative execution vulnerabilities (e.g., Spectre). The key is a novel concept of speculation exposure: The program is instrumented to simulate speculative execution in software by forcefully executing the code paths that could be triggered due to mispredictions, thereby making the speculative memory accesses visible to integrity checkers (e.g., AddressSanitizer). Combined with the conventional fuzzing techniques, speculation exposure enables more precise identification of potential vulnerabilities compared to state-of-the-art static analyzers.</span><br style="color: #000000; font-family: 'Lucida Grande', helvetica, arial, verdana, sans-serif; font-size: 13.608px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial;" /><span style="color: #000000; font-family: 'Lucida Grande', helvetica, arial, verdana, sans-serif; font-size: 13.608px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">Our prototype for detecting Spectre V1 vulnerabilities successfully identifies all known variations of Spectre V1 and decreases the mitigation overheads across the evaluated applications, reducing the amount of instrumented branches by up to 93% given a sufficient test coverage.</span></p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@Inproceedings{SpeckFuzz20UsenixSec,
<br>author = {Oleksii Oleksenko and Bohdan Trach and Mark Silberstein and Christof Fetzer},
<br>title = {SpecFuzz: Bringing Spectre-type vulnerabilities to the surface},
<br>booktitle = {29th {USENIX} Security Symposium ({USENIX} Security 20)},
<br>year = {2020},
<br>isbn = {978-1-939133-17-5},
<br>pages = {1481--1498},
<br>url = {https://www.usenix.org/conference/usenixsecurity20/presentation/oleksenko},
<br>publisher = {{USENIX} Association},
<br>month = aug,
<br>}</div></div><a title="slides" href="https://www.usenix.org/system/files/sec20_slides_oleksenko.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for SpecFuzz: Bringing Spectre-type vulnerabilities to the surface"></a> <a title="video" href="https://www.usenix.org/conference/usenixsecurity20/presentation/oleksenko"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for SpecFuzz: Bringing Spectre-type vulnerabilities to the surface"></a> <a title="code" href="https://github.com/tudinfse/SpecFuzz" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for SpecFuzz: Bringing Spectre-type vulnerabilities to the surface"></a> </div><div class="pbl_astring"><a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/beschaeftigte/oleksii-oleksenko" target="_blank">Oleksii Oleksenko</a>, <a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/beschaeftigte/bohdan-trach" target="_blank">Bohdan Trach</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/inhaber-in" target="_blank">Christof Fetzer</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1115"><span class="pbl_akr">[ASPLOS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/02/lynx_asplos20.pdf" target="_blank">Lynx: a SmartNIC-driven accelerator-centric architecture for network servers</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1115" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Lynx: a SmartNIC-driven accelerator-centric architecture for network servers"></a><div class="remodal" data-remodal-id="modal0_1115" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Lynx: a SmartNIC-driven accelerator-centric architecture for network servers</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{lynx20Tork,
<br>author = {Tork, Maroun and Maudlej, Lina and Silberstein, Mark},
<br>title = {Lynx: A SmartNIC-Driven Accelerator-Centric Architecture for Network Servers},
<br>year = {2020},
<br>isbn = {9781450371025},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3373376.3378528},
<br>doi = {10.1145/3373376.3378528},
<br>booktitle = {Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
<br>pages = {117–131},
<br>numpages = {15},
<br>keywords = {server architecture, hardware accelerators, smartnics, i/o services for accelerators, operating systems},
<br>location = {Lausanne, Switzerland},
<br>series = {ASPLOS ’20}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1115" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Lynx: a SmartNIC-driven accelerator-centric architecture for network servers"></a><div class="remodal" data-remodal-id="modal1_1115" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Lynx: a SmartNIC-driven accelerator-centric architecture for network servers</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>This paper explores new opportunities afforded by the growing deployment of compute and I/O accelerators to improve the performance and efficiency of hardware-accelerated com-<br />
puting services in data centers.</p>
<p>We propose Lynx, an accelerator-centric network server architecture that offloads the server data and control planes to the SmartNIC, and enables direct networking from accelerators via a lightweight hardware-friendly I/O mechanism. Lynx enables the design of hardware-accelerated network servers that run without CPU involvement, freeing CPU cores and improving performance isolation for accelerated services. It is portable across accelerator architectures and allows the management of both local and remote accelerators, seamlessly scaling beyond a single physical machine.</p>
<p>We implement and evaluate Lynx on GPUs and the Intel Visual Compute Accelerator, as well as two SmartNIC architectures – one with an FPGA, and another with an 8-core ARM processor. Compared to a traditional host-centric approach, Lynx achieves over 4× higher throughput for a GPU-centric face verification server, where it is used for GPU communications with an external database, and 25% higher throughput for a GPU-accelerated neural network inference service. For this workload, we show that a single SmartNIC may drive 4 local and 8 remote GPUs while achieving linear performance scaling without using the host CPU.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{lynx20Tork,
<br>author = {Tork, Maroun and Maudlej, Lina and Silberstein, Mark},
<br>title = {Lynx: A SmartNIC-Driven Accelerator-Centric Architecture for Network Servers},
<br>year = {2020},
<br>isbn = {9781450371025},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3373376.3378528},
<br>doi = {10.1145/3373376.3378528},
<br>booktitle = {Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
<br>pages = {117–131},
<br>numpages = {15},
<br>keywords = {server architecture, hardware accelerators, smartnics, i/o services for accelerators, operating systems},
<br>location = {Lausanne, Switzerland},
<br>series = {ASPLOS ’20}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/02/1105-Lynx-final.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Lynx: a SmartNIC-driven accelerator-centric architecture for network servers"></a> <a title="video" href="https://www.youtube.com/watch?v=W-PUkuY7zYQ"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for Lynx: a SmartNIC-driven accelerator-centric architecture for network servers"></a> </div><div class="pbl_astring"><a href="https://www.linkedin.com/in/maroun-tork-807a44a0" target="_blank">Maroun Tork</a>, <span class="pblempta">Lina Maudlej</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2019">2019</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1383"><span class="pbl_akr">[ACM TOCS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/3309987" target="_blank">SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1383" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs"></a><div class="remodal" data-remodal-id="modal0_1383" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{spin19TOCS,
<br>author = {Bergman, Shai and Brokhman, Tanya and Cohen, Tzachi and Silberstein, Mark},
<br>title = {SPIN: Seamless Operating System Integration of Peer-to-Peer DMA Between SSDs and GPUs},
<br>year = {2019},
<br>issue_date = {April 2019},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>volume = {36},
<br>number = {2},
<br>issn = {0734-2071},
<br>url = {https://doi.org/10.1145/3309987},
<br>doi = {10.1145/3309987},
<br>journal = {ACM Trans. Comput. Syst.},
<br>month = apr,
<br>articleno = {Article 5},
<br>numpages = {26},
<br>keywords = {I/O subsystem, Accelerators, operating systems, file systems, GPU}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1383" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs"></a><div class="remodal" data-remodal-id="modal1_1383" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<div class="abstractSection abstractInFull">
<p>Recent GPUs enable Peer-to-Peer Direct Memory Access (<span class="smallcaps smallerCapital">p</span>2<span class="smallcaps smallerCapital">p</span>) from fast peripheral devices like NVMe SSDs to exclude the CPU from the data path between them for efficiency. Unfortunately, using <span class="smallcaps smallerCapital">p</span>2<span class="smallcaps smallerCapital">p</span> to access <i>files</i> is challenging because of the subtleties of low-level non-standard interfaces, which bypass the OS file I/O layers and may hurt system performance. Developers must possess intimate knowledge of low-level interfaces to manually handle the subtleties of data consistency and misaligned accesses.</p>
<p>We present <i>SPIN</i>, which integrates <span class="smallcaps smallerCapital">p</span>2<span class="smallcaps smallerCapital">p</span> into the standard OS file I/O stack, dynamically activating <span class="smallcaps smallerCapital">p</span>2<span class="smallcaps smallerCapital">p</span> where appropriate, transparently to the user. It combines <span class="smallcaps smallerCapital">p</span>2<span class="smallcaps smallerCapital">p</span> with page cache accesses, re-enables read-ahead for sequential reads, all while maintaining standard POSIX FS consistency, portability across GPUs and SSDs, and compatibility with virtual block devices such as software RAID.</p>
<p>We evaluate SPIN on NVIDIA and AMD GPUs using standard file I/O benchmarks, application traces, and end-to-end experiments. SPIN achieves significant performance speedups across a wide range of workloads, exceeding <span class="smallcaps smallerCapital">p</span>2<span class="smallcaps smallerCapital">p</span> throughput by up to an order of magnitude. It also boosts the performance of an aerial imagery rendering application by 2.6× by dynamically adapting to its input-dependent file access pattern, enables 3.3× higher throughput for a GPU-accelerated log server, and enables 29% faster execution for the highly optimized GPU-accelerated image collage with only 30 changed lines of code.</p>
</div>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{spin19TOCS,
<br>author = {Bergman, Shai and Brokhman, Tanya and Cohen, Tzachi and Silberstein, Mark},
<br>title = {SPIN: Seamless Operating System Integration of Peer-to-Peer DMA Between SSDs and GPUs},
<br>year = {2019},
<br>issue_date = {April 2019},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>volume = {36},
<br>number = {2},
<br>issn = {0734-2071},
<br>url = {https://doi.org/10.1145/3309987},
<br>doi = {10.1145/3309987},
<br>journal = {ACM Trans. Comput. Syst.},
<br>month = apr,
<br>articleno = {Article 5},
<br>numpages = {26},
<br>keywords = {I/O subsystem, Accelerators, operating systems, file systems, GPU}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="code" href="https://github.com/acsl-technion/spin" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs"></a> </div><div class="pbl_astring"><span class="pblempta">Shai Bergman</span>, <a href="https://www.linkedin.com/in/tanya-brokhman-828b803" target="_blank">Tanya Brokhman</a>, <span class="pblempta">Tsahi Cohen</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><div class="pbl_snotes">Extended version of the ATC'17 paper</div> </span></div></div><div class="publ_cart_wrapper" id="p779"><span class="pbl_akr">[PACT]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/01/08891620.pdf" target="_blank">Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_779" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur"></a><div class="remodal" data-remodal-id="modal0_779" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{8891620,
<br>author={A. {Watad} and A. {Libov} and O. {Shacham} and E. {Bortnikov} and M. {Silberstein}},
<br>booktitle={2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
<br>title={Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur},
<br>year={2019},
<br>volume={},
<br>number={},
<br>pages={245-257},
<br>keywords={concurrency (computers);file servers;graphics processing units;nearest neighbour methods;parallel processing;storage management;multiGPU distributed data flow runtime;GPU management overheads;CPU load;k-NN multiGPU network service;Centaur;GPU-centric architecture;network request processing;CPU-driven server architecture;k-nearest-neighbors network server;scalability;parallel computing;high-concurrency memory-demanding server applications;Graphics processing units;Servers;Kernel;Throughput;Clustering algorithms;Approximation algorithms;Computer architecture;GPU;Parallel Computing},
<br>doi={10.1109/PACT.2019.00027},
<br>ISSN={1089-795X},
<br>month={Sep.},}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_779" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur"></a><div class="remodal" data-remodal-id="modal1_779" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p><span style="color: #333333; font-family: sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">Centaur is a GPU-centric architecture for building a low-latency approximate k-Nearest-Neighbors network server. We implement a multi-GPU distributed data flow runtime which enables efficient and scalable network request processing on GPUs. The runtime eliminates GPU management overheads from the CPU, making the server throughput and response time largely agnostic to the CPU load, speed or the number of dedicated CPU cores. Our experiments systems show that our server achieves near-perfect scaling for 16 GPUs, beating the throughput of a highly-optimized CPU-driven server by 35% while maintaining about 2msec average request latency. Furthermore, it requires only a single CPU core to run, achieving over an order of magnitude higher throughput than the standard CPU-driven server architecture in this setting.</span></p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{8891620,
<br>author={A. {Watad} and A. {Libov} and O. {Shacham} and E. {Bortnikov} and M. {Silberstein}},
<br>booktitle={2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
<br>title={Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur},
<br>year={2019},
<br>volume={},
<br>number={},
<br>pages={245-257},
<br>keywords={concurrency (computers);file servers;graphics processing units;nearest neighbour methods;parallel processing;storage management;multiGPU distributed data flow runtime;GPU management overheads;CPU load;k-NN multiGPU network service;Centaur;GPU-centric architecture;network request processing;CPU-driven server architecture;k-nearest-neighbors network server;scalability;parallel computing;high-concurrency memory-demanding server applications;Graphics processing units;Servers;Kernel;Throughput;Clustering algorithms;Approximation algorithms;Computer architecture;GPU;Parallel Computing},
<br>doi={10.1109/PACT.2019.00027},
<br>ISSN={1089-795X},
<br>month={Sep.},}</div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/01/PACT-present.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Achieving Scalability in a k-NN Multi-GPU Network Service with Centaur"></a> </div><div class="pbl_astring"><a href="https://www.linkedin.com/in/amirwatad" target="_blank">Amir Watad</a>, <a href="https://alibov.cswp.cs.technion.ac.il/" target="_blank">Alexander Libov</a>, <a href="https://www.linkedin.com/in/ohad-shacham-a084741" target="_blank">Ohad Shacham</a>, <a href="https://www.linkedin.com/in/ebortnik" target="_blank">Edward Bortnikov</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p795"><span class="pbl_akr">[USENIX ATC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/01/atc19-brokhman.pdf" target="_blank">GAIA: An OS Page Cache for Heterogeneous Systems</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_795" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GAIA: An OS Page Cache for Heterogeneous Systems"></a><div class="remodal" data-remodal-id="modal0_795" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GAIA: An OS Page Cache for Heterogeneous Systems</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{10.5555/3358807.3358864,
<br>author = {Brokhman, Tanya and Lifshits, Pavel and Silberstein, Mark},
<br>title = {GAIA: An OS Page Cache for Heterogeneous Systems},
<br>year = {2019},
<br>isbn = {9781939133038},
<br>publisher = {USENIX Association},
<br>address = {USA},
<br>booktitle = {Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference},
<br>pages = {661–674},
<br>numpages = {14},
<br>location = {Renton, WA, USA},
<br>series = {USENIX ATC ’19}
<br>}
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_795" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GAIA: An OS Page Cache for Heterogeneous Systems"></a><div class="remodal" data-remodal-id="modal1_795" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GAIA: An OS Page Cache for Heterogeneous Systems</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p style="box-sizing: border-box; margin: 0px; color: #333333; font-family: Merriweather, serif; font-size: 17px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-style: initial; text-decoration-color: initial;">We propose a principled approach to integrating GPU memory with an OS page cache. We design <i style="box-sizing: border-box;">GAIA</i>, a weakly-consistent page cache that spans CPU and GPU memories. GAIA enables the standard mmap system call to map files into the GPU address space, thereby enabling data-dependent GPU accesses to large files and efficient write-sharing between the CPU and GPUs. Under the hood, GAIA (1) integrates lazy release consistency protocol into the OS page cache while maintaining backward compatibility with CPU processes and <i style="box-sizing: border-box;">unmodified</i> GPU kernels; (2) improves CPU I/O performance by using data cached in GPU memory, and (3) optimizes the readahead prefetcher to support accesses to files cached in GPUs.</p>
<p style="box-sizing: border-box; margin: 0px; color: #333333; font-family: Merriweather, serif; font-size: 17px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 300; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; text-decoration-style: initial; text-decoration-color: initial;">We prototype GAIA in Linux and evaluate it on NVIDIA Pascal GPUs. We show up to 3× speedup in CPU file I/O and up to 8× in <i style="box-sizing: border-box;">unmodified</i> realistic workloads such as Gunrock GPU-accelerated graph processing, image collage, and microscopy image stitching.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{10.5555/3358807.3358864,
<br>author = {Brokhman, Tanya and Lifshits, Pavel and Silberstein, Mark},
<br>title = {GAIA: An OS Page Cache for Heterogeneous Systems},
<br>year = {2019},
<br>isbn = {9781939133038},
<br>publisher = {USENIX Association},
<br>address = {USA},
<br>booktitle = {Proceedings of the 2019 USENIX Conference on Usenix Annual Technical Conference},
<br>pages = {661–674},
<br>numpages = {14},
<br>location = {Renton, WA, USA},
<br>series = {USENIX ATC ’19}
<br>}
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/01/atc19_slides_brokhman.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for GAIA: An OS Page Cache for Heterogeneous Systems"></a> <a title="video" href="https://youtu.be/zKjH6NTl5qI"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for GAIA: An OS Page Cache for Heterogeneous Systems"></a> <a title="code" href="https://github.com/acsl-technion/gaia" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for GAIA: An OS Page Cache for Heterogeneous Systems"></a> <a  title="Lightning Talk"  href="https://youtu.be/9uGCGVlP03A" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-other.gif" alt="Icon Other for GAIA: An OS Page Cache for Heterogeneous Systems"></a> </div><div class="pbl_astring"><a href="https://www.linkedin.com/in/tanya-brokhman-828b803" target="_blank">Tanya Brokhman</a>, <a href="https://www.linkedin.com/in/pavel-lifshits-3b36153" target="_blank">Pavel Lifshits</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p803"><span class="pbl_akr">[USENIX ATC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/01/atc19-orenbach.pdf" target="_blank">CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_803" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves"></a><div class="remodal" data-remodal-id="modal0_803" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {234958,
<br>author = {Meni Orenbach and Yan Michalevsky and Christof Fetzer and Mark Silberstein},
<br>title = {CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves},
<br>booktitle = {2019 {USENIX} Annual Technical Conference ({USENIX} {ATC} 19)},
<br>year = {2019},
<br>isbn = {978-1-939133-03-8},
<br>address = {Renton, WA},
<br>pages = {555--570},
<br>url = {https://www.usenix.org/conference/atc19/presentation/orenbach},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_803" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves"></a><div class="remodal" data-remodal-id="modal1_803" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p style="margin: 0px 0px 0.7em; color: #333333; font-family: 'Open Sans', Arial, Helvetica, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial;">Hardware secure enclaves are increasingly used to run complex applications. Unfortunately, existing and emerging enclave architectures do not allow secure and efficient implementation of custom page fault handlers. This limitation impedes in-enclave use of secure memory-mapped files and prevents extensions of the application memory layer commonly used in untrusted systems, such as transparent memory compression or access to remote memory.</p>
<p style="margin: 0px 0px 0.7em; color: #333333; font-family: 'Open Sans', Arial, Helvetica, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial;">CoSMIX is a Compiler-based system for Secure Memory Instrumentation and eXecution of applications in secure enclaves. A novel memory store abstraction allows implementation of application-level secure page fault handlers that are invoked by a lightweight enclave runtime. The CoSMIX compiler instruments the application memory accesses to use one or more memory stores, guided by a global instrumentation policy or code annotations without changing application code.</p>
<p style="margin: 0px 0px 0.7em; color: #333333; font-family: 'Open Sans', Arial, Helvetica, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial;">The CoSMIX prototype runs on Intel SGX and is compatible with popular SGX execution environments, including SCONE and Graphene. Our evaluation of several production applications shows how CoSMIX improves their security and performance by recompiling them with appropriate memory stores. For example, unmodified Redis and Memcached key-value stores achieve about 2× speedup by using a self-paging memory store while working on datasets up to 6× larger than the enclave’s secure memory. Similarly, annotating a single line of code in a biometric verification server changes it to store its sensitive data in Oblivious RAM and makes it resilient against SGX side-channel attacks.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {234958,
<br>author = {Meni Orenbach and Yan Michalevsky and Christof Fetzer and Mark Silberstein},
<br>title = {CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves},
<br>booktitle = {2019 {USENIX} Annual Technical Conference ({USENIX} {ATC} 19)},
<br>year = {2019},
<br>isbn = {978-1-939133-03-8},
<br>address = {Renton, WA},
<br>pages = {555--570},
<br>url = {https://www.usenix.org/conference/atc19/presentation/orenbach},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/01/atc19_slides_orenbach.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves"></a> <a title="video" href="https://youtu.be/KX1kZ80zGP8"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves"></a> <a title="code" href="https://github.com/acsl-technion/cosmix" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves"></a> <a  title="Lightning Talk"  href="https://youtu.be/JWyyPAiykoE" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-other.gif" alt="Icon Other for CoSMIX: A Compiler-based System for Secure Memory Instrumentation and Execution in Enclaves"></a> </div><div class="pbl_astring"><a href="https://shmeni.github.io/" target="_blank">Meni Orenbach</a>, <a href="https://www.michalevsky.com/" target="_blank">Yan Michalevsky</a>, <a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/inhaber-in" target="_blank">Christof Fetzer</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p816"><span class="pbl_akr">[USENIX ATC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/01/atc19-eran.pdf" target="_blank">NICA: An Infrastructure for Inline Acceleration of Network Applications</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_816" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for NICA: An Infrastructure for Inline Acceleration of Network Applications"></a><div class="remodal" data-remodal-id="modal0_816" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">NICA: An Infrastructure for Inline Acceleration of Network Applications</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {234884,
<br>author = {Haggai Eran and Lior Zeno and Maroun Tork and Gabi Malka and Mark Silberstein},
<br>title = {{NICA}: An Infrastructure for Inline Acceleration of Network Applications},
<br>booktitle = {2019 {USENIX} Annual Technical Conference ({USENIX} {ATC} 19)},
<br>year = {2019},
<br>isbn = {978-1-939133-03-8},
<br>address = {Renton, WA},
<br>pages = {345--362},
<br>url = {https://www.usenix.org/conference/atc19/presentation/eran},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_816" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for NICA: An Infrastructure for Inline Acceleration of Network Applications"></a><div class="remodal" data-remodal-id="modal1_816" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">NICA: An Infrastructure for Inline Acceleration of Network Applications</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p style="margin: 0px 0px 0.7em; color: #333333; font-family: 'Open Sans', Arial, Helvetica, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial;">With rising network rates, cloud vendors increasingly deploy FPGA-based SmartNICs (F-NICs), leveraging their <em>inline</em> processing capabilities to offload hypervisor networking infrastructure. However, the use of F-NICs for <em>accelerating general-purpose server applications in clouds</em> has been limited.</p>
<p style="margin: 0px 0px 0.7em; color: #333333; font-family: 'Open Sans', Arial, Helvetica, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial;"><strong>NICA</strong> is a hardware-software co-designed framework for inline acceleration of the application data plane on F-NICs in multi-tenant systems. A new <em>ikernel</em> programming abstraction, tightly integrated with the network stack, enables application control of F-NIC computations that process <em>application</em> network traffic, with minimal code changes. In addition, NICA’s virtualization architecture supports fine-grain time-sharing of F-NIC logic and provides I/O path virtualization. Together these features enable cost-effective sharing of F-NICs across virtual machines with strict performance guarantees.</p>
<p style="margin: 0px 0px 0.7em; color: #333333; font-family: 'Open Sans', Arial, Helvetica, sans-serif; font-size: 16px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial;">We prototype NICA on Mellanox F-NICs and integrate ikernels with the high-performance VMA network stack and the KVM hypervisor. We demonstrate significant acceleration of real-world applications in both bare-metal and virtualized environments, while requiring only minor code modifications to accelerate them on F-NICs. For example, a transparent key-value store cache ikernel added to the stock <code>memcached</code> server reaches 40 Gbps server throughput (99% line-rate) at 6 μs 99th-percentile latency for 16-byte key-value pairs, which is 21× the throughput of a 6-core CPU with a kernel-bypass network stack. The throughput scales linearly for up to 6 VMs running independent instances of <code>memcached</code>.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {234884,
<br>author = {Haggai Eran and Lior Zeno and Maroun Tork and Gabi Malka and Mark Silberstein},
<br>title = {{NICA}: An Infrastructure for Inline Acceleration of Network Applications},
<br>booktitle = {2019 {USENIX} Annual Technical Conference ({USENIX} {ATC} 19)},
<br>year = {2019},
<br>isbn = {978-1-939133-03-8},
<br>address = {Renton, WA},
<br>pages = {345--362},
<br>url = {https://www.usenix.org/conference/atc19/presentation/eran},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/01/atc19_slides_eran.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for NICA: An Infrastructure for Inline Acceleration of Network Applications"></a> <a title="video" href="https://youtu.be/3AKoueaHfMc"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for NICA: An Infrastructure for Inline Acceleration of Network Applications"></a> <a title="code" href="https://github.com/acsl-technion/nica" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for NICA: An Infrastructure for Inline Acceleration of Network Applications"></a> <a  title="Lightning Talk"  href="https://youtu.be/C19VcKvVY_E" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-other.gif" alt="Icon Other for NICA: An Infrastructure for Inline Acceleration of Network Applications"></a> </div><div class="pbl_astring"><a href="https://haggaie.github.io/" target="_blank">Haggai Eran</a>, <a href="https://www.linkedin.com/in/lior-zeno-921b07119" target="_blank">Lior Zeno</a>, <a href="https://www.linkedin.com/in/maroun-tork-807a44a0" target="_blank">Maroun Tork</a>, <a href="https://www.linkedin.com/in/gabi-malka-a40b0738" target="_blank">Gabi Malka</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p822"><span class="pbl_akr">[FCCM]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/01/08735559.pdf" target="_blank">Design Patterns for Code Reuse in HLS Packet Processing Pipelines</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_822" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Design Patterns for Code Reuse in HLS Packet Processing Pipelines"></a><div class="remodal" data-remodal-id="modal0_822" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Design Patterns for Code Reuse in HLS Packet Processing Pipelines</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{8735559,
<br>author={H. {Eran} and L. {Zeno} and Z. {István} and M. {Silberstein}},
<br>booktitle={2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
<br>title={Design Patterns for Code Reuse in HLS Packet Processing Pipelines},
<br>year={2019},
<br>volume={},
<br>number={},
<br>pages={208-217},
<br>keywords={field programmable gate arrays;high level synthesis;logic design;software libraries;class library;FPGA-based SmartNICs;code reuse;HLS packet processing pipelines;high-level synthesis;high-speed networking applications;UDP stateless firewall;key-value store cache;FPGA circuits;Optimization;Tools;C++ languages;Logic gates;Hardware;Field programmable gate arrays;Data structures;High level synthesis;Design methodology;Networking;Packet processing},
<br>doi={10.1109/FCCM.2019.00036},
<br>ISSN={2576-2613},
<br>month={April},}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_822" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Design Patterns for Code Reuse in HLS Packet Processing Pipelines"></a><div class="remodal" data-remodal-id="modal1_822" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Design Patterns for Code Reuse in HLS Packet Processing Pipelines</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p><span style="color: #333333; font-family: sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">High-level synthesis (HLS) allows developers to be more productive in designing FPGA circuits thanks to familiar programming languages and high-level abstractions. In order to create high-performance circuits, HLS tools, such as Xilinx Vivado HLS, require following specific design patterns and techniques. Unfortunately, when applied to network packet processing tasks, these techniques limit code reuse and modularity, requiring developers to use deprecated programming conventions. We propose a methodology for developing high-speed networking applications using Vivado HLS for C++, focusing on reusability, code simplicity, and overall performance. Following this methodology, we implement a class library (ntl) with several building blocks that can be used in a wide spectrum of networking applications. We evaluate the methodology by implementing two applications: a UDP stateless firewall and a key-value store cache designed for FPGA-based SmartNICs, both processing packets at 40Gbps line-rate.</span></p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{8735559,
<br>author={H. {Eran} and L. {Zeno} and Z. {István} and M. {Silberstein}},
<br>booktitle={2019 IEEE 27th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM)},
<br>title={Design Patterns for Code Reuse in HLS Packet Processing Pipelines},
<br>year={2019},
<br>volume={},
<br>number={},
<br>pages={208-217},
<br>keywords={field programmable gate arrays;high level synthesis;logic design;software libraries;class library;FPGA-based SmartNICs;code reuse;HLS packet processing pipelines;high-level synthesis;high-speed networking applications;UDP stateless firewall;key-value store cache;FPGA circuits;Optimization;Tools;C++ languages;Logic gates;Hardware;Field programmable gate arrays;Data structures;High level synthesis;Design methodology;Networking;Packet processing},
<br>doi={10.1109/FCCM.2019.00036},
<br>ISSN={2576-2613},
<br>month={April},}</div></div><a title="code" href="https://github.com/acsl-technion/ntl" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for Design Patterns for Code Reuse in HLS Packet Processing Pipelines"></a> </div><div class="pbl_astring"><a href="https://haggaie.github.io/" target="_blank">Haggai Eran</a>, <a href="https://www.linkedin.com/in/lior-zeno-921b07119" target="_blank">Lior Zeno</a>, <a href="https://zistvan.github.io/" target="_blank">Zsolt István</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p832"><span class="pbl_akr">[MICRO Top Picks]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/01/08691527.pdf" target="_blank">Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_832" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow"></a><div class="remodal" data-remodal-id="modal0_832" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@ARTICLE{8691527,
<br>author={J. {Van Bulck} and M. {Minkin} and O. {Weisse} and D. {Genkin} and B. {Kasikci} and F. {Piessens} and M. {Silberstein} and T. F. {Wenisch} and Y. {Yarom} and R. {Strackx}},
<br>journal={IEEE Micro},
<br>title={Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow},
<br>year={2019},
<br>volume={39},
<br>number={3},
<br>pages={66-74},
<br>keywords={security of data;software architecture;trusted computing;virtual machines;virtualisation;virtual memory protection;SGX ecosystem;foreshadow;speculative execution attack;security guarantees;virtual machines;physical memory;Intel Software Guard eXtensions;Program processors;Ecosystems;Microarchitecture;Kernel;Side-channel attacks},
<br>doi={10.1109/MM.2019.2910104},
<br>ISSN={1937-4143},
<br>month={May},}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_832" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow"></a><div class="remodal" data-remodal-id="modal1_832" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p><span style="color: #333333; font-family: sans-serif; font-size: 15px; font-style: normal; font-variant-ligatures: normal; font-variant-caps: normal; font-weight: 400; letter-spacing: normal; orphans: 2; text-align: start; text-indent: 0px; text-transform: none; white-space: normal; widows: 2; word-spacing: 0px; -webkit-text-stroke-width: 0px; background-color: #ffffff; text-decoration-style: initial; text-decoration-color: initial; display: inline !important; float: none;">Foreshadow is a speculative execution attack that allows adversaries to subvert the security guarantees of Intel&#8217;s Software Guard eXtensions (SGX). Foreshadow allows access to data across process boundaries, and allows virtual machines (VMs) to read the physical memory belonging to other VMs or the hypervisor.</span></p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@ARTICLE{8691527,
<br>author={J. {Van Bulck} and M. {Minkin} and O. {Weisse} and D. {Genkin} and B. {Kasikci} and F. {Piessens} and M. {Silberstein} and T. F. {Wenisch} and Y. {Yarom} and R. {Strackx}},
<br>journal={IEEE Micro},
<br>title={Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow},
<br>year={2019},
<br>volume={39},
<br>number={3},
<br>pages={66-74},
<br>keywords={security of data;software architecture;trusted computing;virtual machines;virtualisation;virtual memory protection;SGX ecosystem;foreshadow;speculative execution attack;security guarantees;virtual machines;physical memory;Intel Software Guard eXtensions;Program processors;Ecosystems;Microarchitecture;Kernel;Side-channel attacks},
<br>doi={10.1109/MM.2019.2910104},
<br>ISSN={1937-4143},
<br>month={May},}</div></div><a title="project" href="https://foreshadowattack.eu" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-project.gif" alt="project for Breaking Virtual Memory Protection and the SGX Ecosystem with Foreshadow"></a> </div><div class="pbl_astring"><span class="pblempta">Jo Van Bulck</span>, <span class="pblempta">Marina Minkin</span>, <span class="pblempta">Ofir Weisse</span>, <a href="https://web.eecs.umich.edu/~genkin/" target="_blank">Daniel Genkin</a>, <a href="https://web.eecs.umich.edu/~barisk/" target="_blank">Baris Kasikci</a>, <span class="pblempta">Frank Piessens</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://web.eecs.umich.edu/~twenisch/" target="_blank">Thomas F. Wenisch</a>, <a href="https://ts.data61.csiro.au/people/?cn=Yuval+Yarom" target="_blank">Yuval Yarom</a>, <span class="pblempta">Raoul Strackx</span> <span class="pbl_nstring"><div class="pbl_snotes">Selected for publication in IEEE Micro Top Picks</div> </span></div></div><div class="publ_cart_wrapper" id="p1194"><span class="pbl_akr">[SFMA&#039;19]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/02/caladan-position.pdf" target="_blank">One Interface to Rule them All: A Hardware/Software Co-Design for Disaggregated Computing</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1194" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for One Interface to Rule them All: A Hardware/Software Co-Design for Disaggregated Computing"></a><div class="remodal" data-remodal-id="modal0_1194" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">One Interface to Rule them All: A Hardware/Software Co-Design for Disaggregated Computing</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@misc{ caladan-position,
<br>   authors={Lluis Vilanova and Yoav Etsion and Mark Silberstein},
<br>   title = {{One Interface to Rule them All: A Hardware/Software
<br>Co-Design for Disaggregated Computing}},
<br>   series = {SFMA'19},
<br>}
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1194" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for One Interface to Rule them All: A Hardware/Software Co-Design for Disaggregated Computing"></a><div class="remodal" data-remodal-id="modal1_1194" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">One Interface to Rule them All: A Hardware/Software Co-Design for Disaggregated Computing</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Datacenters are moving towards a paradigm of pooling resources (e.g., CPUs, storage and accelerators) into separate nodes to lower costs through easier hardware upgradability and higher resource utilization when running applications with heterogeneous demands.<br />
A single request to an application can trigger a chain of accesses to multiple devices, but each device has wildly different hardware capabilities which expose vastly different data and control interfaces. As a result, applications cannot securely span all these devices in a way that keeps the cost and simplicity benefits of disaggregation while maintaining efficiency.</p>
<p>&nbsp;</p>
<p>In this paper, we propose extending NICs to implement a model of continuation-based computations inspired in dataflow, which is used to weave the execution flow of applications across hardware devices without the need for each device to know each other’s communication protocol.</p>
<p>To achieve this, we lean on the observation that modern technology trends like device<br />
self-virtualization, multi-queue designs, RDMA and remote device transports (e.g., NVMe over fabric [14]) can be extended to allow devices to interact with each other without the need for intermediate software layers. Existing NICs can be easily extended to trigger such continuations as a response to device command completions, translating a continuation into a request directed at the next device on the processing pipeline.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@misc{ caladan-position,
<br>   authors={Lluis Vilanova and Yoav Etsion and Mark Silberstein},
<br>   title = {{One Interface to Rule them All: A Hardware/Software
<br>Co-Design for Disaggregated Computing}},
<br>   series = {SFMA'19},
<br>}
<br></div></div></div><div class="pbl_astring"><a href="https://www.linkedin.com/in/lluís-vilanova-97390918a" target="_blank">Lluis Vilanova</a>, <a href="https://yoav.net.technion.ac.il/" target="_blank">Yoav Etsion</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><span class="pbl_info">Position paper</span></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2018">2018</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1144"><span class="pbl_akr">[USENIX Security]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://foreshadowattack.eu/#paper" target="_blank">Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1144" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution"></a><div class="remodal" data-remodal-id="modal0_1144" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{vanbulck2018foreshadow,
<br>    author = {Van Bulck, Jo and Minkin, Marina and Weisse, Ofir and Genkin, Daniel and Kasikci, Baris and
<br>              Piessens, Frank and Silberstein, Mark and Wenisch, Thomas F. and Yarom, Yuval and Strackx, Raoul},
<br>    title = {Foreshadow: Extracting the Keys to the {Intel SGX} Kingdom with Transient Out-of-Order Execution},
<br>    booktitle = {Proceedings of the 27th {USENIX} Security Symposium},
<br>    year = {2018},
<br>    month = {August},
<br>    publisher = {{USENIX} Association},
<br>    note={See also technical report Foreshadow-NG~cite{weisse2018foreshadowNG}}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1144" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution"></a><div class="remodal" data-remodal-id="modal1_1144" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="field-items">
<div class="field-item odd">
<p>Trusted execution environments, and particularly the Software Guard eXtensions (SGX) included in recent Intel x86 processors, gained significant traction in recent years. A long track of research papers, and increasingly also real-world industry applications, take advantage of the strong hardware-enforced confidentiality and integrity guarantees provided by Intel SGX. Ultimately, enclaved execution holds the compelling potential of securely offloading sensitive computations to untrusted remote platforms.</p>
<p>We present Foreshadow, a practical software-only microarchitectural attack that decisively dismantles the security objectives of current SGX implementations. Crucially, unlike previous SGX attacks, we do not make any assumptions on the victim enclave’s code and do not necessarily require kernel-level access. At its core, Foreshadow abuses a speculative execution bug in modern Intel processors, on top of which we develop a novel exploitation methodology to reliably leak plaintext enclave secrets from the CPU cache. We demonstrate our attacks by extracting full cryptographic keys from Intel’s vetted architectural enclaves, and validate their correctness by launching rogue production enclaves and forging arbitrary local and remote attestation responses. The extracted remote attestation keys affect millions of devices.</p>
</div>
</div>
<div class="field field-name-field-paper-people field-type-node-reference field-label-hidden">
<div class="field-items">
<div class="field-item odd">
<article id="node-217945" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item even">
<article id="node-220812" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item odd">
<article id="node-220813" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item even">
<article id="node-220818" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item odd">
<article id="node-220814" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item even">
<article id="node-217946" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item odd">
<article id="node-220815" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item even">
<article id="node-220816" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item odd">
<article id="node-220817" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
<div class="field-item even">
<article id="node-217947" class="node node-speaker view-mode-schedule">
<div class="content"></div>
</article>
</div>
</div>
</div>
<h2></h2>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{vanbulck2018foreshadow,
<br>    author = {Van Bulck, Jo and Minkin, Marina and Weisse, Ofir and Genkin, Daniel and Kasikci, Baris and
<br>              Piessens, Frank and Silberstein, Mark and Wenisch, Thomas F. and Yarom, Yuval and Strackx, Raoul},
<br>    title = {Foreshadow: Extracting the Keys to the {Intel SGX} Kingdom with Transient Out-of-Order Execution},
<br>    booktitle = {Proceedings of the 27th {USENIX} Security Symposium},
<br>    year = {2018},
<br>    month = {August},
<br>    publisher = {{USENIX} Association},
<br>    note={See also technical report Foreshadow-NG~cite{weisse2018foreshadowNG}}
<br>}</div></div><a title="slides" href="https://www.usenix.org/sites/default/files/conference/protected-files/security18_slides_bulck.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution"></a> <a title="project" href="https://foreshadowattack.eu" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-project.gif" alt="project for Foreshadow: Extracting the Keys to the Intel SGX Kingdom with Transient Out-of-Order Execution"></a> </div><div class="pbl_astring"><span class="pblempta">Jo Van Bulck</span>, <span class="pblempta">Marina Minkin</span>, <span class="pblempta">Ofir Weisse</span>, <a href="https://web.eecs.umich.edu/~genkin/" target="_blank">Daniel Genkin</a>, <a href="https://web.eecs.umich.edu/~barisk/" target="_blank">Baris Kasikci</a>, <span class="pblempta">Frank Piessens</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://web.eecs.umich.edu/~twenisch/" target="_blank">Thomas F. Wenisch</a>, <a href="https://ts.data61.csiro.au/people/?cn=Yuval+Yarom" target="_blank">Yuval Yarom</a>, <span class="pblempta">Raoul Strackx</span> <span class="pbl_nstring"><div class="pbl_snotes">First Prize in CSAW Regional Competition </div> </span></div></div><div class="publ_cart_wrapper" id="p1148"><span class="pbl_akr">[ARXIV]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="http://arxiv.org/abs/1805.08079" target="_blank">Faster Neural Network Training with Approximate Tensor Operations</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1148" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Faster Neural Network Training with Approximate Tensor Operations"></a><div class="remodal" data-remodal-id="modal0_1148" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Faster Neural Network Training with Approximate Tensor Operations</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{DBLP:journals/corr/abs-1805-08079,
<br>  author    = {Menachem Adelman and
<br>               Mark Silberstein},
<br>  title     = {Faster Neural Network Training with Approximate Tensor Operations},
<br>  journal   = {CoRR},
<br>  volume    = {abs/1805.08079},
<br>  year      = {2018},
<br>  url       = {http://arxiv.org/abs/1805.08079},
<br>  archivePrefix = {arXiv},
<br>  eprint    = {1805.08079},
<br>  timestamp = {Mon, 13 Aug 2018 16:48:57 +0200},
<br>  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-08079.bib},
<br>  bibsource = {dblp computer science bibliography, https://dblp.org}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1148" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Faster Neural Network Training with Approximate Tensor Operations"></a><div class="remodal" data-remodal-id="modal1_1148" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Faster Neural Network Training with Approximate Tensor Operations</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>We propose a novel technique for faster Neural Network (NN) training by systematically approximating all the constituent matrix multiplications and convolutions. This approach is complementary to other approximation techniques, requires no changes to the dimensions of the network layers, hence compatible with existing training frameworks. We first analyze the applicability of the existing methods for approximating matrix multiplication to NN training, and extend the most suitable column-row sampling algorithm to approximating multi-channel convolutions. We apply approximate tensor operations to training MLP, CNN and LSTM network architectures on MNIST, CIFAR-100 and Penn Tree Bank datasets and demonstrate 30%-80% reduction in the amount of computations while maintaining little or no impact on the test accuracy. Our promising results encourage further study of general methods for approximating tensor operations and their application to NN training.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{DBLP:journals/corr/abs-1805-08079,
<br>  author    = {Menachem Adelman and
<br>               Mark Silberstein},
<br>  title     = {Faster Neural Network Training with Approximate Tensor Operations},
<br>  journal   = {CoRR},
<br>  volume    = {abs/1805.08079},
<br>  year      = {2018},
<br>  url       = {http://arxiv.org/abs/1805.08079},
<br>  archivePrefix = {arXiv},
<br>  eprint    = {1805.08079},
<br>  timestamp = {Mon, 13 Aug 2018 16:48:57 +0200},
<br>  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-08079.bib},
<br>  bibsource = {dblp computer science bibliography, https://dblp.org}
<br>}</div></div></div><div class="pbl_astring"><span class="pblempta">Menachem Edelman</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1150"><span class="pbl_akr">[PETS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/02/main.pdf" target="_blank">Power to peep-all: Inference Attacks by Malicious Batteries on Mobile Devices</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1150" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Power to peep-all: Inference Attacks by Malicious Batteries on Mobile Devices"></a><div class="remodal" data-remodal-id="modal0_1150" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Power to peep-all: Inference Attacks by Malicious Batteries on Mobile Devices</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{lifshits2018power,
<br>  title={Power to peep-all: Inference attacks by malicious batteries on mobile devices},
<br>  author={Lifshits, Pavel and Forte, Roni and Hoshen, Yedid and Halpern, Matt and Philipose, Manuel and Tiwari, Mohit and Silberstein, Mark},
<br>  journal={Proceedings on Privacy Enhancing Technologies},
<br>  volume={2018},
<br>  number={4},
<br>  pages={141--158},
<br>  year={2018},
<br>  publisher={Sciendo}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1150" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Power to peep-all: Inference Attacks by Malicious Batteries on Mobile Devices"></a><div class="remodal" data-remodal-id="modal1_1150" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Power to peep-all: Inference Attacks by Malicious Batteries on Mobile Devices</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Mobile devices are equipped with increasingly smart batteries designed to provide responsiveness and extended lifetime. However, such smart batteries may present a threat to users’ privacy. We demonstrate that the phone’s power trace sampled from the battery at 1KHz holds enough information to recover a variety of sensitive information.</p>
<p>We show techniques to infer characters typed on a  touchscreen; to accurately recover browsing history in an open-world setup; and to reliably detect incoming calls, and the photo shots including their lighting conditions. Combined with a novel exfiltration technique that establishes a covert channel from the battery to a remote server via a web browser, these attacks turn the malicious battery into a stealthy surveillance device. We deconstruct the attack by analyzing its robustness to sampling rate and execution conditions. To find mitigations we identify the sources of the information leakage exploited by the attack. We discover that the GPU or DRAM power traces alone are sufficient to distinguish between different websites. However, the CPU and power-hungry peripherals such as a touchscreen are the primary sources of fine-grain information leakage.</p>
<p>We consider and evaluate possible mitigation mechanisms,  highlighting the challenges to defend against the attacks. In summary, our work shows the feasibility of the malicious battery and motivates further research into system and application-level defenses to fully mitigate this emerging threat.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{lifshits2018power,
<br>  title={Power to peep-all: Inference attacks by malicious batteries on mobile devices},
<br>  author={Lifshits, Pavel and Forte, Roni and Hoshen, Yedid and Halpern, Matt and Philipose, Manuel and Tiwari, Mohit and Silberstein, Mark},
<br>  journal={Proceedings on Privacy Enhancing Technologies},
<br>  volume={2018},
<br>  number={4},
<br>  pages={141--158},
<br>  year={2018},
<br>  publisher={Sciendo}
<br>}</div></div><a title="slides" href="https://petsymposium.org/2018/files/slides/Power%20to%20peep-all%20-%20Inference%20Attacks%20by%20Malicious%20Batteries%20on%20Mobile%20Devices.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Power to peep-all: Inference Attacks by Malicious Batteries on Mobile Devices"></a> <a title="video" href="https://www.youtube.com/watch?v=20yiog1qmHs"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for Power to peep-all: Inference Attacks by Malicious Batteries on Mobile Devices"></a> </div><div class="pbl_astring"><a href="https://www.linkedin.com/in/pavel-lifshits-3b36153" target="_blank">Pavel Lifshits</a>, <span class="pblempta">Roni Forte</span>, <a href="https://www.cs.huji.ac.il/~ydidh/" target="_blank">Yedid Hoshen</a>, <span class="pblempta">Matt Halpern</span>, <span class="pblempta">Manuel Philipose</span>, <a href="https://users.ece.utexas.edu/~tiwari/" target="_blank">Mohit Tiwari</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><div class="pbl_snotes">Third Prize in CSAW Regional Competition</div> </span></div></div><div class="publ_cart_wrapper" id="p1158"><span class="pbl_akr">[USENIX ATC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://www.usenix.org/system/files/conference/atc18/atc18-oleksenko.pdf" target="_blank">Varys: Protecting SGX enclaves from practical side-channel attacks</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1158" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Varys: Protecting SGX enclaves from practical side-channel attacks"></a><div class="remodal" data-remodal-id="modal0_1158" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Varys: Protecting SGX enclaves from practical side-channel attacks</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {216033,
<br>author = {Oleksii Oleksenko and Bohdan Trach and Robert Krahn and Mark Silberstein and Christof Fetzer},
<br>title = {Varys: Protecting {SGX} Enclaves from Practical Side-Channel Attacks},
<br>booktitle = {2018 {USENIX} Annual Technical Conference ({USENIX} {ATC} 18)},
<br>year = {2018},
<br>isbn = {ISBN 978-1-939133-01-4},
<br>address = {Boston, MA},
<br>pages = {227--240},
<br>url = {https://www.usenix.org/conference/atc18/presentation/oleksenko},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1158" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Varys: Protecting SGX enclaves from practical side-channel attacks"></a><div class="remodal" data-remodal-id="modal1_1158" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Varys: Protecting SGX enclaves from practical side-channel attacks</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="field-items">
<div class="field-item odd">
<p>Numerous recent works have experimentally shown that Intel Software Guard Extensions (SGX) are vulnerable to cache timing and page table side-channel attacks which could be used to circumvent the data confidentiality guarantees provided by SGX. Existing mechanisms that protect against these attacks either incur high execution costs, are ineffective against certain attack variants, or require significant code modifications.</p>
<p>We present Varys, a system that protects unmodified programs running in SGX enclaves from cache timing and page table side-channel attacks. Varys takes a pragmatic approach of strict reservation of physical cores to security-sensitive threads, thereby preventing the attacker from accessing shared CPU resources during enclave execution. The key challenge that we are addressing is that of maintaining the core reservation in the presence of an untrusted OS.</p>
<p>Varys fully protects against all L1/L2 cache timing attacks and significantly raises the bar for page table side-channel attacks &#8211; all with only 15% overhead on average for Phoenix and PARSEC benchmarks. Additionally, we propose a set of minor hardware extensions that hold the potential to extend Varys&#8217; security guarantees to L3 cache and further improve its performance.</p>
</div>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {216033,
<br>author = {Oleksii Oleksenko and Bohdan Trach and Robert Krahn and Mark Silberstein and Christof Fetzer},
<br>title = {Varys: Protecting {SGX} Enclaves from Practical Side-Channel Attacks},
<br>booktitle = {2018 {USENIX} Annual Technical Conference ({USENIX} {ATC} 18)},
<br>year = {2018},
<br>isbn = {ISBN 978-1-939133-01-4},
<br>address = {Boston, MA},
<br>pages = {227--240},
<br>url = {https://www.usenix.org/conference/atc18/presentation/oleksenko},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div></div><a title="slides" href="https://www.usenix.org/sites/default/files/conference/protected-files/atc18_slides_oleksenko.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Varys: Protecting SGX enclaves from practical side-channel attacks"></a> </div><div class="pbl_astring"><span class="pblempta">Oleksii Oleksenki</span>, <a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/beschaeftigte/bohdan-trach" target="_blank">Bohdan Trach</a>, <span class="pblempta">Robert Krahn</span>, <span class="pblempta">Andre Martin</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/inhaber-in" target="_blank">Christof Fetzer</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1198"><span class="pbl_akr">[ARXIV]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://arxiv.org/pdf/1805.08506" target="_blank">You shall not bypass: Employing data dependencies to prevent bounds check bypass</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1198" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for You shall not bypass: Employing data dependencies to prevent bounds check bypass"></a><div class="remodal" data-remodal-id="modal0_1198" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">You shall not bypass: Employing data dependencies to prevent bounds check bypass</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{DBLP:journals/corr/abs-1805-08506,
<br>  author    = {Oleksii Oleksenko and
<br>               Bohdan Trach and
<br>               Tobias Reiher and
<br>               Mark Silberstein and
<br>               Christof Fetzer},
<br>  title     = {You Shall Not Bypass: Employing data dependencies to prevent Bounds
<br>               Check Bypass},
<br>  journal   = {CoRR},
<br>  volume    = {abs/1805.08506},
<br>  year      = {2018},
<br>  url       = {http://arxiv.org/abs/1805.08506},
<br>  archivePrefix = {arXiv},
<br>  eprint    = {1805.08506},
<br>  timestamp = {Mon, 13 Aug 2018 16:48:45 +0200},
<br>  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-08506.bib},
<br>  bibsource = {dblp computer science bibliography, https://dblp.org}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1198" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for You shall not bypass: Employing data dependencies to prevent bounds check bypass"></a><div class="remodal" data-remodal-id="modal1_1198" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">You shall not bypass: Employing data dependencies to prevent bounds check bypass</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>A recent discovery of a new class of microarchitectural attacks called Spectre picked up the attention of the security community as these attacks can circumvent many<br />
traditional mechanisms of defence. One of the attacks— Bounds Check Bypass—can neither be efficiently solved on system nor architectural levels and requires changes in the application itself. So far, the proposed mitigations involved serialization, which reduces the usage of CPU resources and causes high overheads. In this report, we explore methods of delaying the vulnerable instructions<br />
without complete serialization. We discuss several ways of achieving it and compare them with Speculative Load Hardening, an existing solution based on a similar idea. The solutions of this type cause 60% overhead across Phoenix benchmark suite, which compares favourably to the full serialization causing 440% slowdown.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{DBLP:journals/corr/abs-1805-08506,
<br>  author    = {Oleksii Oleksenko and
<br>               Bohdan Trach and
<br>               Tobias Reiher and
<br>               Mark Silberstein and
<br>               Christof Fetzer},
<br>  title     = {You Shall Not Bypass: Employing data dependencies to prevent Bounds
<br>               Check Bypass},
<br>  journal   = {CoRR},
<br>  volume    = {abs/1805.08506},
<br>  year      = {2018},
<br>  url       = {http://arxiv.org/abs/1805.08506},
<br>  archivePrefix = {arXiv},
<br>  eprint    = {1805.08506},
<br>  timestamp = {Mon, 13 Aug 2018 16:48:45 +0200},
<br>  biburl    = {https://dblp.org/rec/journals/corr/abs-1805-08506.bib},
<br>  bibsource = {dblp computer science bibliography, https://dblp.org}
<br>}</div></div></div><div class="pbl_astring"><a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/beschaeftigte/oleksii-oleksenko" target="_blank">Oleksii Oleksenko</a>, <a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/beschaeftigte/bohdan-trach" target="_blank">Bohdan Trach</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://tu-dresden.de/ing/informatik/sya/se/die-professur/inhaber-in" target="_blank">Christof Fetzer</a> <span class="pbl_nstring"></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2017">2017</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1160"><span class="pbl_akr">[USENIX ATC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://www.usenix.org/system/files/conference/atc17/atc17-bergman.pdf" target="_blank">SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1160" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs"></a><div class="remodal" data-remodal-id="modal0_1160" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {203153,
<br>author = {Shai Bergman and Tanya Brokhman and Tzachi Cohen and Mark Silberstein},
<br>title = {{SPIN}: Seamless Operating System Integration of Peer-to-Peer {DMA} Between SSDs and GPUs},
<br>booktitle = {2017 {USENIX} Annual Technical Conference ({USENIX} {ATC} 17)},
<br>year = {2017},
<br>isbn = {978-1-931971-38-6},
<br>address = {Santa Clara, CA},
<br>pages = {167--179},
<br>url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/bergman},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1160" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs"></a><div class="remodal" data-remodal-id="modal1_1160" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="field-items">
<div class="field-item odd">
<p>Recent GPUs enable Peer-to-Peer Direct Memory Access (P2P) from fast peripheral devices like NVMe SSDs to exclude the CPU from the data path between them for efficiency. Unfortunately, using P2P to access <em>files</em> is challenging because of the subtleties of low-level nonstandard interfaces, which bypass the OS file I/O layers and may hurt system performance.</p>
<p><em>SPIN</em> integrates P2P into the standard OS file I/O stack, dynamically activating P2P where appropriate, transparently to the user. It combines P2P with page cache accesses, re-enables read-ahead for sequential reads, all while maintaining standard POSIX FS consistency, portability across GPUs and SSDs, and compatibility with virtual block devices such as software RAID.</p>
<p>We evaluate SPIN on NVIDIA and AMD GPUs using standard file I/O benchmarks, application traces and end-to-end experiments. SPIN achieves significant performance speedups across a wide range of workloads, exceeding P2P throughput by up to an order of magnitude. It also boosts the performance of an aerial imagery rendering application by 2.6× by dynamically adapting to its input-dependent file access pattern, and enables 3.3× higher throughput for a GPU-accelerated log server.</p>
</div>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {203153,
<br>author = {Shai Bergman and Tanya Brokhman and Tzachi Cohen and Mark Silberstein},
<br>title = {{SPIN}: Seamless Operating System Integration of Peer-to-Peer {DMA} Between SSDs and GPUs},
<br>booktitle = {2017 {USENIX} Annual Technical Conference ({USENIX} {ATC} 17)},
<br>year = {2017},
<br>isbn = {978-1-931971-38-6},
<br>address = {Santa Clara, CA},
<br>pages = {167--179},
<br>url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/bergman},
<br>publisher = {{USENIX} Association},
<br>month = jul,
<br>}</div></div><a title="slides" href="https://www.usenix.org/sites/default/files/conference/protected-files/atc17_slides_bergman.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs"></a> <a title="code" href="https://github.com/acsl-technion/spin" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for SPIN: Seamless OS integration of Peer-to-Peer DMA between SSDs and GPUs"></a> </div><div class="pbl_astring"><span class="pblempta">Shai Bergman</span>, <a href="https://www.linkedin.com/in/tanya-brokhman-828b803" target="_blank">Tanya Brokhman</a>, <span class="pblempta">Tsahi Cohen</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1200"><span class="pbl_akr">[HotOS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/02/hotos17p2p.pdf" target="_blank">OmniX: an accelerator-centric OS for omni-programmable systems</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1200" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for OmniX: an accelerator-centric OS for omni-programmable systems"></a><div class="remodal" data-remodal-id="modal0_1200" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">OmniX: an accelerator-centric OS for omni-programmable systems</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{OmniX,
<br>author = {Silberstein, Mark},
<br>title = {OmniX: An Accelerator-Centric OS for Omni-Programmable Systems},
<br>year = {2017},
<br>isbn = {9781450350686},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3102980.3102992},
<br>doi = {10.1145/3102980.3102992},
<br>booktitle = {Proceedings of the 16th Workshop on Hot Topics in Operating Systems},
<br>pages = {69–75},
<br>numpages = {7},
<br>location = {Whistler, BC, Canada},
<br>series = {HotOS ’17}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1200" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for OmniX: an accelerator-centric OS for omni-programmable systems"></a><div class="remodal" data-remodal-id="modal1_1200" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">OmniX: an accelerator-centric OS for omni-programmable systems</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Future systems will be omni-programmable: alongside CPUs, GPUs and FPGAs,<br />
they will execute user code near-storage, near-network, near-memory, or on other<br />
Near-X accelerator Units, NXUs}.<br />
This paper explores the design space of OS support for omni-programmable systems,<br />
aiming to simplify the development of efficient applications that span multiple<br />
heterogeneous processors and near-data accelerators.<br />
OmniX is an accelerator-centric OS architecture that extends standard OS<br />
abstractions, such as task execution and I/O, into NXUs  while maintaining a coherent view of the system among all the processors.OmniX enables NXUs to directly invoke<br />
tasks and access I/O services among themselves, excluding the CPU from the performance-critical<br />
control plane operations. The host CPU serves as a controller &#8212; for protection,<br />
device configuration and monitoring.  We discuss the hardware trends<br />
that motivate our work, outline OmniX design principles, and sketch the core implementation ideas while highlighting missing hardware features, in the hope of motivating hardware vendors to implement them soon.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{OmniX,
<br>author = {Silberstein, Mark},
<br>title = {OmniX: An Accelerator-Centric OS for Omni-Programmable Systems},
<br>year = {2017},
<br>isbn = {9781450350686},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3102980.3102992},
<br>doi = {10.1145/3102980.3102992},
<br>booktitle = {Proceedings of the 16th Workshop on Hot Topics in Operating Systems},
<br>pages = {69–75},
<br>numpages = {7},
<br>location = {Whistler, BC, Canada},
<br>series = {HotOS ’17}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/02/hotos.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for OmniX: an accelerator-centric OS for omni-programmable systems"></a> </div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1204"><span class="pbl_akr">[EuroSys]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/02/cr-eurosys17sgx.pdf" target="_blank">Eleos: Exit-Less OS Services for  SGX Enclaves</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1204" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Eleos: Exit-Less OS Services for  SGX Enclaves"></a><div class="remodal" data-remodal-id="modal0_1204" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Eleos: Exit-Less OS Services for  SGX Enclaves</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{Eleos,
<br>author = {Orenbach, Meni and Lifshits, Pavel and Minkin, Marina and Silberstein, Mark},
<br>title = {Eleos: ExitLess OS Services for SGX Enclaves},
<br>year = {2017},
<br>isbn = {9781450349383},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3064176.3064219},
<br>doi = {10.1145/3064176.3064219},
<br>booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},
<br>pages = {238–253},
<br>numpages = {16},
<br>location = {Belgrade, Serbia},
<br>series = {EuroSys ’17}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1204" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Eleos: Exit-Less OS Services for  SGX Enclaves"></a><div class="remodal" data-remodal-id="modal1_1204" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Eleos: Exit-Less OS Services for  SGX Enclaves</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Intel Software Guard eXtensions (SGX) enable secure and trusted execution of user code in an isolated enclave to protect against a powerful adversary. Unfortunately, running I/O-intensive, memory-demanding server applications in enclaves leads to significant performance degradation. Such applications put a substantial load on the in-enclave system call and secure paging mechanisms, which turn out to be the main reason for the application slowdown. In addition to the<br />
high direct cost of thousands-of-cycles long SGX management instructions, these mechanisms incur the high indirect cost of enclave exits due to associated TLB flushes and processor state pollution.<br />
We tackle these performance issues in Eleos by enabling exit-less system calls and exit-less paging in enclaves. Eleos introduces a novel Secure User-managed Virtual Memory (SUVM) abstraction that implements application-level paging inside the enclave. SUVM eliminates the overheads of<br />
enclave exits due to paging, and enables new optimizations such as sub-page granularity of accesses.  We thoroughly evaluate Eleos on a range of microbenchmarks and two real server applications, achieving notable system performance gains. memcached and a face verification server running in-enclave with Eleos, achieves up to 2.2× and 2.3× higher throughput respectively while working on datasets up to 5× larger than the enclave’s secure physical memory.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{Eleos,
<br>author = {Orenbach, Meni and Lifshits, Pavel and Minkin, Marina and Silberstein, Mark},
<br>title = {Eleos: ExitLess OS Services for SGX Enclaves},
<br>year = {2017},
<br>isbn = {9781450349383},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/3064176.3064219},
<br>doi = {10.1145/3064176.3064219},
<br>booktitle = {Proceedings of the Twelfth European Conference on Computer Systems},
<br>pages = {238–253},
<br>numpages = {16},
<br>location = {Belgrade, Serbia},
<br>series = {EuroSys ’17}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/02/eurosys17_slides_final.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Eleos: Exit-Less OS Services for  SGX Enclaves"></a> <a title="code" href="https://github.com/acsl-technion/eleos" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for Eleos: Exit-Less OS Services for  SGX Enclaves"></a> </div><div class="pbl_astring"><a href="https://shmeni.github.io/" target="_blank">Meni Orenbach</a>, <span class="pblempta">Marina Minkin</span>, <span class="pblempta">Tsahi Cohen</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1209"><span class="pbl_akr">[GPGPU]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/02/gpuattack.pdf" target="_blank">Understanding The Security of Discrete GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1209" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Understanding The Security of Discrete GPUs"></a><div class="remodal" data-remodal-id="modal0_1209" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Understanding The Security of Discrete GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@incollection{zhu2017understanding,
<br>  title={Understanding the security of discrete GPUs},
<br>  author={Zhu, Zhiting and Kim, Sangman and Rozhanski, Yuri and Hu, Yige and Witchel, Emmett and Silberstein, Mark},
<br>  booktitle={Proceedings of the General Purpose GPUs},
<br>  pages={1--11},
<br>  year={2017},
<br>  series = {GPGPU' 17}
<br>}
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1209" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Understanding The Security of Discrete GPUs"></a><div class="remodal" data-remodal-id="modal1_1209" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Understanding The Security of Discrete GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>GPUs have become an integral part of modern systems, but their implications for system security are not yet clear. This paper demonstrates both that discrete GPUs cannot be used as secure<br />
co-processors and that GPUs provide a stealthy platform for malware. First, we examine a recent proposal to use discrete GPUs as secure co-processors and show that the security guarantees of<br />
the proposed system do not hold on the GPUs we investigate. Second, we demonstrate that (under certain circumstances) it is possible to bypass IOMMU protections and create stealthy, long-lived<br />
GPU-based malware. We demonstrate a novel attack that compromises the in-kernel GPU driver and one that compromises GPU microcode to gain full access to CPU physical memory. In general,<br />
we find that the highly sophisticated, but poorly documented GPU hardware architecture, hidden behind obscure close-source device drivers and vendor-specific APIs, not only make GPUs a poor<br />
choice for applications requiring strong security, but also make GPUs into a security threat.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@incollection{zhu2017understanding,
<br>  title={Understanding the security of discrete GPUs},
<br>  author={Zhu, Zhiting and Kim, Sangman and Rozhanski, Yuri and Hu, Yige and Witchel, Emmett and Silberstein, Mark},
<br>  booktitle={Proceedings of the General Purpose GPUs},
<br>  pages={1--11},
<br>  year={2017},
<br>  series = {GPGPU' 17}
<br>}
<br></div></div></div><div class="pbl_astring"><span class="pblempta">Zhiting Zhu</span>, <span class="pblempta">Sangman Kim</span>, <span class="pblempta">Yuri Rozhanski</span>, <span class="pblempta">Yige Hu</span>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1282"><span class="pbl_akr">[EuroCrypt&#039;17]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://eprint.iacr.org/2016/646.pdf" target="_blank">Computational integrity with a public random string from quasi-linear PCPs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1282" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Computational integrity with a public random string from quasi-linear PCPs"></a><div class="remodal" data-remodal-id="modal0_1282" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Computational integrity with a public random string from quasi-linear PCPs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{ben2017computational,
<br>  title={Computational integrity with a public random string from quasi-linear PCPs},
<br>  author={Ben-Sasson, Eli and Bentov, Iddo and Chiesa, Alessandro and Gabizon, Ariel and Genkin, Daniel and Hamilis, Matan and Pergament, Evgenya and Riabzev, Michael and Silberstein, Mark and Tromer, Eran and Virza, Madars},
<br>  booktitle={Annual International Conference on the Theory and Applications of Cryptographic Techniques},
<br>  pages={551--579},
<br>  year={2017},
<br>  organization={Springer}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1282" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Computational integrity with a public random string from quasi-linear PCPs"></a><div class="remodal" data-remodal-id="modal1_1282" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Computational integrity with a public random string from quasi-linear PCPs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>A party running a computation remotely may benefit from misreporting its output,<br />
say, to lower its tax. Cryptographic protocols that detect and prevent such falsities hold the promise to enhance the security of decentralized systems with stringent computational integrity requirements, like Bitcoin [Nak09]. To gain public trust it is imperative to use publicly verifiable protocols that have no “backdoors” and which can be set up using only a short public random string. Probabilistically Checkable Proof (PCP) systems [BFL90, BFLS91, AS98, ALM + 98] can be used to construct astonishingly efficient protocols [Kil92, Mic00] of this nature but some of the main<br />
components of such systems — proof composition [AS98] and low-degree testing via PCPs of Proximity (PCPPs) [BGH + 05, DR06] — have been considered efficient only asymptotically, for unrealistically large computations; recent cryptographic alternatives [PGHR13, BCG + 13a] suffer from a non-public setup phase. This work introduces SCI, the first implementation of a scalable PCP system (that uses both PCPPs and proof composition). We used SCI to prove correctness of executions of up to 2 20 cycles of a simple processor and calculated  its break-even<br />
point [SVP + 12, SMBW12]. The significance of our findings is two-fold: (i) it marks the transition of core PCP techniques (like proof composition and PCPs of Proximity ) from mathematical theory to practical system engineering, and (ii) the thresholds obtained are nearly achievable and hence show that PCP-supported computational integrity is closer to reality than previously assumed.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{ben2017computational,
<br>  title={Computational integrity with a public random string from quasi-linear PCPs},
<br>  author={Ben-Sasson, Eli and Bentov, Iddo and Chiesa, Alessandro and Gabizon, Ariel and Genkin, Daniel and Hamilis, Matan and Pergament, Evgenya and Riabzev, Michael and Silberstein, Mark and Tromer, Eran and Virza, Madars},
<br>  booktitle={Annual International Conference on the Theory and Applications of Cryptographic Techniques},
<br>  pages={551--579},
<br>  year={2017},
<br>  organization={Springer}
<br>}</div></div><a title="slides" href="https://eurocrypt.iacr.org/2017/slides/B04-computational-integrity.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Computational integrity with a public random string from quasi-linear PCPs"></a> <a title="video" href="https://www.youtube.com/watch?v=3cK8I63vAbg"  class="svideo"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-video.gif" alt="video for Computational integrity with a public random string from quasi-linear PCPs"></a> </div><div class="pbl_astring"><a href="https://eli.net.technion.ac.il/" target="_blank">Eli Ben-Sasson</a>, <span class="pblempta">Iddo Ben-Tov</span>, <a href="http://people.eecs.berkeley.edu/~alexch/" target="_blank">Alessandro Chiesa</a>, <span class="pblempta">Ariel Gabizon</span>, <a href="https://web.eecs.umich.edu/~genkin/" target="_blank">Daniel Genkin</a>, <span class="pblempta">Matan Hamilis</span>, <span class="pblempta">Evgenya Pergament</span>, <span class="pblempta">Michael Riabzev</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://www.tau.ac.il/~tromer/" target="_blank">Eran Tromer</a>, <a href="https://madars.org/" target="_blank">Madars Virza</a> <span class="pbl_nstring"><span class="pbl_info">Annual International Conference on the Theory and Applications of Cryptographic Techniques</span></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2016">2016</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1285"><span class="pbl_akr">[SysTex]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/systex16sgx.pdf" target="_blank">SGX Enclaves as Accelerators</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1285" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for SGX Enclaves as Accelerators"></a><div class="remodal" data-remodal-id="modal0_1285" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">SGX Enclaves as Accelerators</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{orenbach16systex,
<br>  title={SGX Enclaves as Accelerators},
<br>  author={Meni Orenbach and Mark Silberstein},
<br>  booktitle={1st Workshop on System Software for Trusted Execution},
<br>  year={2016},
<br>}
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1285" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for SGX Enclaves as Accelerators"></a><div class="remodal" data-remodal-id="modal1_1285" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">SGX Enclaves as Accelerators</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Intel SGX enclaves is a novel technology that holds the promise to revolutionize the way secure and trustworthy applications are built. However, from the perspective of interaction with the rest<br />
of the system, some of the enclave’s characteristics are remarkably similar to the characteristics of traditional hardware accelerators, such as GPUs. For example, enclaves suffer from significant in-<br />
vocation overheads, offer space-constrained private memory, and cannot directly invoke OS services such as network or file I/O. Over the course of GPU computing evolution, there have been developed many techniques to improve system performance and programmability. Our key observation is that the conceptual similarities between enclaves and accelerators may help to build efficient runtime support for enclaves by learning from past experience with GPUs.<br />
We demonstrate this simple idea by implementing SGXIO, a simple yet powerful enhancement to the current SGX runtime which boosts the performance of I/O system calls from enclaves. SGXIO<br />
design is almost identical to the design of GPUfs and GPUnet systems for efficient I/O services for GPU programs. Our preliminary evaluation shows that GXIO improves the performance of<br />
a simple network parameter server for distributed machine learning by up to 3.7×. These promising results suggest new ways to design more efficient runtime and system services for enclaves.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{orenbach16systex,
<br>  title={SGX Enclaves as Accelerators},
<br>  author={Meni Orenbach and Mark Silberstein},
<br>  booktitle={1st Workshop on System Software for Trusted Execution},
<br>  year={2016},
<br>}
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/04/orenbach-systex16-slides.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for SGX Enclaves as Accelerators"></a> </div><div class="pbl_astring"><a href="https://shmeni.github.io/" target="_blank">Meni Orenbach</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1290"><span class="pbl_akr">[ACM TOCS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2963098" target="_blank">GPUnet: networking abstractions for GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1290" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUnet: networking abstractions for GPUs"></a><div class="remodal" data-remodal-id="modal0_1290" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUnet: networking abstractions for GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{silberstein16GPUnet
<br>author = {Silberstein, Mark and Kim, Sangman and Huh, Seonggu and Zhang, Xinya and Hu, Yige and Wated, Amir and Witchel, Emmett},
<br>title = {GPUnet: Networking Abstractions for GPU Programs},
<br>year = {2016},
<br>issue_date = {September 2016},
<br>publisher = {ACM},
<br>address = {New York, NY, USA},
<br>volume = {34},
<br>number = {3},
<br>issn = {0734-2071},
<br>doi = {10.1145/2963098},
<br>journal = {ACM Transactions on Computer Systems},
<br>month = sep,
<br>articleno = {Article 9},
<br>numpages = {31},
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1290" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUnet: networking abstractions for GPUs"></a><div class="remodal" data-remodal-id="modal1_1290" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUnet: networking abstractions for GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<div class="abstractSection abstractInFull">
<p>Despite the popularity of GPUs in high-performance and scientific computing, and despite increasingly general-purpose hardware capabilities, the use of GPUs in network servers or distributed systems poses significant challenges.</p>
<p>GPUnet is a native GPU networking layer that provides a socket abstraction and high-level networking APIs for GPU programs. We use GPUnet to streamline the development of high-performance, distributed applications like in-GPU-memory MapReduce and a new class of low-latency, high-throughput GPU-native network services such as a face verification server.</p>
</div>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{silberstein16GPUnet
<br>author = {Silberstein, Mark and Kim, Sangman and Huh, Seonggu and Zhang, Xinya and Hu, Yige and Wated, Amir and Witchel, Emmett},
<br>title = {GPUnet: Networking Abstractions for GPU Programs},
<br>year = {2016},
<br>issue_date = {September 2016},
<br>publisher = {ACM},
<br>address = {New York, NY, USA},
<br>volume = {34},
<br>number = {3},
<br>issn = {0734-2071},
<br>doi = {10.1145/2963098},
<br>journal = {ACM Transactions on Computer Systems},
<br>month = sep,
<br>articleno = {Article 9},
<br>numpages = {31},
<br>}</div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Sangman Kim</span>, <a href="https://www.linkedin.com/in/amirwatad" target="_blank">Amir Watad</a>, <span class="pblempta">Yige Hu</span>, <span class="pblempta">Xinya Zhang</span>, <span class="pblempta">Seonggu Huh</span>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a> <span class="pbl_nstring"><div class="pbl_snotes">Extended version of the OSDI'14 paper, Fast-track acceptance </div> </span></div></div><div class="publ_cart_wrapper" id="p1295"><span class="pbl_akr">[ROSS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/ross16net.pdf" target="_blank">GPUrdma: GPU-side library for high performance networking from GPU kernels</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1295" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUrdma: GPU-side library for high performance networking from GPU kernels"></a><div class="remodal" data-remodal-id="modal0_1295" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUrdma: GPU-side library for high performance networking from GPU kernels</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{ross16gpurdma,
<br>author = {Daoud, Feras and Watad, Amir and Silberstein, Mark},
<br>title = {GPUrdma: GPU-Side Library for High Performance Networking from GPU Kernels},
<br>year = {2016},
<br>isbn = {9781450343879},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2931088.2931091},
<br>doi = {10.1145/2931088.2931091},
<br>booktitle = {Proceedings of the 6th International Workshop on Runtime and Operating Systems for Supercomputers},
<br>articleno = {Article 6},
<br>numpages = {8},
<br>keywords = {Networking, accelerators, Operating Systems Design, GPGPUs},
<br>location = {Kyoto, Japan},
<br>series = {ROSS ’16}
<br>}
<br>
<br> </div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1295" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUrdma: GPU-side library for high performance networking from GPU kernels"></a><div class="remodal" data-remodal-id="modal1_1295" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUrdma: GPU-side library for high performance networking from GPU kernels</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>We present GPUrdma, a GPU-side library for performing Remote Direct Memory Accesses (RDMA) across the network directly from GPU kernels. The library executes no code on CPU, directly accessing the Host Channel Adapter (HCA) Infiniband hardware for both control and data. Slow single-thread GPU performance and the intricacies of the GPU-to-network adapter interaction pose a significant challenge. We describe several design options and analyze their performance implications in detail.</p>
<p>We achieve 5usec one-way communication latency and up to 50Gbit/sec transfer bandwidth for messages from 16KB and larger between K40c NVIDIA GPUs across the network. Moreover, GPUrdma outperforms the CPU RDMA for smaller packets ranging from 2 to 1024 bytes by factor of 4.5x thanks to greater parallelism of transfer requests enabled by highly parallel GPU hardware.</p>
<p>We use GPUrdma to implement a subset of the global address space programming interface (GPI) for point-to-point asynchronous RDMA messaging. We demonstrate our preliminary results using two simple applications &#8212; ping-pong and a multi-matrix-vector product with constant matrix and multiple vectors &#8212; each running on two different machines connected by Infiniband. Our basic ping-pong implementation achieves 5%higher performance than the baseline using GPI-2. The improved ping-pong implementation with per-threadblock communication overlap enables a further 20% improvement. The multi-matrix-vector product is up to 4.5x faster thanks to higher throughput for small messages and the ability to keep the matrix in fast GPU shared memory while receiving new inputs.</p>
<p>GPUrdma prototype is not yet suitable for production systems due to hardware constraints in the current generation of NVIDIA GPUs which we discuss in detail. However, our results highlight the great potential of GPU-side native networking, and encourage further research toward scalable, high-performance, a heterogeneous networking infrastructure.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{ross16gpurdma,
<br>author = {Daoud, Feras and Watad, Amir and Silberstein, Mark},
<br>title = {GPUrdma: GPU-Side Library for High Performance Networking from GPU Kernels},
<br>year = {2016},
<br>isbn = {9781450343879},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2931088.2931091},
<br>doi = {10.1145/2931088.2931091},
<br>booktitle = {Proceedings of the 6th International Workshop on Runtime and Operating Systems for Supercomputers},
<br>articleno = {Article 6},
<br>numpages = {8},
<br>keywords = {Networking, accelerators, Operating Systems Design, GPGPUs},
<br>location = {Kyoto, Japan},
<br>series = {ROSS ’16}
<br>}
<br>
<br> </div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/04/ROSS2016-GPUrdma.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for GPUrdma: GPU-side library for high performance networking from GPU kernels"></a> </div><div class="pbl_astring"><span class="pblempta">Feras Daoud</span>, <a href="https://www.linkedin.com/in/amirwatad" target="_blank">Amir Watad</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><div class="pbl_snotes">Best Paper Award</div> </span></div></div><div class="publ_cart_wrapper" id="p1299"><span class="pbl_akr">[SYSTOR]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2928275.2928276%20" target="_blank">Supporting data-driven I/O on GPUs using GPUfs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1299" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Supporting data-driven I/O on GPUs using GPUfs"></a><div class="remodal" data-remodal-id="modal0_1299" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Supporting data-driven I/O on GPUs using GPUfs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gpufs16systor,
<br>author = {Shahar, Sagi and Silberstein, Mark},
<br>title = {Supporting Data-Driven I/O on GPUs Using GPUfs},
<br>year = {2016},
<br>isbn = {9781450343817},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2928275.2928276},
<br>doi = {10.1145/2928275.2928276},
<br>booktitle = {Proceedings of the 9th ACM International on Systems and Storage Conference},
<br>articleno = {Article 12},
<br>numpages = {11},
<br>keywords = {GPGPUs, Operating Systems, File Systems},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR ’16}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1299" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Supporting data-driven I/O on GPUs using GPUfs"></a><div class="remodal" data-remodal-id="modal1_1299" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Supporting data-driven I/O on GPUs using GPUfs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Using discrete GPUs for processing very large datasets is challenging, in particular when an algorithm exhibit unpredictable, data-driven access patterns. In this paper, we investigate the utility of GPUfs, a library that provides direct access to files from GPU programs, to implement such algorithms. We analyze the system&#8217;s bottlenecks, and suggest several modifications to the GPUfs design, including new concurrent hash table for the buffer cache and a highly parallel memory allocator. We also show that by implementing the workload in a warp-centric manner we can improve the performance even further. We evaluate our changes by implementing a real image processing application which creates collages from a dataset of 10 Million images. The enhanced GPUfs design improves the application performance by 5.6× on average over the original GPUfs, and outperforms both 12-core parallel CPU which uses the AVX instruction set, and a standard CUDA-based GPU implementation by up to 2.5× and 3× respectively, while significantly enhancing system programmability and simplifying the application design and implementation.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gpufs16systor,
<br>author = {Shahar, Sagi and Silberstein, Mark},
<br>title = {Supporting Data-Driven I/O on GPUs Using GPUfs},
<br>year = {2016},
<br>isbn = {9781450343817},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2928275.2928276},
<br>doi = {10.1145/2928275.2928276},
<br>booktitle = {Proceedings of the 9th ACM International on Systems and Storage Conference},
<br>articleno = {Article 12},
<br>numpages = {11},
<br>keywords = {GPGPUs, Operating Systems, File Systems},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR ’16}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><span class="pblempta">Sagi Shachar</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1301"><span class="pbl_akr">[ICS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2925426.2926259" target="_blank">Fast Multiplication in Binary Fields on GPUs via Register Cache</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1301" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Fast Multiplication in Binary Fields on GPUs via Register Cache"></a><div class="remodal" data-remodal-id="modal0_1301" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Fast Multiplication in Binary Fields on GPUs via Register Cache</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gpufft16ics,
<br>author = {Ben-Sasson, Eli and Hamilis, Matan and Silberstein, Mark and Tromer, Eran},
<br>title = {Fast Multiplication in Binary Fields on GPUs via Register Cache},
<br>year = {2016},
<br>isbn = {9781450343619},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2925426.2926259},
<br>doi = {10.1145/2925426.2926259},
<br>booktitle = {Proceedings of the 2016 International Conference on Supercomputing},
<br>articleno = {Article 35},
<br>numpages = {12},
<br>keywords = {Finite Field Multiplication, GPGPU, SIMD, Parallel Algorithms, GPU Code Optimization},
<br>location = {Istanbul, Turkey},
<br>series = {ICS ’16}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1301" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Fast Multiplication in Binary Fields on GPUs via Register Cache"></a><div class="remodal" data-remodal-id="modal1_1301" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Fast Multiplication in Binary Fields on GPUs via Register Cache</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>Finite fields of characteristic 2 &#8212; &#8220;binary fields&#8221; &#8212; are used in a variety of applications in cryptography and data storage. Multiplication of two finite field elements is a fundamental operation and a well-known computational bottleneck in many of these applications, as they often require multiplication of a large number of elements. In this work we focus on accelerating multiplication in &#8220;large&#8221; binary fields of sizes greater than 232. We devise a new parallel algorithm optimized for execution on GPUs. This algorithm makes it possible to multiply large number of finite field elements and achieves high performance via bit-slicing and fine-grained parallelization.</p>
<p>The key to the efficient implementation of the algorithm is a novel performance optimization methodology we call the register cache. This methodology speeds up an algorithm that caches its input in shared memory by transforming the code to use per-thread registers instead. We show how to replace shared memory accesses with the shuffle() intra-warp communication instruction, thereby significantly reducing or even eliminating shared memory accesses. We thoroughly analyze the register cache approach and characterize its benefits and limitations.</p>
<p>We apply the register cache methodology to the implementation of the binary finite field multiplication algorithm on GPUs. We achieve up to 138x speedup for fields of size 232 over the popular, highly optimized Number Theory Library (NTL) [26], which uses the specialized CLMUL CPU instruction, and over 30x for larger fields of size below 2256. Our register cache implementation enables up to 50% higher performance compared to the traditional shared-memory based design.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gpufft16ics,
<br>author = {Ben-Sasson, Eli and Hamilis, Matan and Silberstein, Mark and Tromer, Eran},
<br>title = {Fast Multiplication in Binary Fields on GPUs via Register Cache},
<br>year = {2016},
<br>isbn = {9781450343619},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2925426.2926259},
<br>doi = {10.1145/2925426.2926259},
<br>booktitle = {Proceedings of the 2016 International Conference on Supercomputing},
<br>articleno = {Article 35},
<br>numpages = {12},
<br>keywords = {Finite Field Multiplication, GPGPU, SIMD, Parallel Algorithms, GPU Code Optimization},
<br>location = {Istanbul, Turkey},
<br>series = {ICS ’16}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/04/full.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Fast Multiplication in Binary Fields on GPUs via Register Cache"></a> <a title="code" href="https://github.com/HamilM/one_stencil" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for Fast Multiplication in Binary Fields on GPUs via Register Cache"></a> <a  title="NVIDIA Blog "  href="https://devblogs.nvidia.com/register-cache-warp-cuda/" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-other.gif" alt="Icon Other for Fast Multiplication in Binary Fields on GPUs via Register Cache"></a> </div><div class="pbl_astring"><span class="pblempta">Matan Hamilis</span>, <a href="https://eli.net.technion.ac.il/" target="_blank">Eli Ben-Sasson</a>, <a href="https://www.tau.ac.il/~tromer/" target="_blank">Eran Tromer</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><div class="pbl_snotes">Also published in NVIDIA Developers Blog</div> </span></div></div><div class="publ_cart_wrapper" id="p1309"><span class="pbl_akr">[ISCA]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/ISCA.camera.ready_.pdf" target="_blank">ActivePointers: A Case for Software Address Translation on GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1309" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for ActivePointers: A Case for Software Address Translation on GPUs"></a><div class="remodal" data-remodal-id="modal0_1309" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">ActivePointers: A Case for Software Address Translation on GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{activepointers16isca,  
<br>   author={Shahar, Sagi and Bergman, Shai and Silberstein, Mark}, 
<br>   booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)},  
<br>   title={{ActivePointers: A Case for Software Address Translation on GPUs}},
<br>   year={2016},  
<br>   pages={596-608}
<br>   series = {ISCA'16}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1309" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for ActivePointers: A Case for Software Address Translation on GPUs"></a><div class="remodal" data-remodal-id="modal1_1309" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">ActivePointers: A Case for Software Address Translation on GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Modern discrete GPUs have been the processors of choice for accelerating compute-intensive applications, but using them in large-scale data processing is extremely challenging. Unfortunately, they do not provide important I/O abstractions long established in the CPU context, such as memory mapped files, which shield programmers from the complexity of buffer and I/O device management. However, implementing these abstractions on GPUs poses a problem: the limited GPU virtual memory system provides no address space management and page fault handling mechanisms to GPU developers, and does not allow modifications to memory mappings for running GPU programs.</p>
<p>We implement ActivePointers, a software address translation layer and paging system that introduces native support for page faults and virtual address space management to GPU programs, and enables the implementation of fully functional memory mapped files on commodity GPUs. Files mapped into GPU memory are accessed using active pointers, which behave like regular pointers but access the GPU page cache under the hood, and trigger page faults which are handled on the GPU. We design and evaluate a number of novel mechanisms, including a translation cache in hardware registers and translation aggregation for deadlock-free page fault handling of threads in a single warp.</p>
<p>We extensively evaluate ActivePointers on commodity NVIDIA GPUs using microbenchmarks, and also implement a complex image processing application that constructs a photo collage from a subset of 10 million images stored in a 40GB file. The GPU implementation maps the entire file into GPU memory and accesses it via active pointers. The use of active pointers adds only up to 1% to the application&#8217;s runtime, while enabling speedups of up to 3.9× over a combined CPU+GPU implementation and 2.6× over a 12-core CPU-only implementation which uses AVX vector instructions.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{activepointers16isca,  
<br>   author={Shahar, Sagi and Bergman, Shai and Silberstein, Mark}, 
<br>   booktitle={2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA)},  
<br>   title={{ActivePointers: A Case for Software Address Translation on GPUs}},
<br>   year={2016},  
<br>   pages={596-608}
<br>   series = {ISCA'16}
<br>}</div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/04/9A-2.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for ActivePointers: A Case for Software Address Translation on GPUs"></a> <a title="code" href="https://github.com/gpufs/gpufs" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for ActivePointers: A Case for Software Address Translation on GPUs"></a> </div><div class="pbl_astring"><span class="pblempta">Sagi Shachar</span>, <span class="pblempta">Shai Bergman</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1313"><span class="pbl_akr">[EuroSys]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/eurosys16loca_camera_ready.pdf" target="_blank">Optimizing Distributed Actor Systems for Dynamic Interactive Services</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1313" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Optimizing Distributed Actor Systems for Dynamic Interactive Services"></a><div class="remodal" data-remodal-id="modal0_1313" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Optimizing Distributed Actor Systems for Dynamic Interactive Services</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{actop16eurosys,
<br>author = {Newell, Andrew and Kliot, Gabriel and Menache, Ishai and Gopalan, Aditya and Akiyama, Soramichi and Silberstein, Mark},
<br>title = {Optimizing Distributed Actor Systems for Dynamic Interactive Services},
<br>year = {2016},
<br>isbn = {9781450342407},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2901318.2901343},
<br>doi = {10.1145/2901318.2901343},
<br>booktitle = {Proceedings of the Eleventh European Conference on Computer Systems},
<br>articleno = {Article 38},
<br>numpages = {15},
<br>location = {London, United Kingdom},
<br>series = {EuroSys ’16}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1313" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Optimizing Distributed Actor Systems for Dynamic Interactive Services"></a><div class="remodal" data-remodal-id="modal1_1313" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Optimizing Distributed Actor Systems for Dynamic Interactive Services</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>Distributed actor systems are widely used for developing interactive scalable cloud services, such as social networks and online games. By modelling an application as a dynamic set of lightweight communicating &#8220;actors&#8221;, developers can easily build complex distributed applications, while the underlying runtime system deals with low-level complexities of a distributed environment.</p>
<p>We present <i>ActOp</i>&#8212;a data-driven, application-independent runtime mechanism for optimizing end-to-end service latency of actor-based distributed applications. <i>ActOp</i> targets the two dominant factors affecting latency: the overhead of remote inter-actor communications across servers, and the intra-server queuing delay. <i>ActOp</i> automatically identifies frequently communicating actors and migrates them to the same server transparently to the running application. The migration decisions are driven by a novel scalable distributed graph partitioning algorithm which does not rely on a single server to store the whole communication graph, thereby enabling efficient actor placement even for applications with rapidly changing graphs (e.g., chat services). Further, each server autonomously reduces the queuing delay by learning an internal queuing model and configuring threads according to instantaneous request rate and application demands.</p>
<p>We prototype <i>ActOp</i> by integrating it with <i>Orleans</i> &#8212; a popular open-source actor system [4, 13]. Experiments with realistic workloads show latency improvements of up to 75% for the 99th percentile, up to 63% for the mean, with up to 2x increase in peak system throughput.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{actop16eurosys,
<br>author = {Newell, Andrew and Kliot, Gabriel and Menache, Ishai and Gopalan, Aditya and Akiyama, Soramichi and Silberstein, Mark},
<br>title = {Optimizing Distributed Actor Systems for Dynamic Interactive Services},
<br>year = {2016},
<br>isbn = {9781450342407},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2901318.2901343},
<br>doi = {10.1145/2901318.2901343},
<br>booktitle = {Proceedings of the Eleventh European Conference on Computer Systems},
<br>articleno = {Article 38},
<br>numpages = {15},
<br>location = {London, United Kingdom},
<br>series = {EuroSys ’16}
<br>}</div></div></div><div class="pbl_astring"><span class="pblempta">Andrew Newell</span>, <span class="pblempta">Gabriel Kliot</span>, <span class="pblempta">Ishai Menashe</span>, <span class="pblempta">Aditya Gopalan</span>, <span class="pblempta">Soramichi Akiyama</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1316"><span class="pbl_akr">[GPGPU]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/gpgpu16preempt.pdf" target="_blank">GPUpIO: The Case for I/O-Driven Preemption on GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1316" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUpIO: The Case for I/O-Driven Preemption on GPUs"></a><div class="remodal" data-remodal-id="modal0_1316" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUpIO: The Case for I/O-Driven Preemption on GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{GPUPIO16GPGPU,
<br>author = {Zeno, Lior and Mendelson, Avi and Silberstein, Mark},
<br>title = {GPUpIO: The Case for I/O-Driven Preemption on GPUs},
<br>year = {2016},
<br>publisher = {ACM},
<br>@inproceedings{10.1145/2884045.2884053,
<br>author = {Zeno, Lior and Mendelson, Avi and Silberstein, Mark},
<br>title = {GPUpIO: The Case for I/O-Driven Preemption on GPUs},
<br>year = {2016},
<br>isbn = {9781450341950},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2884045.2884053},
<br>doi = {10.1145/2884045.2884053},
<br>booktitle = {Proceedings of the 9th Annual Workshop on General Purpose Processing Using Graphics Processing Unit},
<br>pages = {63–71},
<br>numpages = {9},
<br>keywords = {accelerators, GPGPUs, operating systems design, file systems, source-to-source compiliation},
<br>location = {Barcelona, Spain},
<br>series = {GPGPU ’16}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1316" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUpIO: The Case for I/O-Driven Preemption on GPUs"></a><div class="remodal" data-remodal-id="modal1_1316" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUpIO: The Case for I/O-Driven Preemption on GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>As GPUs become general purpose, they are outgrowing the coprocessor model and require convenient I/O abstractions such as files and network sockets. Recent studies have shown the benefits of native GPU I/O layers, in terms of both programmability and performance. However, due to lack of hardware support, the GPU threads performing I/O calls are forced to busy-wait for the completion of I/O operations, resulting in underutilized hardware, higher power consumption, and reduced system throughput.</p>
<p>We argue that I/O-driven <i>preemption</i> improves the performance of existing solutions, despite many challenging system characteristics such as a large kernel state. We analyze the benefits of adding preemption support using a simple system performance model, and, encouraged by the results, explore the design of a software-based preemption mechanism for GPUs. In our prototype, <b>GPUpIO</b>, we implement a source-to-source compiler for state checkpoint and restoration, and a runtime library for scheduling preempted thread-blocks, which together enable I/O-driven preemption for GPUs.</p>
<p>We evaluate our prototype across a variety of system parameters and workloads to determine when preemption is worthwhile. We show that in some workloads the I/O-driven preemption approach may indeed double the effective system throughput by completely hiding the I/O latency behind computations. However, we also observe that the software-only solution is currently limited, not only due to its overheads, but also because it does not have sufficient control of the hardware scheduler queue and therefore may lead to starvation of I/O kernels. We then discuss a new hardware feature that, if added, may render a general I/O-driven preemption mechanism on GPUs practical.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{GPUPIO16GPGPU,
<br>author = {Zeno, Lior and Mendelson, Avi and Silberstein, Mark},
<br>title = {GPUpIO: The Case for I/O-Driven Preemption on GPUs},
<br>year = {2016},
<br>publisher = {ACM},
<br>@inproceedings{10.1145/2884045.2884053,
<br>author = {Zeno, Lior and Mendelson, Avi and Silberstein, Mark},
<br>title = {GPUpIO: The Case for I/O-Driven Preemption on GPUs},
<br>year = {2016},
<br>isbn = {9781450341950},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2884045.2884053},
<br>doi = {10.1145/2884045.2884053},
<br>booktitle = {Proceedings of the 9th Annual Workshop on General Purpose Processing Using Graphics Processing Unit},
<br>pages = {63–71},
<br>numpages = {9},
<br>keywords = {accelerators, GPGPUs, operating systems design, file systems, source-to-source compiliation},
<br>location = {Barcelona, Spain},
<br>series = {GPGPU ’16}
<br>}</div></div></div><div class="pbl_astring"><a href="https://www.linkedin.com/in/lior-zeno-921b07119" target="_blank">Lior Zeno</a>, <span class="pblempta">Avi Mendelson</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2014">2014</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1320"><span class="pbl_akr">[OSDI]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://www.usenix.org/node/186166" target="_blank">GPUnet: Networking Abstractions for GPU Programs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1320" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUnet: Networking Abstractions for GPU Programs"></a><div class="remodal" data-remodal-id="modal0_1320" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUnet: Networking Abstractions for GPU Programs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {gpunet14osdi,
<br>author = {Sangman Kim and Seonggu Huh and Xinya Zhang and Yige Hu and Amir Wated and Emmett Witchel and Mark Silberstein},
<br>title = {GPUnet: Networking Abstractions for {GPU} Programs},
<br>booktitle = {11th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 14)},
<br>year = {2014},
<br>isbn = { 978-1-931971-16-4},
<br>address = {Broomfield, CO},
<br>pages = {201--216},
<br>url = {https://www.usenix.org/conference/osdi14/technical-sessions/presentation/kim},
<br>publisher = {{USENIX} Association},
<br>month = oct,
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1320" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUnet: Networking Abstractions for GPU Programs"></a><div class="remodal" data-remodal-id="modal1_1320" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUnet: Networking Abstractions for GPU Programs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="field-items">
<div class="field-item odd">
<p>Despite the popularity of GPUs in high-performance and scientific computing, and despite increasingly general-purpose hardware capabilities, the use of GPUs in network servers or distributed systems poses significant challenges.</p>
<p><strong>GPUnet</strong> is a native GPU networking layer that provides a socket abstraction and high-level networking APIs for GPU programs. We use GPUnet to streamline the development of high-performance, distributed applications like in-GPU-memory MapReduce and a new class of low-latency, high-throughput GPU-native network services such as a face verification server.</p>
</div>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings {gpunet14osdi,
<br>author = {Sangman Kim and Seonggu Huh and Xinya Zhang and Yige Hu and Amir Wated and Emmett Witchel and Mark Silberstein},
<br>title = {GPUnet: Networking Abstractions for {GPU} Programs},
<br>booktitle = {11th {USENIX} Symposium on Operating Systems Design and Implementation ({OSDI} 14)},
<br>year = {2014},
<br>isbn = { 978-1-931971-16-4},
<br>address = {Broomfield, CO},
<br>pages = {201--216},
<br>url = {https://www.usenix.org/conference/osdi14/technical-sessions/presentation/kim},
<br>publisher = {{USENIX} Association},
<br>month = oct,
<br>}</div></div><a title="slides" href="https://www.usenix.org/sites/default/files/conference/protected-files/osdi14_slides_kim-sangman.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for GPUnet: Networking Abstractions for GPU Programs"></a> <a title="code" href="https://github.com/ut-osa/gpunet/" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for GPUnet: Networking Abstractions for GPU Programs"></a> </div><div class="pbl_astring"><span class="pblempta">Sangman Kim</span>, <span class="pblempta">Seonggu Huh</span>, <span class="pblempta">Yige Hu</span>, <span class="pblempta">Xinya Zhang</span>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a>, <a href="https://www.linkedin.com/in/amirwatad" target="_blank">Amir Watad</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1322"><span class="pbl_akr">[CACM]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://cacm.acm.org/magazines/2014/12/180783-gpufs/fulltext" target="_blank">GPUfs: the case for operating system services on GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1322" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUfs: the case for operating system services on GPUs"></a><div class="remodal" data-remodal-id="modal0_1322" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUfs: the case for operating system services on GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{gpufs14cacm,
<br>author = {Silberstein, Mark and Ford, Bryan and Witchel, Emmett},
<br>title = {GPUfs: The Case for Operating System Services on GPUs},
<br>year = {2014},
<br>issue_date = {November 2014},
<br>publisher = {ACM},
<br>address = {New York, NY, USA},
<br>volume = {57},
<br>number = {12},
<br>issn = {0001-0782},
<br>url = {https://doi.org/10.1145/2656206},
<br>doi = {10.1145/2656206},
<br>journal = {Commun. ACM},
<br>month = nov,
<br>pages = {68–79},
<br>numpages = {12}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1322" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUfs: the case for operating system services on GPUs"></a><div class="remodal" data-remodal-id="modal1_1322" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUfs: the case for operating system services on GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>This is a non-technical article that covers the main aspects of the GPUfs file system layer for GPU software that makes operating system abstractions available to GPU code.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{gpufs14cacm,
<br>author = {Silberstein, Mark and Ford, Bryan and Witchel, Emmett},
<br>title = {GPUfs: The Case for Operating System Services on GPUs},
<br>year = {2014},
<br>issue_date = {November 2014},
<br>publisher = {ACM},
<br>address = {New York, NY, USA},
<br>volume = {57},
<br>number = {12},
<br>issn = {0001-0782},
<br>url = {https://doi.org/10.1145/2656206},
<br>doi = {10.1145/2656206},
<br>journal = {Commun. ACM},
<br>month = nov,
<br>pages = {68–79},
<br>numpages = {12}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://bford.info/" target="_blank">Bryan Ford</a>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a> <span class="pbl_nstring"><div class="pbl_snotes">Invited to Communication of ACM</div> </span></div></div><div class="publ_cart_wrapper" id="p1325"><span class="pbl_akr">[SYSTOR]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><span class="pbl_name">Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-coded Distributed Storage</span></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1325" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-coded Distributed Storage"></a><div class="remodal" data-remodal-id="modal0_1325" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-coded Distributed Storage</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{erasurecoding14systor,
<br>author = {Silberstein, Mark and Ganesh, Lakshmi and Wang, Yang and Alvisi, Lorenzo and Dahlin, Mike},
<br>title = {Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-Coded Distributed Storage},
<br>year = {2014},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2611354.2611370},
<br>doi = {10.1145/2611354.2611370},
<br>booktitle = {Proceedings of International Conference on Systems and Storage},
<br>pages = {1–7},
<br>numpages = {7},
<br>keywords = {Distributed storage systems, Erasure codes, Repair bandwidth},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR 2014}
<br>}
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1325" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-coded Distributed Storage"></a><div class="remodal" data-remodal-id="modal1_1325" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-coded Distributed Storage</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Erasure coding schemes provide higher durability at lower storage cost, and thus constitute an attractive alternative to replication in distributed storage systems, in particular for storing rarely accessed &#8220;cold&#8221; data. These schemes, however, require an order of magnitude higher recovery bandwidth for maintaining a constant level of durability in the face of node failures. In this paper we propose lazy recovery, a technique to reduce recovery bandwidth demands down to the level of replicated storage. The key insight is that a careful adjustment of recovery rate substantially reduces recovery bandwidth, while keeping the impact on read performance and data durability low. We demonstrate the benefits of lazy recovery via extensive simulation using a realistic distributed storage configuration and published component failure parameters. For example, when applied to the commonly used RS(14, 10) code, lazy recovery reduces repair bandwidth by up to 76% even below replication, while increasing the amount of degraded stripes by 0.1 percentage points. Lazy recovery works well with a variety of erasure coding schemes, including the recently introduced bandwidth efficient codes, achieving up to a factor of 2 additional bandwidth savings.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{erasurecoding14systor,
<br>author = {Silberstein, Mark and Ganesh, Lakshmi and Wang, Yang and Alvisi, Lorenzo and Dahlin, Mike},
<br>title = {Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-Coded Distributed Storage},
<br>year = {2014},
<br>publisher = {ACM},
<br>url = {https://doi.org/10.1145/2611354.2611370},
<br>doi = {10.1145/2611354.2611370},
<br>booktitle = {Proceedings of International Conference on Systems and Storage},
<br>pages = {1–7},
<br>numpages = {7},
<br>keywords = {Distributed storage systems, Erasure codes, Repair bandwidth},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR 2014}
<br>}
<br>
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/04/lazy-recovery.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Lazy Means Smart: Reducing Repair Bandwidth Costs in Erasure-coded Distributed Storage"></a> </div><div class="pbl_astring"><span class="pblempta">Publications</span>, <span class="pblempta">Lakshmi Ganesh</span>, <a href="http://web.cse.ohio-state.edu/~wang.7564/" target="_blank">Yang Wang</a>, <a href="https://www.engineering.cornell.edu/faculty-directory/lorenzo-alvisi" target="_blank">Lorenzo Alvisi</a>, <a href="http://www.cs.utexas.edu/~dahlin/" target="_blank">Mike Dahlin</a> <span class="pbl_nstring"><div class="pbl_snotes">Best Paper Award</div> </span></div></div><div class="publ_cart_wrapper" id="p1328"><span class="pbl_akr">[ACM TOCS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2553081" target="_blank">GPUfs: Integrating a file system with GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1328" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUfs: Integrating a file system with GPUs"></a><div class="remodal" data-remodal-id="modal0_1328" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUfs: Integrating a file system with GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{gpufs14tocs,
<br>author = {Silberstein, Mark and Ford, Bryan and Keidar, Idit and Witchel, Emmett},
<br>title = {GPUfs: Integrating a File System with GPUs},
<br>year = {2014},
<br>issue_date = {February 2014},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>volume = {32},
<br>number = {1},
<br>issn = {0734-2071},
<br>url = {https://doi.org/10.1145/2553081},
<br>doi = {10.1145/2553081},
<br>journal = {ACM Trans. Comput. Syst.},
<br>month = feb,
<br>articleno = {Article 1},
<br>numpages = {31},
<br>keywords = {operating systems, GPGPUs, operating systems design, file systems, Accelerators}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1328" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUfs: Integrating a file system with GPUs"></a><div class="remodal" data-remodal-id="modal1_1328" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUfs: Integrating a file system with GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>As GPU hardware becomes increasingly general-purpose, it is quickly outgrowing the traditional, constrained GPU-as-coprocessor programming model. This article advocates for extending standard operating system services and abstractions to GPUs in order to facilitate program development and enable harmonious integration of GPUs in computing systems. As an example, we describe the design and implementation of GPUFs, a software layer which provides operating system support for accessing host files directly from GPU programs. GPUFs provides a POSIX-like API, exploits GPU parallelism for efficiency, and optimizes GPU file access by extending the host CPU&#8217;s buffer cache into GPU memory. Our experiments, based on a set of real benchmarks adapted to use our file system, demonstrate the feasibility and benefits of the GPUFs approach. For example, a self-contained GPU program that searches for a set of strings throughout the Linux kernel source tree runs over seven times faster than on an eight-core CPU.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{gpufs14tocs,
<br>author = {Silberstein, Mark and Ford, Bryan and Keidar, Idit and Witchel, Emmett},
<br>title = {GPUfs: Integrating a File System with GPUs},
<br>year = {2014},
<br>issue_date = {February 2014},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>volume = {32},
<br>number = {1},
<br>issn = {0734-2071},
<br>url = {https://doi.org/10.1145/2553081},
<br>doi = {10.1145/2553081},
<br>journal = {ACM Trans. Comput. Syst.},
<br>month = feb,
<br>articleno = {Article 1},
<br>numpages = {31},
<br>keywords = {operating systems, GPGPUs, operating systems design, file systems, Accelerators}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://bford.info/" target="_blank">Bryan Ford</a>, <a href="https://webee.technion.ac.il/~idish/" target="_blank">Idit Keidar</a>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a> <span class="pbl_nstring"><div class="pbl_snotes">Extended version of the ASPLOS'13 paper, Fast-track acceptance</div> </span></div></div><div class="publ_cart_wrapper" id="p1330"><span class="pbl_akr">[ACM UBIQUITY]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2618401" target="_blank">GPUs: High-performance Accelerators for Parallel Applications.</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1330" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUs: High-performance Accelerators for Parallel Applications."></a><div class="remodal" data-remodal-id="modal0_1330" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUs: High-performance Accelerators for Parallel Applications.</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{uniquity,
<br>author = {Silberstein, Mark},
<br>title = {GPUs: High-Performance Accelerators for Parallel Applications: The Multicore Transformation (Ubiquity Symposium)},
<br>year = {2014},
<br>issue_date = {August 2014},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>volume = {2014},
<br>number = {August},
<br>url = {https://doi.org/10.1145/2618401},
<br>doi = {10.1145/2618401},
<br>journal = {Ubiquity},
<br>month = aug,
<br>articleno = {Article 1},
<br>numpages = {13}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1330" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUs: High-performance Accelerators for Parallel Applications."></a><div class="remodal" data-remodal-id="modal1_1330" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUs: High-performance Accelerators for Parallel Applications.</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Early graphical processing units (GPUs) were designed as high compute density, fixed-function processors ideally crafted to the needs of computer graphics workloads. Today, GPUs are becoming truly first-class computing elements on par with CPUs. Programming GPUs as self-sufficient general-purpose processors is not only hypothetically desirable, but feasible and efficient in practice, opening new opportunities for integration of GPUs in complex software systems.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{uniquity,
<br>author = {Silberstein, Mark},
<br>title = {GPUs: High-Performance Accelerators for Parallel Applications: The Multicore Transformation (Ubiquity Symposium)},
<br>year = {2014},
<br>issue_date = {August 2014},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>volume = {2014},
<br>number = {August},
<br>url = {https://doi.org/10.1145/2618401},
<br>doi = {10.1145/2618401},
<br>journal = {Ubiquity},
<br>month = aug,
<br>articleno = {Article 1},
<br>numpages = {13}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><div class="pbl_snotes">Invited to Ubiquity Symposium on Parallel Computing</div> </span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2013">2013</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1332"><span class="pbl_akr">[Bioinformatics]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3546794/" target="_blank">A System for Exact and Approximate Genetic Linkage Analysis of SNP Data in Large Pedigrees</a></span><div class="pbl_nstring2"><a href="#" title="abstract" data-remodal-target="modal1_1332" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for A System for Exact and Approximate Genetic Linkage Analysis of SNP Data in Large Pedigrees"></a><div class="remodal" data-remodal-id="modal1_1332" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">A System for Exact and Approximate Genetic Linkage Analysis of SNP Data in Large Pedigrees</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p id="__p2" class="p p-first"><strong>Motivation:</strong> The use of dense single nucleotide polymorphism (SNP) data in genetic linkage analysis of large pedigrees is impeded by significant technical, methodological and computational challenges. Here we describe Superlink-Online SNP, a new powerful online system that streamlines the linkage analysis of SNP data. It features a fully integrated flexible processing workflow comprising both well-known and novel data analysis tools, including SNP clustering, erroneous data filtering, exact and approximate LOD calculations and maximum-likelihood haplotyping. The system draws its power from thousands of CPUs, performing data analysis tasks orders of magnitude faster than a single computer. By providing an intuitive interface to sophisticated state-of-the-art analysis tools coupled with high computing capacity, Superlink-Online SNP helps geneticists unleash the potential of SNP data for detecting disease genes.</p>
<p id="__p3"><strong>Results:</strong> Computations performed by Superlink-Online SNP are automatically parallelized using novel paradigms, and executed on unlimited number of private or public CPUs. One novel service is large-scale approximate Markov Chain–Monte Carlo (MCMC) analysis. The accuracy of the results is reliably estimated by running the same computation on multiple CPUs and evaluating the Gelman–Rubin Score to set aside unreliable results. Another service within the workflow is a novel parallelized exact algorithm for inferring maximum-likelihood haplotyping. The reported system enables genetic analyses that were previously infeasible. We demonstrate the system capabilities through a study of a large complex pedigree affected with metabolic syndrome.</p>
<p id="__p4"><strong>Availability:</strong> Superlink-Online SNP is freely available for researchers at <a href="http://cbl-hap.cs.technion.ac.il/superlink-snp" target="_blank" rel="noopener" data-ga-action="click_feat_suppl">http://cbl-hap.cs.technion.ac.il/superlink-snp</a>. The system source code can also be downloaded from the system website.</p>
</div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Omer Weissbrod</span>, <span class="pblempta">Lars Otten</span>, <span class="pblempta">Anna Tzemach</span>, <span class="pblempta">Andrey Anisenia</span>, <span class="pblempta">Omer Shtark</span>, <span class="pblempta">Dvir Tuberg</span>, <span class="pblempta">Eddie Galfrin</span>, <span class="pblempta">Irena Gannon</span>, <span class="pblempta">Adel Shalata</span>, <span class="pblempta">Zvi U. Borochowitz</span>, <a href="https://www.ics.uci.edu/~dechter/" target="_blank">Rina Dechter</a>, <a href="https://www.stat.washington.edu/thompson/" target="_blank">Elizabeth Thompson</a>, <a href="http://www.cs.technion.ac.il/~dang/" target="_blank">Dan Geiger</a> <span class="pbl_nstring"><div class="pbl_snotes">Detailed description of Superlink-onlineSNP system</div> </span></div></div><div class="publ_cart_wrapper" id="p1375"><span class="pbl_akr">[ASPLOS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2499368.2451169" target="_blank">GPUfs: integrating a file system with GPUs</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1375" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GPUfs: integrating a file system with GPUs"></a><div class="remodal" data-remodal-id="modal0_1375" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GPUfs: integrating a file system with GPUs</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gpufs13ASPLOS,
<br>author = {Silberstein, Mark and Ford, Bryan and Keidar, Idit and Witchel, Emmett},
<br>title = {GPUfs: Integrating a File System with GPUs},
<br>year = {2013},
<br>isbn = {9781450318709},
<br>publisher = {ACM},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/2451116.2451169},
<br>doi = {10.1145/2451116.2451169},
<br>booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
<br>pages = {485–498},
<br>numpages = {14},
<br>keywords = {accelerators, operating systems design, file systems, gpgpus},
<br>location = {Houston, Texas, USA},
<br>series = {ASPLOS ’13}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1375" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GPUfs: integrating a file system with GPUs"></a><div class="remodal" data-remodal-id="modal1_1375" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GPUfs: integrating a file system with GPUs</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>GPU hardware is becoming increasingly general purpose, quickly outgrowing the traditional but constrained GPU-as-coprocessor programming model. To make GPUs easier to program and easier to integrate with existing systems, we propose making the host&#8217;s file system directly accessible from GPU code.</p>
<p>GPUfs provides a POSIX-like API for GPU programs, exploits GPU parallelism for efficiency, and optimizes GPU file access by extending the buffer cache into GPU memory. Our experiments, based on a set of real benchmarks adopted to use our file system, demonstrate the feasibility and benefits of our approach. For example, we demonstrate a simple self-contained GPU program which searches for a set of strings in the entire tree of Linux kernel source files over seven times faster than an eight-core CPU run.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gpufs13ASPLOS,
<br>author = {Silberstein, Mark and Ford, Bryan and Keidar, Idit and Witchel, Emmett},
<br>title = {GPUfs: Integrating a File System with GPUs},
<br>year = {2013},
<br>isbn = {9781450318709},
<br>publisher = {ACM},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/2451116.2451169},
<br>doi = {10.1145/2451116.2451169},
<br>booktitle = {Proceedings of the Eighteenth International Conference on Architectural Support for Programming Languages and Operating Systems},
<br>pages = {485–498},
<br>numpages = {14},
<br>keywords = {accelerators, operating systems design, file systems, gpgpus},
<br>location = {Houston, Texas, USA},
<br>series = {ASPLOS ’13}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="code" href="https://github.com/gpufs/gpufs" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-code.gif" alt="code for GPUfs: integrating a file system with GPUs"></a> </div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://bford.info/" target="_blank">Bryan Ford</a>, <a href="https://webee.technion.ac.il/~idish/" target="_blank">Idit Keidar</a>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a> <span class="pbl_nstring"><div class="pbl_snotes">Best Paper Runner-up</div> </span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2012">2012</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1334"><span class="pbl_akr">[OSDI]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://www.usenix.org/system/files/conference/osdi12/osdi12-final-100.pdf" target="_blank">Eternal Sunshine of the Spotless Machine: Protecting Privacy  with Ephemeral Channels</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1334" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Eternal Sunshine of the Spotless Machine: Protecting Privacy  with Ephemeral Channels"></a><div class="remodal" data-remodal-id="modal0_1334" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Eternal Sunshine of the Spotless Machine: Protecting Privacy  with Ephemeral Channels</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{spotless12osdi,
<br>author = {Dunn, Alan M. and Lee, Michael Z. and Jana, Suman and Kim, Sangman and Silberstein, Mark and Xu, Yuanzhong and Shmatikov, Vitaly and Witchel, Emmett},
<br>title = {Eternal Sunshine of the Spotless Machine: Protecting Privacy with Ephemeral Channels},
<br>year = {2012},
<br>isbn = {9781931971966},
<br>publisher = {USENIX Association},
<br>address = {USA},
<br>booktitle = {Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation},
<br>pages = {61–75},
<br>numpages = {15},
<br>location = {Hollywood, CA, USA},
<br>series = {OSDI’12}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1334" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Eternal Sunshine of the Spotless Machine: Protecting Privacy  with Ephemeral Channels"></a><div class="remodal" data-remodal-id="modal1_1334" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Eternal Sunshine of the Spotless Machine: Protecting Privacy  with Ephemeral Channels</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>Modern systems keep long memories. As we show in this paper, an adversary who gains access to a Linux system, even one that implements secure deallocation, can recover the contents of applications&#8217; windows, audio buffers, and data remaining in device drivers&#8211;long after the applications have terminated.</p>
<p>We design and implement Lacuna, a system that allows users to run programs in &#8220;private sessions.&#8221; After the session is over, all memories of its execution are erased. The key abstraction in Lacuna is an ephemeral channel, which allows the protected program to talk to peripheral devices while making it possible to delete the memories of this communication from the host. Lacuna can run unmodified applications that use graphics, sound, USB input devices, and the network, with only 20 percentage points of additional CPU utilization.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{spotless12osdi,
<br>author = {Dunn, Alan M. and Lee, Michael Z. and Jana, Suman and Kim, Sangman and Silberstein, Mark and Xu, Yuanzhong and Shmatikov, Vitaly and Witchel, Emmett},
<br>title = {Eternal Sunshine of the Spotless Machine: Protecting Privacy with Ephemeral Channels},
<br>year = {2012},
<br>isbn = {9781931971966},
<br>publisher = {USENIX Association},
<br>address = {USA},
<br>booktitle = {Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation},
<br>pages = {61–75},
<br>numpages = {15},
<br>location = {Hollywood, CA, USA},
<br>series = {OSDI’12}
<br>}
<br>
<br>  
<br>
<br></div></div><a title="slides" href="https://www.usenix.org/node/170831" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for Eternal Sunshine of the Spotless Machine: Protecting Privacy  with Ephemeral Channels"></a> </div><div class="pbl_astring"><span class="pblempta">Alan Dunn</span>, <span class="pblempta">Mike Lee</span>, <a href="http://www.cs.columbia.edu/~suman/" target="_blank">Suman Jana</a>, <span class="pblempta">Sangman Kim</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Yuanzhong Xu</span>, <a href="https://www.cs.cornell.edu/~shmat/" target="_blank">Vitaly Shmatikov</a>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a> <span class="pbl_nstring"><div class="pbl_snotes">Privacy Enhancement Technologies Award</div> </span></div></div><div class="publ_cart_wrapper" id="p1336"><span class="pbl_akr">[SYSTOR]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2367589.2367596" target="_blank">Scheduling processing of real-time data streams on heterogeneous multi-GPU systems</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1336" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Scheduling processing of real-time data streams on heterogeneous multi-GPU systems"></a><div class="remodal" data-remodal-id="modal0_1336" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Scheduling processing of real-time data streams on heterogeneous multi-GPU systems</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{verner12systor,
<br>author = {Verner, Uri and Schuster, Assaf and Silberstein, Mark and Mendelson, Avi},
<br>title = {Scheduling Processing of Real-Time Data Streams on Heterogeneous Multi-GPU Systems},
<br>year = {2012},
<br>isbn = {9781450314480},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/2367589.2367596},
<br>doi = {10.1145/2367589.2367596},
<br>booktitle = {Proceedings of the 5th Annual International Systems and Storage Conference},
<br>articleno = {Article 8},
<br>numpages = {12},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR ’12}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1336" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Scheduling processing of real-time data streams on heterogeneous multi-GPU systems"></a><div class="remodal" data-remodal-id="modal1_1336" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Scheduling processing of real-time data streams on heterogeneous multi-GPU systems</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>Processing vast numbers of data streams is a common problem in modern computer systems and is known as the &#8220;online big data problem.&#8221; Adding hard real-time constraints to the processing makes the scheduling problem a very challenging task that this paper aims to address. In such an environment, each data stream is manipulated by a (different) application and each datum (data packet) needs to be processed within a known deadline from the time it was generated. This work assumes a central compute engine which consists of a set of CPUs and a set of GPUs. The system receives a configuration of multiple incoming streams and executes a scheduler on the CPU side. The scheduler decides where each data stream will be manipulated (on the CPUs or on one of the GPUs), and the order of execution, in a way that guarantees that no deadlines will be missed. Our scheduler finds such schedules even for workloads that require high utilization of the entire system (CPUs and GPUs).</p>
<p>This paper focuses on an environment where all CPUs share a main memory, and are controlled by a single operating system (and a scheduler). The system uses a set of discrete graphic cards, each with its own private main memory. Different memory regions do not share information, and coherency is maintained by the use of explicit memory-copy operations. The paper presents a new algorithm for distributing data and scheduling applications that achieves high utilization of the entire system (CPUs and GPUs), while producing schedules that meet hard real-time constraints.</p>
<p>We evaluate our new proposed algorithm by using the AES-CBC encryption kernel on thousands of streams with realistic distribution of rates and deadlines. The paper shows that on a system with a CPU and two GPU cards, our current framework allows up to 87% more data to be processed per time unit than a similar single-GPU system.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{verner12systor,
<br>author = {Verner, Uri and Schuster, Assaf and Silberstein, Mark and Mendelson, Avi},
<br>title = {Scheduling Processing of Real-Time Data Streams on Heterogeneous Multi-GPU Systems},
<br>year = {2012},
<br>isbn = {9781450314480},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/2367589.2367596},
<br>doi = {10.1145/2367589.2367596},
<br>booktitle = {Proceedings of the 5th Annual International Systems and Storage Conference},
<br>articleno = {Article 8},
<br>numpages = {12},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR ’12}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><span class="pblempta">Uri Verner</span>, <span class="pblempta">Avi Mendelson</span>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1338"><span class="pbl_akr">[IPDPS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/replication-ipdps2012.pdf" target="_blank">ExPERT: Pareto-Efficient Task Replication on Grids and a Cloud</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1338" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for ExPERT: Pareto-Efficient Task Replication on Grids and a Cloud"></a><div class="remodal" data-remodal-id="modal0_1338" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">ExPERT: Pareto-Efficient Task Replication on Grids and a Cloud</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{baryehuda12ipdps, 
<br>    author={O. A. {Ben-Yehuda} and A. {Schuster} and A. {Sharov} and M. {Silberstein} and A. {Iosup}},  
<br>    booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium},  
<br>    title={{ExPERT: Pareto-Efficient Task Replication on Grids and a Cloud}}, 
<br>    year={2012},  
<br>    pages={167-178},
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1338" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for ExPERT: Pareto-Efficient Task Replication on Grids and a Cloud"></a><div class="remodal" data-remodal-id="modal1_1338" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">ExPERT: Pareto-Efficient Task Replication on Grids and a Cloud</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Many scientists perform extensive computations by executing large bags of similar tasks (BoTs) in mixtures of computational environments, such as grids and clouds. Although the reliability and cost may vary considerably across these environments, no tool exists to assist scientists in the selection of environments that can both fulfill deadlines and fit budgets. To address this situation, we introduce the Expert BoT scheduling framework. Our framework systematically selects from a large search space the Pareto-efficient scheduling strategies, that is, the strategies that deliver the best results for both make span and cost. Expert chooses from them the best strategy according to a general, user-specified utility function. Through simulations and experiments in real production environments, we demonstrate that Expert can substantially reduce both make span and cost in comparison to common scheduling strategies. For bioinformatics BoTs executed in a real mixed grid + cloud environment, we show how the scheduling strategy selected by Expert reduces both make span and cost by 30%-70%, in comparison to commonly-used scheduling strategies.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS{baryehuda12ipdps, 
<br>    author={O. A. {Ben-Yehuda} and A. {Schuster} and A. {Sharov} and M. {Silberstein} and A. {Iosup}},  
<br>    booktitle={2012 IEEE 26th International Parallel and Distributed Processing Symposium},  
<br>    title={{ExPERT: Pareto-Efficient Task Replication on Grids and a Cloud}}, 
<br>    year={2012},  
<br>    pages={167-178},
<br>}</div></div></div><div class="pbl_astring"><span class="pblempta">Orna Agmon Ben-Yehuda</span>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <span class="pblempta">Artyom Sharov</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Alex Iosup</span> <span class="pbl_nstring"></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2011">2011</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1341"><span class="pbl_akr">[SOSP]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/2043556.2043579" target="_blank">PTask: Operating System Abstractions To Manage GPUs as Compute Devices</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1341" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for PTask: Operating System Abstractions To Manage GPUs as Compute Devices"></a><div class="remodal" data-remodal-id="modal0_1341" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">PTask: Operating System Abstractions To Manage GPUs as Compute Devices</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{sosp11rosbach,
<br>author = {Rossbach, Christopher J. and Currey, Jon and Silberstein, Mark and Ray, Baishakhi and Witchel, Emmett},
<br>title = {PTask: Operating System Abstractions to Manage GPUs as Compute Devices},
<br>year = {2011},
<br>isbn = {9781450309776},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/2043556.2043579},
<br>doi = {10.1145/2043556.2043579},
<br>booktitle = {Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles},
<br>pages = {233–248},
<br>numpages = {16},
<br>keywords = {GPUs, operating systems, gestural interface, OS design, accelerators, GPGPU, dataflow},
<br>location = {Cascais, Portugal},
<br>series = {SOSP ’11}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1341" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for PTask: Operating System Abstractions To Manage GPUs as Compute Devices"></a><div class="remodal" data-remodal-id="modal1_1341" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">PTask: Operating System Abstractions To Manage GPUs as Compute Devices</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>We propose a new set of OS abstractions to support GPUs and other accelerator devices as first class computing resources. These new abstractions, collectively called the <b>PTask API</b>, support a dataflow programming model. Because a PTask graph consists of OS-managed objects, the kernel has sufficient visibility and control to provide system-wide guarantees like fairness and performance isolation, and can streamline data movement in ways that are impossible under current GPU programming models.</p>
<p>Our experience developing the PTask API, along with a gestural interface on Windows 7 and a FUSE-based encrypted file system on Linux show that the PTask API can provide important system-wide guarantees where there were previously none, and can enable significant performance improvements, for example gaining a 5× improvement in maximum throughput for the gestural interface.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{sosp11rosbach,
<br>author = {Rossbach, Christopher J. and Currey, Jon and Silberstein, Mark and Ray, Baishakhi and Witchel, Emmett},
<br>title = {PTask: Operating System Abstractions to Manage GPUs as Compute Devices},
<br>year = {2011},
<br>isbn = {9781450309776},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/2043556.2043579},
<br>doi = {10.1145/2043556.2043579},
<br>booktitle = {Proceedings of the Twenty-Third ACM Symposium on Operating Systems Principles},
<br>pages = {233–248},
<br>numpages = {16},
<br>keywords = {GPUs, operating systems, gestural interface, OS design, accelerators, GPGPU, dataflow},
<br>location = {Cascais, Portugal},
<br>series = {SOSP ’11}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><a href="http://www.cs.utexas.edu/~rossbach/" target="_blank">Chris Rossbach</a>, <span class="pblempta">Jon Currey</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Baishakhi Ray</span>, <a href="https://www.cs.utexas.edu/users/witchel/" target="_blank">Emmett Witchel</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1343"><span class="pbl_akr">[ICS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/1995896.1995915" target="_blank">Processing data streams with hard real-time constraints on heterogeneous systems</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1343" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Processing data streams with hard real-time constraints on heterogeneous systems"></a><div class="remodal" data-remodal-id="modal0_1343" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Processing data streams with hard real-time constraints on heterogeneous systems</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{verner11ics,
<br>author = {Verner, Uri and Schuster, Assaf and Silberstein, Mark},
<br>title = {Processing Data Streams with Hard Real-Time Constraints on Heterogeneous Systems},
<br>year = {2011},
<br>isbn = {9781450301022},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1995896.1995915},
<br>doi = {10.1145/1995896.1995915},
<br>booktitle = {Proceedings of the International Conference on Supercomputing},
<br>pages = {120–129},
<br>numpages = {10},
<br>keywords = {hard real-time, gpu, data streams, batch processing, scheduling, accelerator},
<br>location = {Tucson, Arizona, USA},
<br>series = {ICS ’11}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1343" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Processing data streams with hard real-time constraints on heterogeneous systems"></a><div class="remodal" data-remodal-id="modal1_1343" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Processing data streams with hard real-time constraints on heterogeneous systems</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>Data stream processing applications such as stock exchange data analysis, VoIP streaming, and sensor data processing pose two conflicting challenges: short per-stream latency &#8212; to satisfy the milliseconds-long, hard real-time constraints of each stream, and high throughput &#8212; to enable efficient processing of as many streams as possible. High-throughput programmable accelerators such as modern GPUs hold high potential to speed up the computations. However, their use for hard real-time stream processing is complicated by slow communications with CPUs, variable throughput changing non-linearly with the input size, and weak consistency of their local memory with respect to CPU accesses. Furthermore, their coarse grain hardware scheduler renders them unsuitable for unbalanced multi-stream workloads.</p>
<p>We present a general, efficient and practical algorithm for hard real-time stream scheduling in heterogeneous systems. The algorithm assigns incoming streams of different rates and deadlines to CPUs and accelerators. By employing novel stream schedulability criteria for accelerators, the algorithm finds the assignment which simultaneously satisfies the aggregate throughput requirements of all the streams and the deadline constraint of each stream alone.</p>
<p>Using the AES-CBC encryption kernel, we experimented extensively on thousands of streams with realistic rate and deadline distributions. Our framework outperformed the alternative methods by allowing 50% more streams to be processed with provably deadline-compliant execution even for deadlines as short as tens milliseconds. Overall, the combined GPU-CPU execution allows for up to 4-fold throughput increase over highly-optimized multi-threaded CPU-only implementations.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{verner11ics,
<br>author = {Verner, Uri and Schuster, Assaf and Silberstein, Mark},
<br>title = {Processing Data Streams with Hard Real-Time Constraints on Heterogeneous Systems},
<br>year = {2011},
<br>isbn = {9781450301022},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1995896.1995915},
<br>doi = {10.1145/1995896.1995915},
<br>booktitle = {Proceedings of the International Conference on Supercomputing},
<br>pages = {120–129},
<br>numpages = {10},
<br>keywords = {hard real-time, gpu, data streams, batch processing, scheduling, accelerator},
<br>location = {Tucson, Arizona, USA},
<br>series = {ICS ’11}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><span class="pblempta">Uri Verner</span>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1345"><span class="pbl_akr">[CCGrid]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://ieeexplore.ieee.org/document/5948608/" target="_blank">Building an online domain-specific computing service over non-dedicated grid and cloud resources: the Superlink-online experience</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1345" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Building an online domain-specific computing service over non-dedicated grid and cloud resources: the Superlink-online experience"></a><div class="remodal" data-remodal-id="modal0_1345" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Building an online domain-specific computing service over non-dedicated grid and cloud resources: the Superlink-online experience</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{silberstein2011building,
<br>  title={Building an online domain-specific computing service over non-dedicated grid and cloud resources: The superlink-online experience},
<br>  author={Silberstein, Mark},
<br>  booktitle={2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
<br>  pages={174--183},
<br>  year={2011},
<br>  organization={IEEE}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1345" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Building an online domain-specific computing service over non-dedicated grid and cloud resources: the Superlink-online experience"></a><div class="remodal" data-remodal-id="modal1_1345" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Building an online domain-specific computing service over non-dedicated grid and cloud resources: the Superlink-online experience</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Linkage analysis is a statistical method used by geneti cists in everyday practice for mapping disease-susceptibility genes in the study of complex diseases. An essential first step in the study of genetic diseases, linkage computations may require years of CPU time. The recent DNA sampling revolution enabled unprecedented sampling density, but made the analysis even more computationally demanding. In this paper we describe a high performance online service for genetic linkage analysis, called Superlink-online. The system enables anyone with Internet access to submit genetic data and analyze it as easily and quickly as if using a supercomputer. The analyses are automatically parallelized and executed on tens of thousands distributed CPUs in multiple clouds and grids.</p>
<p>The first version of the system, which employed up to 3,000 CPUs in UW Madison and Technion Condor pools, has been successfully used since 2006 by hundreds of geneticists worldwide, with over 40 citations in the genetics literature. Here we describe the second version, which substantially improves the scalability and performance of first: it uses over 45,000 non-dedicated hosts, in 10 different grids and clouds, including EC2 and the Superlink@Technion community grid. Improved system performance is obtained through a virtual grid hierarchy with dynamic load balancing and multi-grid overlay via the GridBot system, parallel pruning of short tasks for overhead minimization, and cost-efficient use of cloud resources in reliability-critical execution periods.</p>
<p>These enhancements enabled execution of many previously infeasible analyses, which can now be completed within a few hours. The new version of the system, in production since 2009, has completed over 6500 different runs of over 10 million tasks, with total consumption of 420 CPU years.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{silberstein2011building,
<br>  title={Building an online domain-specific computing service over non-dedicated grid and cloud resources: The superlink-online experience},
<br>  author={Silberstein, Mark},
<br>  booktitle={2011 11th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
<br>  pages={174--183},
<br>  year={2011},
<br>  organization={IEEE}
<br>}</div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><div class="pbl_snotes">Second Prize, IEEE International Scalable Computing Challenge</div> </span></div></div><div class="publ_cart_wrapper" id="p1347"><span class="pbl_akr">[SYSTOR]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/1987816.1987826" target="_blank">An exact algorithm for energy-efficient acceleration of task trees  on CPU/GPU architectures</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1347" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for An exact algorithm for energy-efficient acceleration of task trees  on CPU/GPU architectures"></a><div class="remodal" data-remodal-id="modal0_1347" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">An exact algorithm for energy-efficient acceleration of task trees  on CPU/GPU architectures</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{Maruyama2011systor,
<br>author = {Silberstein, Mark and Maruyama, Naoya},
<br>title = {An Exact Algorithm for Energy-Efficient Acceleration of Task Trees on CPU/GPU Architectures},
<br>year = {2011},
<br>isbn = {9781450307734},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1987816.1987826},
<br>doi = {10.1145/1987816.1987826},
<br>booktitle = {Proceedings of the 4th Annual International Conference on Systems and Storage},
<br>articleno = {Article 7},
<br>numpages = {7},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR ’11}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1347" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for An exact algorithm for energy-efficient acceleration of task trees  on CPU/GPU architectures"></a><div class="remodal" data-remodal-id="modal1_1347" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">An exact algorithm for energy-efficient acceleration of task trees  on CPU/GPU architectures</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>We consider the problem of <i>energy-efficient acceleration</i> of applications comprising multiple interdependent tasks forming a dependency tree, on a hypothetical CPU/GPU system where both a CPU and a GPU can be powered off when idle. Each task in the tree can be invoked on either a GPU or a CPU, but the performance may vary: some run faster on a GPU, while others prefer a CPU, making the choice of the lowest-energy processor input dependent. Furthermore, greedily minimizing the energy consumption for each task is suboptimal because of the additional energy required for the communication between the tasks executed on different processors.</p>
<p>We propose an efficient algorithm that takes into account the energy consumption of a CPU and a GPU for each task, as well as <i>the communication costs of data transfers between them</i>, and constructs an <i>optimal</i> acceleration schedule with <i>provably minimal</i> total consumed energy.</p>
<p>We evaluate the algorithm in the context of a real application having a task dependency tree structure and show up to 2.5-fold improvement in the expected energy consumption over the best single processor schedule, and up to 50% improvement over the communication unaware schedule on real inputs. We also show how this algorithm can be used to speedup computations rather than minimize power consumption. We achieve achieve up to a 2-fold speedup in real CPU/GPU systems.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{Maruyama2011systor,
<br>author = {Silberstein, Mark and Maruyama, Naoya},
<br>title = {An Exact Algorithm for Energy-Efficient Acceleration of Task Trees on CPU/GPU Architectures},
<br>year = {2011},
<br>isbn = {9781450307734},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1987816.1987826},
<br>doi = {10.1145/1987816.1987826},
<br>booktitle = {Proceedings of the 4th Annual International Conference on Systems and Storage},
<br>articleno = {Article 7},
<br>numpages = {7},
<br>location = {Haifa, Israel},
<br>series = {SYSTOR ’11}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><span class="pblempta">Naoya Maruyama</span>, <a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><div class="pbl_snotes">Best Paper Award</div> </span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2010">2010</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1349"><span class="pbl_akr">[GPU Computing Gems]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/gems.pdf" target="_blank">Applying software managed caching and CPU-GPU scheduling for accelerating dynamic computations</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1349" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Applying software managed caching and CPU-GPU scheduling for accelerating dynamic computations"></a><div class="remodal" data-remodal-id="modal0_1349" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Applying software managed caching and CPU-GPU scheduling for accelerating dynamic computations</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inbook{scratchpad2011GEMS,
<br>author = {Silberstein, Mark and Schuster, Assaf and Owens, John},
<br>year = {2011},
<br>month = {10},
<br>pages = {501-517},
<br>title = {Applying Software-Managed Caching and CPU/GPU Task Scheduling for Accelerating Dynamic Workloads},
<br>journal = {GPU Computing Gems Jade Edition},
<br>doi = {10.1016/B978-0-12-385963-1.00036-8}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1349" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Applying software managed caching and CPU-GPU scheduling for accelerating dynamic computations"></a><div class="remodal" data-remodal-id="modal1_1349" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Applying software managed caching and CPU-GPU scheduling for accelerating dynamic computations</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>In this chapter we cover two difficult problems frequently encountered by GPU developers:  optimizing memory access for kernels with complex input-dependent access patterns, and mapping the computations to a GPU or a CPU in<br />
composite applications with multiple dependent kernels. Both  pose a formidable challenge as they require dynamic adaptation and tuning of execution policies to allow high performance for a wide range of inputs. Not meeting these requirements leads to substantial performance penalty.</p>
<p>We develop our solution using simple examples, and then apply them to a real application for computing the probability of evidence in probabilistic networks. The combined techniques of memory optimization and dynamic assignment<br />
result in up to three-fold runtime reduction over the non-optimized version on real inputs from the  genetic analysis domain, and up to five-fold over an optimized parallel version running on Intel&#8217;s latest dual quad-core 16-thread Nehalem machine.  In the first part of the chapter we describe our methodology for solving the memory optimization problem via<br />
software-managed caching by efficiently exploiting the fast scratchpad memory.  This technique outperforms the cache-less and the texture memory-based approaches on pre-Fermi GPU architectures as well as the one that uses the Fermi hardware cache alone.</p>
<p>The focus of the second part of the chapter is the algorithm for minimizing the total running time of a complete application comprising multiple interdependent kernels. Both a GPU and a CPU can be used to execute the kernels,  but the performance varies greatly for different inputs, calling for dynamic assignment of the computations to a GPU or a CPU at runtime.  However, instead of greedily choosing the best performing device for each kernel, the algorithm minimizes the runtime of the complete application by evaluating the performance of all the assignments jointly, including the overhead of<br />
the data transfer between the devices.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inbook{scratchpad2011GEMS,
<br>author = {Silberstein, Mark and Schuster, Assaf and Owens, John},
<br>year = {2011},
<br>month = {10},
<br>pages = {501-517},
<br>title = {Applying Software-Managed Caching and CPU/GPU Task Scheduling for Accelerating Dynamic Workloads},
<br>journal = {GPU Computing Gems Jade Edition},
<br>doi = {10.1016/B978-0-12-385963-1.00036-8}
<br>}</div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <a href="https://www.ece.ucdavis.edu/~jowens/" target="_blank">John Owens</a> <span class="pbl_nstring"><span class="pbl_info">Book chapter</span></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2009">2009</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1353"><span class="pbl_akr">[SC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/10.1145/1654059.1654071" target="_blank">GridBot: Execution of  Bags of Tasks in Multiple Grids</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1353" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for GridBot: Execution of  Bags of Tasks in Multiple Grids"></a><div class="remodal" data-remodal-id="modal0_1353" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">GridBot: Execution of  Bags of Tasks in Multiple Grids</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gridbot2009SC,
<br>author = {Silberstein, Mark and Sharov, Artyom and Geiger, Dan and Schuster, Assaf},
<br>title = {GridBot: Execution of Bags of Tasks in Multiple Grids},
<br>year = {2009},
<br>isbn = {9781605587448},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1654059.1654071},
<br>doi = {10.1145/1654059.1654071},
<br>booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
<br>articleno = {Article 11},
<br>numpages = {12},
<br>location = {Portland, Oregon},
<br>series = {SC ’09}
<br>}
<br>
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1353" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for GridBot: Execution of  Bags of Tasks in Multiple Grids"></a><div class="remodal" data-remodal-id="modal1_1353" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">GridBot: Execution of  Bags of Tasks in Multiple Grids</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>We present a holistic approach for efficient execution of bags-of-tasks (BOTs) on multiple grids, clusters, and volunteer computing grids virtualized as a single computing platform. The challenge is twofold: to assemble this compound environment and to employ it for execution of a mixture of throughput- and performance-oriented BOTs, with a dozen to millions of tasks each. Our generic mechanism allows per BOT specification of dynamic arbitrary scheduling and replication policies as a function of the system state, BOT execution state, and BOT priority. We implement our mechanism in the GridBot system and demonstrate its capabilities in a production setup. GridBot has executed hundreds of BOTs with over 9 million jobs during three months alone; these have been invoked on 25,000 hosts, 15,000 from the Superlink@Technion community grid and the rest from the Technion campus grid, local clusters, the Open Science Grid, EGEE, and the UW Madison pool.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{gridbot2009SC,
<br>author = {Silberstein, Mark and Sharov, Artyom and Geiger, Dan and Schuster, Assaf},
<br>title = {GridBot: Execution of Bags of Tasks in Multiple Grids},
<br>year = {2009},
<br>isbn = {9781605587448},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1654059.1654071},
<br>doi = {10.1145/1654059.1654071},
<br>booktitle = {Proceedings of the Conference on High Performance Computing Networking, Storage and Analysis},
<br>articleno = {Article 11},
<br>numpages = {12},
<br>location = {Portland, Oregon},
<br>series = {SC ’09}
<br>}
<br>
<br>
<br></div></div><a title="slides" href="https://marksilberstein.com/wp-content/uploads/2020/04/sc09-revised.pdf" target="_blank"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-slides.gif" alt="slides for GridBot: Execution of  Bags of Tasks in Multiple Grids"></a> </div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Artyom Sharov</span>, <a href="http://www.cs.technion.ac.il/~dang/" target="_blank">Dan Geiger</a>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a> <span class="pbl_nstring"><div class="pbl_snotes">George Michael Memorial HPC Fellowship Honorable Mention Award</div> </span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2008">2008</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1358"><span class="pbl_akr">[ICS]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://dl.acm.org/doi/abs/10.1145/1375527.1375572" target="_blank">Efficient computation of sum-products on GPUs through software-managed cache</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1358" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Efficient computation of sum-products on GPUs through software-managed cache"></a><div class="remodal" data-remodal-id="modal0_1358" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Efficient computation of sum-products on GPUs through software-managed cache</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{scratchpad2008ics,
<br>author = {Silberstein, Mark and Schuster, Assaf and Geiger, Dan and Patney, Anjul and Owens, John D.},
<br>title = {Efficient Computation of Sum-Products on GPUs through Software-Managed Cache},
<br>year = {2008},
<br>isbn = {9781605581583},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1375527.1375572},
<br>doi = {10.1145/1375527.1375572},
<br>booktitle = {Proceedings of the 22nd Annual International Conference on Supercomputing},
<br>pages = {309–318},
<br>numpages = {10},
<br>keywords = {sum-product, software-managed cache, GPGPU, CUDA},
<br>location = {Island of Kos, Greece},
<br>series = {ICS ’08}
<br>}
<br>
<br>  
<br>
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1358" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Efficient computation of sum-products on GPUs through software-managed cache"></a><div class="remodal" data-remodal-id="modal1_1358" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Efficient computation of sum-products on GPUs through software-managed cache</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><div class="abstractSection abstractInFull">
<p>We present a technique for designing memory-bound algorithms with high data reuse on Graphics Processing Units (GPUs) equipped with close-to-ALU software-managed memory. The approach is based on the efficient use of this memory through the implementation of a software-managed cache. We also present an analytical model for performance analysis of such algorithms.</p>
<p>We apply this technique to the implementation of the GPU-based solver of the sum-product or marginalize a product of functions (MPF) problem, which arises in a wide variety of real-life applications in artificial intelligence, statistics, image processing, and digital communications. Our motivation to accelerate MPF originated in the context of the analysis of genetic diseases, which in some cases requires years to complete on modern CPUs. Computing MPF is similar to computing the chain matrix product of multi-dimensional matrices, but is more difficult due to a complex data-dependent access pattern, high data reuse, and a low compute-to-memory access ratio. Our GPU-based MPF solver achieves up to 2700-fold speedup on random data and 270-fold on real-life genetic analysis datasets on GeForce 8800GTX GPU from NVIDIA over the optimized CPU version on an Intel 2.4GHz Core 2 with a 4MB L2 cache.</p>
</div>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{scratchpad2008ics,
<br>author = {Silberstein, Mark and Schuster, Assaf and Geiger, Dan and Patney, Anjul and Owens, John D.},
<br>title = {Efficient Computation of Sum-Products on GPUs through Software-Managed Cache},
<br>year = {2008},
<br>isbn = {9781605581583},
<br>publisher = {Association for Computing Machinery},
<br>address = {New York, NY, USA},
<br>url = {https://doi.org/10.1145/1375527.1375572},
<br>doi = {10.1145/1375527.1375572},
<br>booktitle = {Proceedings of the 22nd Annual International Conference on Supercomputing},
<br>pages = {309–318},
<br>numpages = {10},
<br>keywords = {sum-product, software-managed cache, GPGPU, CUDA},
<br>location = {Island of Kos, Greece},
<br>series = {ICS ’08}
<br>}
<br>
<br>  
<br>
<br></div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <a href="http://www.cs.technion.ac.il/~dang/" target="_blank">Dan Geiger</a>, <span class="pblempta">Anjul Patney</span>, <a href="https://www.ece.ucdavis.edu/~jowens/" target="_blank">John Owens</a> <span class="pbl_nstring"></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2006">2006</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1362"><span class="pbl_akr">[HPDC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/HAD.pdf" target="_blank">Materializing Highly Available Grids</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1362" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Materializing Highly Available Grids"></a><div class="remodal" data-remodal-id="modal0_1362" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Materializing Highly Available Grids</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS {had2006HPDC,
<br>author = {A. Sharov and M. Livny and G. Kliot and S. Schuster and M. Silberstein},
<br>booktitle = {Proceedings of the 15th IEEE International Symposium on High Performance Distributed Computing},
<br>title = {Short paper: Materializing Highly Available Grids},
<br>year = {2006},
<br>volume = {},
<br>issn = {},
<br>pages = {321-323},
<br>keywords = {virtual computer;highly available grid service;ha condor system;mission-critical component},
<br>doi = {10.1109/HPDC.2006.1652166},
<br>url = {https://doi.ieeecomputersociety.org/10.1109/HPDC.2006.1652166},
<br>publisher = {IEEE Computer Society},
<br>address = {Los Alamitos, CA, USA},
<br>month = {jun}
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1362" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Materializing Highly Available Grids"></a><div class="remodal" data-remodal-id="modal1_1362" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Materializing Highly Available Grids</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Grids are becoming a mission-critical component in research and industry. The services they provide are thus required to be highly available, contributing to the vision of the grid as a dependable virtual computer of infinite power. However, building highly available services in grid is particularly difficult due to the unique characteristics of the grid environment. We believe that high availability functionality should itself be provided as a service, which can be used by transparently decorating, but not changing, the original services, thus making them highly available. In this work we highlight the major challenges and describe our initial experience in building such a generic high availability service in the context of the Condor system</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@INPROCEEDINGS {had2006HPDC,
<br>author = {A. Sharov and M. Livny and G. Kliot and S. Schuster and M. Silberstein},
<br>booktitle = {Proceedings of the 15th IEEE International Symposium on High Performance Distributed Computing},
<br>title = {Short paper: Materializing Highly Available Grids},
<br>year = {2006},
<br>volume = {},
<br>issn = {},
<br>pages = {321-323},
<br>keywords = {virtual computer;highly available grid service;ha condor system;mission-critical component},
<br>doi = {10.1109/HPDC.2006.1652166},
<br>url = {https://doi.ieeecomputersociety.org/10.1109/HPDC.2006.1652166},
<br>publisher = {IEEE Computer Society},
<br>address = {Los Alamitos, CA, USA},
<br>month = {jun}
<br>}</div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Gabriel Kliot</span>, <span class="pblempta">Artyom Sharov</span>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <a href="http://pages.cs.wisc.edu/~miron/" target="_blank">Miron Livny</a> <span class="pbl_nstring"><span class="pbl_info">Short paper. </span>, <div class="pbl_snotes">Integrated with HT-Condor system</div> </span></div></div><div class="publ_cart_wrapper" id="p1365"><span class="pbl_akr">[HPDC]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/complexity-aware-grid1.pdf" target="_blank">Scheduling mixed workloads in multi-grids: the grid execution hierarchy</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1365" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Scheduling mixed workloads in multi-grids: the grid execution hierarchy"></a><div class="remodal" data-remodal-id="modal0_1365" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Scheduling mixed workloads in multi-grids: the grid execution hierarchy</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{silberstein2006scheduling,
<br>  title={Scheduling mixed workloads in multi-grids: the grid execution hierarchy},
<br>  author={Silberstein, Mark and Geiger, Dan and Schuster, Assaf and Livny, Miron},
<br>  booktitle={2006 15th IEEE International Conference on High Performance Distributed Computing},
<br>  pages={291--302},
<br>  year={2006},
<br>  organization={IEEE}
<br>}
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1365" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Scheduling mixed workloads in multi-grids: the grid execution hierarchy"></a><div class="remodal" data-remodal-id="modal1_1365" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Scheduling mixed workloads in multi-grids: the grid execution hierarchy</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Consider a workload in which massively parallel tasks that require large resource pools are interleaved with short tasks that require fast response but consume fewer resources. We aim at achieving high throughput and short response time when scheduling such a workload over a set of uncoordinated grids of varying sizes and performance characteristics.</p>
<p>We propose the concept of a grid execution hierarchy, where available grids are sorted according to their size, and the execution overheads increase with the size of the grids. We devise a scheduling algorithm for this execution hierarchy of grids by adapting the multilevel feedback queue approach to a multi-grid environment. The algorithm finds a grid of the size, availability, and overhead that best matches a task&#8217;s resource requirements and expected turnaround time. Our approach is inspired by the shortest processing time first policy (SPTF), in the sense that the task&#8217;s processing demands are constantly reevaluated during its run, so that a task is migrated to a more suitable level of the execution hierarchy when appropriate.</p>
<p>We evaluate our approach in the context of the Superlink-online system for processing genetic linkage analysis tasks &#8211; a production system consisting of several grids and utilizing tens of thousands of CPU hours a month. With our approach the system provides nearly interactive response time for shorter tasks, while simultaneously serving throughput-oriented massively parallel tasks in an efficient manner.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@inproceedings{silberstein2006scheduling,
<br>  title={Scheduling mixed workloads in multi-grids: the grid execution hierarchy},
<br>  author={Silberstein, Mark and Geiger, Dan and Schuster, Assaf and Livny, Miron},
<br>  booktitle={2006 15th IEEE International Conference on High Performance Distributed Computing},
<br>  pages={291--302},
<br>  year={2006},
<br>  organization={IEEE}
<br>}
<br></div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <a href="http://www.cs.technion.ac.il/~dang/" target="_blank">Dan Geiger</a>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <a href="http://pages.cs.wisc.edu/~miron/" target="_blank">Miron Livny</a> <span class="pbl_nstring"></span></div></div><div class="publ_cart_wrapper" id="p1368"><span class="pbl_akr">[American Journal of Human Genetics]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://www.sciencedirect.com/science/article/pii/S0002929707639159" target="_blank">Online System for Faster Multipoint Linkage Analysis via Parallel Execution on Thousands of Personal computers</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1368" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Online System for Faster Multipoint Linkage Analysis via Parallel Execution on Thousands of Personal computers"></a><div class="remodal" data-remodal-id="modal0_1368" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Online System for Faster Multipoint Linkage Analysis via Parallel Execution on Thousands of Personal computers</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{SILBERSTEIN2006AJHG,
<br>title = "Online System for Faster Multipoint Linkage Analysis via Parallel Execution on Thousands of Personal Computers",
<br>journal = "The American Journal of Human Genetics",
<br>volume = "78",
<br>number = "6",
<br>pages = "922 - 935",
<br>year = "2006",
<br>issn = "0002-9297",
<br>doi = "https://doi.org/10.1086/504158",
<br>url = "http://www.sciencedirect.com/science/article/pii/S0002929707639159",
<br>author = "M. Silberstein and A. Tzemach and N. Dovgolevsky and M. Fishelson and A. Schuster and D. Geiger",
<br>}</div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1368" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Online System for Faster Multipoint Linkage Analysis via Parallel Execution on Thousands of Personal computers"></a><div class="remodal" data-remodal-id="modal1_1368" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Online System for Faster Multipoint Linkage Analysis via Parallel Execution on Thousands of Personal computers</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>Computation of LOD scores is a valuable tool for mapping disease-susceptibility genes in the study of Mendelian and complex diseases. However, computation of exact multipoint likelihoods of large inbred pedigrees with extensive missing data is often beyond the capabilities of a single computer. We present a distributed system called “SUPERLINK-ONLINE,” for the computation of multipoint LOD scores of large inbred pedigrees. It achieves high performance via the efficient parallelization of the algorithms in SUPERLINK, a state-of-the-art serial program for these tasks, and through the use of the idle cycles of thousands of personal computers. The main algorithmic challenge has been to efficiently split a large task for distributed execution in a highly dynamic, nondedicated running environment. Notably, the system is available online, which allows computationally intensive analyses to be performed with no need for either the installation of software or the maintenance of a complicated distributed environment. As the system was being developed, it was extensively tested by collaborating medical centers worldwide on a variety of real data sets, some of which are presented in this article.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{SILBERSTEIN2006AJHG,
<br>title = "Online System for Faster Multipoint Linkage Analysis via Parallel Execution on Thousands of Personal Computers",
<br>journal = "The American Journal of Human Genetics",
<br>volume = "78",
<br>number = "6",
<br>pages = "922 - 935",
<br>year = "2006",
<br>issn = "0002-9297",
<br>doi = "https://doi.org/10.1086/504158",
<br>url = "http://www.sciencedirect.com/science/article/pii/S0002929707639159",
<br>author = "M. Silberstein and A. Tzemach and N. Dovgolevsky and M. Fishelson and A. Schuster and D. Geiger",
<br>}</div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a>, <span class="pblempta">Anna Tzemach</span>, <span class="pblempta">Nikolai Dovgolevsky</span>, <span class="pblempta">Maayan Fishelson</span>, <a href="https://assaf.net.technion.ac.il" target="_blank">Assaf Schuster</a>, <a href="http://www.cs.technion.ac.il/~dang/" target="_blank">Dan Geiger</a> <span class="pbl_nstring"></span></div></div></div></div><div class="ra_mpart_wrap"> <h2 id="2004">2004</h2><div class="publ_section_wrap"><div class="publ_cart_wrapper" id="p1370"><span class="pbl_akr">[TechRep]</span> &nbsp;&nbsp;<span class="pbl_titlestr"><a href="https://marksilberstein.com/wp-content/uploads/2020/04/AntivirusReport_revised_version.pdf" target="_blank">Designing a CAM-based coprocessor for boosting performance of antivirus software</a></span><div class="pbl_nstring2"><a href="#" title="BibTeX" data-remodal-target="modal0_1370" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-bibtex.gif" alt="BibTeX for Designing a CAM-based coprocessor for boosting performance of antivirus software"></a><div class="remodal" data-remodal-id="modal0_1370" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1"><h2 class="publ_rw_h2">Designing a CAM-based coprocessor for boosting performance of antivirus software</h2></div>
								                <div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{silberstein2004designing,
<br>  title={Designing a CAM-based coprocessor for boosting performance of antivirus software},
<br>  author={Silberstein, M},
<br>  journal={Technion technical report},
<br>  year={2004}
<br>}
<br></div>							                
								           </div><a href="#" title="abstract" data-remodal-target="modal1_1370" ><img src="https://marksilberstein.com/wp-content/themes/acsl/img/publ-icon-abstract.gif" alt="abstract for Designing a CAM-based coprocessor for boosting performance of antivirus software"></a><div class="remodal" data-remodal-id="modal1_1370" >
								                <button data-remodal-action="close" class="remodal-close" ><span class="btn_close">close</span></button>
								                <div class="publ_rw_1_abs"><h2 class="publ_rw_h2">Designing a CAM-based coprocessor for boosting performance of antivirus software</h2></div>
								                <div class="publ_rw_abs"><div class="publ_rw_abs_title">Abstract</div><p>In this report we investigate the benefits of using a coprocessor coupled with content addrassible memory (CAM) for off-loading of a computation-intensive kernels of antivirus software. Overview of antivirus technologies is presented, followed by performance analysis of real antivirus software to justify the application of coprocessor. High level architecture of the coprocessor and its interaction with main CPU is described. CAM usage is described and performance analysis is presented. A broader perspective of a using CAM-based coprocessor application for string pattern matching, various string operations, e.g. string comparisons, and regular expression matching is discussed.</p>
</div><div class="publ_rw_bib"><div class="publ_rw_btxt_title">BibTeX</div>@article{silberstein2004designing,
<br>  title={Designing a CAM-based coprocessor for boosting performance of antivirus software},
<br>  author={Silberstein, M},
<br>  journal={Technion technical report},
<br>  year={2004}
<br>}
<br></div></div></div><div class="pbl_astring"><a href="https://sites.google.com/site/silbersteinmark/Home" target="_blank">Mark Silberstein</a> <span class="pbl_nstring"><span class="pbl_info">Technion Technical Report</span></span></div></div></div></div></div>
				</div><!-- <div class="publ_all_wrapper"> -->



						</div>
						<div class="clearfix"></div>	
					</div> <!-- page_main_content -->
				</div><!-- container main_content_wrapper -->
				
								<div class="clearfix"></div>
				<!-- .content -->
		        
		    <div class="clearfix"></div>

		</main>
				


	<footer>
		<div class="ft_over">
			<div class="container">
				<div class="footer_content">



				<div class="ft_wrapper">
					
					<div class="ft_bl1">
						<div class="ft_b1_st1">
							<div class="ft_name">Prof. Mark Silberstein</div>
						</div>
						<div class="ft_b1_st2">
							<div class="ft_b1_st2_wr">
								<div class="ft_b1_st2_tl">+972 77 887 1503</div>
								<div class="ft_b1_st2_eml"><img src="https://marksilberstein.com/wp-content/themes/acsl/img/footer-e-mail.gif" alt="e-mail"></div>
								<!--<div class="ft_b1_st2_eml"><a class="contains-image" id="fte" href="mailto:mark@ee.technion.ac.il "><img src="https://marksilberstein.com/wp-content/themes/acsl/img/footer-icon-e-mail.png" alt="e-mail"></a></div>-->
							</div>
						</div>
						<div class="ft_b1_st2">
							Meyer Building, Room 1053
						</div>						
						<div class="ft_b1_st2">
							Viterbi Faculty of Electrical Engineering
						</div>
						<div class="ft_b1_st2">
							Technion – Israel Institute of Technology
						</div>
						<div class="ft_b1_st2">
							Haifa 3200003, Israel
						</div>							
					</div>
					
					<div class="ft_bl2">
						<div class="ft_b2_st1">
							Copyright © 2019 by Prof. Mark Silberstein. All rights reserved.
						</div>
						<div class="ft_b2_st2">
							<a href="https://marksilberstein.com/accessibility-information/">Accessibility Information</a>
						</div>
						<div class="ft_b2_st3">
							<a target="_blank" href="http://www.interia.co.il/"><span>INTERIA</span> Web Design & Development</a>
						</div>						
					</div>

				</div>


				</div>			
			</div>
		</div>
	</footer>



	<div class="hidden"></div>
	<div class="loader">
		<div class="loader_inner"></div>
	</div>

	<!-- libs js -->

	<!--[if lt IE 9]>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/html5shiv/es5-shim.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/html5shiv/html5shiv.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/html5shiv/html5shiv-printshiv.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/respond/respond.min.js"></script>
	<![endif]-->
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/jquery/jquery-3.4.1.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/jquery/jquery-migrate-1.4.1.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/waypoints/waypoints.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/animate/animate-css.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/plugins-scroll/plugins-scroll.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/smartmenus/jquery.smartmenus.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/smartmenus/addons/keyboard/jquery.smartmenus.keyboard.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/jquery.mmenu/jquery.mmenu.all.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/masonry/masonry.pkgd.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/masonry/imagesloaded.pkgd.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/magnific-popup/jquery.magnific-popup.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/jquery.keyboard-focus/what-input.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/wow/wow.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/jquery-nice-select-1.1.0/jquery.nice-select.min.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/swiper/swiper.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/easy-ticker/jquery.easy-ticker-noautoplay.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/colcade-master/colcade.js"></script>
	<script src="https://marksilberstein.com/wp-content/themes/acsl/libs/remodal/dist/remodal.js"></script>



	<!-- custom js -->
	<script>
		var lng = 'en';
		var lpath = 'https://marksilberstein.com/wp-content/themes/acsl/';
					var hpage = 0;
			</script>

	<script src="https://marksilberstein.com/wp-content/themes/acsl/js/common.js?v=1.0"></script>
	
</body>
</html>