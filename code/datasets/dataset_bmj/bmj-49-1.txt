This rapid review is an important and timely contribution to the emerging literature on the
COVID-19 pandemic. In its objective to review the literature on prediction models of
COVID-19 diagnosis and prognostication, it identifies biases in every one of the 15 studies.
In this regard, the paper is novel and much-needed in highlighting the dangers of
over-interpreting predictive modelling and making recommendations for practice.
The methodology in this paper is thorough and gives sufficient detail for the reader to
understand and replicate the study process.
I have some specific points to help the reader:
1) My main criticism is that it is not always clear whether the authors believe that the high
risk of bias has invalidated the results of the reviewed papers, or whether these can rightly
be presented and interpreted despite the bias. This is more of a concern in the abstract than
in the text, and I have highlighted below areas where this could be clarified.
2) Abstract Results: given that all studies had a high risk of bias, I suggest it would help the
reader to know this before presenting the findings of the 15 studies. The values of the
C-indexes ranges are given, but are the exact figures relevant if as you say later, you cannot
recommend their use?

3) Abstract Conclusion: ‘The predictors identified in current studies should be considered for
potential inclusion in new models’ – this sentence comes as a surprise in the context of the
preceding statements calling for more rigorous prediction models. If there is such a high risk
of bias, should these predictors be considered for inclusion? I would suggest either dropping
this sentence, or qualifying it.
4) Results paragraph 4 – ‘recovered’ rather than ‘healed’?
5) Discussion paragraph 1 mentions that ‘only two studies carried out an external validation’,
but I could not see the details of which studies these were in the results section – I think this
would be important to mention. Of those that carried out external validation, were there still
biases related to this?
6) It may help for a general readership to include a sentence to introduce the relevance of
the C-index. It would also help to return to this in discussion, as the high C-indexes should
support the argument of overfitting – an index of 1.0 in the papers sounds worrying from the
perspective of a generalisable model - this should be clarified for the reader.
7) The challenges and opportunities section is thorough and raises important
recommendations.
8) ‘Implications for practice’ – the sentence ‘based on the predictors included…’ should, as in
the abstract, be qualified, given the biases reported before this. I agree that these variables
would be a useful starting point, but the rationale for their use, in the context of the biases,
could be explained more fully.
9) The conclusion is concise and clear in balancing the result findings with the bias risk.
10) Box 1: I suggest the statement at the bottom of the box ‘Because all models were at
high risk of bias…’ is moved to the top – if briefly scanning the article, there may be a
tendency to then search for the tools online without appreciating the risk of bias.
11) Table 2: could a fuller version of this table be provided, perhaps as a supplementary
table, with a brief summary of the criteria for each paper that resulted in reporting of
‘unclear’ or ‘high’ bias?