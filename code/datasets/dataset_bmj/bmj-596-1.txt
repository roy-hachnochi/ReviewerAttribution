Overall, I felt this was a very good manuscript. The Introduction nicely sets up the importance of
the question. The findings on the importance of standardization for ensuring reliability, of the
divergence between treating physicians and "medical experts," and the very weak effects of
Trustworthiness struck me as fascinating. The Discussion is cogent and suggests important future
directions.
Page 6. I thought the concept of Trustworthiness, the precise operationalization, and the
impressive level of concordance (which indirectly puts the concordance among disability examiners
in context) were excellent. I hope the scale finds much future use. My only quibble would be with
the name, which sort of carries an emotional meaning. I think that "Relevance" or even
"Coefficient of External Validity" might better capture its meaning. However, this is a quibble - I
think it's a well-done scale whatever it's called.
Page 8, Line 56: "Using Fisherâ€™s exact test..." If I understand correctly, Trustworthiness, Level of
Standardization, and Interrater Agreement were all divided into categories and the relationship of
the former two to Agreement were calculated using Fisher's exact test. Ordinarily I would
recommend against using the categorized scores for determining relationship as there would be
more statistical power using the underlying continuous variables. However, in this case the results
are so clear I can't picture the choice making any difference.
Page 16, Lines 15-18: "all Dutch insurance physicians undergo four years of specialty training in
insurance medicine." Thank you for including this - I would have had no idea about this potential
source of interrater agreement.
Page 16, Lines 33-35: "...our findings suggest that medical experts (versus treating
physicians) are more likely to conclude that claimants are capable of working." The implication
that treating physicians are biased towards disability is well-taken. I might add that, at least in
America, the experts often depend on the disability insurance companies for referrals, or receive a
paycheck directly from the disability payer, and feel implicit pressure to not disable. I am not sure
there are very many impartial experts.
Page 17, Line 32: "...experimental settings may artificially inflate agreement." This point is welltaken.
Page 17, Lines 44-49: "Any decision on what constitutes an appropriate threshold...will require
societal dispute on what constitutes acceptable
differences in the treatment of claimants." I think this is an excellent point, as the descriptors
used for the various ranges of the ICC on page 9 are very lenient.
I believe the American Psychological Association and the American Educational Research
Association feel that while a reliability coefficient of .80 (corresponding to a .64 proportion of truescore variance, analogous to the ICC) is acceptable for a statement involving groups, assessment
of an individual requires a minimum reliability coefficient of .90, and preferably .95 (.81 to .90
proportion of true score variance). By this standard, I believe used in human resources
assessment instruments, only ICC values corresponding to the "excellent" and the upper end of the
"good" range could be used ethically. The current manuscript shows nicely that disability

assessments are nowhere near this standard.
I feel it might also be worth mentioning that the focus on reliability can cover over the fact that we
know very little about validity - to my knowledge there is no sensitivity or specificity data, or
positive or negative predictive values, no probability data on whether a person found fit for work
will be unable to sustain a subsequent job due to impairment, or that a person found disabled will
go on to activities whose pace, intensity, and consistency suggest work capacity.
Page 17, Last Paragraph. I felt the recommended future steps are important and well laid out. I
do feel that "...a minimum intraclass correlation coefficient of 0.6" would result in quite a bit of
misclassification on the individual level.
Page 26. I feel the Box on sources of variation is very informative and cogent.
Overall, I see this as a strong manuscript. I wish you much success.