abstract
background: minimisation can be used within treatment trials to ensure that prognostic factors
are evenly distributed between treatment groups. the technique is relatively straightforward to
apply but does require running tallies of patient recruitments to be made and some simple
calculations to be performed prior to each allocation. as computing facilities have become more
widely available, minimisation has become a more feasible option for many. although the technique
has increased in popularity, the mode of application is often poorly reported and the choice of input
parameters not justified in any logical way.
methods: we developed an automated package for patient allocation which incorporated a
simulation arm. we here demonstrate how simulation of data can help to determine the input
parameters to be used in a subsequent application of minimisation.
results: several scenarios were simulated. within the selected scenarios, increasing the number
of factors did not substantially adversely affect the extent to which the treatment groups were
balanced with respect to the prognostic factors. weighting of the factors tended to improve the
balance when factors had many categories with only a slight negative effect on the factors with
fewer categories. when interactions between factors were included as minimisation factors, there
was no major reduction in the balance overall.
conclusion: with the advent of widely available computing facilities, researchers can be better
equipped to implement minimisation as a means of patient allocation. simulations prior to study
commencement can assist in the choice of minimisation parameters and can be used to justify those
selections.
background
most medical researchers are aware that it is necessary to
perform a randomised controlled trial to effectively establish
the usefulness of a new treatment. the aim is that
treatments are compared on similar groups of patients.
completely random allocation of patients to treatments
does not, however, ensure that the patient groups are similar
with respect to prognostic factors. for example, purely
by chance one of the treatment groups may have been
allocated older or more severely ill patients. if such an
imbalance in prognostic factors has occurred then it may
be difficult to attribute any differences to treatment, the
analyses will require adjustment and the study will have
less power.
minimisation [1-3] is a dynamic allocation procedure that
ensures treatment groups are similar with respect to a
series of pre-specified prognostic factors. as patients are
recruited to the trial they are allocated to the treatment
group that will 'minimise' the differences in the distribution
of those factors between the groups. one pitfall of
this process is that the allocation is not random and hence
could be predicted. this problem is addressed by randomising
each patient but weighting the randomisation
towards the minimisation favoured treatment group for
that individual. by introducing weighted randomisation,
the individual is more likely to be allocated to receive the
preferred treatment, but is not guaranteed to do so. there
is a trade-off between the size of the weighting used and
the ability of the researcher to predict the next allocation.
to apply minimisation requires only simple algebra but
this may be problematic for the clinician with limited
time and resources. the advent of greater access to computing
technology has led to an increase in the usage of
minimisation, which has previously been implemented
relatively rarely. published trials increasingly cite the use
of minimisation for patient allocation. for example, falk
et al [4] minimized patients to receive immediate or
delayed radiotherapy with groups balanced according to
clinician, histology, presence of metastases and who performance
status. pal et al [5] used minimisation to ensure
even distribution within age groups (2–12 or 13–18
years) and whether or not there was cerebral impairment
when conducting a trial of phenobarbital versus phenytoin
for seizure control amongst epileptic children in rural
india. minimisation can similarly be used for allocation
within cluster randomised controlled trials when confounding
factors are applicable at the cluster level. for
example, hilton et al [6] performed a cluster randomised
trial of intervention to lessen individuals' cardiovascular
risk with general practices allocated to intervention or
control using minimisation for jarman score, ratio of
patient to practice nurse hours per week and fundholding
status.
the benefits of minimisation have been debated recently
[7,8] and a recent review of the usage of minimisation recommended
'its wider adoption in the conduct of randomized
controlled trials' [9].
the technique has not been without its critics [10] as well
as advocates, but it is acknowledged to be relatively simple
to implement and perform comparably to more complex
models where prognostic factors are non-numeric in
basis [11]. a common criticism is that minimisation concentrates
only on marginal distributions of prognostic factors
and may not ensure that the interactions are similar
between groups. for example, although there may be similar
numbers of males, females, disease state positive and
negative in the treatment groups post allocation, all of the
positive males may receive one treatment and all of the
positive females the other. if there is an interaction
between disease state and gender on outcome, then this
difference between the treatment arms may be problematic.
however, the likelihood of imbalance is easily countered
via a 4-category minimisation variable: male/
positive, male/negative, female/positive, female/negative.
the usefulness of minimisation as an allocation procedure
within randomised controlled trials is therefore
established and will continue to be recognised and utilised.
however, it has been commonplace for published
studies that have used minimisation to give little or no
information as to how the process has been implemented.
often they cite the minimisation variables but do not state
what metric has been used to determine the preferred allocation
group, whether and what randomisation weightings
have been used for the allocations, whether and how
the factors have been weighted, whether interactions have
been accounted for or, where applicable, how cut-points
for continuous prognostic factors were selected. the
researcher who wishes to embark on a trial using minimisation
as the means of patient allocation often has many
questions to ask. several parameters need to be selected
for each trial to which minimisation is to be applied.
these parameters and, from our experience within the statistical
consultancy, the most common associated questions
related to the choice of each, are given below:
1. number of factors
• how many factors can be balanced simultaneously?
• how does the balance for an individual factor change as
more factors are incorporated?
• in particular, what is the effect on other factors of adding
a single, many-categoried factor such as centre?
2. number of categories for each factor
• how does choice of number of categories (for continuous
prognostic factors) affect the allocation process?
3. whether and how to weight the factors
• how should the factors be weighted?
4. the randomisation weighting to use
• how much should the randomisation be weighted in
favour of the preferred group?
they also want to know
• with a chosen randomisation weighting and given
number of minimisation factors, how big a discrepancy
can be expected for a specified sample size?
and
• how does inclusion of interactions between prognostic
factors change all this?
there is minimal information available in the published
literature to inform researchers when addressing the
above questions.
we have developed a simple computer package to perform
minimisation allocations subject to selected values
of these 4 input parameters. we have also incorporated a
simulation element that allows the researcher to investigate
the size of discrepancies in allocation of prognostic
factors between treatment groups subject to variation in
the input parameters.
we here present the results of some simulations for a
hypothetical proposed trial and show how this process
can assist the researcher in deciding on the parameter values
to be used in their trial. subject to our chosen criteria
for model comparison, we examine the extent to which
varying the minimisation parameters may influence the
equalisation of prognostic factors between treatment
groups.
methods
for each new patient to be allocated, the process of minimisation
considers the imbalance in selected prognostic
factors and weights the randomisation of the next patient,
according to his or her characteristics, in favour of the
treatment that will make the treatment groups most similar
with respect to the prognostic factors. to formalize this
process, assume a trial where patients are allocated to one
of two treatments, t1 and t2. suppose there are m prognostic
factors and cj is the number of categories for the jth
prognostic factor (j = 1,...,m). let anj be the value that the
nth patient takes for the jth prognostic factor (anj∈
{1,2,...,cj}) and let dj be a measure of the difference
between the numbers of patients allocated to each of the
two treatments who are in category anj after allocation of
the (n-1)st patient. assume dj positive if more patients in
category anj are currently receiving t2, negative if more are
receiving t1 and zero if both treatments currently contain
equal numbers of patients at this level for the jth confounder.
therefore dn-1 = {d1, d2, ..., dm} is the vector of
differences between the treatment groups with respect to
the m prognostic factors at the levels seen in the nth
patient prior to allocation of that patient. using minimisation,
according to the size and direction of dn-1, randomisation
of the nth patient will be weighted towards the
treatment group that will make dn numerically smaller
according to some chosen metric ie. the differences
between the treatment groups will be minimised with
respect to the prognostic factors.
for example, consider a study where there are m = 4 minimisation
criteria: gender, age (under/over 18), residency
status of patient (in/out) and severity of disease (mild/
moderate/severe). suppose that 34 patients have been
recruited and allocated to one of 2 treatment arms (17 per
arm) and that they are distributed amongst the minimisation
criteria categories as follows:
suppose that the 35th (n = 35) patient to be allocated (n =
35) is an adult male in-patient with mild disease. prior to
his allocation the numbers of patients falling into these
categories is 8+3+7+4 = 22 in treatment arm t1 and
9+5+7+3 = 24 in treatment arm t2. hence d34 = {8-9, 3-
5, 7-7, 4-3} = {-1, -2, 0, 1} is the vector of differences
between the treatment groups with respect to the 4 prognostic
factors at the levels seen in the 35th patient prior to
allocation of that patient. since there are fewer similar
patients in t1, randomisation of the 35th patient should
be weighted towards this group.
choice of metric to minimise dn
the simplest algorithm for allocation of the nth patient is
to weight the randomisation in favour of t1 if ,
in favour of t2 if and use simple randomisation
(p = 1/2, where p is the probability with which the patient
is allocated to the preferred treatment) if . this
dj
j
m
>
= σ
0
1
dj
j
m
>
= σ
0
1
dj
j
m
>
= σ
0
1
table 1
treatment arm:
t1 t2
gender:
male 8 9
female 9 8
age:
under 18 14 12
over 18 3 5
residency status:
in patient 7 7
out patient 10 10
severity of disease:
mild 4 3
moderate 12 11
severe 1 3
prognostic factors.
the prognostic factors can be given different weightings
(wj) according to their relative importance and
used to determine the allocation. there are a variety of
ways that the wj may be chosen. one potential system that
seems reasonable is to weight according to the number of
categories. for example, if 100 patients are allocated to
two treatment groups then we would expect 25 within
each category of a binary variable for each treatment
group, and 10 within each category of a 5-category variable
for each treatment (assuming, without loss of generality,
equal probability of the categories occurring within
each variable). a maximum difference of the same absolute
magnitude between the two treatment allocations for
any of the variable categories would probably be more
clinically relevant for the 5-category than for the binary
variable:
the absolute (unweighted) differences are identical (= 10)
but for the binary variable t2 contains 50% more patients
within the first category, for the 5-category variable there
are 200% more relative to t1. the deviations from
expected are 20% (5/25) and 50% (5/10) respectively.
weighting the absolute differences (= 10) by the number
of categories gives weighted differences of 20 (10 × 2) and
50 (= 10 × 5) for the 2 and 5 category variables respectively.
the extent to which randomisation is more likely to
favour one treatment over the other depends on the size
of the randomisation weighting used. with p = 1/2 (simple
randomisation) there is no preference for either group.
when p = 1, the patient automatically receives the preferred
treatment, there is no random element and allocation
is said to be deterministic i.e. the researcher could
predict the group allocation of the next patient if they
knew the previous allocations. selecting a value 1/2 <p <
1 will bias allocation in favour of the preferred treatment
whilst retaining an element of randomness so that patient
allocation cannot be predicted. more extreme values of p
(greater bias) will lead to better balancing of prognostic
factors between treatment groups.
there must be a trade-off between introducing sufficient
randomisation weighting (p large enough) and not allowing
allocation of the next patient to be predicted (p not
close to 1).
quantification of balance
the maximum absolute difference between the patients
allocated to each of the categories within a given factor
summarises how well that factor has been balanced by the
minimisation process and is used as a summary measure
of balance for that factor. in our simulations we summarise
across factors with the same number of categories. for
example, if we minimize according to 3 binary variables
and one 15-category factor then there will be 2 summary
measures of balance achieved for each simulated dataset:
the maximum absolute differences allocated to (1) any of
the binary variables i.e. the 6 categories which constitute
these 3 factors and (2) any category within the 15 category
factor.
as previously noted [11] it is the behaviour of an individual
design that is of interest to the researcher rather than
the average over many applications. of interest is the
value below which discrepancies are likely to occur for the
majority of applications of minimisation with given criteria.
an individual investigator is more likely to want to
know the maximum discrepancy that s/he can reasonably
expect with chosen allocation parameters rather than
what the average will be for everyone using those parameters.
for these reasons we prefer the 95th centile of the
simulated distributions as more realistic and relevant
measures than the means or medians which have previously
been used to describe the success of a selected allocation
process. the error in estimating the 95th centile is
about 1 1/2 times the error when estimating the mean
[12] but this difference becomes unimportant if a large
number of simulations are taken.
the 95th centiles of the distributions of simulated values
are used to compare allocation schemes with varying
input parameters (sample size, randomisation weighting,
number and type of variables, weighting of variables).
simulation options
it was estimated that 200 simulations would allow quantification
of the 95th centile of the distribution to within ±
0.2 standard deviations of that distribution with 95% confidence.
increasing the number of simulations to 2500 or
5000 would increase this precision substantially to ± 0.06
and 0.04 respectively. a further doubling of the number of
simulations (to 10000) would only further increase precision
by less than 0.01 standard deviations. hence it was
wjdj
j
m
= σ
1
table 2
t1 t2 absolute difference t1 t2 absolute difference
20 30 10 5 15 10
25 25 0 10 10 0
10 10 0
10 10 0
10 10 0
decided that 5000 simulations would be adequate for a
comparison of minimisation criteria. for each scenario
5000 simulations were performed using a fortran program
incorporating nag subroutines for random selection
of patient characteristics.
measure of balance
the 95th centiles of the distributions of maximum absolute
differences for each factor type were recorded and
classified according to the number of potential categories
within which each individual could fall. these differences
are expressed as the proportionate difference from that
expected by multiplying by the number of categories for
that factor and dividing by the total sample size.
randomisation weighting
all simulations were repeated for p set at 1/2 (simple randomisation)
and also for p taken to be 0.67, 0.75, 0.8,
0.83, 0.88, 0.91, 0.95, 0.97, 0.99 and 0.999, values which
equate respectively to allocation to the preferred treatment
being 2, 3, 4, 5, 7, 10, 20, 30, 100 and 1000 times as
likely as to the alternative.
weighting of variables
simulations were performed with prognostic factors both
unweighted (wj = 1; j = 1,...,m) and with weights equal to
the number of categories of the prognostic factor.
to address the types of questions posed by potential
researchers we here simulate several different scenarios:
firstly, we investigate the effect on balance of increasing
the number of factors. models with 1, 2, 3, 4, 5, 10, 20 and
30 binary prognostic factors are compared. the sample
size for each simulation was set at 500. since all factors are
binary, weighting will not change the results and these
models are only presented unweighted.
secondly, we chose a study with three binary, one 3-category
and one 4-category (total 5) prognostic factors to
simulate. this scenario was chosen as being typical of the
problems we were encountering in the local consultancy
and not dissimilar to published studies citing minimisation
criteria which commonly have several binary criteria
and one or more multiple category confounders [4,6]. we
investigated the extent to which balance was a function of
sample size by simulating the scenario with each simulation
based on samples of 40 and of 500 patients. for sample
size of 500, we also considered the balance achieved
when all 2-way interactions were used as the minimisation
criteria (total of 10 interactions between the 5 confounders).
finally, we generated simulations of
allocations for a sample size of 500 based on 6 minimisation
factors: the original 5 plus an additional 15- category
confounder.
practicalities of application
the practicalities of application require some degree of
automation. we have developed a package for clinical
usage (simin) which both utilises simulations to facilitate
the process of specification selection and provides a userfriendly
front-end for the subsequent allocations within
trial. the fortran programs which generate the simulations
are embedded in this package. the purpose of this
paper is to illustrate the types of patterns that can easily be
determined via simulation and to show how this might
assist the researcher, leading to more informed parameter
selection and enhanced reporting of the decision process.
results
all results were equivalent for randomisation weights of
100 and 1000. hence, only the results for 100 are shown
in the figures.
increasing the number of factors
figure 1 shows the results of the simulations as the
number of binary factors is set at 1, 5, 20 and 30. the output
for 2, 3, 4 and 10 binary factors are not shown on the
figure. as expected, the proportionate change from
expected falls as the randomisation weighting is
increased. the largest fall occurs after the introduction of
any randomisation weighting i.e. between values of 1
(simple randomisation) and 2. as the randomisation
weighting is increased to 5 in favour of the preferred treatment
there are further declines and less so between 5 and
30. after 30 the proportionate change appears to have
reached an asymptote. the differences in proportionate
changes with increasing number of factors are approximately
constant with changing randomisation weights.
weighting the variables
figure 2 shows the 95th centiles of the distributions of proportionate
changes for the 5 prognostic factor (3 binary, 1
3-category and 1 4-category) scenario with a sample size
of 500. the dotted lines show the results when the prognostic
factors are weighted according to the number of categories.
again, any degree of randomisation weighting is associated
with the largest fall in change from expected. proportionate
differences increase with the number of categories.
weighting of the prognostic factors has the effect of
increasing the discrepancies for the binary factors but
reducing them for the factors with more categories.
changing the sample size
figure 3 shows the 95th centiles of the distributions when
a sample of only 40 patients is allocated using 5 minimisation
factors (3 binary, 1 3-category and 1 4-category).
the proportionate differences are much larger with the
smaller sample size (c.f. figure 2).
interactions
figure 4 shows 95th centiles of the distributions of proportionate
changes when minimisation is used to allocate
500 patients to 2 groups with the aim of obtaining even
distribution of all 2-way interactions of 5 confounders (3
binary, 1 3-category and 1 4-category). if the distributions
sof the interactions are similar, then the marginal distributions
of the factors will be also.
the differences are increased from the non-interaction
model (figure 2) approximately 2-fold for the lower randomisation
weights (and when simple randomisation is
used) up to approximately 5-fold for large randomisation
weighting. since the proportionate changes are smaller for
larger randomisation weights, the absolute difference in
the proportionate changes falls with increasing randomisation
weights. it should be noted, however, that the interaction
factors have more categories and the discrepancies
are about the same in terms of the numbers of individuals
allocated.
the effect of weighting of the prognostic factors is similar
to previous models. when factors are weighted according
to the number of categories this has the effect of reducing
the proportionate discrepancies for the factors with more
categories (3 × 4 and 2 × 4 interactions) whilst having the
opposite effect for the factors with fewer categories (2 × 2
and 2 × 3 interactions).
ifnicgrueraesi n1g the number of binary factors
increasing the number of binary factors. 95th centiles of the distributions of proportionate changes from expected for
randomisation weights from 1 to 100 obtained from 5000 simulations and a simulated sample size of 500. the number of minimisation
variables is increased from 1 (black line) to 5 (dark green), 20 (lime green) and to 30 (red).
adding a factor with many categories
figure 5 shows the results when samples of 500 are simulated
using 6 confounders (3 binary, 1 3-category, 1 4-category
and 1 15-category). the inclusion of the 15-category
variable has had little influence on the proportionate
changes for the other factors in the unweighted model
(figure 2). when the factors are weighted the proportionate
changes for the 4-category factor are increased in the
expanded model as opposed to having decreased previously.
weighting of the prognostic factors has most effect
on the extent to which the 15-category factor has a similar
distribution for the 2 treatment groups.
discussion
in this paper we have simulated some common treatment
trial scenarios and compared the results in terms of the
distribution of discrepancies between treatment groups.
whilst only a selection of potential scenarios can be
shown, we have illustrated how prior investigation helps
quantify the sensitivity of minimisation to the choice of
input parameters (randomisation weights, weighting of
prognostic factors, number and type of factors). assuming
that numerically small differences between the groups are
of little practical clinical importance, then we can make
several useful statements regarding the selected scenarios:
sfaigmuprlee s2ize 500, 5 prognostic factors (3 binary, 1 3-category, 1 4-category)
sample size 500, 5 prognostic factors (3 binary, 1 3-category, 1 4-category). 95th centiles of the distributions of proportionate
changes from expected for randomisation weights from 1 to 100 obtained from 5000 simulations. dotted lines
show results when prognostic factors are weighted according to the number of categories. results for binary factors shown in
black, 3-category in blue and 4-category in purple.
• the number of factors to be taken into account can be
increased quite substantially without severely affecting
the overall balance.
• weighting of the factors had most effect on the factors
with many categories and was not highly detrimental to
the factors with fewer categories (in keeping with the findings
of weir and lees [13]).
• including interaction terms in the minimisation did not
greatly increase the overall discrepancies.
• even weighting the randomisation by a small amount in
favour of the preferred treatment had a large effect on the
equality of the distribution of prognostic factors between
treatments.
• increasing the randomisation weights above 5 had little
effect on the extent to which the treatment groups were
similar.
note that for a different number or type of minimisation
factors the above statements may not hold. they are not
meant to be universally true. these are statements about
one particular hypothesised scenario to show how infor-
sfaigmuprlee s3ize 40, 5 prognostic factors (3 binary, 1 3-category, 1 4-category)
sample size 40, 5 prognostic factors (3 binary, 1 3-category, 1 4-category). 95th centiles of the distributions of proportionate
changes from expected for randomisation weights from 1 to 100 obtained from 5000 simulations. dotted lines
show results when prognostic factors are weighted according to the number of categories. results for binary factors shown in
black, 3-category in blue and 4-category in purple.
mation relating to that scenario can be easily generated via
simulations.
we believe that prior simulation according to expected
sample size will be useful for clinicians embarking on a
randomised controlled trial for which prognostic factors
exist and should be equalised between treatment groups.
simulation will help quantify the effect of different input
parameters on the expected discrepancies. it may assist in
the choice of randomisation weighting utilised and the
trade-off between minimizing for more criteria and/or
increasing the categories of minimisation where prognostic
factors are continuous. however, it should be noted
that the decision of which variables to include in the minimisation
process should be informed primarily by the
clinical importance of variables and their impact on outcome.
vaughan reed and wickham [14] give further discussion
to the choice of cut-points for continuous
prognostic factors when performing minimisation. all
minimisation variables should be adjusted for in the final
analyses [1,9] and it is therefore important that only necessary
variables are included to avoid over-parameterisation
of the models. there is a trade-off between
incorporating too many variables/unnecessarily increasing
the number of categories used and allowing imbalance
in important prognostic factors. the results of the
mfiignuimreiz i4ng the difference of the interactions
minimizing the difference of the interactions. 95th centiles of the distributions of proportionate changes from expected
for randomisation weights from 1 to 100 obtained from 5000 simulations. all 10 2-way interactions from 5 prognostic factors
(3 binary, 1 3-category, 1 4-category) used as minimisation criteria. dotted lines show results when prognostic factors are
weighted according to the number of categories. results for the 3 2 × 2 interaction terms shown in black, for the 3 2 × 3 interactions
in dark green, the 3 2 × 4 in lime green and the 1 3 × 4 interaction in red.
simulation exercises can assist in the process but cannot
be used as the sole, or even main, decision criteria for
inclusion of a particular variable.
in theory, the process of minimisation is relatively simple
to undertake [15] but in practice we feel that clinicians do
not find it easy to keep running totals and perform
weighted randomisations. automation of the process (in
addition to telephone allocation where available) reduces
the propensity for conscious or unconscious interference
with the allocation procedure. given the importance of
allocation concealment, this is an additional benefit of
employing minimisation. furthermore, simulated models
are not necessarily straightforward to generate. consequently,
we have developed a software package (simin)
for clinical usage which enables not only easy minimisation
but also generates simulations that may be useful
prior to the commencement of the study to help in determining
which input parameters to use. it is important that
the person performing the allocations is independent of
the trial team. having a quick and simple to use automated
system makes it easier to enrol suitable individuals
for this task.
at study commencement it should be possible to justify
the number and type of minimisation variables, their
faidgduinrge a5 15-category factor
adding a 15-category factor. 95th centiles of the distributions of proportionate change from expected for randomisation
weights from 1 to 100 obtained from 5000 simulations. dotted lines show results when prognostic factors are weighted
according to the number of categories. results for binary factors shown in black, 3-category in blue, 4-category in purple and
15-category in green.
weighting and the choice of randomisation weighting.
simulation enables estimation of the discrepancies anticipated
and their probability. for example, suppose a treatment
trial is estimated to require 40 patients to be
allocated to the new or standard treatments to obtain a
reasonable power to detect differences in outcome of clinical
importance. potential confounders are sex (male/
female), age (under/over 18), whether the individual is an
in- or out-patient, severity of disease (mild/moderate/
severe) and ethnicity (4 categories). all categories of all
minimisation variables are expected to be equally likely.
(this latter criterion may not realistic but the density functions
can be easily adjusted within the simulations.) if a
randomisation weight of 2 (p = 0.67) is used then the proportionate
change from expected of patients allocated to
new and standard treatment is expected to be less than or
equal to 0.35 for sex, age group and patient status (in- or
out- patient), less than or equal to 0.45 for disease severity
and less than or equal to 0.6 for ethnicity for 95% of random
patient samples (figure 3). these are equivalent to
absolute difference of 7, 6 and 6 patients respectively. a
statement such as this could be incorporated into the protocol
in a similar way to having a power calculation. i.e.
the protocol could state, "sex, age (under/over 18), residency
status of patient (in/out), severity of disease (mild/
moderate/severe) and ethnicity (4 categories) were
included as factors in the minimisation. factors were
unweighted and a randomisation weighting of 2 was used
for the allocations. it was estimated that the discrepancy
between patients allocated to the 2 treatment groups
would not exceed 7, 6 or 6 for the binary variables, disease
state and ethnicity respectively with probability 0.95."
frequently, very little information is given on randomisation
weights, weighting of variables or even the categories
used in description of minimisation procedures.
whilst it should be possible to justify the minimisation
criteria, the precise details of the allocation process should
not be widely divulged until after the trial has completed.
the less information that is accessible, the less chance
there is of recruitment being biased by knowledge of the
likely allocation of future patients. we recommend that
the details of and justification for the allocation process
being employed are documented and given in the final
trial reports. however, we also recommend that these
details are not revealed to the research team during the
trial apart from where this is essential.
the international conference on harmonisation e9
guidelines [16] discuss the importance of minimising bias
in the design of trials, with 'bias' defined as "the systematic
tendency of any factors associated with the design,
conduct, analysis and interpretation of the results of clinical
trials to make the estimate of a treatment effect deviate
from its true value." these guidelines also state that
"good design should generally aim to achieve the same
distribution of subjects to treatments within each centre
and good management should maintain this design
objective." the use of dynamic allocation of patients to
treatments is one way to achieve these aims. in this paper
we have investigated some of the issues that arise in the
practical application of one allocation technique the use
of which has risen sharply in recent years.
we have performed simulations using the most common
scenario of 2 treatment groups. a similar process could be
done where there are more treatment groups and this
option has been incorporated into our software.
we have simulated datasets under different minimisation
criteria to show how outcomes may vary as the input
parameters are changed and suggest that this sort of
approach should become standard practice. previously it
has been noted that simulations can be usefully employed
prior to study commencement to determine the best allocation
method to use [9,11,13]. these studies have used
relatively complex models to compare not only minimisation
parameters but also alternative approaches such as
stratification. in some cases they have incorporated existing
data [13]. our results are in keeping with the findings
of these more detailed studies. what we have aimed to
show in this paper is how a relatively simple automatic
algorithm, made available in package form, can be used to
assist clinicians when they have decided to utilise minimisation
and need to determine the optimal parameters. the
package simplifies the practicalities of the process and
hence may make this the preferred allocation method
even when there are few prognostic factors to be taken
into account and stratification is also a feasible option. it
is important that researchers justify the choices they make
with regards to the procedure for allocating patients. the
arguments for this are not dissimilar to the argument for
giving a power calculation or describing other details of
the study protocol.
conclusion
the use of minimisation as a means of patient allocation
is increasing. decisions need to be made regarding the
precise mode of implementation. choice of input parameters
may influence the extent to which the process is successful
in ensuring equality of prognostic factors between
treatment groups. we show how a simple automated
package that we have developed locally can be used to
allow researchers to investigate the effects of varying the
input parameters prior to study commencement. the
advent of the wide availability of computing technology
makes minimisation a more realistic choice for many
researchers. it is important that they utilise the technique
most effectively. we have shown how simulations can be
used prior to study commencement to ensure that the
minimisation has a reasonable chance of providing comparable
treatment groups.

<|EndOfText|>

fear or favour? statistics in pathology
statistics have a role to play in most areas of
medical research including the field of pathology.
we have come a long way since 1954 when
the british medical journal published excerpts
from a debate held by the study circle on
medical statistics as to whether the then growing
influence of statistics in medicine was, in
fact, welcome.1 one speaker declared that,
“medicine was an art, statistics a science; he
conceded that the latter had its uses, but when
it came to mixing science and art, statistics was
as out of place as a skillet in a crown derby
tea-service.” he concluded that “statistics
might be all very well for the elite but were a
menace to the mob.” someone else “referred
darkly to the deliberate misuse of statistics,
fostered—for what purpose ?—by statisticians
themselves. statistical publications, he said,
could be recognised by the prolixity of their
tables. in his view no papers should contain any
tables at all.” the debate concluded with the
motion that the influence of statistics should be
welcomed in all branches of medicine and this
was carried by a narrow majority on a show of
hands.
in the intervening 45 years there has been a
mushrooming of statistical literature designed
to assist the medical researcher, with numerous
articles highlighting misuses of statistics and
giving pointers towards improvement. there
has been a growing understanding that statisticians
are concerned with the whole process of
research, from study design through to final
conclusions, and are not merely purveyors of p
values and analytical methodology. the more
recent evidence based medicine movement has
served to further publicise this recognition. as
h g wells predicted, “statistical thinking will
one day be as necessary for efficient citizenship
as the ability to read and write.”
the lessons have been numerous and only
the major developments are reviewed here.
emphasis has increasingly been placed on
identifying a well defined and answerable
research question before undertaking any
study. this seemingly obvious prerequisite may
be the hardest part, finding the right question
often being more troublesome than finding the
right answer. in the words of einstein, “the
formulation of a problem is often more essential
than its solution which may be merely a
matter of mathematical or experimental skill.”
the incorporation of suitable control groups
and some quantification, before starting a
study, of the necessary sample size required to
conclusively answer the research question have
been stressed. the need for some formal statistical
comparison of the results, usually resulting
in a p value, has also been encouraged. an
informal review of the publications in this journal
over the last 20 years shows that this latter
point has indeed been taken on board. the
majority of the papers published in jcp in
1978 contained little or no formal statistical
analysis: during the whole of that year only 38
papers contained any p values and most of
those had only one. by contrast, in the current
editions most submissions have at least some
formal analysis and usually contain several p
values. when interpreting the clinical value of
results statisticians have, in more recent years,
stressed the importance of quantifying the size
of any effect, rather than merely relying on a
significance level as given by a p value. to this
end, the current guidelines for this journal state
that “95% confidence intervals should be used
wherever appropriate.” this has certainly led
to a dramatic increase in usage. during the
whole of 1978 there was only one confidence
interval presented in jcp, compared with the
current situation where they are to be found in
most issues.
so, in common with most others, this journal
has seen a secular trend in the use of statistics,
and the statistical quality of published research
is undoubtedly superior to that seen 20 years
ago. as we enter the new millennium is there
anything that can be done to assist yet further
improvements?
one potential barrier to such improvement is
the dearth of statistical guidance aimed specifically
at pathologists. it may seem strange to
suggest that the wealth of published statistical
literature is not directly applicable to research
in the field of pathology. every discipline tends
to use certain types of study design and forms
of statistical analyses more than others. the
necessary information is out there but it may be
somewhat off-putting to have to delve through
a mountain of irrelevant material to find it. by
identifying the areas of main interest we can
considerably reduce the ground that must be
covered to gain the necessary knowledge to
produce good quality research that answers
useful questions in our particular area. for
example, the majority of medical statistics texts
aimed at the non-statistician urge us to
perform randomised controlled trials, anything
else being considered inferior, yet these are
hardly ever used by and are largely irrelevant to
pathologists.
most of the research questions addressed by
studies in this journal concern the comparison
between two or more previously defined groups
(for example, diseased and healthy, different
diseased groups, or those at different stages of
the same disease); assessing the reliability/
validity/reproducibility of measurements; predicting
time to death/recovery/relapse/infection
or using new measurements to improve diagnostic
accuracy.
the rest of this paper will focus on two
aspects of medical statistics that are relevant to
all of these scenarios yet are still widely misunderstood
or poorly presented. the aim is to
provide a further learning brick to build on the
improvements that have already been seen over
the last two decades.
choice of sample(s)
individuals
when we perform studies we are trying to find
out what happens in the population. for example,
do two measuring instruments give the
same readings when applied to patients in disease
group x? can we accurately and consistently
measure y? can we predict survival or
time to relapse from p, q, and z? we cannot
measure the whole population, so we observe a
subset or sample of individuals and from these
infer what we think happens in the population
as a whole. statistical analyses are used to make
this inference.
studies can be irretrievably ruined by the
biased choice of samples, particularly if we are
unaware of the size and direction of any bias.
however, choice of sample appears to receive
little thought and is often made according for
convenience rather than representativeness.
commonly all available samples from a given
laboratory or hospital may be included. while
this is all that may be feasible within the time
and practicality constraints imposed on the
researchers, there should be some attempt to
identify whether this sample is in fact representative
of the population of interest. for
example, does this hospital tend to get referred
patients at all stages of this disease or is it
biased towards the more symptomatic? is the
area which this laboratory/hospital serves
socially and ethnically representative? given
this kind of information, the reader can decide
whether the results are likely to apply to their
own population.
quite commonly it is a subgroup of patients
over a certain time frame who are included,
these being chosen according to availability of
blocks, tissue samples, or data. in this case
there needs to be some discussion of the representativeness
of the subgroup. for example,
were those with available tissue more severely
ill? do they tend to have different underlying
diseases? were data more carefully recorded in
the more unusual diagnostic cases?
control groups which consist of “healthy
volunteers” may be used. this group should
ideally be similar to the disease group except
for the presence of disease. it is of interest to
know precisely how this group has been
recruited to help determine whether it constitutes
a reasonable comparison group. for
example, sometimes laboratory staff or patients
admitted for reasons unrelated to the present
study interest are used as controls. in fact
either of these might be considered unsuitable.
the former, laboratory staff, may be younger
than the study disease group and the latter may
not be entirely normal with respect to the study
measures.
volunteers, whether from the disease or the
control group, may differ from non-volunteers,
and it will usually be impossible to assess the
extent of that difference. it is best to avoid
advertising for volunteers as a means of
recruitment. if 50% of those approached to
participate refuse then at least we have some
measure of how representative the final sample
is.
when the sample is to consist of a subset of
some larger group of eligible individuals, then
this subset should be randomly chosen, that is
in a manner unbiased by the characteristics of
the individuals and in a non-systematic way.
random selections must be made using either
tables or suitable software and this should be
made explicit in the description of the sample
selection process.
specimens within individuals
having identified individuals to be included in
the study, there may be the further selection of
a particular specimen to be analysed. this has
been shown2 to be “the most observer dependent
and therefore most subjective step.” many
studies state that “representative sections” or
“systematically selected areas” were chosen,
but precisely how this was done is not made
explicit. if there is a system it should be clearly
outlined so that others can make comparable
choices. if selection is random, the methodology
should be specified.
to summarise, while the ideal of comparable
and representative samples from the study
groups concerned (for example, disease x and
healthy controls, disease x and disease y) is
rarely attained, we can improve published
studies by giving full details of the selection
process for both the individuals and specimens
from those individuals. the representativeness
of these should be discussed to enable readers
to identify applicability and potentially confounding
variables.
a further and related point is that comparability
can be improved by ensuring that those
who make the assessments are blind to the
study group. where several assessors are
involved then there should be high inter-rater
reliability.
size of sample(s)
samples are used to estimate population
effects. it is intuitively obvious that a larger
sample will give a more precise estimation of
the population value. for example, if 20% of
the population display trait x then in a sample
of 10 from this population we would not be
surprised to find anywhere between 0 and 5
individuals with the trait (0–50%). if we
sample 100 individuals we would not be
surprised to observe anywhere between 13 and
29 (13–29%) with the trait; more extreme
numbers may lead us to doubt whether the true
prevalence of x is actually 20%. the thinking
is similar when we present confidence intervals
with sample estimates. from our sample we
estimate the population value (for example, the
mean or proportion; the difference in means or
proportions between normal and diseased
individuals or the median survival in different
groups). we do not expect this estimate to be
exact, although we know that the larger the
statistics in pathology 17
sample the more precise it will be.a confidence
interval gives the range of population values (or
differences) that our sample(s) are compatible
with: 95% confidence intervals give the range
within which we are 95% confident the
population value lies. clearly the addition of a
confidence interval facilitates the clinical
interpretation of the results and highlights any
limitations caused by sample size. most statistical
packages now give confidence intervals as
standard; details of calculation can be found
elsewhere.3 4
the power of a study is its ability to detect a
difference of a given size.5 for example,
suppose qrz in the population of individuals
with disease k is on average 10 and always
varies between 5 and 20 compared with an
average of 20 and range of 10–35 for normal
individuals. (note that the ranges are not symmetric
around the averages and this is to stress
the idea that this thinking applies not only to
normally or symmetrically distributed data.)
we may by chance randomly sample disease k
patients with a tendency to higher values and
normal controls with a tendency to lower
values and hence there will be no significant
difference in the average values in the samples.
we may therefore wrongly conclude that there
is no difference in average qrz between the
groups. of course this will not always happen
and how often it does depends on both the
sample sizes (the larger the samples the more
closely they tend to approximate their respective
population means) and the variability of
the measurements in the populations (if disease
k measures are mostly between 8 and 12 and
the normals between 18 and 22, then it will be
less likely to happen than if the values of qrz
are more evenly spread across the range in each
group). the power of the study, usually
expressed as a percentage, tells us how often a
given difference will be detected for a certain
variability and sample size. as the variability of
a measure is fixed (that is, it exists in the population
and there is nothing we can do about it
except perhaps choose a more homogeneous
population which will change the research
question), the aim is to choose a sample size
that will detect a clinically important difference
with reasonable power. power is usually set at
80% or above. a value of 80% means that four
times out of five the study will detect the difference
if it exists.
it is now accepted as standard practice that
all published randomised controlled trials
should include some statement regarding the
power of the study.6 it is less well recognised
that a similar proviso would benefit the presentation
of all studies, including non-randomised
and single group descriptive studies. such a
policy safeguards the researcher against wasting
time with a sample that is too small to give
conclusive answers. it also serves to assist
interpretation where results are nonsignificant,
in which case we want to know the
power that the study had to detect a difference.
the combination of no power calculations, p
value reporting, and interpretation with little or
no use of confidence intervals is a recipe for
potential disaster.
kirkwood7 gives a good overview of the most
commonly used power and precision calculations.
other useful references8 are for ordinal
variables,9 10 reliability coefficients,4 11–13 survival
analyses,14 15 and for testing equivalence16
17 (which requires larger samples than to
show a difference).
conclusion
if we are to have a new year’s resolution for statistics
in pathology let it be that we will use
unbiased sample selection methods which are
fully reported, perform power calculations, and
present results with confidence intervals. in
this way we can ensure that we are selecting
and interpreting our data without fear or favour
of being misled by biased samples or mystical p
values. conclusions based solely on the latter
should be d valued forthwith.

<|EndOfText|>

summary
cross-sectional covariate-related reference ranges are widely used in clinical medicine to put individual
observations in the context of population values. usually, such reference ranges are created from data
sets of independent observations. if multiple measurements per individual are available, then ignoring the
within-person correlation between repeats will lead to overestimation of centile precision. furthermore, if
abnormal measurements have triggered more frequent assessment, the data set will be biased thus producing
biased centiles. where multiple measures per individual exist, the methods commonly used are either
randomly or systematically to select one observation per individual or to model individual trajectories and
combine these. the first of these approaches may result in discarding a large proportion of the available
data and may itself cause bias and the latter requires the form of the changes within individuals to be
characterized. we have developed an approach to the modeling of the median, spread, and skew across
individuals using maximum likelihood, which can incorporate correlations between dependent observations.
heavily biased data sets are simulated to illustrate how the methodology can eliminate the biases
inherent in the data collection process and produce valid centiles plus estimates of the within-person correlations.
the “select one per individual” approach is shown to be liable to bias and to produce less precise
centiles.we recommend that the maximum likelihood method incorporating correlations be used with existing
data sets. furthermore, this is a potentially more efficient approach to be considered when planning
the future collection of data solely for the purposes of creating cross-sectional covariate-related reference
ranges.
keywords: age-related reference ranges; correlated measurements; dependence; serial measures; unbiased;
z-scores.
1. introduction
covariate-adjusted reference ranges may be used to assess individuals at a single point in time (crosssectional)
or to monitor changes within individuals over time (velocity or conditional). most commonly,
the covariate used is age. if an individual presents for diagnosis/assessment and repeat measurements are
available, then it will generally be advisable to utilize all of these. however, there are many occasions
on which only a single measurement is available and this needs to be evaluated against population values
using a covariate-adjusted cross-sectional reference range.
the methodologies for constructing population-based covariate-adjusted cross-sectional reference centiles
are now well established and were recently reviewed by the world health organization (borghi and
others, 2006, for the world health organization [who] multicentre growth reference study group).
these methodologies commonly assume that the measurements used for construction are independent. if
the data set contains serial measurements from individuals, then these will be correlated within person and
hence the independence assumption is not satisfied. one approach has been to circumvent the problem
by systematically or randomly selecting one observation per individual to create a data set of independent
measurements (e.g. kurmanavicius, wright, royston, wisser and others, 1999; kurmanavicius, wright,
royston, zimmermann and others, 1999; wade and ades, 1994). however, this is wasteful of the data
and may lead to bias.
this paper is concerned specifically with the construction of cross-sectional reference ranges using
serial measurements from individuals. the need for any marginal analyses to include assumptions about
the form of the correlation has been well documented within other applications (diggle and others, 2002).
the laird–ware model (1982) gives a general framework for modeling which allows for variable spacing
of observations and varying structures between individuals. the estimation of parameters for this model
form has received much coverage (davidian and giltinan, 1995; hand and crowder, 1996; vonesh and
chinchilli, 1997; lindsey, 1999; diggle and others, 2002). however, very little of the available literature
applies specifically to the reference range problem. within the majority of texts, characterization of the
average pattern is of primary importance followed by estimation of the covariance/correlation structure
between repeats within individuals where these exist. when reference ranges are to be constructed, the
estimation of any skewness and the spread of values at each covariate are at least as important as quantification
of the median. this shift of emphasis is necessary as it is usually the extreme centiles that are
of most clinical use. by contrast, estimation of the covariance/correlation structure is generally of little or
no direct interest in this scenario.
the who review recommended the use of methodologies that model the covariate-related changes
in distributional features and then combine these to obtain centiles. commonly, the underlying distribution
is assumed to be some transformation of the normal distribution and the kurtosis, skew, spread,
and median are modeled. the form of the models used for the distributional features and the mode of
identifying the best fit parameters vary according to the specific method chosen (cole, 1988, cole and
green, 1992; wright and royston, 1997). previously, we used this methodology within a maximum likelihood
framework with exponential models to create age-related centiles for cd4 counts (wade and ades,
1994), randomly selecting one measurement per child. we subsequently extended the approach by incorporating
suitable correlation structure into the likelihood and thus additionally modeled the correlation
between repeats from the same individual as smooth functions of age and time (wade and ades, 1998),
hence utilizing the entire data set. this extension may be viewed as a generalization of models developed
to identify trends in longitudinal data with explicit modeling of the serial correlation (diggle, 1988).
despite a strong correlation structure, incorporation did not substantially alter the fitted centiles. this
finding was not unexpected because measurements were made at ages defined within a strict protocol,
and hence, frequency of measuring was independent of previous measurements. a similar approach that
has been used is systematically, as opposed to randomly, to select one measurement per individual. for
example, kurmanavicius, wright, royston, wisser and others (1999) and kurmanavicius, wright,
royston, zimmermann and others (1999) used only the first of serial measurements made during pregnancy
to create cross-sectional centiles for fetal biometry.
while it is generally appreciated that incorporation of dependent observations without adjustment for
correlations will lead to overestimation of centile precision, the propensity for bias invalidating the centiles
has received little discussion. when the number and/or timing of observations are related to outcome,
for example, when an abnormal measurement is likely to trigger more frequent assessment for clinical
purposes, then the incorporation of correlations may have a large impact on the centiles by reducing
or removing the bias inherent in the collection process. the problem is one of informative observation
times, whereby future measurement frequency is related to the values of existing measurements for that
individual (lin and others, 2004).
the who review (borghi and others, 2006) identified the following 2 approaches that incorporated
correlated measurements into the construction of cross-sectional reference ranges. laird and ware (1982)
proposed 2-stage random-effects models, while goldstein (1986) proposed a more general framework of
multilevel models which could be parameterized to allow for complex covariance structures and multiple
explanatory variables. marginal distributions obtained from these models would identify cross-sectional
patterns of change (pan and goldstein, 1997). while these models are flexible and present a solution to
the specific problem posed here, they require explicit characterization of a common underlying form for
expected trajectories within individuals. goldstein and others (1994) recognized that the methodology
for conditional (longitudinal) references can theoretically yield cross-sectional references. the second
approach cited by the who review was our previously described maximum likelihood method (wade
and ades, 1998) requiring characterization only of population changes irrespective of how individual
trajectories vary.
in this paper, we illustrate how biases may be removed and precision increased via appropriate modeling
even for heavily biased simulated data sets. we compare the precision with which centiles are
estimated when correlations are incorporated versus the alternative systematic or random “select one”
approach. the methodology is illustrated by application to serial fetal ultrasound measurements collected
at the university hospital in zurich (uhz) and previously modeled using only a subset of the
data (kurmanavicius, wright, royston, wisser and others, 1999; kurmanavicius, wright, royston,
zimmermann and others, 1999).
2. methods
2.1 statistical methods
in previous papers, we have demonstrated the use of splines, fractional polynomials, and exponentials
within the maximum likelihood methodology. any data collection protocol can be accommodated, as
can any amount of variation between the number and timing of measurements per individual. formal
significance tests are easily performed between nested models and confidence intervals constructed for the
model parameters and/or the centiles (wade and ades, 1994, 1998). thompson and fatti (1997) extended
the methodology to create multivariate centile charts. in the analyses presented in this paper, we assume
that a transformation of the normal distribution is appropriate at each covariate value and we model the
changes in the skewness, spread, and median. we maximize the likelihood incorporating a correlation
structure between repeated measurements within the same individual.
we used fortran programs incorporating numerical algorithms group subroutines, which are available
within the supplementary material, available at biostatistics online. an alternative would be to use generalized
additive models for location, scale, and shape (gamlss; rigby and stasinopoulis, 2005). the
gamlss command in r can be used to fit centiles with incorporation of random effects for individuals to
account for serial correlation.
2.2 simulations
full details and results from the simulations are given in the supplementary material, available at biostatistics
online. the features and findings were as follows.
underlying models were assumed so that median and spread were both increasing with gestational age,
as this would be typical in most applications. simulations were based around a scenario often encountered
during pregnancy where measurements are made between 15 and 40 weeks and abnormally low values
trigger additional repeated measurements. repeated measurements within an individual were generated
with an exponentially decaying correlation function.
the extent of bias in the data sets was dependent on how the frequency of repeat measurements was
determined. fitted centiles based on an assumption of independence were heavily biased. the extent of
the correlations between repeats was typically underestimated within the correlation models, although the
centiles obtained were not biased. both precision and accuracy were improved for the correlation model
compared to that assuming independence.
with “select one”, the precision of the centile estimates was reduced and the centile estimates were
biased. this latter finding shows that selecting a subset of independent measurements does not necessarily
yield unbiased centiles. at later gestations, there were more measurements from those fetuses previously
with abnormally low values and hence there was more chance of selecting biased assessments in this
gestational age range.
3. application to ultrasound data set
3.1 the data set
ultrasound measurements were taken from clinic records of pregnant women examined at the uhz, where
routine examinations were performed at 11–13, 18–21, and 28–32 weeks of gestation. high-risk pregnancies
were examined at shorter intervals, every 2 or 3 weeks until delivery. referrals at later gestations from
other ultrasound centers were also included. a relatively common reason for such referral would be suspected
intrauterine growth retardation (iugr) due to placental insufficiency which manifests after 25–28
weeks of gestation with reduced growth of the fetal abdomen. such women then undergo repeat tests until
a definitive diagnosis is made. small values of abdominal circumference (ac) indicate potential iugr,
whereas biparietal diameter (bpd), a measure of skull size, is not expected to be affected by iugr. the
only measurements excluded from the data set were for fetuses found to have a congenital abnormality.
the original analysis used the first fetal measurements made between 12 and 42 weeks from 6557
pregnant women (6557 bpds and 5807 acs). fractional polynomials were used to model age-related
changes in the mean and standard deviation, and shapiro–francia w test was used to check the normality
of the z-scores. for these 2 fetal measurements, a linear cubic in age for the mean and linear model for the
standard deviation were found to be suitable (kurmanavicius, wright, royston, wisser and others, 1999;
kurmanavicius, wright, royston, zimmermann and others, 1999).
the current data set, which has expanded since its use in 1999, consists of information from 12 480
women measured between 1 and 28 times. a total of 48 005 bpds and 45 352 acs are included. hence,
any select one approach would utilize only about 25% of the available measurements. since the purpose
was to illustrate the effects of this modeling, we used the same model forms as kurmanavicius and others
had previously (linear-cubic model for the mean, linear model for the standard deviation, and no skew)
and estimated only their parameters. we allowed the correlation between repeats from the same individual
to fall as the time between those repeats increased and characterized this as a 2-parameter exponential
model (ρ1e−ρ2diff). hence, we estimated 5 parameters for the independence and select one models
(3 for the mean and 2 for the standard deviation) and an additional 2 (for the correlation structure) for
the correlation incorporated models. we compare the fitted centiles with those previously presented by
kurmanavicius, wright, royston, wisser and others (1999) and kurmanavicius, wright, royston,
zimmermann and others (1999).
3.2 fitted models
figures 1(a) and (b) show the 5th, 50th, and 95th centiles from the independence models, the exponentially
correlated models, and those previously presented by kurmanavicius, wright, royston, wisser and
others (1999) and kurmanavicius, wright, royston, zimmermann and others (1999). for both ac and
bpd, taking into account the correlations reduces the centile range at earlier gestations. this pattern
is compatible with a greater frequency of measurement of fetuses with extreme values. the centiles fitted
by kurmanavicius, wright, royston, wisser and others (1999) and kurmanavicius, wright, royston,
zimmermann and others (1999) lie between the correlation and independence models at early gestations
but become increasingly like the independence centiles at later ages.
the effect of incorporating correlations on the centiles at later gestations differs between ac and
bpd. the increased ac 5th centile beyond 30 weeks of gestation may be explained by the inclusion of
late referrals to uhz for suspected iugr. by contrast, bpd is a skull measurement, large values of which
may be of greater concern near to term (40 weeks of gestation). the pattern of differences shown in figure
1(b) suggests that the fetuses with larger bpd were more likely to be measured more frequently in the last
5 weeks of pregnancy. incorporation of correlations reduces the effect of these larger measurements, and
the centiles based on the correlation model are lower.
figures 1(a) and (b) show how incorporation of correlations can remove the selection bias inherent
in clinical data sets. the patterns observed were not anticipated but with hindsight have clinically valid
fig. 1. estimated 5th, 50th, and 95th centiles. the solid lines show the estimated centiles when all measures are
assumed independent and the thick dashed lines when correlations between repeats are incorporated. the lighter
dashed lines show the fitted centiles as presented by kurmanavicius, wright, royston, wisser and others (1999) and
kurmanavicius, wright, royston, zimmermann and others (1999). (a) ac obtained using 45 352 ultrasound measurements
from 12 480 pregnancies. (b) bpd obtained using 48 005 ultrasound measurements from 12 226 pregnancies.
explanations. the results show that the adjustments for correlation will not be uniform in either direction
or quantity even for seemingly highly related measurements, that is, different assessments of growth
from the same ultrasounds in the same group of women. it is perhaps surprising that the centiles based
on the first measurement from each fetus (kurmanavicius, wright, royston, wisser and others, 1999;
kurmanavicius, wright, royston, zimmermann and others, 1999) were more akin to those obtained from
the data set of all measurements. however, this is compatible with the finding of the simulation study.
selecting an independent subset does not necessarily remove bias as late referrals to uhz are probably
atypical.
4. discussion
our simulations and application demonstrate that incorporation of a correlation structure within the fitting
algorithm is to be preferred to the select one approach. although select one is computationally simpler, our
analysis shows that the precision and accuracy of the centiles may be severely affected. the simulations
were developed to represent typical clinical scenarios. the irremovable bias obtained was not expected,
although easily explained with hindsight. it is important to note that such biases may occur in any data set
and will yield biased centiles if select one is used.
simulations are necessarily limited by choice of the parameters and assumptions incorporated. in
particular, we assumed very similar correlation structures within the data generation and fitting phases.we
do know that if the correlation structure is severely misspecified, then this will lead to invalid estimation.
the comparison with the independence model of zero correlation between repeats within individuals is an
extreme case and clearly illustrates this point. there must therefore be some degree of misspecification
that can lead to invalidation of the centiles. for all cases where we modeled the correlation structure, we
assumed exponential decline with increasing time, a reasonable assumption for clinical applications. the
extent of any decline was estimated, and estimates were often biased. however, the model did allow for
any extent of decline (including zero), and the simulations illustrate that biased parameter estimates do
not necessarily lead to biased centile estimates. when constructing cross-sectional reference ranges from
correlated data, estimation of the correlation structure is not of direct interest, but rather is a means toward
the important end of obtaining unbiased estimates of centiles.
the data set we describe consists of longitudinal measurements with informative observation times.
techniques that specifically model the timing mechanism could be employed and would give additional
information. however, this would necessitate the specification of the conditional distribution of an observation
given the history of the process and the centile estimates may not be robust to misspecification
(lin and others, 2004). for the purposes of creating cross-sectional covariate-related reference ranges, the
biases in the measurement process that we wish to eliminate are a function of the clinical scenario. our
simulations show that the method we present is capable of producing unbiased centiles from messy data
sets of the form likely to be found in clinical practice. the extent and direction of centile adjustment when
correlations are incorporated may yield information about the nature of biases inherent in the data set.
despite the numerous advantages of incorporating some form of correlation, the technique has not
been widely used, perhaps because of a mistaken belief that the added complexity of modeling is not
warranted. in this paper, we have shown that simpler methods applied to data with informative observation
times lead to invalid centile estimation. the process of selecting the first observation per individual,
as previously used by kurmanavicius, wright, royston, wisser and others (1999) and kurmanavicius,
wright, royston, zimmermann and others (1999), may lead to a biased solution and necessitates discarding
a large proportion of the data. the resulting reduction in precision will be a function of the percentage
of data discarded and the extent of the within-individual correlation. the reduction may not be uniform
across the age range since selecting the first measurement from each pregnancy will lead to greater loss
of precision at later gestations where there will be fewer women presenting. the uhz received referrals
for suspected problems, based on abnormal ultrasound measurements, from other hospitals. while fetuses
subsequently found to have a congenital abnormality were excluded, biases are still likely to remain. the
simulation results show that incorporating correlation structure into the modeling has the capacity to reduce
biases such as these in estimating centiles. the extent of the bias reduction will depend on the degree
to which the correlation structure has been adequately modeled.
if data are to be collected specifically for the purposes of creating cross-sectional reference ranges,
then the most precise centiles for a given total number of observations will be obtained when these observations
are independent. however, there may be a trade-off between the recruitment cost per individual
and the cost of following individuals serially (goldstein, 1979). if subsequent measurements for a recruited
individual are easier and/or cheaper to obtain than measurements from new recruits, then some
consideration should be given at the design stage to the most efficient way to proceed. it may be ethically
easier to justify serial collection from a smaller pool of prospective subjects, or the pool may be
limited (e.g. children born to hiv-1-infected mothers). often, the remit is to produce both cross-sectional
and conditional or velocity references (borghi and others, 2006). in this case, the optimal approach will
be to incorporate serial observations into the cross-sectional references using appropriate adjustment for
correlation within individuals. the precision with which centiles are estimated under differing correlation
structures, model forms, and/or sample sizes can be readily compared using simulations to identify the
most appropriate recruitment method to use.

<|EndOfText|>

research is only worth doing if it provides useful
information. medical research usually consists
of studying groups of individuals with the
aim of answering a predefined research question.
most commonly in the field of sexually
transmitted infections (sti), the prevalence of
a virus or abnormality is to be estimated or
prevalences compared, either over time or
between different groups of people. alternatively,
several therapies may be compared
within a randomised controlled trial. one
question that arises at the start of any study is
“how many individuals should be included in
this study?” there are several ways of answering
this question. the number included may be
based on practical issues—for instance, the
length of time available to the researcher
together with the time taken to recruit, treat,
and test each individual and the expected
patient accrual rate. these factors will vary
from researcher to researcher and between different
sources of patients—for example, accrual
rates will differ between different hospitals.
to use such variable quantities to
determine the number needed to effectively
answer a given research question is clearly
flawed. ethically it is wrong to either underrecruit
or overrecruit. on the one hand we may
be left with insufficient numbers to conclusively
answer the question. on the other hand,
if we overrecruit, then the best scenario is not
only do we waste time, but also we subject
more individuals than necessary to any inconvenience
associated with being studied. in the
worst scenario, we may be allowing individuals
to receive inferior treatment after sufficient
numbers have been recruited to ensure that the
best treatment is known.
many researchers associate sample size
calculation purely with randomised controlled
trials. most of the studies presented in this
journal do not fall into this category. however
sample size estimation before study commencement
is important for all types of study,
including prevalence studies and observational
comparisons. this article highlights the need
for consideration of study size over and above
issues of feasibility and practicality. information
is presented on how to determine an
appropriate sample size for the most commonly
used study designs within the field of sti.
why size matters
a prevalence study finds that 25% of women in the
outer hebrides have hsv-2 antibodies.
we cannot interpret this information without
knowing the numbers this figure was based on.
for example, one out of four (25%) is a much
less precise estimate than 100 out of 400
(25%). a proper presentation of the results
would include a confidence interval. the 95%
confidence interval for the first scenario is (0.6,
80.6%) and for the second (21.0, 29.5%). for
each of the examples, these are the ranges
within which we are 95% confident the
population prevalence lies. as we would
expect, with a much larger sample size, in the
latter scenario we can make a more precise
statement about the likely population prevalence.
20% of pregnant outer hebrideans have
hsv-2 antibodies compared with 20% of inner
hebrideans.
if the above statement were true and we randomly
sampled and tested 30 individuals in
each group, then we would expect to see about
six antibody positive individuals in each group.
however, we would not be unduly surprised to
find four individuals with antibodies in one of
the groups and eight in the other.
however, we can quantify how likely, in the
absence of a difference, we are to falsely
conclude from our study that there is one. the
statistical significance of a study is the probability
that we will falsely identify a difference
when none exists. the larger the study, the less
likely this is to happen.
20% of pregnant outer hebrideans have
hsv-2 antibodies compared with 10% of mainland
scots.
if the above statement were true and we randomly
sampled and tested 30 individuals in
each group, then we would expect to see about
six antibody positive individuals in the first
group and three in the latter. however, we
would not be unduly surprised to find four
individuals with antibodies in each of the
groups.
key messages
+ sample size is an important issue for all
contributors of studies to this journal.
+ the interpretation of study results depends
on the sample size included that
study.
+ sample size formulas are given for the
most common scenarios encountered in
the field of sti.
question: how do we know that our study
will not indicate there are differences when
none exist?
answer:we don’t.
however, we can quantify how likely we are
to find a difference of a given size if it exists.
the power of a study, usually represented as a
percentage, is the ability of a study of a given
size to detect a difference of a given magnitude.
the larger the difference the smaller the
number needed.
simple sums for sample sizing
choosing the best sample size is not a precise
art. equations exist for calculating the sample
sizes needed to obtain a specified precision or
to identify differences of a given size. the latter
of these are called power calculations. sample
size calculation relies on “guesstimates” of
unknown quantities and hence obtained sizes
are by definition unlikely to be correct. the
extent to which sample size determination is
influenced by erroneous estimates can be
investigated by trying out different guesstimates
in the formulas. below are details of
sample size calculation for the most common
scenarios in sti studies.
(i) the approximate number of individuals
required to estimate a prevalence within ± e%
is given by the formula:
the number required depends on the prevalence
the study is designed to estimate!
note that if the prevalence is x% then the
sample size required is the same as if estimating
a prevalence of (100 − x)%.
for example, if the true prevalence is 25%
and we want to estimate this prevalence to
within ±5% then
individuals are required.
of course we do not know this prevalence
before we undertake the study. our guesstimate
of 25% may be inaccurate. if the true
prevalence is actually 35%, then
individuals would be required to give the same
level of precision. if only 300 individuals are
included (based on the guesstimate of 25%)
then the prevalence will be estimated less precisely
than anticipated.
figure 1 shows the numbers required to
detect various prevalences to within ±1%. for
example, to estimate a prevalence of 25% with
this precision will require approximately 7500
individuals. (note that the same number would
be required to estimate 75% —that is, 100 −
25%, with the same precision.)
if a prevalence needs to be estimated with
greater precision then the sample size must be
increased, for less precision smaller sample
sizes are required.
to estimate prevalences more or less precisely,
the estimates given for ±1% can be
divided by the required precision squared. for
example:
(a) to estimate to within ±2% the numbers
given for 1% need to be divided by 22 (=4), this
curve is shown on the figure. to estimate 25%
to within ±2% requires approximately 7500/4
or 1875 individuals.
(b) to estimate to within ±0.5% the
numbers given for 1% need to be divided by
0.52 (= 0.25). part of this curve is shown on the
figure. to estimate 25% to within ±0.5%
requires approximately 7500/0.25 or 30 000
individuals.
(ii) if the prevalences within different groups
are p1% and p2%, the approximate numbers of
individuals required to detect this difference
with 80% power at the 5% significance level
are:
table 1 shows n for selected p1% and p2%.
for greater power the sample sizes need to
be increased. similarly, larger samples are
required to detect smaller differences between
prevalences.
for 90% power, the samples need to be
increased by about one third.
for example, if 10% of hebrideans and 20%
of mainland scots have hsv-2 infection, then
200 hebridean and 200 mainland scots need
question: how do we know that our study
will not fail to identify a difference of clinical
importance that truly exists?
answer:we don’t.
figure 1 number need to estimate a single prevalence to
within plus or minus 1%, 2%, and 0.5% with 95%
confidence.
10 000
9000
8000
estimate to within:
± 0.5%
± 1%
± 2%
7000
6000
5000
4000
3000
2000
1000
0
50
percentage prevalence
number needed
0 5 10 15 20 25 30 35 40 45
table 1 number required in each group to detect
differences with 80% power at the 5% significance level
given that group prevalences are p1% and p2%
prevalence
(p1%):
prevalence (p2%):
10 20 30 40 50 60 70
5 440 74 33 19 12 8 5
10 200 60 30 17 11 7
20 296 80 37 20 12
30 360 92 40 21
40 392 96 40
50 392 92
60 360
to be tested to detect this difference with 80%
power at the 5% significance level. for 90%
power a total of 266 (= 200 ´ 1.33) will need to
be tested in each group.
as before, the sample size estimate is based
on guesstimates of the study outcome. for the
purposes of sample size determination, the
magnitude of the difference in prevalences
between groups may be chosen on the basis of
what is a clinically important difference that we
want to detect. for example, the best available
evidence may suggest that the hebrideans only
have 5% fewer hsv-2 infections but we decide
to undertake a study to detect a difference of
10% since this could represent a clinically
important difference (in terms of allocating
resources, etc), whereas 5% would not.
often there is more than one factor to
consider. for example, outer hebrideans may
be older than the average scottish person and it
would be of interest to know whether the
difference in prevalence of hsv-2 can be
explained by the difference in ages of the
groups. sample size estimation in these scenarios
is more complex and will depend on the
extent to which the factors are related.1
more of one than the other
when comparisons are made between two or
more groups, power will be maximised (for a
given overall total number enrolled) if each
group is of the same size. to accommodate an
imbalance in numbers while retaining the same
power, the total sample size needs to be
increased accordingly.2
ones that got away
calculations give the estimated numbers required
for statistical analysis. sometimes it will
be necessary to recruit many more to ensure
that sufficient are obtained for that analysis. on
the basis of the expected refusal and compliance
rates, the study should be designed so that
sufficient are contacted/approached/recruited
to account for these losses.
ones that never happen
in some studies, individuals are recruited and
monitored for variable lengths of time with the
aim of comparing times to some defined event,
such as death or infection, between subgroups
of individuals. the nature of the outcome is
that not all individuals will have the event and
a straightforward comparison of percentages
dying or becoming infected is invalidated
because of the variable follow up times.
similarly, comparing average times to death/
infection would also be invalid. a special type
of analysis is required3 and the sample size will
be based on the number of individuals for
whom the event occurs.4 so for a rare event
larger numbers will be required. extending the
length of follow up may be used to increase the
numbers of events occurring.
ones that flock together
if treatments are allocated on a group basis, the
effective sample size will not equal the total
number of individuals. adjustment must be
made according to the extent to which
individual outcomes are influenced by the fact
that they form part of a homogeneous group.5 6
for example, the introduction of trained
specialists within randomly selected clinics7 to
identify whether these specialists have an effect
on adverse outcomes. individuals from the
same clinic may be more alike, perhaps because
of social and ethnic similarities, than those
from different clinics in terms of their tendency
to be recorded as having a problem even before
any intervention. a study that randomises by
clinic will effectively be putting groups of similar
individuals into the same arm of the trial en
bloc. a similar situation occurs when individuals
within the same family, ward/hospital, etc,
are jointly allocated to treatments.
summary
in conclusion, this short article has addressed
the issues surrounding the determination of
appropriate study size. only the sample size
equations relating to the most common study
types in the field of sti are presented. for
more complex but common situations, the
important issues to consider are highlighted.
many other sample size equations exist—for
example, when the outcome is continuous,
such as cd4 count, or more than two groups
are compared. several useful references are
given in the further reading section. this
article raises awareness of the need to perform
studies of the correct size for the given purpose
and informs the researcher in sexually transmitted
infections of the particular points that
they may need to consider.

<|EndOfText|>

abstract
background: a randomised controlled trial of participatory women's groups in rural nepal previously
showed reductions in maternal and newborn mortality. in addition to the outcome data we also collected
previously unreported information from the subgroup of women who had been pregnant prior to study
commencement and conceived during the trial period. to determine the mechanisms via which the
intervention worked we here examine the changes in perinatal care of these women. in particular we use
the information to study factors affecting positive behaviour change in pregnancy, childbirth and newborn
care.
methods: women's groups focusing on perinatal care were introduced into 12 of 24 study clusters
(average cluster population 7000). a total of 5400 women of reproductive age enrolled in the trial had
previously been pregnant and conceived during the trial period.
for each of four outcomes (attendance at antenatal care; use of a boiled blade to cut the cord; appropriate
dressing of the cord; not discarding colostrum) each of these women was classified as better, good,
bad or worse to describe whether and how she changed her pre-trial practice. multilevel multinomial
models were used to identify women most responsive to intervention.
results: among those not initially following good practice, women in intervention areas were significantly
more likely to do so later for all four outcomes (or 1.92 to 3.13). within intervention clusters, women
who attended groups were more likely to show a positive change than non-group members with regard
to antenatal care utilisation and not discarding colostrum, but non-group members also benefited.
conclusion: women's groups promoted significant behaviour change for perinatal care amongst women
not previously following good practice. positive changes attributable to intervention were not restricted
to specific demographic subgroups.
background
maternal and newborn mortality rates remain unacceptably
high in the developing world. most births and newborn
deaths occur outside health facilities, so behaviour
change in relation to home care practices and care-seeking
behaviour is an essential component of any strategy to
reduce deaths. we reported previously a cluster randomised
controlled trial of the effects of participatory
women's groups on neonatal outcomes in rural nepal[1].
the trial intervention was a woman facilitator (who was
not a trained health worker) within each area paid to instigate
and guide women's groups focused on care in the
perinatal period. the trial showed significant falls in neonatal
(30%) and maternal mortality (78%), and appeared
to be cost effective[2].
married women of reproductive age (15–49 years) living
in the study areas at the time of study inception were eligible.
before the trial started, each eligible woman was
asked about her most recent pregnancy. if this resulted in
a stillbirth, infant care practices were asked in respect of
the most recent live birth. information as to who was
present at the birth and whether it took place in an institution
was recorded. in particular it was ascertained
whether there was a skilled attendant at the birth. the
woman was asked whether she had attended antenatal
care, which implement was used to cut the cord, what was
applied to the cord after it was cut (the criterion for cleanliness
was that either nothing or antiseptic was used) and
whether or not she had discarded colostrum before starting
to breastfeed, a practice distinct from discarding the
foremilk at each feed. the evidence base for deciding
which care practices are beneficial for good perinatal outcome
is limited[3]. however, the practices recorded
within the trial (antenatal care, skilled birth attendance,
measures of cleanliness and good breastfeeding practice)
have long been accepted as important[4-8].
after the baseline interview each woman became a member
of the closed cohort who were randomised within village
development committee areas (vdcs) and followed
prospectively. in the original trial the efficacy of women's
groups was measured for all women living within intervention
areas (compared with control areas), even though
many did not attend groups. the use of pre-trial pregnancy
data allowed us to investigate the precise patterns of
behaviour change within individual women and subgroups
of women. some women, in both arms of the trial,
did not have the capacity for positive change attributable
to intervention because they followed good practice in a
pre-trial pregnancy. for women who did not follow good
practice before the trial, our study gives us greater insight
into factors affecting positive behaviour change, such as
group membership, socioeconomic status, ethnicity and
maternal age. the subset of women used for these analyses
had by definition a pre-trial pregnancy and the results
are not necessarily generalisable to women whose first
pregnancy occurred in the trial.
methods
details of the original trial are reported elsewhere[9,10].
briefly, 24 cluster units comprising village development
committee areas (vdcs) – existing geopolitical units of
population about 7000 – were placed into 12 matched
pairings of similar topography, ethnicity and population
densities. one vdc area of each matched pair was randomly
assigned to receive the intervention and the other
formed a control. all eligible women were identified and
details of pregnancies, births and deaths were recorded
prospectively for 33 months.
the analysis includes women who had reported a previous
pregnancy and who had a subsequent pregnancy during
the surveillance period. twin pregnancies were
included only once in the dataset as the process outcomes
under consideration mostly related to the delivery or
woman at that time rather than the individual child.
repeated pregnancies were included in the analysis with
the appropriate clustering to account for within-woman
correlation of outcomes and responses.
statistical analysis
the practices undertaken in each trial pregnancy were
compared with those practices a woman had reported in
her pre-trial pregnancy. each practice was classified for
each pregnancy as:
1) better – lack of good practice in the preceding pregnancy
followed by good practice in the trial pregnancy.
2) good – good practice in both preceding and trial
pregnancies.
3) bad – lack of good practice in both preceding and trial
pregnancies.
4) worse – good practice in the preceding pregnancy but
not in the trial pregnancy.
we fitted multilevel multinomial models, taking into
account the pairing of vdc area clusters, the clustering of
women within vdc areas and households, and the correspondence
between repeat prospective pregnancies in the
same woman, to the 4-category outcomes. multinomial
models were preferred to logistic regressions of the trial
practices corrected for pre-trial behaviour since they distinguished
between changes from bad to good or from
good to bad practice.
multinomial models are extensions of logistic models.
associations between the outcomes and various features
of the women are quantified and presented as coefficients
for the ratios falling into the better category relative to
the other categories. this representation of the model
results was chosen as being the easiest to interpret clinically.
for all 3 ratios thus obtained, larger values were
associated with more favourable outcome. all coefficients
are presented with 95% confidence intervals adjusted for
the clustered nature of the data. for each feature, separate
coefficients are given to quantify the ratios:
1) better relative to good – quantifies the extent to
which women following good practice in the trial pregnancy
were doing so as a result of positive change (as
opposed to continuing the good practices they had
adopted pre-trial).
2) better relative to bad – quantifies the extent to which
women who were following bad practice in the pre-trial
pregnancy improved their practice within the trial. this
coefficient is of particular interest as it describes the extent
to which opportunities for positive change were taken.
3) better relative to worse – quantifies the extent to
which those women who changed practice made a positive,
as opposed to negative, change.
a series of multilevel multinomial models were fitted to
each of the process variables. firstly, models were used to
quantify differences in patterns of change between control
and intervention clusters and the additional effect of
attending a women's group for women within intervention
clusters.
secondly, a series of models were fitted to investigate
whether the effect of intervention varied between women
of differing ages, literacy levels and education, or between
those living within households of differing ethnicity,
assets or food sufficiency. for each of these demographic
variables, a model which incorporated the demographic
variable, a variable representing intervention status, and a
term for the interaction between these two variables was
used. the intervention and demographic variables were
independently significantly associated with outcomes in
all models. the coefficients for the fitted interaction terms
showed which groups of women were most likely to
respond to intervention and these are presented. coefficients
greater than 1 indicate that the women in the intervention
clusters within that demographic subgroup had a
more favourable distribution compared to the baseline
category which was over and above any increase in favourable
practices that could be attributed to intervention
across all subgroups. coefficients less than 1 are associated
with a less favourable response for that demographic
subgroup of women in the intervention compared with
control clusters.
ethics and consent
the study was registered as an international standard randomised
controlled trial, number isrctn31137309. it
was approved by the nepal health research council and
the ethical committee of the institute of child health and
great ormond street hospital for children, and was conducted
in collaboration with his majesty's government
ministry of health, nepal. the aims and design of the trial
were discussed at both national and local meetings, after
which consent to cluster involvement was given by chairpersons
of vdc areas and the makwanpur district development
committee. women who chose to participate in
the study gave oral consent, were free to decline to be
interviewed at any time, and the information they provided
remained confidential.
results
of the women for whom information regarding a previous
pregnancy had been recorded, 4929 had one further
pregnancy during the trial surveillance period, 228 had 2
pregnancies and 5 had 3 pregnancies. hence, there were a
total of 5400 within-trial pregnancies from women with
retrospectively recorded information.
most women delivered at home (93%), without a trained
attendant (92%) or any government health personnel
present (90%), in either the preceding or study pregnancy.
the sentinel care practices of antenatal care uptake, use of
a clean blade to cut the umbilical cord, appropriate dressing
of the cord and feeding of colostrum to the baby were
more variably followed. table 1 shows the demographic
breakdown of the women and the extent to which good
practice was being followed prior to commencement of
the study.
approximately three quarters of the women were appropriately
dressing the cord initially and this proportion was
fairly constant across demographic subgroups. attendance
at antenatal care, boiling of the blade and not discarding
colostrum were all more prevalent amongst the
more highly educated and literate women from wealthier
households.
the effect of being in an intervention vdc
table 2 shows the percentages of pregnancy pairings falling
into each of the 4 categories (better, good, bad,
worse) for the 4 outcomes for women in intervention
and control arms of the trial.
the percentage of women who were following good practice
during their trial pregnancies can be obtained by adding
together the percentages falling into the better and
good categories. for each of the 4 outcomes a greater
percentage of the women in the intervention clusters followed
good practice during the trial.
combining the better and bad categories gives the percentage
of women who were following bad practice pretrial
(and hence had the capacity to change for the better).
for all outcomes apart from the discarding of colostrum,
control clusters had more women with that capacity than
intervention clusters. the percentages of women who
recalled discarding colostrum in their preceding births
were approximately equal between control and intervention
clusters. the percentages lying within the bad category
represent missed opportunities for positive change
and there were consistently fewer women within intervention
clusters falling into this category for each of the 4 outcomes.
women who changed their practice between preceding
and study pregnancies fell into the better and worse
categories. the percentage of women in the intervention
clusters falling into the better category was greater than
the percentage in the worse category, showing that
women were more likely to make a positive, as opposed
to detrimental, change for all outcomes. women in the
control clusters were more likely to stop, as opposed to
table 1: practices in pre-trial pregnancies according to demographic variables
number following good practice pre-trial (% of total)
antenatal care attendance boiling the blade appropriate dressing of
cord
not discarding colostrum
n = 5373 (%) n = 5216 (%) n = 5216 (%) n = 5120 (%)
household
ethnicity:
tamang 757 (21.2) 648 (18.6) 2654 (76.3) 1543 (45.3)
brahmin-chhetri 551 (67.0) 512 (65.0) 601 (76.3) 535 (68.8)
magar 103 (40.9) 83 (33.5) 187 (75.4) 151 (61.9)
other 212 (29.2) 258 (36.8) 526 (74.9) 407 (59.0)
no assets listed 651 (22.1) 634 (22.2) 2175 (76.0) 1333 (47.5)
clock, radio, iron, bicycle 569 (31.9) 517 (29.8) 1305 (75.2) 896 (52.6)
more costly appliances 403 (62.5) 350 (56.6) 488 (79.0) 407 (66.8)
mother
illiterate 704 (18.6) 713 (19.3) 2816 (76.3) 1628 (45.0)
reads with difficulty 320 (45.3) 285 (41.5) 522 (76.1) 418 (62.1)
reads with ease 599 (68.5) 503 (60.0) 630 (75.2) 590 (71.3)
no formal education 949 (21.8) 933 (22.1) 3219 (76.2) 1959 (47.3)
primary schooling only 395 (57.2) 325 (48.7) 503 (75.3) 424 (64.4)
secondary or higher 279 (82.8) 243 (75.7) 246 (76.6) 253 (79.3)
total 1623 (30.2) 1501 (28.8) 3968 (76.1) 2636 (51.5)
median (interquartile range) for those following good (g) and bad (b) practice retrospectively:
household
number of months with g: 10 (7,12) g: 12 (7,12) g: 10 (7, 12) g: 10 (7, 12)
sufficient food b: 9 (7,12) b: 9 (7,12) b: 9 (7, 12) b: 10 (7, 12)
mother
age (per additional year) g: 22.2
(19.9, 26.2)
g: 22.7
(20.1, 27.0)
g: 24.6
(20.9, 29.8)
g: 24.0
(20.8, 28.8)
b: 25.8
(21.6, 31.2)
b: 25.3
(21.3, 30.9)
b: 24.4
(20.9, 29.9)
b: 25.2
(21.1, 30.9)
note: numbers are less than 5400 for each outcome since some women did not have pregnancies that progressed to the stage for that outcome to
be appropriate. for example, 280 of the eligible pregnancies did not result in a live birth of a surviving mother and hence the discarding of
colostrum was only appropriate as an outcome for 5120 women.
start, appropriate dressing of the cord, but otherwise their
changes were similarly more likely to be in a positive
direction.
the differences between women in the intervention and
control vdcs are further quantified by the fitting of multinomial
models to the 4 outcomes with intervention status
as a predictor. the coefficients and confidence intervals
are given for the better/bad and better/worse
ratios. these are all significantly different to 1. for all four
practices women who were initially following bad practice
were significantly more likely to change to good practice
if they lived in an intervention vdc (better/bad ratios).
for example, women who did not attend antenatal care in
preceding pregnancies were more than twice as likely to
do so during the study period if they lived in an intervention
area (odds ratio 2.04 95% ci (1.82, 2.27 times)). of
the women who changed practice these changes were significantly
more likely to be in a positive direction for all
outcomes except antenatal care attendance (better/
worse ratio).
women attending antenatal care and/or using a boiled
blade to cut the cord in pregnancies falling within the
study period were significantly less likely to be doing so as
a result of a positive change in practice if they lived in an
intervention vdc (better/good ratios). these results
are not unexpected given the larger percentages of women
within the intervention vdcs following good practice for
these outcomes pre-trial.
the independent effect of attending a women's group
about one in twelve married women of reproductive age,
and about one third of newly pregnant women in intervention
clusters attended the women's groups. there were
few differences between the percentages of women who
did and did not attend women's groups falling into each
of the 4 categories.
the effect of attending a group over and above the
improvements attributable to living within an intervention
area was greatest for antenatal care attendance. the
percentages of women who attended the groups falling
table 2: behaviour change over time between pre-trial and trial pregnancies for four perinatal care practices.
antenatal care
attendance
boiling the blade appropriate dressing
of cord
not discarding
colostrum
intervention n = 2535 n = 2454 n = 2454 n = 2409
control n = 2838 n = 2762 n = 2762 n = 2711
% better intervention 19.1 21.8 17.9 29.7
control 16.6 12.1 16.3 23.2
% good intervention 36.0 32.5 63.2 41.7
control 12.5 12.8 56.7 34.7
% bad intervention 36.8 39.2 4.2 17.5
control 65.6 68.1 9.3 26.5
% worse intervention 8.2 6.4 14.7 11.2
control 5.2 7.0 17.8 15.5
total (%) intervention 100 100 100 100
control 100 100 100 100
intervention/control
comparisons : odds
ratios (95%
confidence interval)
%better/%bad
ratio *
2.04 (1.82, 2.27) 3.13 (2.78, 3.45) 2.44 (1.92, 3.13) 1.92 (1.69, 2.22)
%better/%worse
ratio*
0.73 (0.59, 0.91) 1.96 (1.59, 2.44) 1.33 (1.15, 1.54) 1.79 (1.52, 2.08)
%better/%good
ratio*
0.40 (0.35, 0.46) 0.71 (0.61, 0.81) 0.99 (0.88, 1.10) 1.06 (0.95, 1.19)
*results from multilevel multinomial models. the estimates and intervals are adjusted to take account of the correlations between pregnancies
within the same women, women from the same household, households from the same vdc and vdcs within the same matched pair. all odds
ratios are significantly different to 1. coefficients greater than 1 indicate that the women in the intervention clusters had a more favourable
distribution, those less than 1 are associated with a less favourable response for the women in the intervention compared with control clusters.
into the better, good, bad and worse categories
were 22.3, 37.3, 33.7 and 6.7 respectively, compared to
17.8, 34.9, 38.9 and 9.1 of those within intervention
vdcs who did not attend groups. hence, a larger percentage
of those attending the women's groups improved their
practice (22.3 vs 17.8%) or maintained previous good
practice (37.3 vs 34.9%). the significantly lower odds of
making a positive as opposed to negative change (better/
worse ratio) in the intervention vdcs were counter-
acted in the subgroup who attended the women's
groups. the women who attended the groups were significantly
more likely to make positive changes than nonattending
women within intervention vdcs (better/
worse ratio 1.77 (1.30, 2.40)). similarly, the women
within intervention vdcs who attended the groups but
did not attend antenatal care in their previous pregnancies
were significantly more likely to start doing so than the
women within those same vdcs who did not attend
(better/bad ratio 1.51 (1.28, 1.79)). this difference
was additional to the 2.04 fold increase seen in the intervention
vdcs overall. the better/good ratio for
attenders vs non-attenders was also significant (1.22
(1.04, 1.45)). women attending the groups were significantly
more likely to make positive changes compared to
non-attending women in the same vdcs with respect to
discarding colostrum (better/worse ratio 1.03 (1.01,
1.06)) and there was some evidence that if they were discarding
colostrum previously they were more likely to
stop doing so (better/bad ratio 1.02 (1.00, 1.04)).
there were no other significant differences.
were specific subgroups of women with the capacity for
positive change more likely to respond to intervention?
table 3 shows the increase in the better/bad ratios for
the intervention group compared to the women in control
areas. values greater than 1 indicate that the intervention
was more successful in those subgroups of women relative
to the baseline demographic category. significant differences
in the effects of intervention on the four process outcomes
were not consistent across demographic
subgroups.
were women who changed practice more likely to do so
positively if they were from specific subgroups?
the extent to which women made positive, as opposed to
negative, changes in practice is quantified by the better/
worse model coefficients. patterns were not consistent
(table 4) but they were based on the smallest groups
(table 2). women from households with more assets
within intervention vdcs were significantly more likely
to make a positive change to dressing the cord but a negative
change with respect to the treatment of colostrum. it
was the older women, those who were less literate and the
less well educated who were significantly more likely to
have stopped, as opposed to started, discarding colostrum
if they lived in intervention, as opposed to control, vdcs.
were women from specific subgroups who followed good
practice during the trial more likely to be doing so as a
result of a positive change?
these differences are quantified in table 5 (better/
good ratios). this table is presented for completeness.
however, it is of the least clinical interest due to the
dependence on the variability between groups of the percentages
who show no changes but continue good practice
throughout.
discussion
within a large scale trial of a community group intervention,
women were followed prospectively to document
patterns of behaviour change for perinatal care. this helps
to understand how primary trial outcomes may be
explained by changes in the practices of individuals
within the communities. of the 6380 women who
became pregnant and were included in the main trial
analyses, a subset of 5162 (77.3%) had a pregnancy pretrial
with which to compare their trial pregnancy behaviour.
within this subgroup we have investigated the
changes for women undergoing their second or subsequent
pregnancies. the findings cannot be extrapolated to
women in their first pregnancies.
as expected, there were strong relationships between past
and present behaviour. those who followed good practice
in previous pregnancies were likely to do so again, regardless
of whether they were allocated to the intervention or
control arm of the trial. having a skilled birth attendant is
known to be an important indicator of outcome. less
than 1 in 12 of the women had such a person present at
either their pre-trial or any trial pregnancy. the numbers
therefore were too low to investigate any impact the intervention
may have had on improving skilled birth attendance.
however, it was possible to investigate changes in
other factors known to be important: antenatal care,
cleanliness of blade and cord, and discarding of colostrum.
the intervention effectively promoted significant
change in all four care behaviours amongst the group of
women not previously following good practice (table 2).
positive changes in antenatal care attendance and the discarding
of colostrum were more likely to be made by
women who attended the groups, but behaviour change
in hygienic cutting and dressing is observed generally in
the intervention areas. the lack of uniform relationship
between group attendance and outcome was expected.
the presence of groups in an area has a wider impact than
merely on the women who attend. in our study only 8%
of married women of reproductive age joined our groups,
but 37% of newly pregnant women attended at least once.
whilst group members showed a greater tendency to posbmc
itive behaviour change than non-group members, this
effect is unlikely to explain the overall improved behaviour
change in intervention versus control clusters. our
data provides evidence that the activities and existence of
the group stimulate wider behaviour change in their communities.
the group intervention is a dynamic process
that is uniform only in its participatory method, thus further
study is necessary to explore these processes of behaviour
change. we hoped to bring about behaviour change
by giving women and grandmothers the knowledge they
need to make informed choices, and by creating favourable
social conditions, and an enabling environment in
which they could take these decisions[11-13]. preliminary
analysis of qualitative data, and the data presented here
suggest that this has been the case in the intervention
areas.
most of the responses to intervention were positive. significantly
greater percentages of women in intervention
vdcs who were following bad practice pre-trial stopped
doing so after the commencement of the women's groups.
it was surprising that significantly more of the intervention
area women stopped as opposed to started attending
antenatal care compared to the women within control
vdcs. this difference was mostly attributable to the
greater proportion of women in intervention vdcs who
stopped attending. for the other 3 practices a greater percentage
of control women stopped previous good practice
and for all 4 practices there was a lower percentage who
started. it is possible that the women in the intervention
vdcs saw women's groups as a replacement for antenatal
care. this potentially detrimental effect of the intervention
requires further investigation, perhaps via the use of
focus groups in similar future initiatives.
since allocation was random, we would not expect baseline
differences between women in control and intervention
vdcs. despite similar mortality rates at baseline[1],
some differences in practices were found in the subgroup
with a previous pregnancy reported here. in particular,
women within intervention vdcs were more likely to
have attended antenatal care (44.2% intervention, 17.7%
table 3: coefficients and 95% confidence intervals for the extent to which women in the intervention vdcs, relative to women in the
control vdcs, within different demographic subgroups were more (or less) likely to make a positive change, relative to those in the
baseline subgroup, if they were not initially following good practice (%better/%bad ratio)
antenatal care attendance
n = 5373
boiling the blade prior to
cord cutting n = 5216
appropriate dressing of the
cord n = 5216
not discarding colostrum n
= 5120
household:
ethnicity:
tamang 1 1 1 1
...brahmin-chhetri 1.41 (0.98, 2.04) 0.43 (0.28, 0.68) 1.11 (0.55, 2.22) 1.16 (0.70, 1.89)
magar 4.17 (2.27, 7.69) 0.95 (0.54, 1.67) 0.38 (0.12, 1.27) 2.50 (1.01, 6.25)
other 1.85 (1.23, 2.86) 0.74 (0.52, 1.06) 8.33 (1.92, 33.33) 1.61 (1.04, 2.50)
no assets listed 1 1 1 1
clock, radio, iron, bicycle 0.84 (0.65, 1.08) 0.96 (0.75, 1.23) 1.10 (0.65, 1.82) 1.02 (0.76, 1.37)
more costly appliances 0.73 (0.48, 1.11) 1.06 (0.70, 1.59) 1.92 (0.85, 4.35) 0.77 (0.44, 1.33)
number of months with
sufficient food
1.01 (0.97, 1.05) 0.97 (0.93, 1.01) 1.10 (1.01, 1.20) 1.05 (1.00, 1.10)
mother:
age (per additional year) 0.99 (0.97, 1.01) 1.00 (0.98, 1.02) 0.93 (0.91, 0.97) 1.00 (0.99, 1.02)
illiterate 1 1 1 1
reads with difficulty 0.59 (0.41, 0.83) 1.08 (0.76, 1.54) 1.09 (0.54, 2.17) 0.67 (0.42, 1.04)
reads with ease 0.73 (0.50, 1.08) 0.68 (0.46, 1.00) 0.89 (0.44, 1.79) 1.04 (0.64, 1.69)
no formal education 1 1 1 1
primary schooling only 0.57 (0.40, 0.83) 0.42 (0.29, 0.61) 1.47 (1.08, 2.04) 1.28 (0.81, 2.04)
secondary or higher 0.25 (0.11, 0.58) 0.53 (0.21, 1.35) 0.92 (0.57, 1.47) 0.50 (0.13, 1.92)
(results from multilevel multinomial models. the estimates and intervals are adjusted to take account of the correlations between pregnancies
within the same women, women from the same household, households from the same vdc and vdcs within the same matched pair. significant
differences are shown in bold.)
control) and to have boiled the blade (38.9% and 19.8%
respectively) in their pre-trial pregnancies. the analyses
presented in this paper show that multigravid women in
intervention vdcs were significantly more likely to continue
or begin good practices after accounting for baseline
differences. these significant differences in behaviour
within this subgroup of just over three-quarters of the
women who fell pregnant within the trial period are compatible
with the reductions in major outcomes found
within the trial.
we have presented secondary analyses of the dataset.
many comparisons are presented and these are meant to
be interpreted in unison and with the main outcome analyses.
the study was not originally designed to detect subgroup
differences and the results should not be
interpreted as though they were primary objectives. what
we have aimed to do is to identify patterns that might be
clinically relevant and informative to future studies. we
have not identified any major consistent patterns, a finding
which is itself of interest. having identified significant
differences which could be attributed to the intervention[
1], this analysis investigates the modes via which
those differences may have been achieved. we would
expect to observe differences in process outcomes since
these are known to be related to mortality outcomes. the
finding that the intervention was associated with
increased uptake of good practices in those previously not
following them is both important and as expected: in this
paper we attempt to quantify the degree of difference. it is
also important to note that no tendency for the intervention
to target only subgroups of privileged or non-privileged
women was found. prior to performing these
analyses we had no notion of the direction that any intervention
bias might fall.
if women were already following good practice, the capacity
for the women's groups to effect positive change was
limited. it was important that those following good practices
continued to do so. therefore, we have considered all
patterns of change and how they related to features of the
mother, the household in which she lived and whether or
not she resided in an intervention area. four pre-trial practices
were found to have a large capacity for positive
change and for there to have been significant alterations
during the study period. the women's groups discussed
table 4: coefficients and 95% confidence intervals for the extent to which women in the intervention vdcs, relative to women in the
control vdcs, within different demographic subgroups were more (or less) likely to make positive as opposed to negative changes,
relative to those in the baseline subgroup, (%better/%worse ratio)
ante-natal care attendance
n = 5373
boiling the blade prior to
cord cutting n = 5216
appropriate dressing of the
cord n = 5216
not discarding colostrum n
= 5120
household:
ethnicity:
tamang 1 1 1 1
...brahmin-chhetri 0.58 (0.39, 0.88) 0.76 (0.45, 1.28) 1.85 (1.14, 2.94) 0.79 (0.47, 1.35)
magar 0.67 (0.39, 1.15) 1.30 (0.37, 4.55) 0.65 (0.32, 1.30) 3.57 (1.32, 10.00)
other 0.83 (0.59, 1.16) 0.59 (0.29, 1.19) 2.38 (1.52, 3.85) 2.27 (1.33, 3.85)
no assets listed 1 1 1 1
clock, radio, iron, bicycle 0.92 (0.57, 1.47) 1.15 (0.71, 1.85) 1.37 (0.98, 1.89) 0.99 (0.68, 1.43)
more costly appliances 1.92 (0.97, 3.85) 0.89 (0.44, 1.82) 2.33 (1.45, 3.85) 0.36 (0.18, 0.70)
number of months with
sufficient food
0.97 (0.89, 1.05) 0.98 (0.89, 1.06) 1.02 (0.96, 1.08) 0.99 (0.93, 1.05)
mother:
age (per additional year) 0.96 (0.93, 1.00) 1.01 (0.97, 1.04) 0.98 (0.96, 1.01) 1.04 (1.01, 1.06)
illiterate 1 1 1 1
reads with difficulty 0.91 (0.51, 1.64) 1.20 (0.66, 2.22) 1.03 (0.62, 1.72) 0.31 (0.18, 0.52)
reads with ease 1.54 (0.89, 2.63) 1.19 (0.69, 2.04) 1.47 (0.97, 2.22) 0.61 (0.36, 1.05)
no formal education 1 1 1
primary schooling only 1.08 (0.60, 1.96) 1.03 (0.56, 1.92) 1.11 (0.84, 1.47) 0.49 (0.27, 0.87)
secondary or higher 2.04 (0.93, 4.55) 0.99 (0.46, 2.17) 0.97 (0.95, 1.00) 0.79 (0.34, 1.85)
(results from multilevel multinomial models. the estimates and intervals are adjusted to take account of the correlations between pregnancies
within the same women, women from the same household, households from the same vdc and vdcs within the same matched pair. significant
differences are shown in bold.)
the prevention of neonatal deaths, home care practices
that might help, and the use of health services for either
routine or emergency care. the issues of antenatal care,
the use of clean cord-cutting implements, avoidance of
unhygienic dressings and the benefits of colostrum feeding
arose as subjects of discussion on many occasions.
these issues could, and were, easily translated into specific
actions.
it was clear that the less educated and illiterate women
were less likely to be following good practice initially.
although these women were significantly targeted by the
intervention for some outcomes, the differences were not
uniform. there were benefits across all of the demographic
subgroups of women.
conclusion
in conclusion, peer-education and empowerment of
women through women's groups has positive effects on
perinatal care practices for women in their second or subsequent
pregnancies. both group members and nongroup
members in the locality benefit from this intervention.

<|EndOfText|>

are adolescents with constipation more likely to suffer psychological maladjustment?1 what percentage of chiari i-type headaches show improvement after foramen magnum decompression (fmd)?2 does bcg vaccination reduce early childhood hospitalisation in denmark?3 is diagnosis of coeliac disease associated with differences in adolescent anthropometry?4 does visual feedback affect the rate of chest compressions?5
these are all questions asked in recent issues of this journal. in each case the authors collated information from a sample of individuals to yield an answer to their question. differing study types were used ranging from observational audits and surveys through to randomised parallel and crossover trials. the study designs, participants, settings, sample sizes and key statistics are summarised in table 1.
table 1: description of the five studies
study
design
participants
setting
sample size
key statistics
1
cross-sectional survey
13-18 year olds
5 schools
1697
(114 constipated)
33.3% of constipated and 14.5% of non-constipated had maladjustment:
or 2.94 (1.95, 4.45)
2
retrospective review of audit database/ before-after study
chiari i-type headache cases having fmd
tertiary hospital
39
80% showed improvement post fmd
3
randomised controlled trial
newborn babies
3 danish hospitals
4262 children
(2129 bcg,
2133 controls)
1047 hospitalisations bcg group vs 1003 controls. hr 1.05 (0.93, 1.18)
4
general health examination database
17 yr old israeli jews
eligibility assessment for military service
2,001,353 adolescents;
(10,566 with coeliac disease (cd))
boys with cd had lower bmi (average 21.2 vs 21.7)
cd girls were shorter (161.5 vs 162.1 cm on average)
5
randomised crossover trial
hospital staff
tertiary hospital
50 pairs of measurements – with and without visual feedback
rate of chest compressions was lower and less variable in those receiving feedback
despite these differences, the same basic principle is followed for each. a sample of the relevant group of individuals is identified and from observing what happens to this sample, inferences are made about the wider population. the inferences may be beneficial to similar individuals and those involved in their care. for example, clinicians trying to determine whether to perform fmd2 or parents considering the pros and cons of bcg vaccination. 3 how well a question is answered by the study depends on how large a sample was studied in conjunction with other factors such as the variability of the measurements and/or event rates. both researchers and patients intuitively understand that findings based on a larger sample are likely to be more accurate, and will have more confidence in results based on a randomised trial of 1,000 individuals than if only 10 patients had been recruited. what is less intuitive is that if a treatment is not shown to be effective in a small sample, it may still have benefits. similarly, we are generally less inclined to also apply such intuitive logic to observational descriptive studies. this article will explain the rationale behind consideration of sample size for all types of research study, wherever data is collated to address a proposed research question.
making statements based on the available sample
to explore these concepts further, consider the chiari i-type headache study2. here 32/39 of individuals showed improvement post fmd, which gives a sample estimate of 82.1% improvement rate. a 95% confidence interval for the rate is (67, 91%), which means that we are 95% confident that at least 67% of the population (in this case, chiari i-type headache sufferers) will improve. if we wanted a more accurate estimate, then a larger sample size would give this. for example, suppose 1000 had been assessed and of these 821 had improved, then this would still be a rate of 82.1%, but the 95% confidence interval would now be (80, 84%), and we would therefore be 95% confident that at least 80% would improve. the data that we have is compatible with population estimates anywhere within the 95% confidence interval at the 5% significance level. any hypothesised population estimate that we test against outside that interval will yield a p-value < 0.05 indicating a statistically significant difference and non-compatibility. there is a conceptual distinction between significance tests, which determine compatibility with a pre-specified hypothesised value, and confidence intervals, which have no prior hypothesis and seek only to identify a range of compatibility. for some study types one approach may be favoured over the other. significance tests are generally considered when presenting the results of a randomised trial, whereas an observational study may omit this approach entirely depending on the precise research question.for example, suppose that prior to the study the authors ascertained that improvement in at least 75% of patients would warrant routine use of fmd. when testing against a hypothesised value of 75%, the sample of 39 would have yielded a p-value >0.05, a non-significant difference, indicating compatibility with 75% (as also shown by the confidence interval which contains this value). for the sample of 1000 (where the 95% confidence interval does not contain 75%), a significant result would be obtained (p<0.05), indicating non-compatibility.
this example illustrates the correspondences in interpretation between p-values and confidence intervals. larger samples lead to narrower confidence intervals as they enable more population scenarios to be excluded. note that if interest lies on the difference between two groups, for example the heights of 17 year olds with and without coeliac disease, then the hypothesised population value will be zero (ie. no difference in average height between the two groups). the confidence interval will be for the difference in means (or percentages) between the two groups. if this interval excludes zero then the difference is statistically significant.
what do power calculations have to do with this?
studies don’t always give a definitive, or even very useful, answer to the research question posed. for example, if the aim of the headache study had been to determine whether the improvement rate was at least 75%, then the sample of 39 would not have been sufficient. even though performing the significance test gives a non-significant p-value >0.05, this does not necessarily mean that the improvement rate is lower than 75%. the 95% confidence interval (67, 91%) shows that the data are in fact compatible with an improvement rate as high as 91% (as well as values below 75%). we still don’t know whether fmd yields the necessary improvement rate to warrant usage as the answer given from the available sample is too imprecise. if a larger sample had been studied then the results would have been more conclusive. before starting a study a decision needs to be made as to whether it is feasible to collect a sufficiently sized sample to address the research question within a plausible time frame. power calculations can tell us how many subjects are needed to obtain a significant p-value if there is a difference of a given size from the hypothesised value (75% in example above). alternatively, power calculations can give the number needed to estimate a specified size of estimate (again 75% in above example) with given precision.
finding the right number
there are formulae, that are known as power calculations, which can be used to identify how many need to be sampled to make the estimates sufficiently precise and/or statistical significance likely. these formulae can readily be identified in appropriate statistics textbooks and articles,6-13 or via the many online calculators available, identified by a simple google search. hence in theory this is a relatively easy process – locate a formula or online calculator, plug in a few values and get a number of individuals/items/things that you should collect information on to answer your specified research question. however, there are decisions to make as to which formula and/or online calculator to use, what values to plug into this and how to properly interpret the number that magically comes out. the aim of this short paper is to guide the reader through some calculations so that they are better equipped to address these issues. formulae are given and
these relate to those found on our online calculators webpage.14 (http://tinyurl.com/samplesizecasc ).
using a formula/online calculator
there are two types of sample size formulae. the first of these is aligned with significance testing and providing p-values, the second is akin to confidence intervals. although within the results you will probably present both of these, you need only do one type of sample size calculation. it depends on whether the emphasis in your study is on detecting a difference, or on estimating parameters with sufficient precision.
in this paper, both types of formulae are presented for both binary and numeric outcomes. a binary outcome is one which takes one of two values. for example, the headache study had a binary outcome - headaches either improved or not and the study was interested to identify the percentage who improved3. by contrast, a numeric outcome is usually summarised by the mean of the values. for example, the average of the changes in rates of chest compressions for a clinician using two feedback methods.5
often the population parameter being estimated is the difference between two distinct groups of patients (with and without disease; treated vs control). in this case it is the difference in percentages or means between groups for binary and numeric outcomes respectively that is of interest. the difference may be between distinct groups of individuals, for example the percentage difference between those with and without constipation1, or the difference in mean bmi between boys with coeliac disease or not4. alternatively, measurements may be paired, within individual or by taking matched pairs of individuals, and these differences summarised, for example the rate of chest compression when the same clinician uses visual feedback or not.5 formulae are shown for these scenarios.
only formulae for binary outcomes and means are given in this paper. whilst these are the most commonly used and widely applicable examples of power calculations, it should be noted that formulae exist for many other scenarios, such as non-normal data, hazard ratios, odds ratios and/or hierarchical data. the principles of these formulae are similar although they relate to more complex situations, and are hence beyond the scope of this paper.
terms to understand
if the outcome is numeric, then an estimate will be needed of the variability of the measurements. this is expressed as the standard deviation (sd). larger values of the sd indicate greater variation.
with a numeric outcome, we can express the difference we would like to detect as a standardised difference (sdiff), which is the difference divided by the sd. for example, if the sd of the change in rates of chest compression using two methods is 13, a difference of 8 will be equivalent to a sdiff of 0.6 (8/13).
power is the ability of a study to detect a difference if it exists, and is usually set at 80, 90 or 95%. a power of 80% means that if the difference exists there is an 80% chance that this study will identify it. hence there is a one in 5 (20% = 100-80%) chance of not identifying the
difference, so although a power of 80% is often used (and will require smaller numbers), it is generally better to have a higher power.
significance level is usually set at 5%. this is the chance of falsely declaring a difference when the population value is actually as hypothesised.
precision is a measure of how closely we would to estimate the true value. the width of the confidence interval is synonymous with precision. when using the confidence interval based formulae, the precision needs to be expressed in the same terms as the outcome (percentage or mean range) and is defined, in the formulae presented here (and associated weblink given above) as half the width of the resultant confidence interval. for example, to estimate the difference in average height of coeliac and non-coeliac 17 year olds to within ± 0.1, the precision is entered as 0.1 and we expect to obtain a confidence interval of width 0.2
some power calculations
some commonly used formula are presented here with examples. as explained above, the appropriate formula depends on whether it is a difference that is to be detected or a precision attained, and whether the outcome is numeric or categoric. the formulae are organised accordingly.
detecting a difference
1) numeric outcomes
to detect a specified difference sdiff with 90% power between two groups at the 5% significance level requires 𝟐𝟏𝒔𝒅𝒊𝒇𝒇𝟐 in each group.
reduce this number by a quarter for 80% power and add a quarter for 95% power.
for example, the sd of heights of 17 year olds is known to be about 10cm and a study aims to detect a difference in average height of coeliac and non-coeliac 17 year olds of 0.5 cm or more. this is a sdiff of 0.5/10 = 0.05.
the sample size required to do this is 210.052=8400 per group ie. a total of 16,800 17 year olds, half of whom have coeliac disease.
to detect the same difference with 80% power, would require 6300 per group (8400 x 0.75). for 95% power, the numbers per group need to be increased to 10,500 (8400 x 1.25).
paired data
if there are pairs of observations and it is the mean difference between pairs that is to be compared to an average of zero (implying no difference), then half the sample size given above is the number of paired observations that need to be made. note that the sdiff must be based on the sd of the within pair differences, which will be different to the sd within each group as the pairing removes variation due to differences between groups (such as differences in age, sex, diet, exercise level, disease status).
for example, with the rate of chest compressions crossover trial, patients are measured using different methods but it is the difference that is of interest ie. each individual contributes one difference to the dataset despite having 2 measures made. to detect a difference between methods of 0.4 sdiff with 90% power at the 5% significance level will require 10.50.42=66 clinicians to make paired measurements. to detect the difference with 80% or 95% power requires 50 and 83 clinicians respectively.
2) binary outcomes
the percentages in each group with the outcome are to be compared. if these are %1 and %2, then this difference can be detected with 90% power at the 5% significance level if the following number are assessed in each group: 𝟏𝟎.𝟓{%𝟏(𝟏𝟎𝟎−%𝟏)+%𝟐(𝟏𝟎𝟎−%𝟐)}(%𝟏−%𝟐)𝟐 as before, this number reduces by a quarter for 80% and increases by a quarter for 95% power.
for example: i) the randomised trial of bcg vaccination aimed to detect a fall in the hospitalisation rate of 20% to 16% or lower. for 90% power, 5% significance, this requires:
10.5{20(100−20)+16(100−16)}(20−16)2=10.5(1600+1344)42 = 1932 per group, a total of 3864 randomised to 2 equal sized groups (bcg vaccinated or not). ii) assuming 15% of normal children and 25% of children with constipation have psychological maladjustment, this difference can be identified with 90% power at the 5% significance level with two groups of 331 children (10.5{25(100−25)+15(100−15)}(25−15)2=10.5(1875+1275)100=331). for 80% power the sample could be reduced to 249 per group.
notice that the above two examples relate to quite different study forms, a rct and an observational study, yet the sample size formula required is the same. the formula required depends on the outcome (in this case difference in percentages in two groups) and the power and significance required.
being sufficiently precise divide the quantity stated by the precision required squared (ie. precision2) to give the sample size required to estimate with 95% confidence.
1) numeric outcomes
8sd2 per group
for example, to estimate the difference in average height between coeliac and non-coeliac 17 year olds to within ± 1cm ( precision = 1), assuming a sd of 10 cm, will require 8 𝑥 10212=800 per group, total 1600.
for a more precise estimate within ± 0.5 cm, requires a larger sample of 8 𝑥 1020.52=3200 per group, total 6400.
paired data for paired measurements, the number of pairs required is half of the sample size per group as given above (ie. 4sd2 paired measurements). for example, to estimate the average difference between rates of compression using 2 methods to within ± 4, where the sd of the within pair differences is 13, requires 4 𝑥 13242=43 clinicians making paired assessments.
2) binary outcomes to estimate a single percentage ( %1 ): 4 %1 (100 - %1) for example, if 80% of patients with chiari i-type headaches improve then this can be estimated to within ± 8% with 95% confidence using a sample of 4𝑥80(100−80)82=320 𝑥 20 64=100 patients.
to estimate a difference in percentages (%1, %2) : 4 {%1 (100 - %1)+ %2 (100 - %2)} for example, to estimate a fall in percentages hospitalised when given bcg vaccination from 20% to 16% with a precision of 2.5% (ie. confidence interval width 5%) would require a sample of 4 𝑥 (20.80+16.84)2.52=117766.25=1885 per group, a total of 3770 children.
unequal groups
sometimes when two groups are to be compared it is not anticipated that they will be of equal size. for example, in the study to compare psychological maladjustment rates between adolescents with and without constipation, this was a survey across schools and the numbers in the two groups would not be expected to be equal. an imbalance can be adjusted for by increasing the overall sample size.7 if the above formulae estimate that n per group is required assuming equal sized groups, this is a total sample of 2n. to account for an imbalance between groups of k:1, the total sample size will need to be increased to 𝒏(𝟏+𝒌)𝟐𝟐𝒌 for example, in the constipation study it was anticipated that about 10% of the children would have constipation. this is an imbalance of 9:1 ie. for every 9 that are healthy, there will be 1 who is constipated and hence k=9. the previous formula showed that 249 per group were required to detect a difference of 10% in psychological maladjustment (15% and 25% per group) with 80% power and 5% significance. this is a total sample of 598. to adjust for the smaller numbers of constipated children, the sample needs to be increased to 249 𝑥 (1+9)22 𝑥 9=2490018=1384, which will consist of 138 with constipation (10%) and 1246 without.
some points to note
each of the formulae requires estimation of some quantities, for example the sd of the measures or the percentages in each group. this may appear nonsensical. for example, if we knew the percentages of bcg vaccinated and non-vaccinated who were hospitalised (to put into the formula), we would not be doing a study to estimate the percentage difference between the groups!
sample size estimation is not a precise art. it can give guidance and ball-park figures, but if all information for exact calculation were available we would not need to do the study.
this does not mean that sample size calculation is not worth doing. it is important to ensure that a study is likely to have a reasonable chance of yielding useful information. it is unlikely that we would have no idea of the likely range of estimates required and these can be used to inform calculation.
the size of difference to be detected, sdiff or the difference in percentages, should be informed by an understanding of the minimal clinically important difference. it is important that all estimates are clinically plausible and suitably justified, with estimation never determined with reference to the available or preferred sample size.
in the above calculations, the formulae give the minimum number required and in all cases, where this is not a whole number, has been rounded up. the number given is the minimum
number for statistical analyses, consideration needs to be given when designing the study to the proportion of eligible participants that will refuse to take part and the likelihood of missing data and/or loss to follow up. these factors will impact on the feasibility of attaining the necessary sample size in the timeframe available. there are some relatively minor discrepancies with the sample size estimates given in the example papers and the numbers given here, but this does not indicate errors. all calculations agree to a reasonable extent, with differences attributable to differing approximations in the formulae used. there are often other factors that should be considered. for example, if we compare heights between those with and without coeliac disease, we may wish to adjust for differences in age, sex and ethnicity of children as well as other potential confounders associated with anthropometry. it is worth noting that in this case, taking into account these covariables will only serve to reduce overall variation (sd), so estimation not taking them into account will be conservative. the formulae given are based on a single primary outcome. if there are multiple comparisons, then the sample sizes will need to be larger. as noted earlier, only the most basic calculations are given in this paper, further formulae exist for more complex scenarios. no amount of increasing the sample size can account for biases in the data.
“but i’m not doing a clinical trial so this is irrelevant”
it’s a common misconception that power calculations are only required for clinical trials of the randomised controlled type variety. this is untrue. wherever sampled data is used to address a research question, the sample size needs to be adequate to give a useable answer to that question. in this paper, a variety of examples are given to illustrate applicability. the headache study was a single sample descriptive study, the differences in constipated and non-constipated an observational comparison.
conclusions this article should provide a large enough sample of information to enable the reader to understand that sample size calculation should always be given consideration before commencing a study with 95% confidence. it should be borne in mind that having an adequate sample size is only one important facet of research design. samples selected should be representative and measures of outcome both reliable and valid. no amount of increasing the sample can correct for such deficits in design and doing so will merely result in obtaining a more precise estimate of the wrong answer, or the right answer to the wrong question.
when preparing a manuscript for publication this journal refers authors equator guidelines15 which aim to ensure that whatever type of study is being undertaken all important statistical considerations are made. the majority of the guidelines make reference to sample size determination, including those for observational (strobe16) and diagnostic testing (stard17) studies. this paper explains the basis of sample size calculation with simple examples given as manual calculations, replicable via online calculators if preferred. sample size estimation need not be overly complex nor a black-box affair. the aim of this paper is to enhance adherence to guidelines and incorporation of this important element of research in practice.

<|EndOfText|>

abstract
why might the average paediatrician need to get involved in understanding
statistics? what do they need to know? are there simple rules that can be followed
in determining the appropriate analyses? where can help be found?
these are the questions that we aim to answer in this short review of
how to design and analyze research studies.
keywords statistical-analyses; study-design; critical-appraisal
introduction
in the modern day there is a plethora of information available at the
practicing clinicians’ fingertips. between 100 and 150 paediatric
journals produce on average about 150,000 publications related to
child health annually and these, together with research presented in
journals not solely confined to paediatric medicine, contribute
roughly 2 million paediatric related articles within pubmed online
resource. in the us there are currently around 30,000 clinical trials
being undertaken on children and these are mainly initiated by
universities and institutes rather than drug companies.
so, with all this happening, why is there any need to be able to
understand the research process and statistics?why not just leave it
to the experts to do the work and provide the results?
the problem is that not all published, or even all peer-reviewed,
information is good information. studies are not always optimally
performed and analyses may be sub-standard. anyone wishing to
use the available literature to inform practice needs to be able to
critically appraise content and not just skim abstracts. there is
usually no malicious intent with badly performed research, but
nonetheless it frequently exists and the reader needs to be able to
identify potential flaws as well as useful and applicable research.
even if a study has been well designed, executed and presented,
there will need to be verification that it is indeed generalisable to
any context the reader may wish to apply the results in.
to be fully commensurate with all aspects of medical statistics
from research design through to analyses and interpretation of
results however is too much of a daunting task for the majority of
practicing clinicians. thankfully, such in-depth knowledge is not
necessary to be able to discern the good from the bad and to gain
useful insights into the quality of publications, nor indeed to
perform ones own research study. what is necessary is to understand
the basics of design and also the thinking that underlines
statistical analyses. this, plus the awareness to recognize where
a fairly basic analysis may not be appropriate and it is time to enlist
more expert help, should stand most readers in good stead.
what do we want to know?
whether reviewing the work of others or aiming to undertake our
own research, the first thing we need to do is to establish the
correct research question.
sometimes data is collected primarily for clinical purposes
and research a by-product i.e. individuals’ have information
documented for their own benefit, but these individual bits may
be combined within a research project. alternatively, data may
be collected specifically to address the research question posed.
in the latter case data may be obtained that can more accurately
address the research question.
it is generally useful to consider a pico breakdown of the
research question:
p e patient, problem or population
i e intervention or exposure of interest
c e comparison
o e outcome
for example, we may be interested in how to cure nits or find
the risk factors for early onset asthma but these questions are too
loose and it is not easy to see how they may be answered via
a single study. by contrast, the questions:
“in primary school children, does combing with conditioner
post shampooing (as opposed to just shampooing) lead to less
infestations of nits?”
and
“are family history and introduction of solid food prior to
6 months associated with onset of asthma before age 10?”
are clearly answerable with obvious pico elements.
note that not all elements occur in all research questions. for
example, “what is the prevalence of asthma in 5 year olds?” is an
answerable well-defined question that has a ‘p’ (5 year olds) and
an ‘o’ (asthma yes/no), but no i or c.
it is, however, useful to consider in each case whether there
should be a p, i, c and o and what these are.
design, design, design!
design is of over-riding importance in any study. with even the
most sophisticated elegant analyses, if basic data collection set
up is less than ideal, then the conclusions must be tempered to
take account of this.
there are oftenmany differentways to address the same research
question. if you are undertaking your own research, then youwould
want to ensure that the most efficient and valid feasible design is
used. if you are evaluating published research, then the decision to
be made is whether the design they have used, even if not optimal,
can usefully address the research question posed. in either case, it is
worth remembering that it may be impossible to implement the best
theoretical design due to practical, financial or ethical limitations.
not all designs fit into a neat framework. figure 1 shows the
most commonly cited designs where two groups of individuals
are to be compared. they are split into observational studies,
where the researcher does not change things but merely observes
what is happening, and experimental where there is some
manipulation of individuals for the study purposes.
when observing individuals there are various approaches that
can be taken:
i) consider past habits etc. that are associated with current
outcomes (case-control).
ii) consider associations in the present time (cross-sectional).
iii) classify individuals and follow forward in time to observe
outcomes (cohort).
with experimental studies the researcher gets to decide who
goes into which group. the split can be done systematically (nonrandomized)
or randomly (randomized controlled trial). a before
and after trial is a form of non-randomized experimental study
which is rarely recommended as there will be no measure of what
would have happened in the absence of treatment. randomized
controlled trials (rct) where individuals are consented to the study
and then randomly allocated to a treatment arm are generally
considered the most effective way to show causal relationships. a
crossover (or within person) rct is where each individual receives
both treatments in random order. a crossover trial is less likely to
have hidden confounders but will only be appropriate to investigate
a treatment giving short term relief of chronic symptoms.
sometimes the associations between behavior and outcomes
of individuals are considered on a grouped basis:
if the study is observational then this form of study is often
known as ecological. for example, an ecological study compared
childhood cancer rates between those born in hospitals with
differing intramuscular vitamin k policies. no evidence was found
of an association and this counteracted previous suggestions that
administration of vitamin k may increase childhood cancer risk.
if the study is a rct, then the groups will be randomized en
masse to different treatment arms and this is known as a cluster
randomized trial. for example, villages were randomized to
different educational programs in a bid to reduce infant mortality in
rural areas of nepal. the outcome for babies born in villages which
received the new educational program were compared to those in
the villages which did not receive additional input (controls).
note that the main named study types are given here but
there are plenty of studies that do not easily pigeonhole into
these mainstays and yet are equally valid.
is there anything that might get in the way of any
comparisons?
the majority of studies are designed to address comparative
research questions. for example: do children with sickle cell
anaemia have different scd163 and/or plasma haptoglobin levels?
does giving antenatal corticosteroids (ac) reduce respiratory
disorders in late preterm infants?
whether the study is observational or experimental, things we
are not interested in may get in the way. they do this by having
different distributions in the groups being compared and also
being associated with outcome. when a variable behaves like
this it is known as a confounder.
often studies are designed specifically to avoid confounding.
groups may be chosen to be similar with respect to the potential
confounder(s), for example age and sex matched pairs, stratified
randomization. a problem is that there may be many potential
confounders, some of which are not even known, and it is not
possible to consciously correct for all. a strength of randomized
trials is that in a large enough trial all factors will be evened out
between the groups and hence there will not be confounding.
for example to address the question as to whether ac reduces
respiratory disorders in late preterm infants, we need two groups
of preterm infants: those given ac or not. there are several ways
in which these two groups can be chosen relating to different
types of study. i.e.:
a) an ecological study: outcomes compared between hospitals
with different ac policies.
b) a case-control study: babies with and without respiratory
disorders compared with respect to ac history.
c) a cohort study: ac and not ac groups classified then followed
to see who develops respiratory disorders.
d) a randomized controlled trial of ac versus not ac.
in designs (a)e(c), the observational studies, there is far more
capacity for confounding and a causal relationship cannot be
proved. with (d) there is less chance of confounding and it is
possible to infer causality if a difference is found.
how generalisable are any results?
generalisability is an issue whether the study is observational or
experimental. a random sample of the target population (of the
research question) should ideally be drawn whatever the study
design. it is worth remembering that such an ideal sample is rarely
obtained. for example, individuals were randomly sampled from
those registered with the two largest unions in hong kong to
investigate associations between lifestyle and obesity; schools were
randomly selected in the athens region when assessing the validity
of a food questionnaire amongst school children; different doses of
vitamin d were compared in a rct in schoolchildren in taleghan
near tehran. although these may all provide suitably representative
samples, we should consider whether they actually are
generalisable outside of the groups the selection was from (unionregistered
individuals in hong kong, schoolchildren in the athens
region or taleghan). very often there is no need to worry with rcts
in particular since what works in one sub-population will probably
also work elsewhere. for example, if a rct shows that a preparation
is beneficial to asthmatics in liverpool, then it will probably
also be beneficial to asthmatics in the rest of the country (and
possibly the world), so long as our population of asthmatics is
similar. with observational studiesmore caution may be warranted
as there is greater potential for confounding and effects may not be
constant across different communities.
similarly, we should be happy that any sampling is representative
on a time basis. for example, if a drug is trialed exclusively
in summer, will the effects be similar in winter? when dealing
with children there are often differences in diet and exercise during
term time and outside which may confound the results if not
properly adjusted for. weekends and weekday habits also often
differ: the greek children were asked to complete food questionnaires
on two consecutive weekdays and one weekend day.
if comparisons are made over a long time period then causal
agents may be very difficult to infer as there may be underlying
improvements for all kinds of related reasons. for example,
survival rates increased and levels of severe neurodevelopmental
impairment decreased substantially between 1998 and 2003 for
inborn infants with birthweight below 1000 g, but it would be
hard to pinpoint one single causal factor.
summaries
for any quantitative study, information is recorded for each individual
and the values combined within the study groups to provide
summaries of similarities and differences. the appropriate form of
summary depends on whether the particular piece of information is
numeric (such as height, weight, scd163) or categoric (such as
family history: yes/no, severity of disease: mild/moderate/severe,
gender:male/female).acategoric variable with only two categories
(eg. yes/no, male/female) is known as binary.
numeric data should be summarized as either mean and standard
deviation or median and range or inter-quartile range. the
median is the 50th centile, with half the values being higher than
this and half lower, whatever the distribution. the inter-quartile
range is the 25the75th centiles i.e. the ‘middle half’ of the data if we
chop of the top and bottom quarters. if the distribution of the
variable is skew (tailing off in one direction), then the mean and
standard deviation should not be used.
for example, height does not have a skew distribution since
there are as many short as there are tall people whereas incomes
do have a skew distribution as there is a minimum level of earning
and relatively few very high earners. for height, the mean and
median will be approximately equal and either provides a good
summary of average, the standard deviation can also be used. for
income levels, the mean will not be representative of average
earnings as it will be skewed by the few high earners, whereas the
median and inter-quartile range will give a useful summary.
differences between groups can be quantified as the difference
in means or medians as appropriate.
categoric data can be summarized using proportions who fall
into one category and differences between groups quantified as
either the absolute or relative difference. these are sometimes
known as the arr (absolute risk reduction) and rr (relative
risk) respectively. for example, a recent study showed antenatal
corticosteroid treatment at 34e36 weeks gestation did not reduce
the incidence of respiratory morbidity (36/143 ¼ 25% corticosteroid
group; 30/130 23% placebo group). hence arr¼ 25e23
¼ 2% and rr¼ 25/23 ¼ 1.09. respiratory distress syndrome
(rds) incidences were also similar (2/143 ¼ 1.4% and 1/130 ¼
0.77% respectively, yielding an arr of 0.6% and rr of 1.40/0.77
¼ 1.82).
note that no difference in absolute terms is given by zero,
whereas for relative comparisons, no difference is defined as 1.
an approximation to the rr which is often used is the odds
ratio (or), for which a value of 1 similarly means no difference
between groups.
how many is enough?
it is important to study enough individuals to address the
research question but unethical to waste time and subject more
individuals to scrutiny than is necessary. all studies should have
some stated rationale for the proposed numbers to be included
prior to study commencement.
there are many different sample size formulae and the
correct one to use depends on the nature of the outcome
(numeric or categoric) and the purpose of the study (to identify
a difference between groups or to estimate a quantity with
sufficient precision). each formula will require you to provide
several pieces of information, such as the size of difference
that you want to detect, or the precision required. note
however, that there is a circular argument to sample size
estimation which may initially appear confusing. calculation is
also based on outcome and if you had all the information to do
the calculation properly you wouldn’t need to do the study!
hence, these calculations can only ever be educated guesswork
but nonetheless it is always worth guessing. some web
links which contain suitable applications are given at the end
of this article.
analyses
figure 2 shows when to use the seven most commonly cited
tests for comparing a single outcome between two groups. the
aim is either to compare the proportion in one category of
a categoric outcome (left hand branch) or the mean (right hand
branch, left side) or median (right hand branch, right side)
between the groups. if the groups are paired (for example, age
and sex matched pairs of individuals in the two groups or
a crossover treatment trial yielding paired measurements within
person) then the appropriate test is mcnemars (categoric
outcome), paired t-test or wilcoxon’s test. if there is no pairing
then the appropriate test to compare the groups is chi-square or
fishers exact (categoric), two sample t-test or mannewhitney u
test respectively.
for example:
chi-square test was used to compare respiratory morbidity
between ac and placebo treated groups (36/143 vs 30/130, p ¼
0.69). the lownumbers with rds (2/143 and 1/130) meant that
fishers exact test was used for this comparison (p¼0.54).
a two sample t-test would be used to compare scd163 levels
between patients with and without sickle cell anaemia.
mannewhitney u test would be used to compare plasma
haemoglobin levels which have a skew distribution.
if each child with sickle cell anaemia had a matched control
selected from their class at school, then the data would consist
of matched pairs and the appropriate tests would be a paired
t-test and wilcoxon paired test for the scd163 and plasma
haemoglobin comparisons respectively.
if the aim is to make a comparison after adjustment for other
factors or to build a predictive model, then regression will be
appropriate. the type of regression to use depends on the nature
of the outcome. table 1 gives an overview of what type of
regression to use when.
for example:
to compare respiratory morbidity rates between those given
ac or not, adjusting for gestational age and gender, we would
use a logistic regression since the outcome (respiratory
morbidity) is binary (yes/no).
poisson regression is used for discrete (count) data and results
are given as relative risks (rr). for example, a recent study
showed that there was a significant decrease in mortality in
the delivery room for babies with an estimated ga of 22
weeks between 1998 and 2008: rr ¼ 0.47 (95% ci (0.24 to
0.93)).
linear regression would be used to compare scd163 between
sickle cell children and controls taking into account age and
weight.
the extent to which onset of childhood asthma (yes/no) is
associated with family history and early diet and infections can
be investigated using a logistic regression model.
not the whole story
papers that only cite p-values as the results of statistical analyses,
although commonplace, are flawed. it is not possible to ascertain
the clinical impact of a finding using the p-value alone. the
p-value merely shows how compatible the data obtained is with
the hypothesis of no difference (average difference or arr ¼ 0,
rr or or ¼ 1), but not how likely other scenarios might be.
estimates of effect size should always be given and presented
with confidence intervals. a 95% confidence interval gives the
range of population scenarios that the sample data is compatible
with 95% confidence.
for example:
neither respiratorymorbidity norrds were significantly different
in the trial of corticosteroid versus placebo (rr 1.09, p¼0.69 and
1.82, p ¼ 0.54 respectively). however, confidence intervals for
therrreveal the range ofvalueswhich the trial is compatible with
and paint a different picture. the 95%confidence intervals for the
rr are (0.72, 1.66) formorbidity and (0.17, 19.8) for rds.we are
farmore confident in excluding large differences inmorbidity but
for rds the interval is very wide (due to the small number of
events) and almost 20-fold differences cannot be excluded even
though the difference is statistically non-significant.
filling the gaps
rarely is a study as simple as the textbook examples often given
where a single outcome is compared between two or more groups
of well-defined individuals. more commonly, there is a whole host
of information collected from each participant that will be
combined to give an overall picture. some pieces of information
may correlate with others to give a more comprehensive overview
of the issues. although this is a good thing to do and may lend
validity to the ‘main’ question, the collection of large amounts of
information carries with it pitfalls. most notably, there is greater
capacity for some individuals to have incomplete data. unfortunately
most statistical analyses require each individual to supply
values for all variables included and so it is necessary to either fill
the gaps or exclude those individuals with missing data.
figure 3 gives a guide to useful and not so useful techniques that
can be used. replacing the missing values by some substitute with
no allowance for potential error in doing so is always wrong (left
hand branch) since this will lead to overly precise results and
possibly also bias. if the data are missing completely at random,
then removing any individuals with any missing data (listwise
deletion) will not introduce bias but precision may be less than it
needs to be. ‘missing at random’ means that the missing data could
be inferred from that available. for example, if we have the age and
gender of a child then we would be able to make a reasonable guess
at their height. for data missing at random, or missing completely
at random, the preferred option is multiple imputation and this will
give unbiased results with the best possible precision. multiple
imputation techniques are now available in most large packages
and details can be found in the references at the end of this article.
particular issues for paediatricians
mostly problems are the same as for any discipline. when
dealing with frontline clinical medicine, as opposed to the laboratory
scientist, there are the additional issues to face around
recruitment of people who may choose not to be part of the study
or may agree and then not provide all required data. they may
not provide valid information (for example, they may be inaccurate
in reporting gestation and self-reported smoking histories
have long been known to be open to bias) or adhere to preferred
time-scales (for example, a scheduled annual follow up may need
to be undertaken much earlier or later due to illness or holidays).
when dealing with children there are the added problems of
whether ethics require assent from the child and/or consent
from the parent/guardians, plus the aging process may mean
that they are not a homogenous group. the latter is evidenced
in the need for age (or growth) related standards to interpret
individual data. for example, it is usual to interpret childhood
lung function measurements with reference to the height of the
child. hence adjustment is often necessary for comparing
groups of children unless those groups are only within a relatively
small age range (in which case the results would not be
generalisable outside of the range). this infers a need for more
complex analyses.
making sense of it all!
in this short article we have given an overviewof some issues facing
the paediatrician either trying to interpret published research or
undertaking their own study. it cannot be comprehensive but aims
to provide a starting point. further recommended reading is given
below.
to summarize, we hope that:
p aediatricians have become more
i nformed after reading this article
c ompared to those who have not read it, with the longer term
o utcome of better understanding of published research.