risk of hypoglucaemia related to dpp-4 inhibitors plus sulphonylureas: systematic review and metaanalysis
i apologise for the delay in completing this report.
the authors have conducted a meta-analysis of rcts looking at the risk of hypoglycaemia. they
undertake two analyses, a meta-analysis of relative risks (rr) and a meta-analysis of numbers
needed to treat (nnt) to observe a harmful event.
1. the rr meta-analysis method is described on page 7, and is based on either a fixed effect or
random effects model dependent on the statistical significance of the test of heterogeneity (using a
p<0.1 criteria). no method is described for comparing subgroups.
2. the nnt meta-analysis method is described on page 8, and the methodological description simply
described as “pooled in a forest plot”. this is an inadequate description and it is unclear what has
been done.
3. for the rr analysis, the authors report results of comparisons of subgroups (according to
definition of hypoglycaemia, according to dose) but do not explain what test for the required tests
for differences between subgroups have been undertaken. for the comparison of hypoglycaemia a
p-value is reported for “evidence of heterogeneity between the groups” on line 7 of page 10, but we
do not have a method. for comparison of doses the focus is on whether each group is statistically
significant rather than assessing for differences between the groups (lines 9-10), which is regarded
as a misleading way of undertaking subgroup analyses.
4. it is not recommended that an average nnt is computed by pooling, as appears to have been
done in this manuscript (although the method used is not clear). this is because nnts
mathematically depend on the underlying event rates, which typically vary across studies,
introducing heterogeneity. for example, one determinant of event rates is length of follow-up,
which always increases event rates. thus pooling studies with mixed length of follow-up (here
studies vary between white with 76 weeks follow-up and baseline event rate of 6.3% and kikucho
and seino with 12 weeks followup both with baseline event rates of 1.0%) is likely to introduce
heterogeneity for nnts, whereas the relative effects are more likely to be consistent at different
follow-up points.
5. the recommended approach (as stated in the cochrane handbook) to estimate an average nnt is
to obtain the pooled rr estimate from the meta-analysis and to estimate nnts from it across a

range of prevalences which reflect different settings. these prevalences may be obtained from the
data in the trials, or from other sources. clearly here it is important to standardise for the length of
follow-up time, and the nnt needs to be stated conditional on that duration of treatment (the
longer you treat for the more events will happen).
6. i would also encourage the authors to stick with the notation and terminology introduced by
altman for nnts, which is the nnt for one person to be harmed nnt(h) or benefit nnt(b). the
authors introduce this at the beginning, but then slip into the rather inappropriate nnh – number
needed to harm. although widely used, this abbreviation is erroneous.

<|EndOfText|>

statistical review
risk of hypoglycaemia related to the addition of dpp-4 inhibitors to sulphonylureas: systematic review and metaanalysis
the authors have taken on board comments about the computations of numbers needed to treat in their revised
manuscript. i still have the following issues.
1) i previously pointed out that computation of an nnt requires stating an expected event rate, and as more events
accumulate the longer a group is followed, any computation of the nnt needs to be conditioned on a stated period of
follow-up. in their response, the authors agree with this, and identified estimates of expected event rates for different
durations. however, most of their nnt computations, including those in the abstract are for studies with mixed and
unstated follow-up, which continues their original error. whilst it is always possible to put together a set of studies with
mixed follow-up to compute an expected event rate, the answer you obtain cannot be applied. i would request that any
nnt that is stated in the paper is specific to a stated follow-up period.
2) the authors have chosen to compute an expected event rate used for computation of nnts using data from a
different meta-analysis, and not the data in their meta-analysis. i am not convinced of why they needed to do this – and
it is notable that the expected event rates in the chosen ma are around twice as high as in their data, leading to the
nnts being twice as strong (e.g. the nnt is 10 rather than an nnt of 20). given that this computation is now post hoc,
a very strong justification needs to be made as to why the studies in their meta-analysis are not suitable for making this
computations, whereas the ones included in someone else’s meta-analysis are preferable.
3) the statistical reporting in the abstract needs improvement, particularly the methods and results.
4) page 9 (all page numbers refer to track changed word file) states “the study was performed in accordance with
prisma”. prisma is a reporting standard not a performance standard, so it could be reported in accordance with
prisma.
5) page 9 – please check whether the abbreviation pbo is defined – i do not think it is now defined in the text.
6) statistical methods – page 10 states that the subgroups were compared with cochrane q test and i2 index. first it is
cochran, not cochrane. second the cochran q test measures the heterogeneity in a group, not a difference between
groups. please refer to the cochrane handbook for the correct way to describe this test.
7) how did you judge that patient characteristics were imbalanced across groups? this is not included in the quality
assessment, and is usually a very subjective judgement.
8) in reporting the quality assessment, the only detail that is given is that three studies were judged to have a high risk
of reporting bias and one a high risk of detection bias. could you please explain why you came to these judgements?
what was it about these studies which supports these judgements?
9) in the discussion page 15 that the risk of bias assessment indicated that study quality was high which was confirmed

by the grade assessment. as grade is based (in part) on the quality assessment, it is rather a nonsense to imply that
grade confirms the quality assessment was correct? clearer expression is needed. there are other points in the
discussion which need more careful wording – for example where the results of sensitivity analyses are interpreted as
saying there was no significant change – no assessment of the significance of differences is undertaken in a sensitivity
analysis.


<|EndOfText|>

bmj.2015.025078
consumption of spicy foods and total and cause-specific mortality: a 7-year prospective study of 0.5 million
chinese adults
the authors have made substantial revisions to this manuscript in responses to comments made, and all
addressed all important points.
i have no further comments to make.
my apologies over the time taken for me to complete this review of the revision.

<|EndOfText|>

statistical review bmj.2014.023070.r1
consumption of sugar-sweetened beverages, artificially sweetened beverages and fruit juice
and incidence of type 2 diabetes
the authors have submitted a revised manuscript.
the authors have now included a quality assessment process for the included studies which is
based around the cochrane acrobat-nsri tool for assessing risk of bias in non-randomised
intervention studies. i am not completely clear from the manuscript how they have undertaken
this process or that the results of it have been appropriately presented.
1. page 6 – they do not describe whether the acrobat-nsri assessment was undertaken by a
single observer, checked by a second or done independently in duplicate.
2. page 6 -it also state here that sensitivity analysis was undertaken for each of the seven
quality domains in the acrobat-nsri tool, but no results of these are mentioned in the text or
presented in any table.
3. page 9 – a key aspect of the acrobat-nsri tool is documenting which confounders are
balanced/matched/adjusted for in each study. there is no list of the confounders reported – the
best description is given in the middle of page 9 as “socio-demographic variables, clinical
factors (family history of diabetes or prevalent diseases) and lifestyle factors including a diet”.
however, the adjustments used in table 2 are noted in the footer as being only for
“demographic and lifestyle covariates” which isn’t the same. the legend for figure 1 doesn’t

mention adjustment for these factors at all, which i presume is an oversight. i would have
expected, particularly given the extension supplementary material provided, to have a
tabulation of the actual adjustments made study-by-study. table s4 gives the results of
unadjusted and adjusted analyses and does not fully state what was adjusted for.
4. it is also not clear what criteria were used to rate the risk of confounding. in table s2 it is
noted that only one study was rated as being at high risk of bias due to confounding. table s4
lists four studies of omitting adjustment for “diet and clinical factors” so it is not clear why
these are also not flagged as being at risk of bias from confounding. other studies may omit
other key variables, but given that no list of variables is presented we cannot tell.
5. there is no mention whether the analyses of the drink types are mutually adjusted for each
other (for example, is the ssb analysis adjusted for asb and fruit juice?) it is hard to think that
consumption of each drink is independent.
6. table s2 and supplementary material on page 17. overall quality assessment has to make a
leap from the ratings of the individual domains to obtaining an overall assessment of likelihood
of bias. it is not clear what rule the authors used to achieve this. the text on page 17 does not
describe a consistent system for doing this. for example, studies 25 and 48 are stated as being
at high risk of bias because their classification of diet was wrong, but the other seven studies
marked as having high risk of bias on the dietary measures domain are not classified as being
at high risk of bias overall. the same problem appears across multiple domains in the tool.
7. page 13 – the authors indicate that publication bias created a false positive effect for asb.
however, the degree of publication bias seems rather small (not really visible at all in the
funnel plot) and adjustment for it did not substantially change the magnitude of the effect.
8. page 11 - the authors make grade assessment and place two outcomes (asb and fruit
juice) as being of low quality and one (ssb) as being of moderate quality. there is no strong
argument why ssb is argued to be of moderate quality. it is hard to see why one outcome
would differ from the others given that they are all reported in the same studies which were
done using the same methods and adjusted for the same confounders. given that the estimates
for both ssb and asb shift considerably between the analyses adjusting for measurement
error, confounders and publication bias, it is hard to attribute moderate or high credibility to
any of them. the estimate for fruit juice seems to be close to a null effect in all analyses – the
authors seem distracted by it moving either side of the null effect value, but it seems
consistently close to it in all analyses.
9. the population attributable fraction computations are based on assumptions of causality, and
on reducing consumption of the three types of drink to zero. given that the estimates of effect
vary considerably between the sensitivity analyses, they perhaps should investigate how much
the estimates varies. the authors do state the assumptions behind this, and indicate that
causality is a concern, but are keen to promote intense public health interventions based on
this evidence. would not trials of ssb reduction be justified now rather than public health
interventions? also i wonder whether the illustration would be more helpful if it were based on
the sort of magnitude of reduction in ssb that was achievable by a public health intervention
and not an unachievable reduction to zero.

<|EndOfText|>

bmj.2014.023279.r1
birthweight and later life adherence to healthy lifestyles in predicting type 2 diabetes: a prospective study
the authors have responded to many of the points made by the peer reviewers and editors.
i have several comments concerning the manuscript.
the headlines from the manuscript are based on the calculation of the population attributable risk, which they
state to be 91%. this is quite sensational, and i have concerns about it from several directions.
1) first, is that it is based on the concept that it would be possible for everybody to achieve the baseline lifestyle
and birthweight categorisation. in the cohorts studied, only 1.91% of participants actually were in this category. i
imagine it must be the least likely category to be in. thus it is rather naïve to consider that this is possible –
particularly to adjust birthweights and to reduce your bmi. it would be much more appropriate for the manuscript
to consider the magnitude of reductions which could be achieved by interventions rather than consider a rather
fanciful idea that all risk factors could be removed.
2) second, despite the many comments from the reviewers, the authors do not seriously discuss the possibility
that the relationships observed could in anyway be causal. they are clear that they are making an assumption of
causality, but do not venture into discussion as to how likely it is that this could be the case.
3) third, the analysis of the event rate in the baseline category is based on little data with few events – there are
confidence intervals included, but it is wise to note that it is based on only 19 events across all the cohorts.
4) finally the authors present data (table 4) which make it clear that bmi is the dominant factor which is driving
the lifestyle relationships – adding bmi as a requirement for a healthy lifestyle increases the percentage
attributable risk from 57.2 to 91.2 – thus it represents nearly 40% of the observed attributable risk. this certainly
needs profiling and discussion – currently there is no mention of it in the text.
5) i would also point to the strange use of “confident intervals”


<|EndOfText|>

statistical review
bmj.2014.023058.r1
arthroscopic surgery for the degenerative knee: a systematic review and meta-analysis of
benefits and harms
the authors have submitted a strong response to the comments made with an appropriately
revised manuscript. they have updated the analysis as i suggested, and their key findings
remain strong (if not stronger) than in the original manuscript.
i have one comment that i would like them to address:
1) the conversion of the effect size to the vas scale difference is not fully described. it must be
made based upon some presumed value of the standard deviation of the vas scale. as an es of
0.14 corresponds to a vas difference of 2.4mm, so i presume that the sd is about 17mm). it
would be appropriate to fully explain this in the paper and explain where the value of 17mm
has arisen from


<|EndOfText|>

statistical review bmj-2019-050974
the manuscript reports a pooled analysis of data from 3 cohort studies reporting on the
association between egg consumption and cardiovascular disease, and also contains a
meta-analysis of cohort studies updated with the new data. the statistical methods and
reporting in the manuscript are generally strong. the authors have access to three
particularly good data sets, with large sample sizes, standardised repeated assessments of
dietary intake, good covariate data allowing adjustment for major predictors of cvd events,
and long follow-up with high numbers of events to allow precise estimates of risk. however,
there are two main issues with the prospective studies and several issues with the additional
meta-analysis which the authors need to pay attention to.
1) the report includes a ‘replacement’ analysis, that hypothesises as to how switching egg
consumption to other food types would affect cvd. this is a hypothetical modelling
exercise, contrasting coefficients for egg consumption with each other food group in turn.
the data set does not contain any empirical data that looks at individuals who have switched
consumption between each of the two food types – this is simply a game of contrasting

model coefficients and forecasting what the switch would create. it is based on an unstated
set of assumptions concerning the independence of the different foods. whilst i appreciate
that such analyses are in vogue in nutritional research, the strength of evidence which can
be attributed to these results is exceptionally poor, and their inclusion is to the detriment of
the excellent epidemiology in the rest of the manuscript. in particular including these
estimates in the abstract and in the first paragraph of the discussion is poor scientific
reporting as it is likely to mislead readers as to the credibility of these findings. the
manuscript would be greatly strengthened by total removal of the pretence of evidence that
this ‘replacement’ analysis depicts. particularly when you notice that those who consume
eggs are the same as those who consume more red meat so the idea of people ‘switching’ is
not evidence based, and unlikely to be true. the rest of the manuscript is really strong, this
part is at high risk of being misleading and false.
2) a strength of the datasets which are analysed is that they contain repeated dietary
assessments. the authors discuss including ‘cumulative exposure up until each follow-up
period’ but it is not really clear to me what this means. what is a follow-up period? there
is no explanation whether the covariate values are changing over time, and if so how they
are being incorporated into the regression models. are time-varying models being used?
that would seem appropriate. it would also seem appropriate to include updated covariates
for the other predictors of risk at the same time. can the authors please improve their
explanation of the model, and if time varying covariate models are not being used, please
can they investigate their usage.
3) as there are three data sets in the analysis, i would expect all analyses to be stratified by
study, and i think that the authors have done this. however, the text indicates that they are
stratified by study(sex) – please can you be precise what has been done here (i suspect that
the authors are using short hand to indicate that stratifying by study also stratifies by sex).
4) the results appear to show overall that those with high egg consumption are more likely
to have cvd events but that after adjustment for other differences between the egg
consumption groups, the direction of the association is reversed (note the manuscript states
‘attenuated’ – to me this indicates reduction of magnitude, not reversal of direction – the
authors may want to check their wording). in all analyses, the confidence that the increase
(or decrease) in effect exists is not high, but there is reasonable confidence that an
important increase in risk is very unlikely. the authors could more clearly emphasis this
difference between unadjusted and adjusted findings, and discuss the increases and
decreases in risk which are compatible with the findings.
5) please note that prisma is not a method, but a reporting guideline. it states the details
of what needs to be included in a systematic review report, not how to do the systematic
review.
6) the search strategy and inclusion criteria for the systematic review are rather weak.
inclusion of studies ad hoc is explicitly non-systematic – if there are important studies that
the search strategy missed, it needs to be improved, rerun and new assessments made. if
there are new studies then the strategy needs to be rerun. exclusion of non-english
language studies (google translate greatly facilitates their assessment and inclusion) is an
unnecessary restriction. the database selection is limited – why has embase not been
searched? also, was a professional search specialist used to create the search? it seems a
very brief strategy, and input from a professional may have helped ensure that an
appropriately sensitive strategy is used.
7) it is good to see the assessment of the quality of the non-randomised studies being
undertaken rigorously including detailed assessment of the adjustments made in each
analysis. could more be reported on these issues in the manuscript? currently there is no
mention of the findings of these assessments in the results section of the manuscript – it is
important to inform the reader of the certainty which can be attributed to the conclusions of

these studies, and any limitations which were found which need to be considered. the data
for this are all reported in the supplementary materials, but no summary is reported.
8) there are a number of instances where the wording or presentation can be improved:
a. results, page 14 paragraph 2. the link between the covariates and the results in table 1
are not as clear as reported in the text. table 1 does not contain data for all participants in
the study – please can the missing columns be inserted? they are important to be able to
make sense of the numbers in the study.
b. results, page 14 paragraph 3 – this is where the word ‘attenuated’ is used, which may be
replaced with ‘reversed’. it is not always clear in this paragraph whether the quoted risks
are unadjusted or adjusted.
c. results, page 16 paragraph 4 – this is where i would expect to read some summary of the
risk of bias in the included studies.
d. results, page 17 paragraph 1 – ‘heterogeneity was <40%’ is an incomplete statement. i
suspect you mean that the i^2 value was <40%
e. table 1 – please include the missing columns.
f. figure 1 – please drop this figure and reporting of these results
g. figure 2 – please label the scale as hr or rr and not es. please choose appropriate
points to mark on the x-axis and consider rescaling as there is so much white space to the
left of the es=1 line.
h. supplementary figure 4. labelling of the axes, and choice of data points to report again
could be greatly improved.


<|EndOfText|>

whilst the authors agreed that my comments were insightful and appropriate,
they have elected only to make made some very small additions following my
previous comments, and to continue with reporting the “replacement food
analysis” against my recommendations. in my opinion, including this analysis as
currently reported makes the paper misleading and not acceptable for publication
as it continues to imply that the authors can make stronger claims about the
value of food replacement than are warranted. it is an overinterpretation of the
data. it does not appropriately acknowledge that all the replacement analysis is
a statistical modelling exercise. adding two sentences to the end of the
discussion about this is inadequate.
i have taken the opportunity to “test” the understanding of this analysis with
some experienced colleagues here, all of whom have been misled by the claims
which the authors are making. for example, the claims in the abstract that: “a
reduction in one serving/day of red meat along with an increase in an alternative
food choice was associated with a lower risk of death, and the largest benefits
were seen for replacement by nuts”; “decreasing red meat and simultaneously
increasing other healthier animal or plant foods over years was associated with
lower mortality” are written implying that every person who i have shown this
too has thought that you must be studying people who have made this change,
rather than it being predicted from a statistical modelling exercise.
as i indicated previously, the change data on red meat and other food product
consumption that the authors have in this study is of value and importance. the
replacement data is a hypothetical modelling exercise, is at best speculative, and
should not be reported alongside the real cohort data.

additional questions:
please enter your name: jon deeks
job title: professor of biostatistics
institution: university of birmingham
reimbursement for attending a symposium?: no
a fee for speaking?: no
a fee for organising education?: no
funds for research?: no
funds for a member of staff?: no
fees for consulting?: no
have you in the past five years been employed by an organisation that may
in any way gain or lose financially from the publication of this paper?: no
do you hold any stocks or shares in an organisation that may in any way
gain or lose financially from the publication of this paper?: no
if you have any competing interests <a
href='http://www.bmj.com/about-bmj/resources-authors/forms-policies-and-ch
ecklists/declaration-competing-interests'target='_new'> (please see bmj policy)
</a>please declare them here:



<|EndOfText|>

statistical report
the authors now more clearly report the methods which they have followed in producing
this report. it clearly has been a substantial project and the authors should be
congratulated on their work.
however, it is now clear that the reported findings largely depend on the model which has
been fitted to the data, particularly for the countries and regions where data are sparse or

absent. the structure of the model (in terms of the grouping of countries into regions and
regions in super regions) will have had a strong influence on the reported results which
needs consideration and discussion. it is also important to be clear as to what results are
supported by observed data, and which are extrapolations – currently all results are
presented as being equally valid, which is not the case.
1. whilst the use of the hierarchical model is appropriate, the interpretation of results
needs to be made with care. as was raised in the previous comments, there are concerns
that the level of extrapolation that is being used by the model where data are missing for
particular countries, regions or super-regions is inadequately acknowledged by the authors,
and is not suitably flagged to a reader. i would expect to read more about the impact of
the degree of extrapolation in the limitations section of the discussion.
2. the pattern of missing data is very uneven, with some regions and super regions having
far fewer (if any) studies contributing to estimates than others. where no data are
available, my understanding is that the model estimates will entirely be based on
“borrowed evidence” from higher levels in the model, such that the average region value is
used for the country estimate when there is no country specific data, that the average
super region value is used for countries when there are no data within a region, and that
the global average is used when there are no data from within a super region. looking at
the results, particularly in the figures, the data for the regions is presented is the same
way regardless of whether it is based largely on data observed in the countries, or by
“borrowing” from other regions. i believe that it is very important for readers to be able to
distinguish observed results from extrapolated results. could the authors look to augment
the evidence presented in the figures with a summary of the amount of the evidence is
based on observed studies and how much is from borrowing strength? i do not know what
graphical device or statistic could be used, but it is really important to indicate the real
data from the extrapolated data, and the level at which the extrapolation is made.
the authors also need to be clear that the region and super region estimates where data
are sparse are limited in that they are the values based on the small number of studies of
studies in the same grouping. it is important that the reader is not mislead into thinking
that they are based on regional or super regional level studies.
3. i cannot get all the figures in the text to match with those in the tables. for example
page 10 includes the statement:
“psoriasis occurred more frequently in adults than in children. in children, the prevalence
of psoriasis varied between 0.02% (0.01% to 0.04%) in east asia table states to 0.22%
(0.06% to 0.81%) in australasia and 0.21% (0.11% to 0.41%) in western europe (figure
1)”
several of the figures here do not agree with those in etable 7. for example, the estimate
of east asia is 0.03 (0.01 to 0.09). is there an explanation or are these errors? similarly
i cannot locate all the figures in the next statement:
“in adults, the disease varied between 0.14% (0.05% to 0.40%) in east asia to 1.99%
(0.64% to 6.60%) in australasia. other regions with an occurrence of the diseases above
1% were western europe 1.92% (1.07% to 3.46%); central europe 1.83% (0.62% to
5.32%); high-income north america 1.50% (0.63% to 3.60%); high-income
southern-latin america 1.10% (0.36% to 2.96%); figure 2.”
4. there are also issues in the text concerning being clear where the reported values are
from observed data and where it is based on extrapolation from the model. for example,
in the statement immediately above, i do not believe that there were any studies in
southern-latin america which contributed data, so this is an extrapolated value, whereas

other examples are generated from the data. it would be helpful to have some way of
separating out the observed data results from those which are based upon the model.
5. the regions and super regions are not described in the main paper at the moment.
when i found them in the additional document i was rather surprised by their structure, as
they are largely based around income brackets and appear to vary between the different
population groups and do not fit with geography as i recalled it (e.g. argentina being
classified as a north american country in etable 8). it is very important for this structure
to be described as it determines the way in which estimates for missing data are made and
the rationale for this grouping to be explained and justfied. it will have by itself created
the income related pattern that has been commented on by others. if a different structure
were used, estimates for countries with no data will change according to the observations
of other countries within the super region and region. the dependence of the findings
upon both the categorisation of countries into regions and super regions definitely requires
greater discussion and acknowledgement as a limitation in the discussion.
6. i have also observed some discrepancies between the tables in the appendix. for
example, etable 3 lists the countries which provide data on prevalence in children. there
are no datasets listed here from sub-saharan african countries. however, in etable 7
there is a report that data are available for tanzania which contradicts this etable 3.
