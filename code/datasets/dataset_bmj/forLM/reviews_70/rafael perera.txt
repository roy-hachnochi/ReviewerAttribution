in this version of the manuscript, further adjustments for relevant conditions occurring
within the exposure timeframe were carried out. the findings have remained robust to these
adjustments and therefore the potential for reverse causality has been minimised.
i think this current version is suitable for publication. i have one very minor point in the results section when describing the strength in association between paee and
deltapaee with the different outcomes, the point estimates for all analyses are consistent
but as the models adjust for more covariates and the number of participants/events
decrease, the confidence intervals for the effect of pa on 'cancer mortality' includes 'no
effect'. this is correctly reported for the sensitivity analyses but is not included in the
reporting of the primary analysis. please correct for consistency.

additional questions:
please enter your name: rafael perera
job title: professor of medical statistics
institution: university of oxford
reimbursement for attending a symposium?: no
a fee for speaking?: no
a fee for organising education?: no
funds for research?: no
funds for a member of staff?: no
fees for consulting?: no
have you in the past five years been employed by an organisation that may
in any way gain or lose financially from the publication of this paper?: no
do you hold any stocks or shares in an organisation that may in any way
gain or lose financially from the publication of this paper?: no
if you have any competing interests <a
href='http://www.bmj.com/about-bmj/resources-authors/forms-policies-and-checklists/dec
laration-competing-interests'target='_new'> (please see bmj policy) </a>please declare
them here: none



<|EndOfText|>

stats report for bmj – efficacy and safety of first-line treatments for advanced
egfr-mutated nsclc: a systematic review and network meta-analysis
the manuscript presents results from 19 trials evaluating several interventions used as
first-line treatment for advanced egfr-mutated nsclc relying on a network meta-analysis
to draw conclusions about comparable efficacy and safety across these interventions. the
findings are novel and potentially relevant but there are several issues that need addressing
to make sure that these are: a) accurate and b) placed in context given the sparsity of data
in this area.
• major issue is one of data sparseness. the number of comparisons made and estimates
obtained is way beyond the number of comparisons in the original studies. this has
implications regarding the reliance on prior distributions and assumptions of transitivity and
consistency of the network used to obtain these estimates. this needs to be highlighted in
the discussion section as a critical limitation.
• critical to know the aes for each of the drugs, this is part of the same aspect of the
evaluation. please provide in your manuscript a description of the ae typically observed and
particularly if these differ by type of intervention.
• with regards to the reporting of the model used, more clarity is required about the priors
used. it is unclear how given the low number of studies included, a non-informative prior will
allow the model to converge. if possible, sensitivity analyses using alternative priors would
allow evaluation of the robustness of your findings.
• related to the above, the reporting of the mcmc methods used is not adequate. in
particular: the differences between three chains, the burn-in, the number of iterations (after
burn in) and the way ‘convergence’ was assessed needs to be reported better and
separately.
• the statement that ‘transitivity has been ensured’ is not scientific. this is impossible to
ascertain. at best you can say that, ‘to minimise issues arising from potential lack of
transitivity, …’. as part of this, please carry out an evaluation of important study and patient
characteristics was done once data were collected to assess network transitivity and report
this as well (including which characteristics were evaluated).
• the assumption made for the flaura study, analysis of the erlotinib and gefitinib arm, is a
strong one which needs evaluating as part of a sensitivity analysis to check what effect this
has on the results. the simplest option would be to remove this trial in a sensitivity analysis
but alternatives could also be explored.
• for the pairwise meta-analysis, the approach of model selection based on heterogeneity
creates a biased estimate. this is definitely not recommended. please review this and
adjust appropriately. the model selection should be based on previous assumptions of
comparability/equivalence of interventions/outcomes and should be done before evaluation

of heterogeneity. sensitivity analyses based on alternative models could be an alternative
(and reported as supplementary material).
• related to the above, as you have used a fixed-effect approach for your bayesian nma
then i would suggest that a fe model for the pairwise comparisons would also be applicable.
if you decide to switch to a re for the pairwise comparisons, this would also impact on
potentially switching to a re for the bayesian nma model. regardless of your choice, this
will need to be justified in the manuscript and commented on in the discussion (limitations).
• although you have assessed local inconsistency (pairwise comparisons estimates vs
bayesian nma estimates) please also assess and report the global inconsistency of your
network. see: dias s, welton nj, sutton aj, et al. nice dsu technical support document 4:
inconsistency in networks of evidence based on randomised controlled trials. 2011; for
reference. regarding this, to deliver a proper comparison between nma and pairwise
comparisons, the same statistical approach (bayesian or frequentist) should be applied.
credible intervals are not directly comparable with confidence intervals. this should at least
need to be included in the discussion section.
• the funnel plots provided are of no use given the number of trials included in each
comparison, please delete them and explain why these were not used in your limitation
section.


<|EndOfText|>

stats review:
critical (in abstract and main body of manuscript) - whenever reporting means (results), please also provide sds
in abstract - please specify that these are number of coffees/person x years. there is some confusion here as in the
‘outcome measures’ it says ‘total coffee purchased over a calendar year …’ but then in the results these are ported as
per individuals ‘male doctors bought…’

in ‘what this study adds’ depending on editors, this could read ‘purchasing habits’ instead of ‘drinking habits’. similarly
‘surgeons purchase most coffee’. nevertheless purchasing can be regarded as a very good proxy for drinking (this might
be included as a limitation or potentially in the background).
statistical methods:
if they are interested in pairwise comparisons, as they have several groups that can be compared they are likely to need
some kind of adjustment for multiple comparisons (if they want to do formal hypothesis testing). the option of just
presenting 95%ci does not deal with this multiple comparisons. having said that, if their intention is just to rank the
specialties by coffee consumption then this should be ok and just use anova to say that there were differences.
it depends on what they are interested in doing, formally test for differences or just present descriptive statistics of
coffee consumption.
they need to specify more clearly in the methods their unit of analysis. for their primary analysis it seems it is just total
number of coffees consumed. however, for the specialty analysis (as well as gender) it appears to be coffees x person x
year (and not coffees x year) by specialty. this is mention in the results but please clarify in the methods.
same as above for the outcome of “rounds”

<|EndOfText|>

the authors have replied to all reviewers' comments. they have done an excellent job and the
manuscript is clear and accurate. there are two very minor points that can be addressed as part of the
final editorial process but have no impact on the adequacy of the science or the reporting. these are:
a) for tables s3, s4, & s5 - please change label to read:
'data are mean (standard deviation) or percentages.'
and
b) figures s5 to s8 - please provide grids to enhance comparability. similar to the ones given in figure
2.
i am happy to support publication of the current version of this manuscript in the bmj.

<|EndOfText|>

bmj 51219.r1
association between prescription opioid cessation, duration on opioids, and overdose or
suicide mortality among us veterans: an observational evaluation
stats report:
the authors have adjusted their manuscript accordingly and most of the comments made by
the reviewers have been answered adequately. there are a few of minor points that are
nevertheless important in relation to the correct reporting of this research.

the first one is about the models used in their analysis. the authors mention the use of
survival models but do not clarify what these are based on. most likely, given the reported
use of sas phreg, is that these are cox proportional hazard models with time varying
covariates to take into account the interaction observed between duration of opioid
treatment and cessation with the outcome (overdose/suicide). in any case, the authors do
need to be more explicit about the models used and, as requested initially, how they dealt
with checking for the assumptions their model uses (like any model). these will only require
a couple of sentences in the methods and if necessary adding some supplementary material
as appendix.
the second point is regarding their life table graphs. given the way the data are collected, it
is not surprising that the majority of the events used in these estimates are concentrated in
the first year. the impact of this is that the estimates towards the end of the second year
are highly volatile, particularly for figure 1.b. i would suggest that to prevent people from
focusing on these volatile estimates, the authors should present the data only for the first
year of follow-up (or first 18 months) in the main manuscript. the current figures could be
presented as supplementary material instead. providing a table with the absolute numbers,
actual estimates, and the precision around these estimates would also be particularly useful
(supplement).
regarding this last point, the values reported for the models (e.g. table 2) with the hr and
95%ci provide a good measure of the precision around these estimates. unfortunately as
there are no hr reported for the interactions (correctly, to minimise confusion), there is not
information regarding the precision around these estimates for the interaction. please
provide a similar table as supplementary material with the parameter estimates and the
standard errors for these estimates for the models reported in table 2 and appendix 3.
finally, after reading the manuscript i could not find what they have used as index date for
their survival analyses. i assume it was 1 october, 2012 as that was the start date for the
cohort. in any case, please make it explicit somewhere.


<|EndOfText|>

statistical review:
in my view the new version of this manuscript adequately addresses all the questions asked by the
reviewers. there are three very minor points that need checking:
1) in their letter of response to reviewers (page 2) the authors write that as part of their sensitivity
analysis –“however, it found that for each 1 day increase in length of stay for these patients, there would
have been an associated 6% increase in their offs of death during 11-30 day time period after hospital
admission over the study period (95% confidence interval 1.05 – 1.08; p<0.001).” in the next page (page
3 of the reply) they state that in the results this increase was of 7% with an associated 95%ci of 1.07 –
1.10. this is consistent with what is presented in the manuscript but not with the paragraph above. please
check.
2) looking at figure 2, the result for 2009 appears to be an outlier. if possible please can they check the
influence of this extreme year on their results? it could just be reported as a single sentence in either the
same figure or in the discussion.
3) in their response to reviewers letter, the authors comment that they had originally planned to use cox
models but that the assumption of proportional hazards was not met. please can this also be reported in
the limitations/conclusions as it is a change from the original approach that could be useful for readers.
this also explains why they use kaplan-meier estimates but do not report hazard ratios.
these are all very minor points that have minor impact on the current manuscript.

<|EndOfText|>

bmj 049015-r1: development and reliability of an instrument to evaluate the credibility of
anchor-based minimally important difference estimates for patient reported outcomes
the present manuscript provides a useful tool for the evaluation of studies identifying mids
for proms. there are some issues that would be useful to discuss or clarify before
publication could be recommended.
points:

• kappa calculations – the use of quadratic weights for the kappa calculation implies that
the categories are ordinal and equidistant. this does not make sense given the categories
used in the items. in particular 'impossible to tell' cannot be deemed to be closer to
‘definitely no’ than ‘definitely yes’. please correct if this is what was done or clarify in your
paper if this is just a reporting issue.
• table 1, the examples provided for the 5th criteria need expanding. currently these are
not informative enough.
• the term ‘transition rating’ is used continuously and is central in several parts of the
manuscript. this needs to be defined somewhere prominent in the manuscript as it is not
necessarily a term familiar to many readers. suggest this is included in a box somewhere
near the start of the manuscript.
• related to the above, the authors make a distinction between the five core credibility
criteria relevant for all prom-mids and the extension for the ‘transition rating anchors’.
nevertheless most (possibly all) of the examples given are for transition rating anchors.
please provide clearer examples of other forms of anchors in the main body of the
manuscript as well as in table 1 (see comment above).
• it is also unclear in the results why the reliability analysis was available for 135 of the
core credibility criteria and 137 of the first item in the extension. naively i assumed that
the extension would be applicable to a subset of the total number of studies with the core
being applicable to all. please clarify. please also comment on the limitations that this
framework has due to inadequate reporting of the correlation to answer extension
questions 2 to 4
• regarding the time thresholds given, i think there needs to be a caveat regarding the
actual prom link to the condition. if it is a chronic condition not likely to change much,
these times might not be adequate. similarly, for those conditions for which change might
be counted in minutes or less. please consider at least mentioning this in the discussion.
• there needs to be a justification or a reference for the thresholds given for the
correlations in the extension questions.
• ‘overall judgement of credibility’ – based on the current framework, it appears to me that
there are particular items for which the assessment of the mid might prove more/less
robust to. for example, regardless of the other criteria, if item 5 is not met, could you still
call this an mid?


<|EndOfText|>

stats report:
this manuscript uses medical and pharmacy administrative claims from a large
database to evaluate the risk of gastrointestinal bleeding found in new cases of
individuals taking dabigatran and rivaroxaban comparing against those found in new
cases of people taking warfarin. as there are important differences in the
characteristics of the individuals in each of these groups, the authors use propensity
scores to obtain matched (1:1) samples between intervention and control. the
authors present results separately for the group with and without atrial fibrillation
and find little difference overall but significant interactions with age suggest that
recommendations for treatment need to take age into consideration.
after reviewing the authors’ replies to the reviewers of the original manuscript, i
believe many of the queries have been solved but unfortunately not all. these are
summarized below:
main points:
information in the abstract – the data source quoted here, although not incorrect, is
misleading. the total population on which this analysis was based on is less than 20k
individuals for each comparison. please correct/clarify. the “main outcomes” talk
about incidence rates and cox proportional hazard ratios. however, the “results” only
provide crude incidence rates of two of the groups (not for warfarin) and no hrs.
please give incidence rates for all groups with confidence intervals (not currently
provided) as well as the hrs (with cis) for the main comparisons – total bleeding by
noac by af/non_af. i assume that the age interaction was part of the primary
objective and hence at least the most relevant hrs (e.g. for age 75+) should also
appear in the results so that the current “conclusion” is adequately supported.
no inclusion of mortality/effectiveness data: - a major issue arising from the
introduction is that, within rcts, evidence of equivalence in efficacy with extra rates
of adverse events has been identified. the manuscript presents evidence that in “real
life” there is no evidence of extra adverse events. however, the same analysis could
(should?) be done to determine if in “real life” equivalence of effect (in stroke and
systolic embolism) is found. from the data reported, although the authors do not
have access to mortality data, they appear to have access to stroke (as an event).
presenting if the finding of equivalence in effect on stroke prevention in the present
data is maintained would therefore help to interpret the findings in light of the
evidence obtained from rcts.
one-to-one matching:- related to the issue of total sample size, the 1:1 matching
seems excessive as many of the warfarin cases are not used (more than 50% lost).
given that in some of these comparisons there are borderline statistically significant
findings (“less gib found in the dabigatran group”) it would have made sense have
tried for as many matches as possible. this needs at least to be mentioned in the
discussion (excluded more than half of the information in the warfarin group). this
has potential issues about generalizability of the findings to the overall population
somewhat mentioned in the discussion when talking about o-t-c aspiring use.

use of language about statistical significance:- in terms of reporting, the phrase
“dabigatran had a slightly lower risk of gib” (page 10, line 5) needs changing. based
on the 95%ci there is no evidence of difference between the risks in the two groups.
figures 2 and 3:- please delete the multiple comparisons with the p-values associated
(presented as text in the graphs). these would need to be adjusted (bonferroni?) to
deal with multiple comparisons and in any case all the information is provided by the
graph with the point estimate and confidence intervals. it would be more useful to
instead provide the total sample for each of the age groups by intervention.
new data:- the data for figures a7 to a10 in the appendix are not used/discussed in
the manuscript. there seems to be a considerable difference between these graphs
(a7 to a10) and what appears in table 3 and figures 1 and 2. going through the
“response to reviewers” it is apparent that these are the crude event rates by age
group used to create figures 2 and 3. please add explanation to these in the
appendix.


<|EndOfText|>

bmj.053803
association between newly-diagnosed atrial fibrillation and the excess risk of death: temporal trends
over 40 years in the framingham heart study
statistical review:
in this article, the authors have unique data collected as part of the framingham heart study to analyse
changes in the prognosis of af, specifically excess risk of death, over time. the results suggest that
although there have been improvements in both early identification and treatment of this patient group,
af is still strongly associated with an increased risk, impacting on a reduction in life expectancy of
around 2years (compared to non-af).
given the nature of the data, this study should be able not only to provide an adequate description of
the continuing increased risk but also explore some of the potential issues regarding changes over time.
specifically (as mentioned in the discussion) if there has been a change in the population identified as
having af and/or in their treatment.
in short, the main questions that they should be able to address (besides a pure description of a
continuous elevated risk) are:

a) what are the similarities/differences of these different ‘epochs’ overall (e.g. baseline characteristics
like sbp, treatments, etc). are these pointing towards a ‘healthier’ cohort or a more multimorbid cohort
in each ‘epoch’?
b) what are the similarities/differences of these cohorts at time of diagnosis? specifically, for the af
group, is the assumption of early identification of low-risk individuals (as mentioned in the discussion)
valid?
c) is the treatment provided to the af group changing (improving) over time? this is also touched on in
the discussion and is mentioned as part of the limitation. given their timeline it would not be unlikely
that the improvements suggested have reached a plateau and hence there is no evidence of a trend.
this might be the case that any information (even if incomplete would be better than no information.
it might be that no further information is available, in which case, a more extended limitation section in
the discussion would be relevant to address these points.
besides this, there are several issues (listed below) which would help clarify and expand on some of the
findings presented.
issues to clarify:
choice of epochs
-please provide an explanation for the decision to group the data into three epochs. currently, the
manuscript does not specifically explain the choice of a) number of epochs nor b) the reasons for
choosing those years as cut-offs.

participants
-please provide a figure with the timelines for the different cohorts/examinations/measures linking to the
identification of the epochs. if possible, also include in this figure (or an alternative one) information for
the identification of the data used in the ‘population analysis’ as well as for the ‘matched analysis’.
-the identification of af is based on the visits/examinations during any given epoch. please provide
information (possibly as a supplement) about the number of visits and who attended these visits. the
increased number of diagnoses (proportional) in epoch 2 might need explaining too.
-related, please comment if there is a bias created by controls providing information into several
epochs.
covariates included
-given that the significant improvement observed over time has been on cvd mortality, it would have
been particularly useful to have included lipid measures (at baseline) as a relevant covariate as well as
lipid treatment (e.g. statins) in a similar way as antihypertensives are reported. if not available, this
might need to be included as an important limitation.
statistical analyses
-the choice of different study designs (population based and matched cases-controls) is adequately
described, but please expand here as to which is used as primary analysis and why.

-i am unclear on the use of meta-regression to evaluate a time trend. is this based on 3 ‘datapoints’? if
so, a comment on the power of such approach would be useful. related, there are a number of
comparisons (for trend) presented in the paper, a mention in the limitation section of the potential for
spurious finding given this would be appropriate.
-critically, the analysis based on rmst reaches a different conclusion to that of the time-varying
covariates cox model. please discuss include (probably in the limitations) an explanation as to why
these differences occur. i imagine it is due to the way the time-varying covariates are incorporated to
the models, but this might require some clarification.
tables
-table 2 gives total number and events but for the whole population. please provide these also for the
af group for each of the epochs.
figures
- figure one will need some adjustments. current one has a problem with overlap of text confidence
intervals and graphical ones. suggest maybe separating using lines?
-figure 2. please provide light coloured grid to aid with comparisons across different epochs. (similar
issue for figures s2 and s3)
-figure s4 – substantial reduction in cumulative incidence of cardiovascular death. this would need
some discussion/interpretation. see point above about lipid levels and use of lipid lowering drugs.


<|EndOfText|>

bmj-2020-059724.r1- pharmacologic treatment for covid-19: living systematic review and network
meta-analysis

i believe that the authors have responded to all reviewers’ questions. i was particularly glad to see that
they have decided to include results only for those treatments where a minimum sample size (100
patients or 20 events) had been accrued. having said that, this is likely to have been a post-hoc
adjustment and requires a mention in the limitations section. related to this, given that the results are
only given for those interventions with 100+ patients or 20 events, a sensitivity analysis of the models
including only those interventions would be appropriate. consider running models to check that results
are robust to this.
major point for journal or for adjustment by authors:
many thanks for including the information regarding the extracted data for all studies. as the authors
comment, this information is easy to visualise and use as an excel spreadsheet but impossible to use as
a pdf. please can the journal (with the authors) make sure this information is available to readers. as a
related issue, the current pdf version of the manuscript has hundreds of pages that are impossible to
read/use.
critical issue:
recommendations and conclusions (including abstract) for dexamethasone are based on the direct
evidence estimate. given that you advocate for a nma as the main way of answering the question, there
is a need for some nuance regarding this. i am a bit conflicted as i understand why you have done this
but scientifically, i would have expected a primary analysis/results based on a nma estimates with
discussion around why this might have not been robust. this is also important as the results are
expected to be updated once new data are available.
minor edits:
- runaway sentence from a previous version of the sr looking at prevention:
“outcomes of interest for prophylaxis of covid-19 include mortality, infection with covid-19,
hospitalization, adverse events leading to discontinuation, and time to symptom resolution or clinical
improvement.”
- sentence needs writing in the past tense:
“we will use a plausible prior for variance parameter, and uniform prior for the effect parameter
suggested by turner et al based on empiric data.”
- when explaining in the methods their use of absolute measures of risk:
“for all other outcomes, we used the mean or median from all studies in which participants received
standard of care for each outcome.”
please explain how you pooled the data for the means (simple addition?).


<|EndOfText|>

the authors have responded to reviewers comments adequately and i would be happy to
support publication of the manuscript. having said that, there are three minor points that
the authors might want to consider as i think will aid with some of the clarity in the
results.
1) figure(s) 2 - please provide within each subfigure a label to identify which exposure
marker is being used for the comparison. this is done in the figure legends but given the
number of subfigures, it would be much easier for a reader to keep track on each individual
plot.
2) figure(s) 3 - the points representing each one of the studies are misleading as, i
believe, these are not what are being used to generate the splines. in a simple view, there
is a perception that all dots are 'in the middle" suggesting generally that there is no
association. the issue with this is that these dots are averages and do not take into
consideration the differences within each study (which is the real strength in this paper).
please could you either delete these dots or think of alternative ways to represent this
information which would not confuse readers?
3) the use of the newcastle-ottawa scale might attract criticism as robins-i is now seen
as a better (certainly newer) option. please could you consider mentioning this in your
limitations section? the robins-i page in cochrane even suggests that the n-o score is
an alternative so this might be used as reference.


<|EndOfText|>

i believe the authors have done adequately replied to all the reviewers’ comments and that the manuscript is clear and
accurate.
i have two very minor points for clarification:
1) the sensitivity quoted is 92% which means that roughly 10% of cases could be missing. this would only be an
issue if there were differential identification (e.g. identification of vte case more likely if treated with testosterone).
this is unlikely to be the case but might be worth including in the discussion.
2) their definition of recent use, i believe it should be – “that ended at a point between 2 years before and 30 (or
31?) days before index date”.

<|EndOfText|>

review bmj 47845
effect of dual sodium-glucose cotransporter (sglt)-1/2 inhibitor sotagliflozin on glycemic
and nonglycemic outcomes and on hypoglycemia in type 1 diabetes. a meta-analysis of
randomized trials
this manuscript presents results from a systematic review that includes evidence from six
trials. there are a number of important methodological errors and some issues that might
require correction or clarification. i list these ones below.

•
please provide a more complete description of the inclusion/exclusion criteria for
study selection. in particular, describe acceptable controls in the rcts used. in the
results it says that all trials had as background treatment insulin. as this maintained in the
“control arm” where placebos used? further information required.
•
in the description of the outcomes, please include in the main body of the
manuscript only those for which results are presented. the complete set of outcomes can
then be reported as supplementary material. currently the presentation of all glycemic
efficacy outcomes with their description/definition makes reading the manuscript difficult.
•
please report the methods used for conversion from any measure of dispersion to
sd in a supplementary material. also provide in supplementary table 1 or similar table
the actual measures of dispersion extracted. similarly, please report which studies did not
report change and for which the final sds had to be imputed.
•
you report that all but one of the studies were funded and or sponsored by
pharmaceutical companies. there is good empirical evidence that this has an impact on the
the risk of bias for the study. this does not seem that have been captured in the current
rob evaluation presented nor in grade. please expand and clarify.
•
related to the above, the current reporting of grade as well as the appraisal of all
studies suggest a very high level of evidence consistent with having a very clear complete
answer for all questions and all outcomes. in reality for adverse events it is still unclear
and there are a handful of studies, with just a few thousand individuals included and very
short follow up. this needs to be reflected as part of your assessment, not only in the
conclusions. also, the lack of long-term outcomes should be captured here.
•
“treatments were evaluated on an intention-to-treat principle” this means that a)
no attrition was observed and all randomised individuals were analysed and reported in
each study based on their allocated treatment or b) for those for which no outcome was
reported, you carried out imputation to be able to include their expected impact on the
outcome. either of these approaches need to be described in more detail. it is possible that
there is a combination of both with some trials providing complete reporting and other
have not.
•
please consider if a dose effect for adverse reactions/effects could exist but the
effect is too small to detect with the given numbers. if so, please include in your
discussion.
•
removing one study at a time is not a particularly useful sensitivity analysis.
sensitivity analyses aim to evaluate the impact that decisions in the analysis methods
impact on the results. for example, the choice of random effects instead of fixed effect,
the inclusion of all studies regardless of quality, the use of imputed values based on other
assumptions (like different correlation levels). several of these are relevant to this
systematic review and i would suggest these are therefore revisited and carried out.
sensitivity analyses based on the rob items might focus only in including those studies at
low-risk of bias as opposed to all.
•
the list of sensitivity analyses proposed are more related to subgroup analyses
(instead) as these are more about differences in effect dependent on study/intervention
characteristics. please re-label them as such even if these were not possible to do.
•
when looking at dose-effect, within trial comparisons as well as between trial
comparisons are possible given the data available (please see: bmj 2017;356:j573).
please consider this option as an alternative analysis.
•
will be useful to have a good description of potential adverse events in the
background and the discussion.
•
critical: pairwise comparisons rely on estimating the effect based on
independent data. in this case, several of the comparisons are not independent as they
use the same placebo arm. this will need to be adjusted. there are several options to deal
with this, including separating the placebo arm or combining the interventions. please see
cochrane handbook for a description on how to do it. this will have an impact on your
findings as you have less information than what is currently presented.
•
looking at the impact of this on severe hypoglycaemia, i find that the final
comparison is no longer significant (once this adjustment is made). if you find the same,
please adjust this and the rest of your findings.

•
there is a need for a more complete table of study characteristics to be able to
assess the rob. please extend what is currently supplementary table 1.
•
when event rates are large enough the rr are preferable than or. if events are
rare, it would be best to use peto or as summary statistic. please consider this and decide
which one you will use and give a reason why in your discussion. sensitivity analyses using
the alternative option should be made to check for robustness of the results to your choice.
similar issue for your choice of random effects instead of fixed effect.
•
why have you not provided information for the 75mg if you are looking at dose
effect? this should be available for baker 2017 (supplementary table 1). if so, please
include.
•
the funnel plot for hba1c is not consistent with dose-effect association. please
comment.


<|EndOfText|>

stats report:
this manuscript uses medical and pharmacy administrative claims from a large
database to evaluate the risk of gastrointestinal bleeding found in new cases of
individuals taking dabigatran and rivaroxaban comparing against those found in new
cases of people taking warfarin. as there are important differences in the
characteristics of the individuals in each of these groups, the authors use propensity
scores to obtain matched (1:1) samples between intervention and control. the
authors present results separately for the group with and without atrial fibrillation
and find little difference overall but significant interactions with age suggest that
recommendations for treatment need to take age into consideration.
after reviewing the authors’ replies to the reviewers of the original manuscript, i
believe many of the queries have been solved but unfortunately not all. these are
summarized below:
main points:
information in the abstract – the data source quoted here, although not incorrect, is
misleading. the total population on which this analysis was based on is less than 20k
individuals for each comparison. please correct/clarify. the “main outcomes” talk

about incidence rates and cox proportional hazard ratios. however, the “results” only
provide crude incidence rates of two of the groups (not for warfarin) and no hrs.
please give incidence rates for all groups with confidence intervals (not currently
provided) as well as the hrs (with cis) for the main comparisons – total bleeding by
noac by af/non_af. i assume that the age interaction was part of the primary
objective and hence at least the most relevant hrs (e.g. for age 75+) should also
appear in the results so that the current “conclusion” is adequately supported.
no inclusion of mortality/effectiveness data: - a major issue arising from the
introduction is that, within rcts, evidence of equivalence in efficacy with extra rates
of adverse events has been identified. the manuscript presents evidence that in “real
life” there is no evidence of extra adverse events. however, the same analysis could
(should?) be done to determine if in “real life” equivalence of effect (in stroke and
systolic embolism) is found. from the data reported, although the authors do not
have access to mortality data, they appear to have access to stroke (as an event).
presenting if the finding of equivalence in effect on stroke prevention in the present
data is maintained would therefore help to interpret the findings in light of the
evidence obtained from rcts.
one-to-one matching:- related to the issue of total sample size, the 1:1 matching
seems excessive as many of the warfarin cases are not used (more than 50% lost).
given that in some of these comparisons there are borderline statistically significant
findings (“less gib found in the dabigatran group”) it would have made sense have
tried for as many matches as possible. this needs at least to be mentioned in the
discussion (excluded more than half of the information in the warfarin group). this
has potential issues about generalizability of the findings to the overall population
somewhat mentioned in the discussion when talking about o-t-c aspiring use.
use of language about statistical significance:- in terms of reporting, the phrase
“dabigatran had a slightly lower risk of gib” (page 10, line 5) needs changing. based
on the 95%ci there is no evidence of difference between the risks in the two groups.
figures 2 and 3:- please delete the multiple comparisons with the p-values associated
(presented as text in the graphs). these would need to be adjusted (bonferroni?) to
deal with multiple comparisons and in any case all the information is provided by the
graph with the point estimate and confidence intervals. it would be more useful to
instead provide the total sample for each of the age groups by intervention.
new data:- the data for figures a7 to a10 in the appendix are not used/discussed in
the manuscript. there seems to be a considerable difference between these graphs
(a7 to a10) and what appears in table 3 and figures 1 and 2. going through the
“response to reviewers” it is apparent that these are the crude event rates by age
group used to create figures 2 and 3. please add explanation to these in the
appendix.
