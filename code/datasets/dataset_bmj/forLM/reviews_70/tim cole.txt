the authors have responded fully and very positively to all the reviewer comments made. with
one exception they have addressed all my concerns.
1. i pointed out that the plethora of confidence intervals and percentages to two decimal places
made the results much less readable. in response the authors have removed some of the cis,
but the percentages all still have two decimal places. i have argued that generally speaking
percentages are best with no decimal places except when comparing very similar percentages
(see http://adc.bmj.com/cgi/content/full/archdischild-2014-307149). to justify two decimal
places the percentages would need to be equal to the first decimal place, which is never the
case. i encourage the authors to reduce the numbers of decimal places, either to 0 or 1
depending on the context.
incidentally, the statement that cis for aucs allow the models to be compared ignores the fact
that cis for the difference between aucs would be more appropriate. also, note that table 2
refers to auc 95% cis which are no longer there.
2. the authors have added in table 3 a net reclassification analysis. however i find both the
layout and the numbers in the table hard to follow. it refers to 10% high risk and low risk
groups, so the low risk group should be labelled as 90% of the total and the high risk group as
10%, with corresponding totals of 949333 and 105482. the denominator of 1054815 should
also appear in the title. having decoded these numbers i have failed to calculate the nris labelling the cells of the 2x2 table as a-b-c-d in the usual way, what is the formula for the nri?
the description refers to rates of events correctly and incorrectly reclassified, but does not
make clear which denominators apply. also the rows within the low risk and high risk categories
are reversed, presumably corresponding to non-events and events for low risk, but the reverse
for high risk. they need to be labelled, and consistently. the table layout would be improved
with the nri-ne row immediately below the low risk table.

<|EndOfText|>

the authors propose changes to the continuity of care monitoring system to improve rmncahn. i
have some comments mainly on the presentation.
1. the title could be improved. the paper addresses a rather different question - how to make better
progress.
2. the introduction first sentence is not referenced, but i assume it's [1] and also that it is the
"countdown to 2030" referred to both in the paper and the bmj's series title. it would be helpful to
flag it as such (as is done with gs). further down there's a reference to countdown's 2017 report, but
there is no citation for 2017.
3. the next paragraph refers to all 138 lmics plus panama, but i suggest the number of countries and
the detail about panama be postponed until the middle of page 3. incidentally the acronym lmic is
never defined.
4. key message 2 refers to schedulable interventions without explaining what this means. key
message 4 talks of the need to revise the coc chart, but later says it "will be defined through a broad
consultative process". should this be "should be" rather than "will be" - is it aspirational or more than
that? for the final key message, is the list of advisory groups useful?

5. the first paragraph on page 3 identifies three approaches to monitoring health interventions,
described in the following sections as steps 1, 2 and 3. but they could be signposted more clearly in
the opening paragraph. incidentally the words "fairing" and "hone" should be "faring" and "home".
6. step 1 relates to the continuum of care chart as seen in figure 1 and table 1. i suggest including
the phrase "continuum of care" in the figure title to make this clearer, and citing it earlier in the
paragraph. the number of countries (138) should appear here, and the detail about panama (if it's
needed, which i doubt). note that the dots mark the median not the average coverage for each
country (last line). the spelling for diarrhea / diarrhoea is inconsistent in the text and figures / tables.
7. step 2. i'd use the word 'interval' rather than 'bucket' in the first paragraph. table 2 and figure 2
need citing. measles vaccination is referred to, but it appears as mcv1 vaccination in the figures and
tables and msl on page 5. the text refers to "the flatlining in immunization coverage", yet rotavirus
immunization has almost the largest gap closure.
8. the footnote on page 4 explains the complicated choice of survey dates in the time intervals
2009-2013 and 2014-2018. in the first interval they are near the midpoint of 2011, while in the
second interval they are the most recent. why not use the earliest surveys in 2009-2013 for
symmetry? incidentally the complicated formula given there can be simplified to %cgc = 100 * (c2 c1) / (100 - c1) / n.
9. step 3 line 1. for me "percolate" involves falling not rising (wikipedia says it involves cycling nearly
boiling water through coffee grounds using gravity). perhaps "rise" or "bubble up" instead?
10. the last three components of the cci map are described as averages, but 'mean' or 'weighted
mean' would be simpler and clearer. incidentally where do the weights for the immunization
component come from? the four components in figure 3 need to have names that match the
component descriptions. figure 3 gives the top 5 (not 10) best and worst performers. the worst
performers are mainly from africa, but yemen is not.
11. the last paragraph on page 6 is arguably the key paragraph in the paper, pointing out that new
indicators are needed for children age 5-9 and adolescents age 10-19. but the last part of the
paragraph switches to the past tense in describing initiatives that have already happened, and i'm not
clear how it fits in.
12. on page 7 the monitor advisory group is later referred to as monitor.
13. page 8 introduces the acronym coc - i suggest expanding it to continuum of care, as it's the
dominant theme of the paper. the next sentence expands the acronym rmncahn as "rmncah and
nutrition" - why not use the acronym as is or else expand it in full?
14. the references need some attention. the un, who and world bank appear respectively as
assembly ung, organization wh and group twb.
15. some comments on the figures and tables. in figure 1 the colours in the vertical and horizontal
bars do not exactly match. why is 2014 in the title in red? i suggest including "continuum of care" in
the title.
16. in table 2 it would be useful to rank the rows based on the numbers in one of the columns,
depending on the message the authors want to put across. the units of percentages are not specified,
and i suggest replacing pp change with change (%) (pp is also undefined). the columns in figure 2
should be in the same order as in table 2. the legend in figure 2 can be simplified to 2009-2013 /
2014-2018.
17. it's not immediately obvious in figure 3 that the heat map consists of three separate sections:
interventions, components and cci. i suggest wider bars separating them.

18. figure 4 looks very good (though adolescent / adolescence needs to be consistent with figure 5).
slanting column titles would help the reader (particularly when reading on a tablet, where the figure
switches between landscape and portrait as you try to read them).
19. in table 1 i wondered if the country lists were useful, particularly those at the top.
tim cole

<|EndOfText|>

the systematic review shows clearly that current risk prediction models for hospital
readmission have a long way to go before they become practically useful. the quality and
quantity of relevant data are uneven, and the c-statistics currently achieved are mostly
below 0.8 and hence reflect poor performance.
1. i wonder if the authors might discuss the c-statistic, what it means in practice and how
large it would need to be before the models would be useful. i note they responded to
reviewers "we would hypothesize that the inclusion of these features in some of the

predictive models that we have identified in our systematic review could potentially raise the
c-statistic over the 0.8 threshold to be considered a strong predictive model." this implies
that they view a c-statistic of above 0.8 as useful, but is that really true? i acknowledge the
crude c-statistic classification that says >0.8 is a good model, but this may still reflect a
sensitivity or specificity that is too low to be clinically useful.
2. related to this, i am unclear how the outputs of these models are to be used. if a patient
is thought to be at high risk of readmission, what exactly is the hospital to do about it? this
also relates to the actionability of the models, i.e. whereabouts in the patient's hospital stay
the information becomes available. of course the authors may not have much to say about
this, but if they do it would be helpful to hear.
3. the acronym sdoh is introduced and used in the abstract and main text, but it is entirely
unmemorable and would be better avoided.
4. a tiny point - it should be cox regression not cox regression.
tim cole


<|EndOfText|>

the authors have addressed many of my points, but there remain some matters of concern.
1. table 1 summarises the cities in the analysis, giving mean daily pm10 and mortality. an important
but unaddressed question is to what extent the mean pm10 scores in the different cities explain
variation in mean mortality. i recognise that this is different from the main focus of the paper, the
association between short-term changes in pm10 and mortality, but it is nevertheless fundamental to
the research question - are mortality and pm10 linked?
the mean daily deaths by city in table 1 are unhelpful as they reflect population size more than
anything else. i would like to see a plot of age-sex-standardised mortality vs mean pm10 by city, i.e.
making use of the information in table sm2.
2. the fixed effects model (1) is described in great detail, whereas the random effects model (foot of
page 9) is poorly described. does it contain just the pm10 term in equation (1) omitting the other
terms, or are the other terms included but applied to all cities? this needs to be made clear. also it's
not clear whether the fixed or random effects coefficients are being used in later analyses.
3. there is no need to apply a chi-square test to figure 2, as the i2 value summarises heterogeneity.
also using p = 0 or p = 0.000 is wrong, it should be p < 0.001 - this applies throughout.
4. the discussion of the different lags in figures 2 and sm1 to sm6 does not state whether using lagged
pm10 in addition to concurrent pm10 added significantly. i'm not convinced that figures sm1 to sm7
add usefully to the paper, as they are hard to compare with each other. a table summarising the results
for each lag or combination of lags should be provided.
5. figures 3 and 4 rank the cities in the same order, but differently from figure 2. better to use the
figure 2 order for figures 3 and 4 as well. the i2 value for figure 3 is virtually the same as for figure 2
(59%), whereas that for figure 4 is appreciably smaller (38%). this is worth commenting on, as it
shows that the cities are more homogeneous for non-crd than for crd mortality.
6. putting the various summary regression coefficients on pages 7-9 into a table rather than the text
would make them easier to see and compare. the comparisons for sex and age group give the separate
coefficients with cis, but for comparison purposes the difference (i.e. the interaction with pm10) and its
ci should be provided - to say that the separate cis overlap is not sufficient. also, to say that the pm10
effect was (just) significant for those over 60 and not for those under 60 does not make the age groups
significantly different - again the interaction term should be fitted with its ci. (the authors' response
letter says that this age interaction is significant at p < 0.1, i.e. not significant).
7. using subgroups by sex and age group strikes me as both inefficient and potentially biased. if say the
sexes are analysed separately then all the coefficients in equation (1) will differ by sex, and those that
are correlated with pm10 (say weather conditions) will impact on the pm10 coefficient. far better to
include the sex and age terms in equation (1), which will also allow their interaction to be tested. this
relates to point 2 above.
8. the paper still focuses unnecessarily on statistical significance. on page 9 lines 48-50 the phrase "...
and statistically significant at the 5-percent level" is both redundant and wrong - it is considerably more
significant than that.
9. the notes with figures sm9 and sm10 refer to "total mortality for cardiorespiratory and noncardiorespiratory deaths separately" which look incorrect.
10. the comments above also apply to the city analyses for mean pm10, north vs south, gdp and %
construction workers. the results need to be to presented as coefficients with confidence intervals, and
when comparing groups (e.g. figure sm 12) the interactions with ci should also be given. several of the
figures demonstrate the existence of one or more high outliers, which will bias the regression
coefficient. urumqi in figure 1 is also a notable western outlier that needs to be acknowledged.
11. to say that air pollution effects were smaller in more polluted cities (figure sm11) is not correct the p value of 0.07 is not significant. it should be made clear here that the "air pollution effect" is the
city pm10 regression coefficient. again i don't know if this is the fixed or random city effect.
12. table 3 needs some attention. the constant terms are of no interest and should be omitted. why
are there only 18 cities for model 2 but 38 for all the others? confidence intervals should be given for

each coefficient, not p values. the numbers should be given to 2 or 3 significant digits, not 3 decimal
places. the north vs south analysis should be given as the main effect (say north) and the difference
between north and south. is there any reason why sex and age are not included in the table?
presenting the results of six distinct models is excessive - better to focus on model (6) including mean
pm10, north, south vs north, gdp, % construction, and perhaps sex and age group as well.
13. the discussion repeats several erroneous statements from the results. there is not a significant
age effect (at least it has not been shown), there is no sex effect (it is not significant), the air pollution
effects were not smaller in more polluted cities (p = 0.07), also they were not more homogenous in
northern cities than in southern cities (again the interaction is not shown to be significant), and the
association with gdp was far from significant. there are also statements about significance at the 5%
level that should be omitted. the only convincing association in table 3 is that for the percentage of
construction workers.

<|EndOfText|>

the authors have responded very positively to the reviewer comments, in particular
shifting the time of matching to the time of receiving fenofibrate, and restricting the ps
analysis to data at the same time. however there remain a few points that need
addressing.
1. it's useful to understand why the fenofibrate group mortality appeared to be zero in the
first three months. i'm not sure though that starting the mortality clock at 3 months, i.e.
moving the km curve back 3 months solves the problem. would it not be better to start the
fenofibrate clock when treatment started, and the benefit of fenofibrate would then
gradually appear during the 3 months? the statistical methods do not mention excluding
outcome events in the first 3 months.

2. the results show a significant effect of fenofibrate on the composite coronary events
outcome. in figure 3 this difference is tested in no fewer than 12 subgroup analyses, which
are not described in the statistical methods so it is unclear if the analyses were
prespecified. the conclusion is that high tg and/or low hdl-c patients particularly benefit
from fenofibrate. however figure 3 also includes p-values for interaction, and none of them
are significant, particularly for the constructed tg/hdl-c comparison where p = 0.2. so
there are no grounds for claiming that fenofibrate benefits one patient group over another
(the discussion acknowledges the non-significant interaction p-value). these claims in the
abstract and results cannot be justified and should be removed.
3. previously i said "the hr axis in figure 3 should be on a log scale, so that for example
0.5 and 2 are equally distant from 1." unfortunately the authors have taken this to mean
presenting the log hr, which few readers will understand. please give the hr in hr units
(not log), but use a log scale for the axis so that 0.5 and 2 are equally distant from 1.
4. some smaller points of presentation. the abstract states that patients were "matched
up to 1:5". this is unclear, and i suggest instead something like "patients on combined
therapy were matched with up to 5 patients on monotherapy".
5. it's not clear why the abstract quotes the non-significant hazard ratios for chd and is,
as they are not the primary outcome. and as already stated, the last sentence of the
abstract results should be omitted. the same applies to the second item under what this
study adds.
6. the results section of risk of major cardiovascular events could be rearranged to
advantage. the first paragraph could cite table 2 instead of repeating the relevant
numbers in the text, and then point out that none of the three components of the
composite score are significant. then the second paragraph can say the composite score is
significant, without needing to mention the separate components. line 9 on page 12 can
also be omitted, abut the insignificance and small numbers.
7. the last sentence of the results describes a slight but not significant difference in the
proportion of patients with high creatinine. if it's not significant i'm unclear why it is worth
highlighting.
8. the discussion first sentence suggests that the benefit of fenofibrate was achieved
mainly by preventing chd. this is true in the sense that the numbers of events in the two
groups were most different for chd. however the hr for chd was larger than for is or
mortality, so actually its impact was less. i suggest omitting that phrase.
9. the p-values would be better presented to one significant digit, see
https://adc.bmj.com/content/100/7/608. and the percentages in the tables would be
easier to read given in the format % (n) with the percentage as a whole number.

<|EndOfText|>

the authors have responded very positively to the reviewer comments. i have just two
minor points.
1. in response to a comment about the number of decimal places for the optimal
bandwidth, the authors say "we have now rounded all bp values in the paper to the first
integer, because it is indeed measured in whole mmhg." i'm not clear what is meant by
"the first integer", do they mean that bp is rounded to one decimal place?
2. in the discussion they speculate about factors that might explain the reduction in bp,
listing weight loss, smoking, alcohol and exercise as having large effects. in each case the
coefficient is far from one but the confidence interval brackets one, so i think they mean
the confidence interval includes values that indicate a large effect (either positive or
negative). this needs to be clearer.
tim cole

<|EndOfText|>

the authors discuss the equity of aid contributions, both in terms of who gives and who
receives them. i didn't see any particular statistical problems, but there is a more general
data issue in that there is a considerable amount of numeric information that readers will
struggle to assimilate.
1. figure 1 is a key example. it is a very beautiful but complex gapminder-ggplot-type
graph with nine distinct facets, each facet containing information for a large (though
unspecified) number of countries. the entire text describing the figure is:
"the distribution of the overall envelope of aid for rmnch became more vertically
equitable over time, in the sense that donors increasingly prioritized low-income countries
(whose share increased from 43% of aid for rmnch in 2010 to 51% in 2017) and to some
extent those with higher mortality levels (figure 1). however, countries of similar

mortality and income continued to receive very different levels of aid per person,
indicating a lack of horizontal equity (figure 1).
the separate components of aid for rmnch – aid for reproductive health, maternal and
newborn health, and child health – all increased substantially from 2010 to 2017 (figure
1). during this same period, maternal, newborn and child mortality levels fell. among
these three, progress in maternal and neonatal mortality lagged behind child mortality
(figure 1) and aid for maternal and newborn health did not increase as a share of aid for
rmnch."
if one is familiar with the field the layout of the figure and the associated statements may
be self-evident, but for the non-specialist they are absolutely not. the layout of the figure
needs to be explained first. in addition the final two points, that mortality fell over time
and and more so for child than maternal or neonatal mortality, are far from obvious. it
doesn't help that maternal mortality is measured as life expectancy, i.e. in the reverse
direction to child and neonatal mortality.
2. i'm not convinced that the extensive supplementary data add much to the story.
3. two very minor points. data are plural, so "data is" and "data suggests" would be
better as "data are" and "data suggest".
4. most percentages in the paper are usefully given as whole numbers (see my
recommendations on numerical presentation, https://adc.bmj.com/content/100/7/608).
but figure 4 gives percentages to one decimal place which i suggest would be better as
whole numbers.
tim cole

<|EndOfText|>

the authors have provided a comprehensive response to my observation that the time
interval between the two baseline tests could be informative. i am happy both with their
extra analyses, and with their argument that adjusting for it is not appropriate, as it relates
to the outcome measure of excessive testing.

<|EndOfText|>

the authors use two large cohorts to construct five shape trajectory groups from age 5 to 50, and then
compare mortality in the diffferent groups. i have some comments on the study design, analysis and
presentation.
1. the key exposure here is the recalled somatotype at ages 5, 10, 20, 30 and 40, and the corresponding
rating at age 50 is inferred from the age 40 rating. the way this is done strikes me as clunky, based on
just the previous rating and ignoring the earlier ones. it also requires the age 40 rating to be present to
estimate the age 50 rating. since the purpose is to represent shape over the life course it would surely be
better to use all the available shape ratings and bmi at 40 to impute the age 50 rating.
the description on page 39 implies, though does not state, that bmi was measured at ages 40 and 50:
“…we assessed the average bmi from age 47 to 53 as the bmi for age 50. we then divided bmi at these
two ages into 9 categories”. which two ages?
“the cutoff points for each category were calculated as the median bmi of this category at age 40 plus a
constant to account for weight gain from age 40 to 50”. but why use the median as the upper cut-off,
which will misclassify half those in the group? surely one needs cutoffs midway between the group
medians?
also, using a single value of 1.5 kg/m2 for 10-year bmi gain ignores the fact that bmi is increasing over
time in some groups but not in others. the calculation needs to take into account all the available
information on individual trajectories.
2. related to this, figure 1 shows that 28% of individuals were excluded as they had “missing somatotype
data for more than two different age points”, or put more simply, fewer than 4 somatotypes. this serious
data loss strikes me as unnecessary – figure 1 shows that the group trajectories are essentially linear
(despite the cubic fit), which means that anyone with 2 or more somatotypes could reasonably be
analysed. even requiring a minimum of 3 ought to reduce the dropout appreciably.
3. a second data exclusion is for bmi < 18.5 kg/m2. i can see that this is meant to reduce reverse
causation, but since the whole purpose is to model bmi, it seems illogical to omit individuals whose bmi is
arbitrarily low. in any case the numbers involved are tiny and will make no difference to the results.
4. related to point 6 above, the essential linearity of the group trajectories indicates that a simple randomslope-random-intercept model would lead to broadly the same conclusions, and the relative size of the
slope and intercept random effects in predicting mortality would quantify the importance of mean bmi
versus bmi gain.
5. is there a way to superimpose on the group trajectories of figure 1 the mean bmi values appearing in
table 1? it would provide some validation of the group allocation.
6. the hazard ratios in tables 2 and subsequently are adjusted for a string of covariates including lifestyle
factors such as physical activity, alcohol consumption and dietary score. are these factors not on the causal
pathway, and hence should not be adjusted for? the research question involves the shape trajectories
versus mortality, which must be due at least in part to lifestyle differences – so why adjust for them if the
interest is in the trajectories themselves?
7. table 2 shows that for deaths due to stroke in women smokers (though not in men), groups 3 and 4 are

significantly protected relative to the lean-stable group. this is surely worth a mention.
8. the interaction in figure 2b is said to be insignificant (p = 0.46), yet the two trends look strikingly
different, and much more so than in figures 2a and 2c. is it correct? it’s not entirely clear what sort of
interaction has been fitted – i assume it's comparing the linear trends across shape groups in the two
diabetes groups.

<|EndOfText|>

the authors have responded positively to all my suggestions. i have two further comments.
1. having reduced the percentages in the abstract to whole numbers they precede them with '~' to indicate
'approximately'. i'm not sure why they feel this is necessary, as few readers will care whether it is (say)
26.5%, 27% or 27.5%. in any case if they are that interested, they can delve into the results and
calculate the percentages themselves to full accuracy.
2. in response to my point 5 the authors have tried redoing figure 1 to show the smoothed curves for each
journal separately, but without success. what is needed is the interaction of the spline smoother with
journal, but i accept that this is not straightforward to obtain and am happy that they stick with the current
figure 1. i suggest though that they make the mean curve thicker than the others, to ensure it stands out.

<|EndOfText|>

the authors have done a good job in making the paper easier to read. their key analysis
change, altering how episodes were identified and constructed, though complex, is well
described in the appendix.
1. some comments on the abstract. it refers to 226 bpci hospitals and 700 control
hospitals, three times as many, yet their respective numbers of episodes are similar at 261k
and 211k. it's not clear to me if the mismatch is due to the 20% sample for the control
hospital data or because the control hospitals are appreciably smaller. it would be good to
add a phrase explaining the mismatch.
i would omit the phrase saying there was no difference in the proportions of male patients,
as the aim of matching is to make them the same, so it's hardly surprising.

the final sentence of the abstract conclusions refers to the time needed to see changes, yet
there is nothing in the results to support the statement.
2. i didn't understand the sentence on page 10, "we added index discharge to a skilled
nursing facility, index discharge with home health services and the total number of skilled
nursing days post-hoc to better elucidate observed spending effects." perhaps it's the phrase
"index discharge" i don't follow.
3. there are still lots of acronyms e.g. drg, aco, ma, pac etc, which i doubt are necessary.
figures 1 and 2 particularly need attention.
4. i am puzzled by the propensity-score-matched analysis. usually it is applied to match
individual index hospitals to one or more control hospitals, yet here it seems to be applied to
the groups of bpci hospitals and control hospitals. i don't follow how they are matched as
groups, and how some control hospitals are included and others excluded. please explain.
5. the difference-in-difference model assumes there is a step change in outcome when the
intervention is introduced in a particular hospital. yet the abstract conclusion is that the
change takes years to show itself. so i wonder if the model should be extended to look for
tapered effects, by including bpci x time since start of intervention as an interaction term
along with the bpci main effect. this could be just a sensitivity analysis, but it seems an
obvious extension to look at given the conclusion.
6. what is a quarter-time fixed effect? - is it quarters of a year?
7. the numbers in the first sentence of the results do not match those in table 1. if they are
thought interesting enough to pull out from the table, perhaps the same should be done for
the control hospitals.
8. in table 2 it would be worth adding the dates for the two periods, to explain why the
treatment period numbers are much smaller than for baseline.
9. the differential change in treatment cost is given as $172.4 (page 17). this precision
strikes me as excessive, particularly given the likely size of the standard error, and i'm
always keen to minimise digits where appropriate (see my guidelines
http://adc.bmj.com/cgi/content/full/archdischild-2014-307149). the same applies to
percentages and p-values. related to this, the percent changes in table 3 would be better all
with one decimal place.
10. it's odd that table 3, with its 15 outcomes, gives the unadjusted results, whereas the
adjusted primary outcome results are restricted to figures 1, 2 and appendix figures 3 and
4. surely the adjusted results need presenting in full as well?
tim cole

<|EndOfText|>

this is a large and statistically complex analysis of the impact of the feed the future
program on the nutritional status of children from 33 countries in sub-saharan africa. i
have comments on the study design, analysis, presentation and interpretation.
1. the presentation involves two alternative formulae describing the regression models
fitted, followed by the numerical results of many such models. the reader may or may not
be comfortable with formulae, but no attempt is made to demonstrate the models visually.
the nearest the paper comes to illustrating the model is efigure 1, which shows the
regression lines for ftf and control up to 2011, i.e. before the intervention. but no
corresponding lines are shown for post-2011. so the reader has to imagine the pattern of
regression lines pre- and post-ftf to understand the model.
it is important to show both the data and the superimposed regression lines for one or
more of the regression models, to visualise the analysis and test the face validity of the fit.
the raw mean country-year data are usefully shown as a series of country facets in
efigures 2-4, but the figures are hidden away and i missed them on first reading - they
need to be in the main paper. but in addition they need to be seen in a way that allows the
model to be tested. this could be done by combining the data in each of efigures 2-4 as
two plots, superimposing the ftf countries in one plot and the controls in another. this
would allow the reader to look for an inflection in the ftf countries plot around 2011.
the fitted regression lines for each country need to be shown superimposed on the country
facets, to test the fit. in addition they could be shown combined in a single figure (without
the data), providing a visual summary of the fitted model. it would also be plausible to
provide more than one such combined figure, e.g. to contrast the impact of different
assumptions on the fitted lines.
2. the model in equations 1 and 2 assumes a step change in malnutrition following the
intervention, i.e. parallel regression lines with different intercepts before and after. but it is
unrealistic to think that the impact of the intervention will be visible on day 1, and a more
realistic model would allow the effect to build over time. this model is tested in etable 8,
but it needs to be introduced earlier on as a realistic alternative to the simpler model.
3. the study design is multilevel, actually four levels, with data from country, year within
country, household within year and child within household, yet the data are analysed with
robust standard errors at a single level. it would be useful to explain why separate errors
at the different levels are not estimated, with the intervention effect tested using the
appropriate level error. in addition the cluster level at which the standard error is

estimated varies from model to model, when surely the study design defines which level is
appropriate.
4. the data are weighted by survey design and by country population, but it’s important to
recognise that weighting may not be relevant if the study aim is purely to show the
statistical impact of the intervention. using weightings ensures that the estimated effect
sizes apply to the underlying population, but it inevitably affects the significance of the
findings. the key issue is how to interpret the study aim “to evaluate the impact of the
feed the future program”. is the impact to be measured in the effect size or the
significance of the effect size? for me the significance is what counts, and in this case
weighting is not appropriate. so the impact of weighting on the significance levels needs to
be demonstrated for one or more of the models.
5. some more minor comments. implausible observations were excluded based on who
criteria (page 7), but more detail should be given.
6. the statistical approaches section (page 8) refers to the probability of stunting, waisting
and underweight, but “probability” would be better replaced by “proportion”.
7. in equation 2 the main effect terms for ftf and post are deliberately omitted due to
collinearity. it is a fundamental principle when fitting interactions to include the main
effects as well, so this is unconvincing. a better and simpler solution would be to centre
(i.e. subtract the mean) of the ftf and post variables prior to analysis, which would
obviate the need to include the main effects.
8. the results at the top of page 13 speak of a “decrease” in prevalence associated with
ftf, implying that ftf caused it. but as an observational study this assumption is not
warranted, and the wording should be more nuanced. the next paragraph estimates the
numbers of children “prevented” from being stunted due to ftf, and here the causal
assumption needs to be explicitly stated.
9. table 3 gives results for eight different models, showing how the ftf effect size varies
according to the degree of covariate adjustment. however the models are not directly
comparable, with fewer data for models 5-8. it would be better to use the smaller sample
sizes for all eight models, allowing direct comparisons between them, and the loss of power
would be small. also the lines in the table giving n could be omitted.
a focus on levels of significance is now depracated, and the standard errors and asterisks
in table 3 would be better replaced by confidence intervals. it would work better giving the
values to one decimal place rather than two, as the extra precision is unwarranted (see
https://adc.bmj.com/content/100/7/608). the standard errors are typically 0.8 or greater,
so the confidence interval widths exceed 3. on this basis the second decimal place is
uninformative, and the same applies to the etables.
that said, the appendix includes results for 59 models (excluding the
leave-one-country-out models), and it is hard to judge them against each other. presenting
them all graphically (including those of table 3) in something like a forest plot would be
useful, and this would emphasise the message of the paper that the conclusions are
broadly robust to model perturbations.
10. the final paragraph of the results explores to what extent the ftf and control
countries were similar at baseline, as the did analysis assumes. it would make better
sense to start with this, discussing it in the context of table 2, rather than coming to it as
an afterthought. this might also be a better way to present the underlying model, by first
describing it pre-ftf and then expanding it to include the intervention.

11. i had difficulty matching the before-after effect sizes in figure 1 with those of model 8
in table 3. in fact the histograms show differences corresponding to model 1, though this
is not explained. the top lines in the figure, describing the model 8 differences, are
confusing and unhelpful.
tim cole


<|EndOfText|>

the authors have responded very positively to the reviewer comments. i just have three
very minor points of detail.
1. the abstract states that children not first born were excluded. this is not quite correct,
in that a few fathers will have had a child before the cohort started in january 1994. the
wording in the methods makes this clear - "the birth record of the first child born within
the cohort interval was paired to the father".
2. table 1 summarises the three groups of fathers, and in particular it shows that on
average the ivf and icsi fathers had more years of formal education. this is of course
adjusted for in the analyses, but it might still be worth pointing out.
3. and a very tiny point - on page 10 line 183 it should be "sensitivity analyses _were_
conducted".

additional questions:
please enter your name: tim cole
job title: professor of medical statistics
institution: ucl great ormond street institute of child health
reimbursement for attending a symposium?: yes
a fee for speaking?: no
a fee for organising education?: no
funds for research?: no
funds for a member of staff?: no
fees for consulting?: no
have you in the past five years been employed by an organisation that may
in any way gain or lose financially from the publication of this paper?: no
do you hold any stocks or shares in an organisation that may in any way
gain or lose financially from the publication of this paper?: no
if you have any competing interests <a
href='http://www.bmj.com/about-bmj/resources-authors/forms-policies-and-checklists/d
eclaration-competing-interests'target='_new'> (please see bmj policy) </a>please
declare them here:

reviewer: 2
recommendation:


<|EndOfText|>

this rewrite of 49180 is much clearer than the original, but the authors still make it hard
for the reader by their over-technical and unclear presentation. in addition they have by

mistake omitted the genotype analysis of table 5 from the results, referring to it only in
the discussion.
1. the many acronyms are unhelpful, particularly where undefined, as they make the
paper harder to read for non-specialists. just in the abstract there are tb (undefined),
hhc, dst (undefined), mdr, inh (undefined), and ds (undefined). later there are dm
(undefined), tst, pza (undefined), ipt (undefined) and drp (undefined). they should all
be defined, even tb, and many (most?) could be avoided entirely, e.g. hhc would be far
simpler and clearer as 'contacts'.
2. the paper is about drug resistance, so it is important to be clear how it is categorised.
individuals can be drug sensitive or susceptible (which? - both appear in different places)
(ds), or drug resistant (dr) or multi-drug resistant (mdr). but tables 1 and s1 also have
the categories pan-susceptible, mono-resistant, poly-resistant and multidrug-resistant. the
latter two obviously involve resistance to more than one drug, and the distinction between
them is apparently important, but it is nowhere explained. the footnote simply says that
poly-resistance is resistant to more than one drug, but not mdr. this begs the question what is mdr?
i encourage the authors to trawl through the paper identifying all the different drug
resistance categories, collect them in one section, harmonise the notation, and explain
what they all are. if this could be done without acronyms, so much the better.
3. these categories relate to the first paragraph of the results, where 1274 patients with
dsts were resistant to at least one drug; 538 to only one and 478 to both isoniazid and
rifampicin. but this leaves a further 1274 - 538 - 478 = 258 who are not mentioned at all.
this obviously relates to the categories in table 1, but because they are not explained it is
impossible to make sense of the numbers. (incidentally the acronym dts here should be
dst.)
4. page 10. "... those exposed to inh mono-resistant tb had a 15% (95% ci: 5%-16%)
higher risk of infection ...". these numbers do not appear in table 2, the relevant cell being
1.17 (1.09-1.25).
5. the terms univariate and multivariate in table 2 and elsewhere are used incorrectly.
they describe the number of dependent variables in the analysis, in this case one, i.e.
univariate. the number of independent variables is indicated by univariable/multivariable,
which should be used instead. in addition pr should be expanded to prevalence ratio, and
the abbreviated drug names need giving in full. the footnotes give percentages of missing
data in models 2 and 3, which presumably means that the number column in the table
applies only to the univariable analysis and hence is misleading. better to give the total
numbers for each analysis in the column header.
6. table 4 has tiny numbers, and looks underpowered to draw any useful conclusions.
what is the denominator for the number column, and where do the n = 10099 and 10109
come from? they are much larger than any previous numbers.
7. i was surprised to see the discussion say that "patients with dr-tb were also more
likely than those with ds-tb to be part of a cluster as defined by genotype", as up to this
point i had not seen the word "genotype". doing a formal search for it threw up table 5 on
page 58 of the submission, which is not referred to anywhere else. yet the discussion (foot
of page 8) talks about the genotype findings. clearly table 5 and its commentary have
been omitted from the results.
8. phrases relating to "statistical significance" appear in the abstract and elsewhere. there
is a global movement against such terminology, and they would be better expressed in
terms of "importance" or similar, based on the confidence interval.

9. "contacts were defined as secondary cases if diagnosed between days 15 and 455" page 7. where does the 455 days come from, as they were followed up to 12 months?
10. miru is another undefined acronym that could be explained if there was a section
describing the genotype analysis.
11. what are the reference numbers for the ethical approvals?
12. tables 1 and s1 look unnecessarily large to me. are all the covariates of interest? in
addition the formatting could be improved by presenting the numbers and percentages in
the format % (n), using whole percentages. i recommend whole percentages throughout
(see https://adc.bmj.com/content/100/7/608), as they are easier to read; the decimal
place is uninformative, and if people are desperate to know it they can calculate it from the
numbers.
tim cole


<|EndOfText|>

the authors provide a systematic review and meta-analysis of sero-diagnostics for covid-19. i have
some comments mainly on the presentation.
1. one of the exclusion criteria was fewer than five participants per study. in practice the smallest
included studies had 16 patients, but even this is surely far too small to draw any useful conclusions.
please justify the cut-off of five, or alternatively raise it to something more realistic.
2. the text accompanying figure 1 says "we identified 4969 unique titles. we excluded 4696 based on
title and abstract screening and 238 after full-text review. 39 studies15-53 met inclusion criteria." it's
striking that none of these numbers except 39 appear in figure 1, which means the reader has to do
sums to reconcile text and figure. please make the figure more reader-friendly.
3. the results on pages 6-7, based on table 1, are hard work to read and would be better in a table.
incidentally the many percentages would be clearer formatted as % (numerator/denominator) rather
than the other way round, since the percentages are the main focus.
4. anyone with a calculator will quickly find that the sensitivities and specificities in tables 2 and 3 do
not match those based on tp, fn, tn and fp. it needs stating in the text that as the results are based
on the random effects model, the numbers do not match exactly. however one extreme example looks
odd - chen, zhang in table 2 has tp=7 and fn=0 implying 100% sensitivity, yet the tabulated value is
94% with ci 60%-99%, i.e. excluding the observed sensitivity.
5. it will important in the future for the specificity to be appreciably greater than 99%. as it is, several
tests achieve 99% but this is very different from say 99.4%. i think it would be worth giving the
specificities in table 3 that are between 99.1% and 99.9% to one decimal place precision rather than
rounding them, to make this clear. obviously 100% can remain as 100%.
6. note that table 3 should have specificity not sensitivity in the title.
7. tables s5 and s6 include tau-squared values to between four and six significant digits of precision. i
am unconvinced that tau-squared adds much useful anyway, but claiming this degree of precision makes
no sense.
8. the many forest plots in figure s2 show all the specificities crammed up against 100%, making it
hard to distinguish between them. is there a way of presenting them on a scale that is stretched
approaching 100%, analogous to the log scale for risk ratios? for example, plotting sp% at the point
100 - sqrt(sp%(100-sp%)) has this effect. it's just a thought...
9. coronoviruses on page 6 line 6 needs attention.
tim cole

additional questions:
<b><em>the bmj</em> uses compulsory open peer review. your name and institution will be included
with your comments when they are sent to the authors. if the manuscript is accepted, your review,
name and institution will be published alongside the article.</b>

if this manuscript is rejected from <em>the bmj</em>, it may be transferred to another bmj journal
along with your reviewer comments. if the article is selected for publication in another bmj journal,
depending on the editorial policy of the journal your review may also be published. you will be contacted
for your permission before this happens.

for more information, please see our <a href="https://www.bmj.com/about-bmj/resources-reviewers"
target="_blank">peer review terms and conditions</a>.

<b>please confirm that you understand and consent to the above terms and conditions.</b>: i consent
to the publication of this review
please enter your name: tim cole
job title: professor of medical statistics
institution: ucl great ormond street institute of child health
reimbursement for attending a symposium?: yes
a fee for speaking?: no
a fee for organising education?: no
funds for research?: no
funds for a member of staff?: no
fees for consulting?: no
have you in the past five years been employed by an organisation that may
in any way gain or lose financially from the publication of this paper?: no
do you hold any stocks or shares in an organisation that may in any way
gain or lose financially from the publication of this paper?: no
if you have any competing interests <a
href='http://www.bmj.com/about-bmj/resources-authors/forms-policies-and-checklists/declaration-co
mpeting-interests'target='_new'> (please see bmj policy) </a>please declare them here:



<|EndOfText|>

the revision is considerably improved, with a clear structure and message. i have a couple
of minor observations.
1. the many acronyms complicate the story. it may be that they are familiar to the target
audience, but i personally would be happier with fewer of them.
2. the figures now are much clearer. i suggest in figure 1 omitting the all columns, to
match figures 4-6, and reversing the legend to reflect the graph.
tim cole

<|EndOfText|>

the paper describes differences in coverage of nutrition interventions across countries.
i have some comments on the paper's structure and presentation of the findings.
1. the paper is rather shapeless, without a clearly stated aim or description of how it is
addressed. reading the paper i saw three outcomes emerge, all relating to coverage of
nutrition interventions, which are described as the opportunity gap (gap in coverage
between health services and the nutrition intervention), the equity gap (rural versus
urban coverage gap) and what could be called the regional equity gap (regional
coverage gap). the latter appears right at the end, almost as an afterthought, yet in
the conclusions its importance is highlighted. this is at odds with the figures which
focus on the equity gap.
the problem with the paper's structure is that the first of these outcomes, the
opportunity gap, gets defined only after the first data have been presented in figure 1.
there needs to be a clear statement at the outset that the outcomes of interest are
coverage, and in particular differences in coverage as described by the three gaps.
2. there also needs to be more said up front about where the data came from and
what was done with them. the fact that they are dhs and mics data is stated only on
page 18, apart from a brief mention on page 6. figure 3 involves some quite
complicated statistics that are not explained.
3. the tables and figures are referred to almost without comment, e.g. table 1 and
figure 1 on page 4. this makes them hard to process, but in addition the figures
themselves are, though pretty, poorly designed and overly complicated. in addition the
supplementary material contains two tables and three figures, of which only the first
table is cited. the others might just as well not be there.
4. taking the figures in turn, figure 1 has no label on the y axis - quite why i find
inexplicable. it makes it very hard to interpret. and the same applies to the x axis in
figure 2, the many y axes in figure 3, and both the x and y axes in figure 4. in each
case i suspect they represent percentage coverage, but it really would be better to say
so.

5. in figure 2 the x axis is presumably coverage, whereas in figures 1 and 3 coverage
is on the y axis. why not transpose figure 2 so coverage is on the y axis? also, why
include the numbers in the body of the graph when there is an x axis? - it only
complicates things. a better design might be to use an xy plot with coverage on both
axes, rural versus urban, which would halve the number of points.
6. figure 3 is extremely complicated and yet poorly explained - the regression lines are
not even mentioned on page 5. in addition the title refers to fixed effects models that
have not been described, adding further confusion. what is the message to be drawn
from figure 3? it deserves a proper description.
7. figure 4 is remarkable in having two distinct facets with coverage on the x axis in
one and on the y axis in the other. as with figure 2 it would be worth transposing the
left facet and omitting the numbers.
8. the 985% facility delivery in el salvador on page 6 looks to be on the high side.
9. in the final line of page 6, "data is limited", data should be plural.
tim cole