This is an interesting article that reports on an important evaluation of a major health
improvement programme in the NHS (the VMI partnership programme). The emerging
insights and implications of this evaluation and the underlying programme will be of great
interest to the clinical community, and should provide considerable new perspectives on
the translation of improvement methods and the developing of improvement cultures
within healthcare organisations.
One of the challenges this paper faces is presenting some complex and emerging ideas in
the constrained format of a “BMJ Analysis” article, which are typically short articles that

present a clear and compelling (and sometimes controversial) point of view on an
important topic. Many of the issues raised in the article are very important (how regulators
should support and facilitate improvement; tensions of traditionally aiming for simple fixes
to complex problems; challenges of creating time and space in a facilitative culture; how
senior teams can come together to share information and experience, etc). These are
important and timely issues, and the paper is clearly based on extensive and detailed
empirical research.
However, to my mind, the current structure of the paper doesn’t yet do justice to the
importance and insight that this work might offer the largely clinical audience of the BMJ.
These short Analysis articles need to do a lot of work in a very short amount of space to
quickly hook readers into why this is so important, and clearly explain what the big
problem is and how it can be addressed.
The paper could therefore be greatly improved in four ways:
1 - Concepts and explanation: the core concepts presented need to be specified and
explained in much greater detail, especially for a non-social science audience.
2 - Prioritise the argument: the argument of the paper would benefit from being organised
around the core single premise (eg that new forms of interaction and authority support
improvement and learning in different ways); explain up front why that is so important
and why that is so different to what may be typical in healthcare; and then use examples
from VMI to illustrate the key mechanisms described.
3 - Tangible examples: provide concrete and tangible examples of what is being described.
It is interesting to have the conceptual points echoed by the qualitative data, but this
doesn’t currently give the reader much flavour for the ‘what’ that is actually being done in
the meetings or the VMI programme as a whole.
4 - Analysis not empirical: the paper at the moment feels like a very condensed empirical
paper, and so risks falling between, on the one hand, not providing the level of empirical
analysis and evidence that is warranted to make key claims in the paper; and on the other
hand, not providing a simple, strong and compelling argument for what is being
presented.
Much of this is about presentation, framing of the argument and shaping the article into a
much more punchy and direct “Analysis” style piece that moves quickly and introduces
ideas thoroughly to a non-social-science audience. I appreciate there would be a
reasonable amount of work to be done to follow through on these suggestions, but I feel
the pay off would be considerable in terms of bring these important ideas to a wider
audience. In that spirit of improvement, I offer some specific observations and
suggestions:
p2 line40 - relational authority is the critical and key concept that unlocks the whole
paper. It is important to say much more here about what it is, what it looks like, how it is
different. What is relational authority and who has it; how does it work; to what ends?
Why does it matter? How does it relate to inter-organisational learning? What does
inter-organisational learning look like? Why is it important? Are there any examples where
the organisations have learnt either directly or vicariously from one another?
It feels like it would be more relevant to lead with this proposition, opening the paper with
an argument for the power and importance of relational authority as a key driver of
learning, and the sorts of mechanisms and antecedents required: Time; Honesty; Informal
accountability; Unity and diversity; Reflection and resilience; etc. And then, use the VMI
programme as illustrations of that. (Rather than, at the moment, present this as a very
shortened empirical analysis of an evaluation of the VMI programme, but without enough
space to provide the appropriate level of evidence and methodological detail that would be
required.)

p2. Much more information is needed on the VMI programme and principles. What is lean?
Who are Virginia Mason and why are they involved? What are the Trusts doing? What
impact is expected? etc etc.
ideally this would be presented in a box, so it is easy to refer to for busy readers; and it
saves text space in the main article. For instance, is this programme being run by one of
the new teams imported into NHSI that brings with it a pre-existing culture of
improvement? This is important to know, as NHSI is a large and sprawling organisation
with multiple sub-cultures and groups.
More importantly, what is the TGB? Who attends? What role does it play? What are the
objectives and purpose? What do they do there? Why? If this provides the core example of
the phenomena under analysis, then the tangible meeting and activities need to be
described. Again, this could go in the same box.
p2 - Methods - there isn’t really space in an Analysis article to mention methods, and it
potentially invites criticism for saying so little, especially from more hard-nosed clinicians.
Qualitative research has rarely been published in BMJ (which is a huge shame). I would
suggest a short note at the end of a box on the VMI programme, noting that this is
(formative, summative, etc?) large scale evaluation, seeking to establish A, B, C and to
date X, Y, Z empirical work has been conducted.
(It is interesting to note that the evaluation was only commissioned two years after the
programme was initiated, around half way through the five year period. Others might
query this too and it may be worth noting in a sentence if and how this presents
limitations.)
p2 line47 - VMI programme may be unique, but if a key argument is that this is unique,
then some more justification of that would be useful here. Again, this may be within a box
on the VMI programme. How, for instance, are the meetings you describe different to
traditional improvement collaboratives? Other programmes that seem similar on first blush
are: Health Foundation’s Safer Patient Initiative seems worth mentioning here; or the
’Matching Michigan’ programme. Or the Health Foundation’s “Making safety visible”
programme, between external advisors, commissioners and exec teams of 10 NHS trusts.
How unique is the VMI programme compared to these; or is this building on similar
lessons and experiences of those programmes that have come before?
p3 line 3 - to my mind, the use of quotes and data is a little problematic at present. For
example, reporting that this is ’best day of the month’. It is of course genuinely a good
thing that the participants of the meetings enjoy the meetings. But, why does that matter?
This is not a facetious question.
What can be said about the actual success (or otherwise) of the programme or
collaborative, and why is it so important that participants enjoy it?
More broadly, this points to the challenges of using these sorts of data excerpts in such a
short paper. As a qualitative researcher, I say this somewhat grudgingly, but I am not
sure that the quote excerpts add much to the paper as it stands. For a longer empirical
paper, certainly detailed quotes are needed to evidence the analytic points being
developed. Here, space is so limited that I don’t feel that a short paragraph quoting a CEO
in the main text is particularly revealing. Evidence like this could be allocated to a table or
box, which could give readers a flavour of the positive views participants have, and free up
much more space in the main body of the text to provide more analytic development —
such as what does honesty entail between regulators and regulatees? What were the
incentives to create the regular time and space and how can these be held in place? Or
perhaps simply cut down the quotes to 5-6 words to illustrate the point. But to my mind it
is the point that matters in this sort of paper, not the quote. (As I say — I say this
grudgingly.)

p4 - Definitions and concepts again: What is ‘informal accountability’? This seems really
important, so needs a much more detailed definition or explanation of what is meant. Why
is this such a “radical departure” (p4 line 14) to what has gone before? Is this drawing on
prior theory?
p4 - What do you mean by a regulators’ mandate for ‘grip and control’? I assume this
refers to the tendency within the NHS for command and control modes of governance
organised around prescriptive requirements and close supervisory control. However, for a
primarily clinical audience it feels like it will be important to say a little more about this,
what that looks like in practice, where these tendencies tend to arise from and why they
can sometimes be detrimental to improvement efforts. (For example, formal accountability
need not be tied to tendencies to expect quick fixes to complex problems, though that is
commonly the case in some areas of healthcare regulation.)
From the associated quote, it seems to imply that information accountability is simply no
holding people to account with quantitative metrics. However, my sense is that this is
intended to go far beyond that. This seems a very important aspect of the argument that
is being advanced here and it would be worthwhile to explain this in more detail.
p4 - is unity and diversity the most useful explanatory concept for what you are describing
here? The key characteristics that strike me from this description are a reduction in
inter-organisational competition, and the removal of performance metrics and
measurements activities. Are you proposing that these are drivers of unity?
p4 line 36 - is it correct that there are no measures of performance outcomes associated
with this programme? Not even measures of organisational culture and climate? This
seems quite a striking decision if so. It would be worth explaining that further, and what
other mechanisms operate to allow leaders and organisations to understand if they are
developing a culture of continuous improvement
The use of anonymity of the Trusts seems a little undermined by the reporting of the
(male) CEO of Trust C leaving. A quick Google and it is clear who Trust C is (there are only
5 of them). It would seem sensible to simply say something along the lines of, ‘during the
programme, one trust CEO announced their departure).
