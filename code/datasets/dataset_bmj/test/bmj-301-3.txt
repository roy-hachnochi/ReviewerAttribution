This manuscript describes an analysis designed to “examine the risk of overdose- or
suicide-related mortality associated with opioid cessation”. This is certainly a clinically
relevant question given the push to minimize opioid exposure, with legitimate concerns
about the potential impact on patients – particularly when long-term therapy is being
deprescribed whether by choice or involuntarily.
Major critiques
1. The authors have failed to make a compelling case for why patients discontinuing
long-term therapy and patients “discontinuing” short-term therapy should be included in the
same analysis, given that this design choice introduces an unnecessary source of bias and
renders the current analysis uninterpretable. As demonstrated in Tables 1 and 2, the
likelihood of cessation/continuation is so strongly tied to the opioid prescribing trajectory
(short vs. long-term therapy) that they are essentially endogenous. Increased risk for
mortality outcomes may have nothing to do with opioid cessation but is attributable to
unmeasured factors related to the underlying reasons/circumstances surrounding acute
opioid use, in contrast to patients on existing long-term therapy. While this idea is given
some attention in the discussion, this is not just an inherent limitation to studying this
subject, but a fatal flaw arising from the design choice to conflate these two vastly different
patient populations. For example, I could understand an analysis that identified patients who
were existing long-term opioid recipients at some point in time (time 0) and then conducting
a similar analysis to the current paper looking at outcome mortality rates with subsequent
opioid use modeled as a time-varying exposure. There would still be concern about
causality; that mortality risk was not attributable to opioid discontinuation but related to the
underlying reason why opioids were discontinued. For example, perhaps patients on
long-term therapy who unexpectedly stop filling their prescriptions is a marker for transition
to illicit opioid use, which carries greater overdose risk and is the real underlying driver of
risk. As discussed in the current paper, however, this is an acceptable limitation because
even if not causal, an association would still support the idea that the period of
discontinuation (whether voluntary or involuntary) represents a period of risk for patients
which warrants diligent monitoring by health care providers. And then coming back to my
original point – the authors could then do a completely separate analysis among incident
opioid recipients; again, with subsequent opioid use modeled as a time-varying variable. But
including these very different patient populations in the same analysis is fatally flawed.
2. The “proportional hazards analyses” section of the methods does not contain some basic
design information that is necessary to evaluate the design – or at least that isn’t presented
in a way that I could understand after reading the methods several times – and has
significant implications for evaluating the validity of the findings (see critique #3). First,
there is no clear description of how a patient’s time zero was assigned. There is a description
in a prior section about how episodes of use were defined but I couldn’t find any description
of how these usage periods were used to assign a time zero point for each patient. Second,
it is not clear how time-varying opioid exposure during the follow-up period was determined.
Presumably, when opioid episodes were being assessed and the “last episode” during the
cohort FY was identified, the cessation date was the end of that episode. But that’s never
expressly stated. It’s also not clear how subsequent episodes were handled in the analysis.
For example, if a patient’s “last episode” ended early in the observation period they could
have been exposed to subsequent opioid episodes before the end of follow-up. Were patients

allowed to go off and back on again or were they considered discontinued for the remainder
of the follow-up period once their index episode ended?
3. Immortal time bias could potentially explain the findings. The authors indicate they
accounted for this during the run up to the start of the “last episode” (page 9). However, this
bias is not accounted for during the remainder of the follow-up period. But as reflected in the
prior critique (i.e. I’m not sure how time-varying exposure during the follow-up period was
determined/coded in the analysis), I could be wrong about this. But assuming that my best
guess is right – that continued use during follow-up was based on the episode definition
provided on page 7 and that cessation was determined by the end of the “last episode” –
then immortal time bias is a fatal flaw in this analysis. The episode definition includes 3
criteria which could signal the end of an episode – all of which are based on gaps between
two prescriptions and thus require knowing that a next prescription exists. Because the
outcome is mortality – and we don’t prescribe drugs to the deceased – knowing that the
patient had a subsequent prescription means that the patient could not have died any time
prior to that. In other words, while patients had a time-varying status of continued use, this
entire period of supposed exposure time is immortal (i.e. outcome events are impossible
during this time period, but this period is invalidly being considering as “at risk” time in the
CPH analysis) – except for the brief time period that begins on the release date of the last
observed prescription and in duration equal to the days supply dispensed on the last
prescription. For most patients that period of time will be at most 30 days (due to
prescribing limits for schedule II opioids). As mortality events could not be observed during
the majority of supposed exposure time (particularly among long-term opioid recipients),
this would hugely bias the analysis in the direction of increased risk during cessation periods
(which is what was observed).
4. The authors have not presented any information concerning the assumption of
proportional hazards (at least none that I could find). This is particularly important given
that the data in Figure 1 seems to indicate that this assumption might be violated. It’s not a
violation for absolute risks/hazards to change over time. However, some quick calculations
of ratios between cessation vs. discontinuation groups from data in the figure shows that the
proportional probabilities decrease over time, which is noted by the authors in the last
sentence of the results section. However, if this is true, then this seems like the proportional
hazard models may not be valid. I understand that the life table analyses were performed
differently than the CPH models (perhaps used different time zero points – that part is also
unclear to me) and the findings may not be directly comparable. But given this observation,
it is particularly vital to present information for statistical tests of the proportional hazards
assumption.
Minor critiques
1. I see no rationale/justification for the comparisons being made in the appendix tables 2
and 3. Why would you isolate and make these specific between group contrasts? Relatedly, I
don’t know understand the rationale of the grouping structure to begin with. Why would you
cull out long-term vs short-term prescribing just for short-acting opioids? The most
important distinction is clearly long-term vs short-term therapy. Lumping all the long-acting
opioid patients into one bucket (that includes both short-term and long-term use) doesn’t
seem to make any sense – and same for tramadol.
2. Assuming they can be segregated, it would be helpful to present sensitivity analyses
looking at the two outcomes separately (overdose mortality vs suicide mortality), which is
standard practice when looking at a composite endpoint as the primary outcome. For
example, it’s possible that overdose risk is higher during periods of continued use and
suicide outcomes are higher following cessation. These two outcomes could run in opposite
directions. And I understand that it’s difficult in the real-world to know whether a
drug-related overdose was an intentional suicide or not (which is thus reflected in potential
inaccuracies in coding) – but it would still be useful to understand if different outcome events
demonstrated different associations with exposure – to best they can be ascertained. I don’t

have any direct experience with the SDR-NDI data, or much familiarity with these particular
ICD-10 codes, so I’m not certain whether this could be done.
