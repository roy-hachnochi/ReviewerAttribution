Thank you for inviting me to review this interesting paper. It is very clear that the
authors have undertaken a painstaking overview of the existing evidence in regards
to diet and prevent of type 2 diabetes. A huge undertaking, and umbrella reviews
are very important to provide a broad summary of an ever expanding field. Please
find below my comments and suggestions. I sincerely hope these help the BMJ and
the authors going forward.
1) I must admit that I am circumspect of many nutritional epidemiology studies, as
often it is hard to identify exactly the type of food/diet under review and exactly
if/how this is related to outcome risk. I think similar concerns arise in this overview,
as by taking an umbrella overview of all diet studies in this field, the scale is very
broad and it is hard to identify specific implications for what diet is beneficial. For
example, in the abstract the main conclusions relate to food/drink such as sugary
sweetened beverages, processed meat, and red meat. But these are very broad
groups – e.g. what specific sweetened beverages are we talking about? What
specific processed meat? E.g. in their discussion they say: “In accordance, an
unhealthy dietary pattern, high consumption of red meat, especially processed meat
(e.g. bacon, hamburgers or hot dogs), animal protein and heme iron were related to
an increased risk of T2D.” – but is it bacon or a hot dog I should be avoiding?
I find that focussing recommendations on a broad class is difficult to interpret. Of
course, this is a consequence of the authors summarising the existing evidence – so
I am not criticising the authors themselves, as they can only summarise what is
reported. But I do worry about the translation of the findings for the BMJ reader,
and that the press may pick up on some broad (non-specific) message.
2) Another reason for concern is the difficulty in adjusting for confounders, as the
findings are all based on primary studies that were observational. As the focus in the
review is at the broad umbrella review level, I do find it quite detached from the
original primary studies. In particular, what adjustment factors were used in each
primary study? Were they adequate? What methods were used to adjust for
confounding in primary studies and were they suitable? Is a linear dose response
relationship truly justified? Indeed, was this even checked in the original studies, let
alone at this umbrella review stage? These are just some examples of why I find the
review rather detached from the original primary studies, and thus it is hard to
ascertain whether the findings are meaningful.
3) In regards to the adjustment factors, the authors say: “Almost all of the primary
studies adjusted at least for age and sex, with the exception of four primary studies
which reported crude estimates.” – surely these 4 studies should be removed?

Further, “ 80% of the primary studies conducted a multivariate adjustment (e.g. for
total energy, body mass index, smoking status and physical activity).” – yes, but
were the adjustment factors adequate? It would perhaps have been clearer had
the authors pre-specified a set of adjustment factors that were considered essential
(minimum required), in order to have some credence that the adjusted results were
only prone to small residual confounding.
4) Related point: in the discussion it says “It is likely that individuals with unhealthy
dietary behaviours, such as low intake of whole grains and fibre, as well as higher
intake of red and processed meat, have an unhealthier lifestyle per se, such as
higher rates of obesity, smoking and physical inactivity83-85. Most of the included
studies adjusted for these factors, and associations persisted” – the word ‘most’ is
not reassuring to me, but moreover the question remains as to whether the
adjustment of these factors (when done) was actually adequate. Was a regression
approach used without backwards/forwards selection of adjustment variables? Or
perhaps a propensity score analysis was done – but was it done well? Etc.
5) Multivariate adjustment should say multivariable adjustment
6) I find the data extraction description confusing in the methods. E.g. “If the RR
estimates from primary studies of a dose-response meta-analysis were not reported
in the published meta-analysis, we did not recalculate the meta-analysis, but
extracted the SRR from the published meta-analysis. If we could not identify a RR
estimate from a primary study of a high vs. low meta-analysis in the published
meta-analysis or the primary study itself, we excluded that particular primary study
from our meta-analysis.” – please re-write this in clearer language for the BMJ
reader to follow.
7) I might be wrong, but it appears to me that the authors are pooling
meta-analysis results. Why not actually take the original primary study results, and
pool these in a single meta-analysis? I do not see why pooling the original
meta-analysis results is more helpful. Please can they justify this. Also, does this not
then make the heterogeneity a between-meta-analysis heterogeneity? Rather than a
between-study heterogeneity? If so, this is hard to interpret.
8) It also appears that the meta-analysis results bare eing pooled ignoring the
uncertainty in heterogeneity estimates (within a meta-analysis and across
meta-analyses). This would be easier to address if pooling all the study-specific
results in one go. See references such as Cornell et al. and the use of methods such
as the hartung Knapp method for widening confidence intervals
Cornell JE, Mulrow CD, Localio R, et al. Random-effects meta-analysis of inconsistent
effects: a time for change. Ann Intern Med 2014;160(4):267-70.
Hartung J, Knapp G. A refined method for the meta-analysis of controlled clinical
trials with binary outcome. Stat Med 2001;20(24):3875-89.
9) Heterogeneity should not be measured by I2, and it is wrong to use values of I2
to define low, moderate or high heterogeneity. Better to report estimate of the
heterogeneity itself (tau-squared) and, possible, prediction intervals to disseminate
the heterogeneity.
Rucker G, Schwarzer G, Carpenter JR, et al. Undue reliance on I(2) in assessing
heterogeneity may mislead. BMC Med Res Methodol 2008;8:79.
10) Funnel plot asymmetry does not imply publication bias; a better word is
small=study effects, which indeed may be due to pub bias, but might also be due to
other things.

11) The authors report relative risks. But are the studies really reporting hazard
ratios? And if not, then what are the time-points of interest for diabetes onset, as
the RRs are time-specific measures. This is a critical issue, because I do not see
justification for why relative risks are useful in this context and not hazard ratios. ?
If they are hazard ratios, then really are these constant over time? Was this
checked in the original studies? Another example, perhaps, of being too detached
from original studies.
12) What does this mean: “For most of the associations, there was no indication for
presence of publication bias according to Egger’s test (p≥0.10), with the exception
of chocolate, whole grain, wheat germ, rice, white rice, soy products, legumes, hot
dogs, animal protein, monounsaturated fatty acids, total carbohydrates, total fibre,
vitamin D, total iron in high vs. low meta-analyses, as well as total dairy, low-fat
milk, coffee and cereal fibre from dose-response meta-analyses
(Table 1).” – the authors imply no publication bias, and then list many areas where
there may be. I find this confusing.
13) Is it justified to mix cohort and case control studies? Moreover, it seems that
‘cross-sectional’ studies are also included. But surely we need a design with a
time-to-event outcome, to at least have reassurance that the diet recording was
made at a point before the onset of diabetes. More explanation is needed in these
matters.
14) “the quality of evidence by applying the NutriGrade scoring system, which
comprises different sources of bias (including funding), study design, heterogeneity
between studies, the effect size and its precision.” – I do not see why the effect size
and its precision should be used to define quality. A more precise estimate does not
imply higher quality. Indeed a good quality study should be defined independent to
any effect size estimate and any magnitude of precision. Yes, bias may impact these
things, but the actual decision about quality should be based on the information
about the factors that cause it.
15) In regards to evaluating quality, I also found it confusing that the overall quality
assessment is made at the meta-analysis level (i.e. each meta-analysis included in
the umbrella review), and not at the study-specific level. If the authors rather pool
the original studies, rather than the meta-analysis results, should the quality
assessment be made at the study-specific level? They could even remove primary
studies that were at high risk of bias, which would otherwise still be included in the
meta-analysis feeding into the umbrella review.
16) Is publication bias examined at the study-level or the meta-analysis level. That
is, are multiple primary study-specific estimates plotted on the funnel, or the
multiple meta-analysis results per diet type presented on the funnel plot. Again, I
find it hard to ascertain the level of the pooling. I think it is the primary study level.
Sorry that I have many concerns/comments. Most of these relate to the potential
issues with the primary studies, which perhaps cannot be addressed easily at the
umbrella level, yet do impact upon interpretation and translation of the paper’s
findings for the BMJ reader.
Best wishes, Richard Riley
