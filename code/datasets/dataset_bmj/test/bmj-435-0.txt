RE: “New drugs: Where did we go wrong and what can we do better?”
The Analysis submission by Wieseler and colleagues focuses on Germany’s recent
experience with evaluating the added therapeutic benefit of new drugs. This is a
very well-written article that discusses an important and timely topic, which I expect
will be interesting and relevant for the general clinician, policymaker, and patient
readership of the BMJ. The authors paint a balanced and data-rich – and therefore
objective – picture of therapeutic innovation in the biopharmaceutical sector. Their
findings will likely prompt significant debate and will be an important contribution to
the literature.

My only major comment on this submission is the limited extent to which it refers
and builds on the broader literature that previously evaluated similar questions,
including evaluations from Germany (e.g., Eur J Health Econ 2014; 15(6):
577–589). Presenting the findings of this analysis within its wider research and
policy context and comparing/contrasting the findings with those from studies
conducted in other settings and during different time periods would further
strengthen this article. Such a comparison would also demonstrate that ‘innovation’
in the biopharmaceutical sector has not improved over the past decade (e.g., (1) Eur
J Clin Pharmacol 2010;66:445-8, (2) BMJ 2005; 331: 815, and (3) Health Policy
2012; 105: 221-5.)
While the information presented in the Box is very helpful to understand the German
context, readers would benefit from how Germany defines ‘standard of care’ and
whether this definition differs across different countries. In addition, further
emphasis is warranted on Germany’s preference for randomized controlled trial
designs and clinical endpoints as opposed to many other countries that are
increasingly accepting single-arm trials with surrogate endpoints. Such differences in
evidence standards across assessment bodies in different settings would be
important to highlight.
The German experience with post-approval evidence requirements is instructive in
its consistency with the international experience. More detail on the post-approval
studies would be helpful: are these considered to be commitments or requirements?
Are there penalties that can be enforced? From the authors’ description, it doesn’t
sound like the regulators have the authority to enforce penalties (such as
withdrawing products from the market or monetary charges). It is worth mentioning
that even regulatory agencies with such powers (e.g., US FDA) have not yet
exercised these powers.
The authors also discuss potential reasons that may explain the observed findings.
Several BMJ Analysis articles addressed similar questions in the past, some of which
may be relevant to the authors’ current submission. Two recent examples include
BMJ 2012; 345: e4348 and BMJ 2015; 351: h5542.
I was surprised that the EMA’s evidence standards and their implications for health
technology assessment bodies were not discussed in more detail. Would requiring
more robust comparative data from randomized controlled trials by the EMA address
the current limitations of the system? The authors briefly referred to the recent joint
HTA proposal as a potential opportunity. Could the authors discuss the potential
implications of this policy proposal for performing comparative efficacy assessments
of newly approved drugs if EMA’s evidence standards are not raised in parallel?
Minor points:
A table showing the magnitude of benefit associated with the 54 products
with evidence of added benefit over standard of care would be valuable to include.
This will help readers understand how ‘proof of an added benefit over standard of
care’ has been defined by German authorities.
Across all categories of benefit listed in paragraph 3 of page 2, some
examples would be helpful. For instance, what are some cases where only minor
benefit was observed? What are the 2 products that showed less benefit than
standard of care? A table that lists some examples from each category would be
worthwhile to include.
In cases where comparative trials were available, but no added benefit was
observed (19 drugs, 15% of cases), was this due to non-inferiority designs? Or did
the trials fail to meet their superiority objectives?

In cases where the assessment deemed the comparator arm of a trial
inappropriate, was this specific to the German context? In other words, did these
cases reflect leniency of the EMA to approve drugs on the basis of trials including
inappropriate comparators?
In cases with no comparative data, were drugs approved on the basis of
placebo-controlled trials? Were single-arm studies included in this analysis?
In the section on post-approval evidence, please clarify that the example
refers to cancer medicines (Davis et al. 2017).
Figure 2 could be alternatively presented in a stacked bar chart.
The finding that almost 60% of new cancer medicines demonstrated an
added therapeutic benefit to standard of care is surprising. To what extent is this
finding consistent with those from previous evaluations?
