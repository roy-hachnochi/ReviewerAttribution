Li et al report a restrospective cross-sectional comparison to determine whether a weekend effect on mortality
differs for strokes ascertained in a clinical registry (OXVASC) and via hospital administrative data. In addition, they
present a systematic review of prior work on the weekend effect in stroke. They found that “false positive” stroke
admissions were more common during weekdays (largely elective evaluation admissions), that these events had
lower mortality and that if these events were accounted for, the apparent weekend effect resolved (or reversed).
Similarly, no weekend effect was identified in OXVASC-ascertained strokes. They report data supporting a number
of explanations for this effect: miscoding of elective admissions during the week and severity/patent behavior
differences between weekends and weekdays. These findings were supported by their systematic review which
found that studies that used more rigorous ascertainment methods or adjusted for severity were less likely to find
weekend effects than those that did not make similar adjustments.
The methods appear to be sound and the combination of both approaches and their aligned findings is a major
strength of this manuscript. The implications of these findings are also potentially important. First, they have
immediate relevance to any initiatives in the UK to increase weekend services. Second, they have implications for
the use of administrative data for stroke research in other contexts and other systems. My only substantive concern
is the extent to which these findings generalize outside the OXVASC environment. Can the key findings be applied
to environments with different incentives for accurate coding, different systems of care, and potentially different
patient populations.
Major Issue:
1. Generalizability Concerns — A variety of issues make me uncertain about the extent to which the key findings
generalize to other systems. Coding and coding incentives seem likely to vary across hospitals and settings. In the
United States, for example, stroke is a relatively poorly reimbursed hospitalization and as a consequence hospitals
don’t have an incentive to “over count” stroke. How strong are the incentives for or against stroke-coding in the UK
and how may they differ? Similarly, the authors have made important observations about how systems of stroke
care are likely to influence the accuracy of stroke diagnoses. Systems that routinely admit strokes regardless of
severity or systems that rely more heavily on inpatient evaluation as opposed to outpatient evaluation may have
sufficiently different patterns of care to make coding either easier or harder. For example, if “admit all strokes” is
the plan, then its unlikely that patients would be later admitted for a diagnostic evaluation as it would most likely
occur during the initial hospitalization. Finally, as the authors’ acknowledge, the nature of the stroke population at a
single academic center may influence their findings. If, for example, if the stroke population involves more
diagnostic uncertainty or complexity, it may be harder for coders to code accurately in this population. Similarly, if
the local practice pattern involves more or less hospitalizations for evaluation, this may also influence the
magnitude of the effect.
These concerns are supported by two observations: 1. The wide divergence in the likelihood of identifying a
weekend effect based on the country where the question was studied. 2. The relatively poor positive predictive
value of an administrative stroke diagnosis (apparently under 0.70) compared to generally better performance in
other settings.
These concerns have less applicability to the UK policy question and are more a question of what these findings
mean in more widely divergent systems of care. Expanding the systematic review, if possible, to assess whether

systems factors (% ambulance, % emergent admission, % of strokes admitted, etc.) correlate with the likelihood of
finding a weekend effect may be helpful.
Minor Issues:
1. Lacking description of the administrative methodology: The primary administrative method for stroke
identification is not clearly specified — what codes were used? ICD-10 sensitivity analyses are specified, but
presumably ICD-9 codes were in use for the early years of the study. Also, were these events limited to the primary
diagnostic position? This may help situate the poor performance of the administrative coding scheme compared to
prior work.
2. Please clarify the extent to which could OSVASC miss weekend cases? It would be helpful to know what
proportion of both the “false positives” and “false negatives” by weekday/weekend status were identified for
evaluation by OXVASC. Were all true and false positives claims diagnoses identified by OXVASC? Given that
administrative methods are part of the OXVASC approach, it seems this should be a small effect and may not exist
at all.
3. In the intro, the statement that “quality of care” has been shown to improve outcomes may be misleading. are
stroke units only differentiated from non stroke unit care by their quality? it seems that they also differ,
substantially, on the intensity of care.