 Thiazolidinedione use and risk of hospitalization for pneumonia in type 2 diabetes: population based matched case-control study. Review Background Results from a recent meta-analysis of randomized controlled trials suggest both drugs increase the risk of pneumonia ( Thorax 2011; 66:383-8 ): Pioglitazone: RR=1.63; 95% CI 1.09, 2.46. Rosiglitazone: RR=1.26; 95% CI 0.90 1.76. An undue emphasis on statistical significance leads the authors to suggest these results are inconsistent, but both results show a large overlap in the confidence intervals in a range indicating an increased risk that is perhaps greater for pioglitazone than rosiglitazone. Package inserts on both pioglitazone and rosiglitazone carry warnings for heart failure and edema, along with increased risk of upper respiratory tract infection. Further, heart failure increases the risk of hospitalization for pneumonia ( Eur J Intern Med 2013 Jun; 24 (4): 349-53 ) as does diabetes, especially with poor glycemic control ( Diabetes Care 2008 August; 31 (8): 1541–1545 ). Results This study reports small increases in risk of hospitalization for pneumonia with recent exposure to pioglitazone (OR=1.15; 95% CI 1.00, 1.32) and pioglitazone (OR=1.09; 95% CI 0.83, 1.44), but not for current exposure to pioglitazone (OR=1.04; 95% CI 0.60, 1.79). Current exposure to rosiglitazone was associated with a reduced risk of pneumonia (OR=0.33; 95% CI 0.11, 0.95). The relatively higher rate of pneumonia with pioglitazone compared with rosiglitazone is consistent with the results from clinical trials, but the magnitudes of the effect estimates reported here are markedly reduced, and recent exposure is associated with greater risk than current exposure. This pattern of results is puzzling and the authors offer no compelling explanation. Methodology The study description raises no obvious bias to account for a systematic reduction in risk estimates nor the greater risk with recent versus current exposure. There are, however, several uncertainties in the study methods that may have a bearing on validity: The study is described as a new user design. The new user design was described by Ray ( Am J Epidemiol 2003; 158: 915–920 ): ‘ A new-user design begins by identifying all of the patients in a defined population (both in terms of people and time) who start a course of treatment with the study medication. Study follow-up for endpoints begins at precisely the same time as initiation of therapy, or t0. The study is further restricted to patients with a minimum period of nonuse (washout) prior to t0. The study should include all patients in the study population meeting these criteria. Data for all patient characteristics are obtained at a time just before t0’ . The new user design is described for cohort studies, but can be adapted easily to a case-control study nested within a cohort of new users. Nevertheless, it is not clear that the current study follows the new user design described above by Ray. First, key to a new user design is that “new use” is defined by a drug dispensing following a period of minimum duration (e.g., 6 months or 1 year) with no dispensing of the drug. In the current study, the inclusion criteria as described do not include any minimal drug-free period. This raises a question of whether the study population truly comprises new users. The current study indicates that the start of follow-up or index date corresponds to a diagnosis of type 2 diabetes (Table 1). This is also consistent with Figure 1, in which the cohort is defined by a diagnosis and without regard to therapy. However, the study methods indicate that therapy was required: “We assembled an incipient cohort of all patients with type 2 diabetes who filled at least one prescription for any hypoglycemic agent between 2002 and 2008” (emphasis added). The methods go on to list as an inclusion criterion that individuals had to “contribute at least 6 months of medical or pharmacy coverage in the calendar year of diabetes diagnosis.” This strategy is problematic in several respects. First, the required therapy for cohort entry is any hypoglycemic agent and does not specify those medications which may be suitable therapeutic alternatives to glitazones. According to the new user design, the index date should be the first prescription of one of the glitazones or a therapeutic alternative (with analyses conditional on use of other medications). Secondly, the six months of required observation time is not specified as occurring before the start of therapy or being drug-free. Instead, the required period is defined without regard to the date of initiation of therapy and only as occurring during the same calendar year as a diagnosis of type 2 diabetes (the apparent index date). This means that the six months of observation could occur before, after, or spanning the diagnosis date and putative start of follow-up. To the extent that the required observation time before the diagnosis was less than six months, even if it was a diagnosis-free and drug-free period, the probability is diminished that the patient was free of the diagnosis prior to inclusion and, therefore, that this is not a cohort of newly diagnosed patients. Further, to the extent that the inclusion criteria require observation time after a diagnosis and start of follow-up, the corresponding follow-up time is “immortal” and represents a source of bias ( J Clin Oncol 2009; 27: e55-6 ). Finally, to detect diagnoses, patients would have to have medical coverage, and to detect prior therapy, patients would have to have pharmacy coverage. But the requirement of medical or pharmacy coverage does not ensure that either diagnosis or therapy would be detectable. If the patients had only medical coverage during this period, for instance, prescriptions of antidiabetic therapy would not be reimbursable and would not appear on the claims database. For this reason, claims database studies such as this one are typically restricted to patients having both medical and pharmacy benefits. To summarize, the inclusion criteria do not define a cohort that is either newly diagnosed or newly treated. There are at least two potential concerns with the study as described. First, if it is not a new user design, then the cohort would include prevalent users of glitazone therapy. Prevalent users represent a “survivor” cohort of patients who have a good experience with therapy, by obtaining effectiveness and also by tolerating the therapy well; patients who did not do well are more likely to discontinue therapy. The inclusion criteria provide no assurance that the study cohort failed to exclude prevalent users. The new user design was developed in part to eliminate the “healthy user” effect, but this type of selection remains a concern with inclusion criteria described for this study. Another important feature of the new user design is that of defining a minimum drug-free period before the start of therapy (which should correspond to the start of follow-up), also defines the minimal baseline period during which risk factors (i.e., covariates) are identified as potential confounding variables. The current study does not describe the time period during which risk factors are identified. If the authors defined risk factors as occurring before the outcome (i.e., pneumonia) instead of before the start of glitazone therapy, then covariates such as the “Diabetes Complication Severity Index” and “enrolment pattern” occurred (at least in part) after initiation of glitazone therapy. It is not advisable to control for factors that occur after the study exposure because they could be a result of exposure and, therefore, in the causal pathway between exposure and outcome. Analytic control of such factors would inappropriately attenuate the true relation between the exposure and the endpoint. The authors included patients “without any claim for congestive heart failure,” noting that heart failure shares similar clinical and radiographic findings as pneumonia. Their goal was to reduce outcome misclassification, presumably concerned that cases of heart failure could be confused with cases of pneumonia (and vice versa). I have two comments on this strategy. First, if the authors are concerned that claims data cannot accurately distinguish heart failure from pneumonia, then how did they exclude patients with heart failure? How do they know that patients with heart failure who were excluded did not have pneumonia? Secondly, including patients “without any claims for congestive heart failure” would exclude all patients with a claim of heart failure without regard to timing of the heart failure diagnosis. Specifically, cases of heart failure that occurred after initiation of glitazone therapy could be the result of glitazone therapy. Moreover, even if there was no misclassification, because heart failure increases the risk of hospitalization due to pneumonia ( Eur J Intern Med 2013 Jun; 24 (4): 349-53 ), excluding cases of heart failure that occurred after the start of therapy would also exclude cases of pneumonia etiologically related to glitazone therapy (because heart failure lies in a causal pathway). The impact would be to attenuate the relation between glitazone therapy and pneumonia. The authors state that they matched controls to cases on duration of follow-up, according to the method of incidence density sampling. Actually, incidence density sampling stipulates that controls be in the cohort (and contributing person-time to the denominator of a theoretical incidence rate) at the time a case occurred, but does not require the control have the same duration of follow-up as the case ( Am J Epidemiol 1982; 116; 547-53 ). Controls should be sampled to represent the exposure frequency in the entirety of person-time at risk, which includes people with any duration of follow-up (both longer than and shorter than the case’s duration of follow-up). To the extent that glitazone therapy may be related to duration of follow-up, matching by duration of follow-up would have provided an exposure distribution that was not representative of the base population, creating a control selection bias. A causal effect of an exposure is always measured relative to some alternative. A drug may cause an effect (RR1) compared with one drug, and prevent the same effect (RR1) when compared with another drug (that has an even stronger causal effect). These findings, especially that of a reduced risk for rosiglitazone, should be understood in terms of the reference category. The current study measures current and recent use of each glitazone relative to non-use of glitazones within two years. Non-use of glitazones is consistent with the absence of therapy, as well as many possible combinations of concomitant antidiabetic and other medications (some of which may be related to risk of pneumonia). It might be preferable to specify the comparator as a therapeutic alternative(s) to the glitazones. A related issue is that effects of other medications evidently were not controlled. Glycemic control has been related to risk of pneumonia. Although no direct measure of glycemic control is likely available in the claims database, data on the dispensing of and adherence to antidiabetic agents is available. The authors call for additional studies using other methods to better control for confounding, but it appears that better control of confounding is possible with the data used in this study. The higher risk for recent exposure than current exposure is peculiar and seems to indicate an increased risk of recent discontinuation. Several explanations are possible, including an increased risk due to loss of glycemic control after discontinuation, or discontinuation due to early prodromal symptoms of adverse events that were diagnosed after discontinuation. If drug exposure caused the outcome, one would expect higher risks during exposure than after exposure. Further analyses aimed at identifying reasons for discontinuation would be of interest. In addition, duration of therapy might be important, and analyses of risk by duration of therapy might be illuminating. 