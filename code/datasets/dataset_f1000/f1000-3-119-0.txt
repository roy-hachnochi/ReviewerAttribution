Iorns and Chong state in the first paragraph of their Opinion Article that 70% of surveyed peer-reviewed articles cannot be independently verified . Iorns, who heads the company, Science Exchange, Inc., reported the same statistic in an interview with Jennifer Welsh in Business Insider, 2012. Now she and Christin Chong present a set of recommendations for alleviating this problem. But the way they support their claim that 70% of research is irreproducible is problematic. They base their value primarily on four references 1 , 2 , 3 , 4 that demand scrutiny. These references include three cases on drug effects that are marginal and a fourth on sex differences. Two of the references include data not peer reviewed and authored by individuals from commercial companies 1 , 2 . A third is retrospective and involves the re-evaluation of statistical calculations of the original authors 3 . Only one, testing the effects of drugs on increased longevity of SOD1G934 mice, provides data that can be assessed 4 , and even those data, obtained in an impressive manner, are presented in a review article. There is merit in questioning the reproducibility of studies on marginal drug effects or sex differences, but it seems irresponsible to present, as Iorns and Chong have, a sweeping statement that 70% of all published peer-reviewed articles are irreproducible, even with the qualification of articles. Do these authors really believe that this 70% value applies to studies on signal transduction pathways, the phenotypes of mutants from viruses to bacteria to mammals, the interactions and roles of cytoskeletal molecules, the molecular evolution of species, the functions of molecules in embryogenesis and a vast variety of other biological fields? If Iorns and Chong had limited their commentary to the efficacy of drugs in model systems with marginal effects, they could have made an important and plausible case. But even then they would have had to do a better job referencing their argument. And to bring up the fact that 259 cases of misconduct were investigated by the Public Health Service, followed by their statement That in contrast ~480,000 papers funded by the NIH were published ., appears to be an attempt to globalize the problem by insinuation rather than hard supporting data. The suggestion by the authors that publishers should assess the methods and statistics used by third parties is already in place. It is, obviously, the peer review system, and of course it has its problems. But the insinuation is that this process is failing in 70% of cases. Publishers should indeed be more responsible for making sure that reviewers are selected who can really assess whether the methods employed and the statistics applied are valid, especially when marginal effects are claimed. I am sure that all other scientists would whole heartedly agree with that general suggestion. But a vehicle for immediately replicating data in every published paper is extraordinarily impractical, potentially very expensive and not at all necessary in areas of research in which answers are far-more straight forward. And who would foot the bill? The publishers? They are, in almost all cases, for-profit. For replication, they would charge a small fortune. And would scientists spend half of their research funds replicating other scientists discoveries. With the radical decrease in funding we are now experiencing, I would not bet on it. Iorns is co-founder of Science Exchange, Inc., a for profit company that charges scientists to have measurements performed in 900 laboratories worldwide that appear to have been recruited to perform experiments for a fee, and a profit, presumably for them and a presumable cut for Science Exchange, Inc. Would Science Exchange, Inc. be the vehicle for such testing? The authors should realize that big discoveries are immediately reproduced by other scientists, to build on those discoveries. Therefore, most scientists are obsessed with the validity of their results. And reproducibility is a tough chore if scientists do not apply the exact same procedures, under the exact same conditions, with the exact same strains and the exact same reagents. Biological systems, from cell cultures to biofilms to biochemical reactions have inherent plasticity and variability, highly responsive to the smallest changes in genetic background, temperature, composition of the atmosphere, trace elements, source of reagents and extracts, and even the quality of double distilled water. But contradictions in the results published by different laboratories have a way of shaking themselves out. Most seasoned biologists at the bench know this is the case. Iorns and Chong have made a reasonable case for a limited area of biomedical research that involves searching for small or marginal effects and which involve apparently high noise levels. But they have presented no proof that supports their claim that 70% of all biomedical research is irreproducible, an overstatement which insinuates a significant number of scientists are at worst actively trying to dupe the rest of the scientific world or at best incompetent. By globalizing the problem to a majority of the entire scientific research community in the first paragraph of their commentary, they have sensationalized the targeted problem.