I would like to thank the authors for addressing all points raised in response to the original version. The manuscript has been mostly improved as a result, with the added power analysis, comments on the menstrual cycle phase, clarification of the sex of the panel of judges, and clarification for the reason of the repeated freeze-thaw cycles. A few comments remain, which Id like to list simply as points of reference for the authors, and readers. I am happy to approve the manuscript as is without reservation, but think it is useful to still communicate these comments as part of the manuscript to allow the reader to take them into consideration. The authors have added a power analysis, but the way the power analysis was conducted and presented is probably not 100% optimal. To use the effect sizes from your own sample for power analysis allows you to indicate how strong the effects were for those tests which came out significant, and how much variability was explained by the factors you manipulated and controlled. That is one aspect of power analysis. What might be important to address in addition, however, is the question of what the chances were to observe a significant effect in your sample if it exists in the population, for those tests that were not significant in your study. In the context of the current study, two of the main effects in question did not show significance - a potential progesterone response to stress, and the effect of cyberball on cortisol. Thus, it would be important to indicate what the chances of the current study were to observe significant effects here if they existed in the population. I had suggested to use previous studies to estimate the expected effect size in their study and then calculate the power from that for your study, given your alpha-level and your sample size - in the current study, this would translate into finding previous studies that observed a progesterone response to stress, and previous studies that found an effect of the cyberball stressor on cortisol release, estimate the effect size from those studies, and use it to calculate the power to find an effect in the current study. Related to this, it is not sufficient to use one effect size from your own findings for all power analyses (in this case, the group by sex effect on cortisol) - you would want to conduct different power analyses with different effect size estimates depending on the effects under investigation. (See, for example, the article by OKeefe on that topic: OKeefe, D. (2007). The authors were not very enthusiastic about the idea of using a within-subject design; this was a side point as their between-subjects design is certainly valid. However, the argument why a within-subject design might be suboptimal was not entirely convincing to me, either. While habituation to repeated exposure of the same stressor is a significant issue in stress studies, cross-habituation to laboratory stressors in general is less frequently investigated, and - at least to my knowledge - not frequently observed. In fact, the opposite phenomena, sensitization across different stressors, is more prominently investigated and discussed in the stress literature (which a simple search on PubMed using these keywords will reveal). While this would also add to the complexity of interpreting the results, randomization in the order of stressor presentation would help to interpret the results in either case. I certainly do agree with the authors that a full within subject design is impractical for the resulting 16 different orders. But a mixed within and between subject design would probably be feasible, reduce the number of cells substantially, and allow to co-investigate the TSST and the Cyberball task within the same person. The menstrual cycle phase effects might go beyond the effects on changing hormone levels, also influencing what women perceive as stressful depending on the phase they are in (see the recent paper by Duchesne et al . (2013) on this topic). Thus, I think it is important to not only control for the baseline levels of hormones affected by the cycle, but ideally also keep the phase constant, or have enough subjects to include the phase as separate factor in the analysis. I thus am grateful that the authors have included a respective comment in the Limitations section. I thank the authors for clarifying that the increase between time point 3 and time point 4 in the women occurred in the TSST stress group. Regardless, the results depicted in Figure 2 still seem to suggest that the control version of the TSST also led to an - at least descriptive - increase in cortisol levels in the women between samples 3 and 4. I think this suggests that there are some aspects to the control version of the TSST that are perceived as stressful by at least some of the female participants - otherwise, you would expect to observe simply a decline of cortisol levels throughout the task, in line with the circadian rhythm of cortisol. As it is not clear what aspect of the TSST control version leads to the increase in cortisol, it would thus be advisable to not repeat any aspect of this task in any other task, as it otherwise might create a confound. The authors point out that the TSST control task is frequently used - I dont doubt that, but would argue that it doesnt matter. Repeating any aspect of one stress task in another will complicate the interpretation of the results, if the aim is to understand what is stressful about one task vs. another. Thank you for clarifying that the judges panel in the TSST was always sex/gender mixed. I think this is best practice to avoid any potential effect of the sex/gender of the panel on the results. Along the same lines, the fact that the Cyberball panel was always of the (perceived) same sex/gender raises the question of whether different results could be expected if the panel was of mixed, or opposite sex/gender. Thank you for clarifying why three freeze-thaw cycles were employed. 