This paper describes a computational method for extracting information from a large variety of inherently noisy biological data describing protein-protein interactions and purports to be able to discover signalling pathways, or at least segments of signalling pathways. Not being an expert on Bayesian modeling, I can't comment directly on the method although it seems to be predicated on well-supported hypotheses and aims to be conservative in the interests of decreasing noise and increasing biological validity. Significantly, the pathway segments suggested by the model are annotated with existing functional information from Gene Ontology annotations. The authors claim to validate their results by correlating the proposed interactions with existing gene expression relying on the hypothesis that highly co-expressed genes are true interactors. It should also be noted that this study was performed on S. cerevisiae , a highly studied model organism for which the authors had access to 8 different types of high-throughput methods aimed at inferring protein-protein interactions (PPIs). I've personally always struggled with the validity of using computational methods to amalgamate high-throughput PPI data for the purposes of pathway discovery. PPI networks are dynamic and I'm not convinced that we can measure them completely (in every condition, cell type, tissue type, etc.) or that we can always assume that PPIs observed in one cell, organism, or condition can be extrapolated to others so any attempt we make to catalog PPIs is necessarily vastly incomplete. Furthermore, given the wealth of data necessary to attempt applying a computational method I wonder how generally applicable these methods can be. For example, this paper relied on data from 8 different methods - how often can we expect to have that much information about a cell or organism of interest? Is it appropriate to validate computationally-derived PPIs with gene expression data? Would it not be more appropriate to perform an assay that directly or indirectly interrogates the actual interaction between proteins? I also wonder how circular the logic behind these computational methods is. The authors used data from SGD, a well-known public resource, in order to generate PPI networks and then bootstrapped these networks by using GO, another well-known public resource. I would be surprised if GO annotation was performed without knowledge from SGD so can we believe that the networks derived in this paper are based on solely on the Bayesian model? Or are we just re-discovering information we partially already knew? And if we believe the signalling pathway segments reported here are newly and independently discovered, how widely applicable is the proposed method? Can we use it for other organisms or for yeast under changed conditions, for example? How much PPI data do we need before a computational method is more efficient and informative than well-designed biochemical experiments? Were the two reported pathway segments the only ones that could be inferred from 22,650 interactions between 2554 proteins (roughly half of the entire proteome)? Is there anything exciting (and new) to be found if the model is allowed to be less conservative? What contribution to biology do the authors expect from this method?