 General comments I am not an fMRI expert myself; therefore I deemed it necessary to invite two co-reviewers to add comments on the manuscript. Please find a set of suggested changes hereafter. The manuscript describes a recent rich amendment of an existing fMRI open dataset (documented in studyforrest.org), aimed at increasing the amount of shared data from the same subjects, stimuli and procedures for 7T fMRI slab recordings, and 3T whole-head anatomical scans, but with a different cognitive task consisting of listening to music in 5 different genres (vocalized or not) and answering a dual-choice question (did the clip have a happy melody? [yes/no]). In addition, the dataset includes recordings of several physiological parameters. The dataset is extremely rich and very well documented and as such has the potential to be used as a reference dataset for various research questions from auditory to music and emotional processing. The choice of freely available software packages for data processing and the inclusion of the processing scripts greatly enhance reproducibility and augment the documentation of the processing steps and analyses provided in the paper. The idea of an open-source sharing framework for replication of results and follow up projects is greatly appreciated, together with the suggestion of having fMRI data available for benchmarking. The authors describe the experimental procedures and the data processing techniques that led to a pre-processing of the data, with the goal to run a preliminary quality check and validation on the material that will afterwards be available for future studies (the authors name this part quality control). Secondarily, the authors provide a pre-processing of the stimuli set, too, with the aim to provide elementary descriptors which could be used to relate fMRI brain responses to delivered music snippets for encoding models estimation. Thirdly, the authors mention the goal to validate the encoding models generated by the previous dataset (studyforrest.org). Alongside the main goals, the authors mention the possibility to use the latest fMRI corpus as a resource for benchmarking algorithms for functional alignment. Could the authors make examples of such algorithms, ideally with references? Firstly, in my opinion the stimuli and the experimental procedures are generally clearly described, but the pre-processing of fMRI analyses could be further commented in order to allow appropriate replication. In fact, some procedures are mentioned in other papers and that would require the knowledge of previous work done by the group. To ease the readers into the topic could the authors add one/two sentences for each procedure or method that is relevant for the points made in the present manuscript? For example at page 3 a landmark-based procedure is mentioned. Could the authors briefly mention what was used as a landmark and which software or metric allowed this? Additionally, one shortcoming of the dataset is the lack of a characterization of the audio presentation. The transforms were computed on the source waveforms. However, it is not so clear what waveform arrives at the ear and how the gain adjustments scaled them. This information would be important for the investigations of neural sound encoding with this dataset. In addition, this information would be of great use for users who intend to calculate other transforms on the source waveforms. Secondarily, while the authors premises are valid in only providing a quick and preliminary analysis of the data as a quality check, it would be helpful to briefly introduce the research context behind it. A couple of sentences in the introduction would be sufficient to explain the expected activated networks for those readers that are unfamiliar with neuroimaging studies on music. Finally, it would be helpful to briefly outline which ones of the many tools are made available in the paper directly, and which ones are preparatory for future studies. For example the computation of cepstral coefficients is often used in speech recognition, to separate vocal tract from speech descriptors and to create features for recognition, but is not clear if and how they are used in the current manuscript. We are aware of the amount of work carried out by the authors, in documenting and making the material available, however the achieved goals should not be mixed with future ones. Please amend in order to outline the current state of the research framework to the general reader. Detailed comments: Abstract. What is the advantage of a slow event-related paradigm (long ISI) for this experiment? Please comment on it in the text. p.4. Some more information about the acquisition procedures and the procedures applied to the preprocessed dataset should be provided, or at least stated where they can be found (e.g. scripts in the dataset). For example a short description of the FOV, (e.g. covering temporal and inferior frontal areas of the brain) may be added in the article itself. p.5. See previous comment. A better description of the physiological recordings is needed. Are they acquired with standard Siemens sensors? p.5. Preprocessing of fMRI data. Similarly to the previous comments, it is our opinion that the authors should thoroughly describe the set of steps that lead to the subsequent analyses, despite them being already documented in other papers. Critically, having missed on this point will not facilitate the reader in the choice among three different flavors of BOLD datasets at disposal. Please add more operative details, a flow chart figure or indicate where to find them. For example, a distortion correction technique is mentioned, along with a realignment of the fMRI volumes. A template image is also mentioned. How is the template generated? Is there a slice-time correction step? Is the distortion correction applied before, after or during the realignment? p.5. In the description of the mel coefficients could the authors briefly explain the difference between DCT_II and the other flavors of the DCT algorithm (or cite a representative reference)? p.7. What is the contrast of the univariate analysis? I understand that this is a standard analysis, but in our opinion its description is missing some crucial information on how it was performed. For example: a) Id like some basic information on how the validation analyses were done: is the source code for the classification provided too? b) Given this statement "Given the confirmed wide-spread availability of genre-discriminating signal we conclude that these data are suitable for studying the representation of music and auditory features. it would be good to have a brief overview of previous studies (with references) in this field and the brain areas they usually associate with music processing + processing of different genres to facilitate understanding for readers without a background in the neurobiology of music. p.8. Figure 4 is a bit confusing. As I understand it the color code on top only refers to Figure 4a. Maybe label a) statistical analysis and b) classification analysis and use different colors in b. The legend refers to a small symphonic music cluster in RIFG which I cannot identify on the actual brain images. Minor comments Abstract and p.2. The term quality control might be slightly misleading. One could just state that basic GLM and MVPA analyses were conducted as a proof of principle of effective classification on the data. p.3 Correct the sentence continuum of research question into questions p.3 Participants: which of the functional scans was done first? p.4 Were the sound adjustments done only once at the beginning of the experiment or for every functional run? Is the level of the sound adjustment documented in the material? p.5 Correct the sentence flag whether a control question with presented into was presented p.5 As the exact same alignment target was used, this led to a very similar field-of view configuration across acquisitions. Somewhat unclear. Does this mean that the subjects head was in the same position in both experiments (i.e. voxels match functionally) or does it mean that the FOV was in the same scanners coordinates? It is unlikely that both conditions are met simultaneously. p.5 While raw BOLD data are suitable for further analysis, they suffer from severe geometric distortions. BOLD data that have been distortion-corrected9 at the scanner console are provided in bold_dico.nii.gz. Please provide more information about the correction (e.g. k-space or voxel space correction). Is it documented? Is all information that was used available in the dataset? Users may want to apply their own correction p.5 A log file of the automated conversion procedure is provided in the same directory (conversion.log). Conversion of what? p.5 Audio features Are the sound files provided with the dataset? You might want to state that here. Otherwise state how the user could obtain them to apply their own transforms. It would be important to characterize the sound presentation system. The transforms were calculated on the sound files but it is not so clear what actually reached the ear and how the genres might have differed in energy etc. This is information could greatly extend the usefulness of this rich dataset. p.5 frequency domain filter bank Are the parameters provided? If yes, mention that here. p.5 The description of the audio features reports a highest signal frequency of ~22KHz but the signals in figure 1 show a clear decrease in gain for all stimuli after ~16KHz. Could the authors document what the sampling frequency of the audio waves was and if a low pass filter was applied? 