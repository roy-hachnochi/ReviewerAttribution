High quality curation by trained database curators is needed in our community to convert the literature to computable models, but it is difficult to imagine how manual curation will scale to handle the ever-growing data generation rate in biology. Thus, the biological research community needs to figure out how to get crowdsourcing working for everyone as a tool to improve access to computable data. This paper does a very good job of describing how a set of COPD networks were constructed and enhanced (they grew in size and level of detail) through an interesting three-phase process. However, it would be useful to better describe the utility of the resulting networks and to further analyze the crowdsourcing process itself. Addressing these points will give the work a broader impact. Utility of networks: It is not clear what advantages the use of causal networks brings compared to more established models in the community, such as molecular interaction networks used by many algorithms (e.g. gene function prediction, module detection, interpretation of molecular profile data, network biomarkers) or detailed biochemical pathway models (used by most textbooks and pathway databases). While many results are published in terms of causal networks (e.g. A activates B), one important issue with networks constructed by collecting these relationships is that they may be difficult to integrate across resources since they are context specific: A may activate B in the lung, but inhibit B in the heart and when these are integrated, a conflict arises. Many computational analysis methods require integration of networks from multiple sources to construct the largest available network and integrate this data with disease-specific molecular profile data (e.g. gene expression data) to gain context (as it seems is done in the RCR approach). It would be useful for the authors to further discuss the utility of context-specific causal networks for follow on discovery. I only noticed one sentence mentioning use: By building the network model set in the BEL language format, we have generated a model framework suitable for biomarker discovery and for the interpretation of transcriptomic signatures found in human lung tissue. However, this sentence is not clear and doesnt cite any prior literature. How does using the BEL format create models suitable for biomarker discovery? Cant molecular interaction or other types of networks also be used for biomarker discovery? What type of biomarker discovery is referred to here? How are transcriptomic signatures interpreted and analyzed? Crowdsourcing comments: Networks that were not enhanced with COPD-specific mechanisms from the literature or RCR included the DNA Damage and Notch Signaling networks. Although both these networks relevant to the development of COPD, they were not augmented beyond the original, non-diseased network scaffolds, because no studies on the differences in signaling between non-diseased and diseased states were available. How do the authors know that no relevant studies were available? It seems that many papers at least have discussed links between COPD and DNA damage or Notch signaling (e.g. PMID: 19106307 published in 2009 Down-regulation of the notch pathway in human airway epithelium in association with smoking and chronic obstructive pulmonary disease.) In total, 12 new nodes and 28 new edges were added to the Th1-Th2 Signaling network model during the jamboree discussions, thereby creating a comprehensive biological network of T-helper cell activity and their interactions with other immune cells in the context of COPD. How is measured? How do we know how much of the available literature was covered by the crowdsource process? That is, what is the sensitivity of the crowdsourcing process? How many contributors were involved in enhancing each network in phase 2? Where were they from e.g. academia, industry? What incentivized them to contribute for instance, were they COPD researchers? For the sake of research into crowdsourcing in biology, it would be very useful to provide additional analysis of the contributor community. We need to learn more about what works and what doesnt in crowdsourcing initiatives so future generations of these approaches can be improved. The authors state With nearly 900 new pieces of evidence added by the challenge crowd, a significant overall enhancement of the networks was achieved in a relatively short time (5 months), How many papers (PMIDs) supported the 900 pieces of evidence? Questions about use of BEL: Figure 4. The shorthand BEL notation is not widely recognized as a visual format and difficult to read in general. An easy to read visualization format would make the network figures much easier to understand. Also, what do the different edge end symbols (e.g. arrow, dot, diamond) mean? Part C of Figure 1 mentions BEL to openBEL conversion. Whats the difference between BEL and openBEL? Other comments: A broader review of the literature of pathway databases and crowdsourcing efforts should be included in the introduction.