This data note describes a dataset consisting of time indices and annotations for the emotional content of scenes from the movie Forest Gump. The primary intent of this dataset is to encourage analyses of real-world cognition during the viewing of naturalistic stimuli and, as such, it is meant to accompany a previously released dataset of functional neuroimaging data using the same movie stimulus as used here. I have only minor quibbles: The authors may wish to indicate which observers were familiar with the movie prior to annotation. I recommend adding a section in which the authors discuss some of the potential issues that may limit the correspondence between the emotion annotation dataset and the neuroimaging dataset of the same movie. Specifically, the use of random scene order during annotation (but not during movie viewing) or the gender split among observers who annotated the audio movie and those that annotated the audiovisual movie. At the expense of looking a gift horse in the mouth, an ipython notebook capable of generating all figures and descriptive data would have been marginally preferable to a script. Finally, I would like to note that the release of this dataset along with the associated neuroimaging data previously released by members of this group represents an extremely generous sharing of resources. I commend the effort and look forward to seeing what emerges from researchers looking into this treasure trove of data.