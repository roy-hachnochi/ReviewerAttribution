The sample is a convenience sample based only on one year and one subject field (health sciences), with a predominantly journal- and English-based publication culture. The authors describe their first objective as "Explore the coverage, precision, and characteristics of publications matched versus not matched with UIDs as the match key", after introducing the more general goal to investigate "how well UIDs work for citation linking" (p.3). In order to truly answer the goals and objectives, the hypothesis should be discussed and tested that implementation of UIDs may vary across disciplines, depending on the amount of e.g. smaller, regional journals and easy data import options for a system like Pure from, e.g. PubMed. In this perspective a careful sampling strategy representative for all subjects that are, to a varying extent, covered in the target database SciVal/Scopus as well as more publication years, would have been much more fruitful in order to assess the coverage and thus usability of UIDs in both systems. Thus, data from a university-wide implementation of Pure would make up a reasonable case study. The authors deal inconsistently with this issue as they try to rectify their sample on the one hand "As this type of publication and the health sciences are well-covered in Scopus/SciVal [...], we expected the DoCM publication set to be well-fitted for our purpose, namely to explore the citation linking process, rather than how well SciVal covers publications from a department" (p.4) - which is a non-adequate argument as the coverage could be considered separately. On the other hand, they concede that their "case study" may not lead to generalizable results and that results will therefore be compared to those from a literature review (p.4). This claim, however, is not really fulfilled, as the studies mentioned in the literature review use UIDs for different purposes, constellations and databases. More importantly, no real comparison takes place, as the authors only recap "but all conclude that UIDs do not cover all records in the databases" (p.6). In order to contextualize their own results, concrete settings and results of other studies should be represented and discussed. With regard to the second purpose "Illustrate how publication sets formed by using UIDs as the match key may affect the bibliometric indicators: Number of publications, number of citations and the average number of citations per publication", the authors do not actually calculate citation indicators including and excluding publications (which are covered, but could not be matched via UIDs), but discuss the problem mostly theoretically. I would strongly suggest expanding the initial sample to other fields. Thus, title and abstract information do - in my opinion - not reflect the actual limits of the study adequately. Methods and data (with exceptions mentioned separately below) are sufficiently clearly documented, but the whole study lacks generalizability and, partly, elaborateness of analyses, as in case of the citation indicator perspective. Besides, given the rather manageable amounts of unmatched publications in this study, a comprehensive and more elaborate search and analysis of the causes of the missed match (not covered, missing UID in Scopus, ..) would be preferable. In larger corpora, this could be done via a random sample. In the introduction and literature review, it should be made clearer that the authors use a specific definition of the term citation linking (linking items between databases) for their study and it should be clarified if other studies refer to the same or other scenarios (like reference matching or deduplication). The authors write "In the integration between Pure and SciVal DOI, PMID and EID are used as match keys for citation linking. From March 2016 the integration between Pure and SciVal is based on EID alone. This will not affect the present study as we analyze publication sets downloaded in August and December 2015" (p.3). The authors should discuss what this does mean with respect of the relevance of their results. Could it mean that the matching of current publications will be probably better? Regarding the publication type categorization: Has the categorization been informed by some available classification or, e.g. database scheme? In my opinion, some mappings are sub-optimal and particular; especially the assignment of Doctoral Thesis to "Other" instead of "Book", Encyclopedia chapter to "Other" instead of "Contribution to Book", Editorial to "Other" instead of "Journal", Article in Proceedings to "Journal" instead of "Contribution to Book" (please compare the WoS document type and publication type classification for the third and fourth case). Including so many and different publication types in a residual category is unprofitable for the later analysis. I did not understand the fact that EIDs seem to have been attributed automatically without being visible in the raw data. How?