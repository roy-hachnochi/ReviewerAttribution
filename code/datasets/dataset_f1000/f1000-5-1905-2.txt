The authors describe the BRISSKit, a software infrastructure for biomedical research consisting of several open-source applications. The applications have been virtualised and deployed in a cloud environment, as well as wrapped in layers with custom APIs to allow for inter-application communication. This aims to make use of open source software more viable for researchers, by solving problems of installation, maintenance, hosting and application integration, while also taking into account information security and encapsulation. The authors have also ensured that BRISSKit remains independent of any specific cloud infrastructure vendor, ensuring portability. The authors address an important problem and provide a valuable study on how open source software can successfully be deployed, integrated and used as a service in the biomedical research domain. The scenario being studied is described in considerable detail and has clear practical value, and the source code is publicly available. As such, I believe that the paper and the toolkit is a nice contribution and should be published. However, I have some concerns that the authors might address. Improving the ease of access, configuration, integration and use of open source software is a worthy goal. The drudgery of configuration and integration may certainly represent a significant barrier to adoption in many cases, and supplying the software as a service has potential to go a long way towards removing these barriers. Many X-as-a service offerings exist, and it would be useful to define more precisely which area the framework targets. For example, what are the essential needs of biomedical, as opposed to other, kinds of research? What are the essential needs of research software and infrastructure as opposed to infrastructure targeting other kinds of users or activities? If this is clearly stated, it becomes easier to evaluate the approach. I believe that one essential concern in research software - as opposed to, say, industrial or consumer oriented software - is that method innovation may be a routine part of everyday work, as research goes hand in hand with method and tools development. This method innovation may often include changes or enhancements to software. Thus, while it is important to remove inessential tedious procedures that act as barriers to adoption, it is equally important that customisation, extension and tinkering is possible, even for unsophisticated users, if the framework is to have maximal relevance and impact. Ideally, the framework should provide convenience without erecting any new barriers. Thus, I would like to see a discussion of the amount of effort needed to add new applications to an existing BRISSKit installation, or to make customisations or modifications, from the point of view of a small research group with modest resources and software skills. It is important that this autonomy is not lost if researchers choose to depend on service/cloud-based offerings for their basic infrastructure. Alternatively, if BRISSKit is only intended for research scenarios where the software methodology has been fixed in advance, then this should be made clear. One of the main difficulties that seems to remain in deploying and using multiple software applications in concert, even after the BRISSKit methodology has been adopted, is making applications talk to each other. BRISSKit solves this by dividing the applications into layers and specifying that each layer only has to talk to adjacent layers. It is not clear to me that the layer model is always applicable (unless BRISSKit specifically only targets environments that need the three layers of management, data collection and data warehousing - in which case this should be stated). What would be a good architecture if the three-layer model does not apply in some scenario? There is also a lack of standards or guidelines for the API design, which would mean in the worst case that the integration problem is not solved, only transposed into the problem of API design and development. It would be useful to see some design principles here. In general, I think it would be good to state the scope of the BRISSkit design more precisely and explicitly. While the paper does describe the framework in detail, its success with respect to the stated objectives is not evaluated - for example, from the point of view of users and researchers. The authors do mention that another publication with use cases is forthcoming, but I believe that this paper would benefit from at least a brief evaluation or theoretical justification of BRISSKitâ€™s success in meeting the stated objectives.