The authors were very responsive to the previous round of reviews, including more robust cross-validation and cross-study validation and comparison with other classifiers. Particular concerns remain that the author’s conclusions that it is inappropriate to perform cross-study validation due to batch effects are incorrect, particularly since this challenging task is essential to assess overfitting and for clinical translation of classifiers. In addition, the conclusion was insufficiently revised to place their classifier in the context of the broader literature in this field. Methods Abbreviations SVM and RF must be spelled out as Support Vector Machine and Random Forest on first use. This was not addressed in the revised methods section. Results The authors did perform a robust cross-study validation, as requested in the previous review. We agree this is challenging, due in part to batch effects as reported in this manuscript. However, such cross-study validation is essential to assess the accuracy of classifiers. It is also essential to have translation of genomic signatures into the clinic, where even different assays may be used. To address these concerns the authors must do the following: (a) Remove the sentence “This heterogeneity indicates that it is inappropriate to test our gene expression signatures derived by one of these datasets using the other dataset.” (b) Discuss the importance of cross-study validation, challenges in this application, and potential of overfitting of suggested by these results. The author’s response that specific therapies were not provided in METABRIC is incorrect. According to Curtis et al. , (2012) “Nearly all oestrogen receptor (ER)-positive and/or lymph node (LN)-negative patients did not receive chemotherapy, whereas ER-negative and LN-positive patients did. Additionally, none of the HER2 + patients received trastuzumab. As such, the treatments were homogeneous with respect to clinically relevant groupings.” Therefore, the previous criticism #12 remains. Covariates such as ER/HER2/LN or PAM50 subtypes must be included in a table describing the sample cohorts remains. In addition, accuracy must be computed separately for these co-variates or included in the machine learning model. Conclusion The discussion is insufficient. It still lacks sufficient context of existing genomics classifiers in the literature. The discrepancy between their algorithm and clinical assays is confusing in revised sentence “Unlike Mammaprint and Oncotype Dx tests, this model focuses on predicting survival prediction based on gene expression in the tumor, presumably before or during drug therapy.” As written, it appears to disregard the long history of predicting clinical outcome from gene expression involved in developing these classifiers from gene expression data (e.g., van't Veer et al., 2002) into clinical assays based upon expression of smaller numbers of genes. Based on the previous review, the authors include context with other predictions of the METABRIC data in the response to the reviewers. This must also be included in the Conclusion to assess the relevance of their findings in the literature. References 1. Curtis C, Shah SP, Chin SF, Turashvili G, et al.: The genomic and transcriptomic architecture of 2,000 breast tumours reveals novel subgroups. Nature . 2012; 486 (7403): 346-52 PubMed Abstract | Publisher Full Text 2. van 't Veer LJ, Dai H, van de Vijver MJ, He YD, et al.: Gene expression profiling predicts clinical outcome of breast cancer. Nature . 2002; 415 (6871): 530-6 PubMed Abstract | Publisher Full Text Competing Interests: No competing interests were disclosed. I confirm that I have read this submission and believe that I have an appropriate level of expertise to confirm that it is of an acceptable scientific standard, however I have significant reservations, as outlined above. Close READ LESS CITE CITE HOW TO CITE THIS REPORT Fertig EJ. Reviewer Report For: Predicting Outcomes of Hormone and Chemotherapy in the Molecular Taxonomy of Breast Cancer International Consortium (METABRIC) Study by Biochemically-inspired Machine Learning [version 3; peer review: 2 approved] . F1000Research 2017, 5 :2124 ( https://doi.org/10.5256/f1000research.11525.r19727 ) The direct URL for this report is: https://f1000research.com/articles/5-2124/v2#referee-response-19727 NOTE: it is important to ensure the information in square brackets after the title is included in all citations of this article. COPY CITATION DETAILS Report a concern Author Response 12 May 2017 Peter Rogan , University of Western Ontario, London, Canada 12 May 2017 Author Response Methods Comment 1. Abbreviations SVM and RF must be spelled out as Support Vector Machine and Random Forest on first use. This was not addressed in the revised methods section. Response: These abbreviations ... Continue reading Methods Comment 1. Abbreviations SVM and RF must be spelled out as Support Vector Machine and Random Forest on first use. This was not addressed in the revised methods section. Response: These abbreviations are now spelled out upon their first use in the main text (Methods section). Results Comment 2. The authors did perform a robust cross-study validation, as requested in the previous review. We agree this is challenging, due in part to batch effects as reported in this manuscript. However, such cross-study validation is essential to assess the accuracy of classifiers. It is also essential to have translation of genomic signatures into the clinic, where even different assays may be used. To address these concerns the authors must do the following: (a) Remove the sentence “This heterogeneity indicates that it is inappropriate to test our gene expression signatures derived by one of these datasets using the other dataset.” (b) Discuss the importance of cross-study validation, challenges in this application, and potential of overfitting of suggested by these results. Response: In regards to this point: (a) This sentence has been removed, as requested. (b) To address concerns regarding potential overfitting of our models, we cross-validate the acquired models to a non-METABRIC data set (from an independent study). In the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge, cross-study validation was performed using the “OsloVal” data set, which consists of gene expression and copy number data from 184 breast cancer patients (Margolin et al. , 2013). However, this dataset is not publically available and requires Ethics Board / IRB Review which we did not believe to be worth the effort. Instead, we performed cross-study validation on the gene expression of 310 breast cancer patients made publically available by Hatzis et al. (2011). Analysis of this dataset was successful for the mRMR + SVM models developed using chemotherapy-treated patient (“CT” models), where the threshold for resistance was set to 3-years and 4-years. The “CT 3-year” model performed well predicting responsive patients (74.2% accuracy), while the “CT 4-year” model performed better predicting non-responsive patients (75.1% accuracy). The “CT 4-year” model outperformed the “CT 5-year” model for both sensitive and resistant patient data sets. Random Forest and mRMR+SVM models which used hormone-treated patients (“HT” and “CT+HT”) were much less accurate compared to the “CT-only” models, and predict patients a large percentage of patients from the Hatzis data as sensitive. In the main manuscript, we have replaced the removed sentence from (a) and have written the following: “Cross-study validation allows for the comparison of classification accuracy between the generated gene signatures. The observed heterogeneity in gene expression highlights one of the many challenges of cross-validation of gene signatures between these data from the same study exhibit drastic differences (for example, BCL2L1 ; Supplementary file 2). Furthermore, these gene expression differences also affect the performance of these methods when these datasets were combined (compare Table 2 and Table 4 for RF; Table 3 and Table 5 for mRMR). We considered the possibility that the Discovery model might be subject to overfitting. We therefore performed cross-study validation of the Discovery set-signature with an independently-derived dataset (319 invasive breast cancer patients treated with paclitaxel and anthracycline chemotherapy 5 ). The mRMR+SVM CT-models performed well (4-year threshold model had an overall accuracy of 68.7%; 3-year threshold model exhibited lower overall accuracy [52%], but was significantly better at predicting patients in remission [74.2%]).” References Margolin AA, et al. Systematic analysis of challenge-driven improvements in molecular prognostic models for breast cancer. Sci Transl Med. 2013 Apr 17;5(181):181re1. doi: 10.1126/scitranslmed.3006112. Hatzis, C., et al. 2011. A genomic predictor of response and survival following taxane-anthracycline chemotherapy for invasive breast cancer. JAMA. 305, 1873–1881. Comment 3. The author’s response that specific therapies were not provided in METABRIC is incorrect. According to Curtis et al., (2012) “Nearly all oestrogen receptor (ER)-positive and/or lymph node (LN)-negative patients did not receive chemotherapy, whereas ER-negative and LN-positive patients did. Additionally, none of the HER2 + patients received trastuzumab. As such, the treatments were homogeneous with respect to clinically relevant groupings.” Therefore, the previous criticism #12 remains. Covariates such as ER/HER2/LN or PAM50 subtypes must be included in a table describing the sample cohorts remains. In addition, accuracy must be computed separately for these co-variates or included in the machine learning model. Response: Thank you for the clarification regarding patient treatment. As a response, we have added an additional supplementary table which breaks down the accuracy of our models by subtype (ER, HER2, PR, LN and PAM50; Dataset 2). In the main text, we note that accuracy of most models are consistent between subtypes (+/- 10% deviation in accuracy). Subtypes with less than twenty individuals were ignored due to its small sample size. The following deviations in accuracy were noted: Random Forest and mRMR models are shown to be consistently more accurate in predicting ER+, HER2- when treated with hormone therapy (both “HT” and “CT and/or HT” categories), when compared to ER- and HER2+ patients. The PAM50 basal subtype is consistently low in accuracy when testing patients treated with hormone therapy. This is most likely partially influenced by the RF and mRMR models for ‘HT’ to more often predict patients as sensitive, combined with the fact that ER+ and HER2- patients were more likely to response to therapy. It is important to note that the accuracy of predictions by RF and mRMR with patients treated only with chemotherapy was fairly consistent across all available subtypes (+/- 10% accuracy). SVM paclitaxel models performed significantly better with HER2+ patients (26 correct, 3 misclassified; 90% accurate) in HER2- patients (40 correct, 15 misclassified; 73% accurate) when tested on patients treated with both hormone and chemotherapy. In Dorman et al (2016), it was stated that MAPT expression (which is present in the paclitaxel model) segregated with PAM50 luminal and basal subtypes. For this model, the accuracies of these subtypes are nearly identical to the accuracy of the entire subset. Text describing these results can be found in the third paragraph of the results. Conclusion Comment 4. The discussion is insufficient. It still lacks sufficient context of existing genomics classifiers in the literature. The discrepancy between their algorithm and clinical assays is confusing in revised sentence: “Unlike Mammaprint and Oncotype Dx tests, this model focuses on predicting survival prediction based on gene expression in the tumor, presumably before or during drug therapy.” As written, it appears to disregard the long history of predicting clinical outcome from gene expression involved in developing these classifiers from gene expression data (e.g., van't Veer et al., 2002) into clinical assays based upon expression of smaller numbers of genes. Response: We have removed the indicated sentence, which we agree was insufficient to the comment from the previous iteration of this article: “Must be discussed in the context of existing genomics classifiers for breast cancer (e.g., OncotypeDx and/or Mammaprint)”. We in no way meant to ignore the long history of predicting clinical outcome from gene expression (as well as other genomic factors). A discussion on this topic was not included in earlier submissions as it initially had an imposed word length limit (upon first submission). We did, however, reference other articles which do discuss this topic. In Dorman et al. (2016), which described some of the methodology for initial gene selection that this study was based on, these contributions are well-referenced, including the history of the prediction of clinical outcome from genomic status: “Previous studies have derived associations between the genomic status of one or more genes and tumor response to certain therapies (Duan et al. , 2003; Glinsky et al. , 2005; Hatzis et al. , 2011; Ma et al. , 2004; Rajput et al. , 2013; van't Veer et al. , 2002). Correlations between single gene expression and tumor resistance (Duan et al. , 2003, 1999) do not take into account multiple mechanisms of resistance or assess interactions between multiple genes. ABC transporter overexpression has long been shown to confer resistance, but enzymatic or functional inhibition has not substantially improve patient response to chemotherapy (Samuels et al. , 1997). Multi-gene analytical approaches have previously been successful in deriving prognostic gene signatures for metastatic risk stratification (Oncotype DX™, MammaPrint ), subtypes (PAM50), and efforts have been made to predict chemotherapy resistance (Hess et al. , 2006; Hatzis et al. , 2011). “ In response to Dr. Fertig’s comments, we have added a short discussion with citations of previously published approaches (including MammaPrint and Oncotype DX): “Genomic information has been shown to correlate with tumor therapy response in previous studies 5,12-16 . From these studies, analytical methods have been used to develop gene signatures for chemotherapy resistance prediction 5 , subtypes (PAM50), and metastatic risk stratification (Oncotype DX™, MammaPrint ).” Comment 5. Based on the previous review, the authors include context with other predictions of the METABRIC data in the response to the reviewers. This must also be included in the Conclusion to assess the relevance of their findings in the literature. Response: We have added the indicated text from the previous ‘response to the reviewers’ (modified) to the Conclusions: “We also examined the method exhibiting the best performance in the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge 17 , which was also phenotype-based, however it produces outcome signatures based on molecular processes, rather than the cancer drugs themselves. While interesting and informative, the results cannot be directly compared.” Please note that the majority of entries in the DREAM project were not fully curated and only exist as source code. Analyzing these files to determine what methodology was attempted by these groups is beyond the scope of our study. A description of the second place of the METABRIC phase of the DREAM challenge is provided in the link below. This link describes how the METABRIC data is trained using a bipartite graphing as input for linear models, boost models, and RankSVM. While they state that RankSVM was the least successful between the three methods, it does not appear that this particular study has been published to the literature. As a result, we cannot fully review their results, and thus cannot be compared to our methodology in the main manuscript. https://sagesynapse.wordpress.com/2012/11/01/breast-cancer-challenge-team-pitttransmed-places-second-for-metabric-phase-of-the-challenge/ Methods Comment 1. Abbreviations SVM and RF must be spelled out as Support Vector Machine and Random Forest on first use. This was not addressed in the revised methods section. Response: These abbreviations are now spelled out upon their first use in the main text (Methods section). Results Comment 2. The authors did perform a robust cross-study validation, as requested in the previous review. We agree this is challenging, due in part to batch effects as reported in this manuscript. However, such cross-study validation is essential to assess the accuracy of classifiers. It is also essential to have translation of genomic signatures into the clinic, where even different assays may be used. To address these concerns the authors must do the following: (a) Remove the sentence “This heterogeneity indicates that it is inappropriate to test our gene expression signatures derived by one of these datasets using the other dataset.” (b) Discuss the importance of cross-study validation, challenges in this application, and potential of overfitting of suggested by these results. Response: In regards to this point: (a) This sentence has been removed, as requested. (b) To address concerns regarding potential overfitting of our models, we cross-validate the acquired models to a non-METABRIC data set (from an independent study). In the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge, cross-study validation was performed using the “OsloVal” data set, which consists of gene expression and copy number data from 184 breast cancer patients (Margolin et al. , 2013). However, this dataset is not publically available and requires Ethics Board / IRB Review which we did not believe to be worth the effort. Instead, we performed cross-study validation on the gene expression of 310 breast cancer patients made publically available by Hatzis et al. (2011). Analysis of this dataset was successful for the mRMR + SVM models developed using chemotherapy-treated patient (“CT” models), where the threshold for resistance was set to 3-years and 4-years. The “CT 3-year” model performed well predicting responsive patients (74.2% accuracy), while the “CT 4-year” model performed better predicting non-responsive patients (75.1% accuracy). The “CT 4-year” model outperformed the “CT 5-year” model for both sensitive and resistant patient data sets. Random Forest and mRMR+SVM models which used hormone-treated patients (“HT” and “CT+HT”) were much less accurate compared to the “CT-only” models, and predict patients a large percentage of patients from the Hatzis data as sensitive. In the main manuscript, we have replaced the removed sentence from (a) and have written the following: “Cross-study validation allows for the comparison of classification accuracy between the generated gene signatures. The observed heterogeneity in gene expression highlights one of the many challenges of cross-validation of gene signatures between these data from the same study exhibit drastic differences (for example, BCL2L1 ; Supplementary file 2). Furthermore, these gene expression differences also affect the performance of these methods when these datasets were combined (compare Table 2 and Table 4 for RF; Table 3 and Table 5 for mRMR). We considered the possibility that the Discovery model might be subject to overfitting. We therefore performed cross-study validation of the Discovery set-signature with an independently-derived dataset (319 invasive breast cancer patients treated with paclitaxel and anthracycline chemotherapy 5 ). The mRMR+SVM CT-models performed well (4-year threshold model had an overall accuracy of 68.7%; 3-year threshold model exhibited lower overall accuracy [52%], but was significantly better at predicting patients in remission [74.2%]).” References Margolin AA, et al. Systematic analysis of challenge-driven improvements in molecular prognostic models for breast cancer. Sci Transl Med. 2013 Apr 17;5(181):181re1. doi: 10.1126/scitranslmed.3006112. Hatzis, C., et al. 2011. A genomic predictor of response and survival following taxane-anthracycline chemotherapy for invasive breast cancer. JAMA. 305, 1873–1881. Comment 3. The author’s response that specific therapies were not provided in METABRIC is incorrect. According to Curtis et al., (2012) “Nearly all oestrogen receptor (ER)-positive and/or lymph node (LN)-negative patients did not receive chemotherapy, whereas ER-negative and LN-positive patients did. Additionally, none of the HER2 + patients received trastuzumab. As such, the treatments were homogeneous with respect to clinically relevant groupings.” Therefore, the previous criticism #12 remains. Covariates such as ER/HER2/LN or PAM50 subtypes must be included in a table describing the sample cohorts remains. In addition, accuracy must be computed separately for these co-variates or included in the machine learning model. Response: Thank you for the clarification regarding patient treatment. As a response, we have added an additional supplementary table which breaks down the accuracy of our models by subtype (ER, HER2, PR, LN and PAM50; Dataset 2). In the main text, we note that accuracy of most models are consistent between subtypes (+/- 10% deviation in accuracy). Subtypes with less than twenty individuals were ignored due to its small sample size. The following deviations in accuracy were noted: Random Forest and mRMR models are shown to be consistently more accurate in predicting ER+, HER2- when treated with hormone therapy (both “HT” and “CT and/or HT” categories), when compared to ER- and HER2+ patients. The PAM50 basal subtype is consistently low in accuracy when testing patients treated with hormone therapy. This is most likely partially influenced by the RF and mRMR models for ‘HT’ to more often predict patients as sensitive, combined with the fact that ER+ and HER2- patients were more likely to response to therapy. It is important to note that the accuracy of predictions by RF and mRMR with patients treated only with chemotherapy was fairly consistent across all available subtypes (+/- 10% accuracy). SVM paclitaxel models performed significantly better with HER2+ patients (26 correct, 3 misclassified; 90% accurate) in HER2- patients (40 correct, 15 misclassified; 73% accurate) when tested on patients treated with both hormone and chemotherapy. In Dorman et al (2016), it was stated that MAPT expression (which is present in the paclitaxel model) segregated with PAM50 luminal and basal subtypes. For this model, the accuracies of these subtypes are nearly identical to the accuracy of the entire subset. Text describing these results can be found in the third paragraph of the results. Conclusion Comment 4. The discussion is insufficient. It still lacks sufficient context of existing genomics classifiers in the literature. The discrepancy between their algorithm and clinical assays is confusing in revised sentence: “Unlike Mammaprint and Oncotype Dx tests, this model focuses on predicting survival prediction based on gene expression in the tumor, presumably before or during drug therapy.” As written, it appears to disregard the long history of predicting clinical outcome from gene expression involved in developing these classifiers from gene expression data (e.g., van't Veer et al., 2002) into clinical assays based upon expression of smaller numbers of genes. Response: We have removed the indicated sentence, which we agree was insufficient to the comment from the previous iteration of this article: “Must be discussed in the context of existing genomics classifiers for breast cancer (e.g., OncotypeDx and/or Mammaprint)”. We in no way meant to ignore the long history of predicting clinical outcome from gene expression (as well as other genomic factors). A discussion on this topic was not included in earlier submissions as it initially had an imposed word length limit (upon first submission). We did, however, reference other articles which do discuss this topic. In Dorman et al. (2016), which described some of the methodology for initial gene selection that this study was based on, these contributions are well-referenced, including the history of the prediction of clinical outcome from genomic status: “Previous studies have derived associations between the genomic status of one or more genes and tumor response to certain therapies (Duan et al. , 2003; Glinsky et al. , 2005; Hatzis et al. , 2011; Ma et al. , 2004; Rajput et al. , 2013; van't Veer et al. , 2002). Correlations between single gene expression and tumor resistance (Duan et al. , 2003, 1999) do not take into account multiple mechanisms of resistance or assess interactions between multiple genes. ABC transporter overexpression has long been shown to confer resistance, but enzymatic or functional inhibition has not substantially improve patient response to chemotherapy (Samuels et al. , 1997). Multi-gene analytical approaches have previously been successful in deriving prognostic gene signatures for metastatic risk stratification (Oncotype DX™, MammaPrint ), subtypes (PAM50), and efforts have been made to predict chemotherapy resistance (Hess et al. , 2006; Hatzis et al. , 2011). “ In response to Dr. Fertig’s comments, we have added a short discussion with citations of previously published approaches (including MammaPrint and Oncotype DX): “Genomic information has been shown to correlate with tumor therapy response in previous studies 5,12-16 . From these studies, analytical methods have been used to develop gene signatures for chemotherapy resistance prediction 5 , subtypes (PAM50), and metastatic risk stratification (Oncotype DX™, MammaPrint ).” Comment 5. Based on the previous review, the authors include context with other predictions of the METABRIC data in the response to the reviewers. This must also be included in the Conclusion to assess the relevance of their findings in the literature. Response: We have added the indicated text from the previous ‘response to the reviewers’ (modified) to the Conclusions: “We also examined the method exhibiting the best performance in the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge 17 , which was also phenotype-based, however it produces outcome signatures based on molecular processes, rather than the cancer drugs themselves. While interesting and informative, the results cannot be directly compared.” Please note that the majority of entries in the DREAM project were not fully curated and only exist as source code. Analyzing these files to determine what methodology was attempted by these groups is beyond the scope of our study. A description of the second place of the METABRIC phase of the DREAM challenge is provided in the link below. This link describes how the METABRIC data is trained using a bipartite graphing as input for linear models, boost models, and RankSVM. While they state that RankSVM was the least successful between the three methods, it does not appear that this particular study has been published to the literature. As a result, we cannot fully review their results, and thus cannot be compared to our methodology in the main manuscript. https://sagesynapse.wordpress.com/2012/11/01/breast-cancer-challenge-team-pitttransmed-places-second-for-metabric-phase-of-the-challenge/ Competing Interests: PKR cofounded Cytognomix. A patent application related to biologically inspired gene signatures is pending. The other authors declare that they have no competing interests. Close Report a concern Respond or Comment COMMENTS ON THIS REPORT Author Response 12 May 2017 Peter Rogan , University of Western Ontario, London, Canada 12 May 2017 Author Response Methods Comment 1. Abbreviations SVM and RF must be spelled out as Support Vector Machine and Random Forest on first use. This was not addressed in the revised methods section. Response: These abbreviations ... Continue reading Methods Comment 1. Abbreviations SVM and RF must be spelled out as Support Vector Machine and Random Forest on first use. This was not addressed in the revised methods section. Response: These abbreviations are now spelled out upon their first use in the main text (Methods section). Results Comment 2. The authors did perform a robust cross-study validation, as requested in the previous review. We agree this is challenging, due in part to batch effects as reported in this manuscript. However, such cross-study validation is essential to assess the accuracy of classifiers. It is also essential to have translation of genomic signatures into the clinic, where even different assays may be used. To address these concerns the authors must do the following: (a) Remove the sentence “This heterogeneity indicates that it is inappropriate to test our gene expression signatures derived by one of these datasets using the other dataset.” (b) Discuss the importance of cross-study validation, challenges in this application, and potential of overfitting of suggested by these results. Response: In regards to this point: (a) This sentence has been removed, as requested. (b) To address concerns regarding potential overfitting of our models, we cross-validate the acquired models to a non-METABRIC data set (from an independent study). In the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge, cross-study validation was performed using the “OsloVal” data set, which consists of gene expression and copy number data from 184 breast cancer patients (Margolin et al. , 2013). However, this dataset is not publically available and requires Ethics Board / IRB Review which we did not believe to be worth the effort. Instead, we performed cross-study validation on the gene expression of 310 breast cancer patients made publically available by Hatzis et al. (2011). Analysis of this dataset was successful for the mRMR + SVM models developed using chemotherapy-treated patient (“CT” models), where the threshold for resistance was set to 3-years and 4-years. The “CT 3-year” model performed well predicting responsive patients (74.2% accuracy), while the “CT 4-year” model performed better predicting non-responsive patients (75.1% accuracy). The “CT 4-year” model outperformed the “CT 5-year” model for both sensitive and resistant patient data sets. Random Forest and mRMR+SVM models which used hormone-treated patients (“HT” and “CT+HT”) were much less accurate compared to the “CT-only” models, and predict patients a large percentage of patients from the Hatzis data as sensitive. In the main manuscript, we have replaced the removed sentence from (a) and have written the following: “Cross-study validation allows for the comparison of classification accuracy between the generated gene signatures. The observed heterogeneity in gene expression highlights one of the many challenges of cross-validation of gene signatures between these data from the same study exhibit drastic differences (for example, BCL2L1 ; Supplementary file 2). Furthermore, these gene expression differences also affect the performance of these methods when these datasets were combined (compare Table 2 and Table 4 for RF; Table 3 and Table 5 for mRMR). We considered the possibility that the Discovery model might be subject to overfitting. We therefore performed cross-study validation of the Discovery set-signature with an independently-derived dataset (319 invasive breast cancer patients treated with paclitaxel and anthracycline chemotherapy 5 ). The mRMR+SVM CT-models performed well (4-year threshold model had an overall accuracy of 68.7%; 3-year threshold model exhibited lower overall accuracy [52%], but was significantly better at predicting patients in remission [74.2%]).” References Margolin AA, et al. Systematic analysis of challenge-driven improvements in molecular prognostic models for breast cancer. Sci Transl Med. 2013 Apr 17;5(181):181re1. doi: 10.1126/scitranslmed.3006112. Hatzis, C., et al. 2011. A genomic predictor of response and survival following taxane-anthracycline chemotherapy for invasive breast cancer. JAMA. 305, 1873–1881. Comment 3. The author’s response that specific therapies were not provided in METABRIC is incorrect. According to Curtis et al., (2012) “Nearly all oestrogen receptor (ER)-positive and/or lymph node (LN)-negative patients did not receive chemotherapy, whereas ER-negative and LN-positive patients did. Additionally, none of the HER2 + patients received trastuzumab. As such, the treatments were homogeneous with respect to clinically relevant groupings.” Therefore, the previous criticism #12 remains. Covariates such as ER/HER2/LN or PAM50 subtypes must be included in a table describing the sample cohorts remains. In addition, accuracy must be computed separately for these co-variates or included in the machine learning model. Response: Thank you for the clarification regarding patient treatment. As a response, we have added an additional supplementary table which breaks down the accuracy of our models by subtype (ER, HER2, PR, LN and PAM50; Dataset 2). In the main text, we note that accuracy of most models are consistent between subtypes (+/- 10% deviation in accuracy). Subtypes with less than twenty individuals were ignored due to its small sample size. The following deviations in accuracy were noted: Random Forest and mRMR models are shown to be consistently more accurate in predicting ER+, HER2- when treated with hormone therapy (both “HT” and “CT and/or HT” categories), when compared to ER- and HER2+ patients. The PAM50 basal subtype is consistently low in accuracy when testing patients treated with hormone therapy. This is most likely partially influenced by the RF and mRMR models for ‘HT’ to more often predict patients as sensitive, combined with the fact that ER+ and HER2- patients were more likely to response to therapy. It is important to note that the accuracy of predictions by RF and mRMR with patients treated only with chemotherapy was fairly consistent across all available subtypes (+/- 10% accuracy). SVM paclitaxel models performed significantly better with HER2+ patients (26 correct, 3 misclassified; 90% accurate) in HER2- patients (40 correct, 15 misclassified; 73% accurate) when tested on patients treated with both hormone and chemotherapy. In Dorman et al (2016), it was stated that MAPT expression (which is present in the paclitaxel model) segregated with PAM50 luminal and basal subtypes. For this model, the accuracies of these subtypes are nearly identical to the accuracy of the entire subset. Text describing these results can be found in the third paragraph of the results. Conclusion Comment 4. The discussion is insufficient. It still lacks sufficient context of existing genomics classifiers in the literature. The discrepancy between their algorithm and clinical assays is confusing in revised sentence: “Unlike Mammaprint and Oncotype Dx tests, this model focuses on predicting survival prediction based on gene expression in the tumor, presumably before or during drug therapy.” As written, it appears to disregard the long history of predicting clinical outcome from gene expression involved in developing these classifiers from gene expression data (e.g., van't Veer et al., 2002) into clinical assays based upon expression of smaller numbers of genes. Response: We have removed the indicated sentence, which we agree was insufficient to the comment from the previous iteration of this article: “Must be discussed in the context of existing genomics classifiers for breast cancer (e.g., OncotypeDx and/or Mammaprint)”. We in no way meant to ignore the long history of predicting clinical outcome from gene expression (as well as other genomic factors). A discussion on this topic was not included in earlier submissions as it initially had an imposed word length limit (upon first submission). We did, however, reference other articles which do discuss this topic. In Dorman et al. (2016), which described some of the methodology for initial gene selection that this study was based on, these contributions are well-referenced, including the history of the prediction of clinical outcome from genomic status: “Previous studies have derived associations between the genomic status of one or more genes and tumor response to certain therapies (Duan et al. , 2003; Glinsky et al. , 2005; Hatzis et al. , 2011; Ma et al. , 2004; Rajput et al. , 2013; van't Veer et al. , 2002). Correlations between single gene expression and tumor resistance (Duan et al. , 2003, 1999) do not take into account multiple mechanisms of resistance or assess interactions between multiple genes. ABC transporter overexpression has long been shown to confer resistance, but enzymatic or functional inhibition has not substantially improve patient response to chemotherapy (Samuels et al. , 1997). Multi-gene analytical approaches have previously been successful in deriving prognostic gene signatures for metastatic risk stratification (Oncotype DX™, MammaPrint ), subtypes (PAM50), and efforts have been made to predict chemotherapy resistance (Hess et al. , 2006; Hatzis et al. , 2011). “ In response to Dr. Fertig’s comments, we have added a short discussion with citations of previously published approaches (including MammaPrint and Oncotype DX): “Genomic information has been shown to correlate with tumor therapy response in previous studies 5,12-16 . From these studies, analytical methods have been used to develop gene signatures for chemotherapy resistance prediction 5 , subtypes (PAM50), and metastatic risk stratification (Oncotype DX™, MammaPrint ).” Comment 5. Based on the previous review, the authors include context with other predictions of the METABRIC data in the response to the reviewers. This must also be included in the Conclusion to assess the relevance of their findings in the literature. Response: We have added the indicated text from the previous ‘response to the reviewers’ (modified) to the Conclusions: “We also examined the method exhibiting the best performance in the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge 17 , which was also phenotype-based, however it produces outcome signatures based on molecular processes, rather than the cancer drugs themselves. While interesting and informative, the results cannot be directly compared.” Please note that the majority of entries in the DREAM project were not fully curated and only exist as source code. Analyzing these files to determine what methodology was attempted by these groups is beyond the scope of our study. A description of the second place of the METABRIC phase of the DREAM challenge is provided in the link below. This link describes how the METABRIC data is trained using a bipartite graphing as input for linear models, boost models, and RankSVM. While they state that RankSVM was the least successful between the three methods, it does not appear that this particular study has been published to the literature. As a result, we cannot fully review their results, and thus cannot be compared to our methodology in the main manuscript. https://sagesynapse.wordpress.com/2012/11/01/breast-cancer-challenge-team-pitttransmed-places-second-for-metabric-phase-of-the-challenge/ Methods Comment 1. Abbreviations SVM and RF must be spelled out as Support Vector Machine and Random Forest on first use. This was not addressed in the revised methods section. Response: These abbreviations are now spelled out upon their first use in the main text (Methods section). Results Comment 2. The authors did perform a robust cross-study validation, as requested in the previous review. We agree this is challenging, due in part to batch effects as reported in this manuscript. However, such cross-study validation is essential to assess the accuracy of classifiers. It is also essential to have translation of genomic signatures into the clinic, where even different assays may be used. To address these concerns the authors must do the following: (a) Remove the sentence “This heterogeneity indicates that it is inappropriate to test our gene expression signatures derived by one of these datasets using the other dataset.” (b) Discuss the importance of cross-study validation, challenges in this application, and potential of overfitting of suggested by these results. Response: In regards to this point: (a) This sentence has been removed, as requested. (b) To address concerns regarding potential overfitting of our models, we cross-validate the acquired models to a non-METABRIC data set (from an independent study). In the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge, cross-study validation was performed using the “OsloVal” data set, which consists of gene expression and copy number data from 184 breast cancer patients (Margolin et al. , 2013). However, this dataset is not publically available and requires Ethics Board / IRB Review which we did not believe to be worth the effort. Instead, we performed cross-study validation on the gene expression of 310 breast cancer patients made publically available by Hatzis et al. (2011). Analysis of this dataset was successful for the mRMR + SVM models developed using chemotherapy-treated patient (“CT” models), where the threshold for resistance was set to 3-years and 4-years. The “CT 3-year” model performed well predicting responsive patients (74.2% accuracy), while the “CT 4-year” model performed better predicting non-responsive patients (75.1% accuracy). The “CT 4-year” model outperformed the “CT 5-year” model for both sensitive and resistant patient data sets. Random Forest and mRMR+SVM models which used hormone-treated patients (“HT” and “CT+HT”) were much less accurate compared to the “CT-only” models, and predict patients a large percentage of patients from the Hatzis data as sensitive. In the main manuscript, we have replaced the removed sentence from (a) and have written the following: “Cross-study validation allows for the comparison of classification accuracy between the generated gene signatures. The observed heterogeneity in gene expression highlights one of the many challenges of cross-validation of gene signatures between these data from the same study exhibit drastic differences (for example, BCL2L1 ; Supplementary file 2). Furthermore, these gene expression differences also affect the performance of these methods when these datasets were combined (compare Table 2 and Table 4 for RF; Table 3 and Table 5 for mRMR). We considered the possibility that the Discovery model might be subject to overfitting. We therefore performed cross-study validation of the Discovery set-signature with an independently-derived dataset (319 invasive breast cancer patients treated with paclitaxel and anthracycline chemotherapy 5 ). The mRMR+SVM CT-models performed well (4-year threshold model had an overall accuracy of 68.7%; 3-year threshold model exhibited lower overall accuracy [52%], but was significantly better at predicting patients in remission [74.2%]).” References Margolin AA, et al. Systematic analysis of challenge-driven improvements in molecular prognostic models for breast cancer. Sci Transl Med. 2013 Apr 17;5(181):181re1. doi: 10.1126/scitranslmed.3006112. Hatzis, C., et al. 2011. A genomic predictor of response and survival following taxane-anthracycline chemotherapy for invasive breast cancer. JAMA. 305, 1873–1881. Comment 3. The author’s response that specific therapies were not provided in METABRIC is incorrect. According to Curtis et al., (2012) “Nearly all oestrogen receptor (ER)-positive and/or lymph node (LN)-negative patients did not receive chemotherapy, whereas ER-negative and LN-positive patients did. Additionally, none of the HER2 + patients received trastuzumab. As such, the treatments were homogeneous with respect to clinically relevant groupings.” Therefore, the previous criticism #12 remains. Covariates such as ER/HER2/LN or PAM50 subtypes must be included in a table describing the sample cohorts remains. In addition, accuracy must be computed separately for these co-variates or included in the machine learning model. Response: Thank you for the clarification regarding patient treatment. As a response, we have added an additional supplementary table which breaks down the accuracy of our models by subtype (ER, HER2, PR, LN and PAM50; Dataset 2). In the main text, we note that accuracy of most models are consistent between subtypes (+/- 10% deviation in accuracy). Subtypes with less than twenty individuals were ignored due to its small sample size. The following deviations in accuracy were noted: Random Forest and mRMR models are shown to be consistently more accurate in predicting ER+, HER2- when treated with hormone therapy (both “HT” and “CT and/or HT” categories), when compared to ER- and HER2+ patients. The PAM50 basal subtype is consistently low in accuracy when testing patients treated with hormone therapy. This is most likely partially influenced by the RF and mRMR models for ‘HT’ to more often predict patients as sensitive, combined with the fact that ER+ and HER2- patients were more likely to response to therapy. It is important to note that the accuracy of predictions by RF and mRMR with patients treated only with chemotherapy was fairly consistent across all available subtypes (+/- 10% accuracy). SVM paclitaxel models performed significantly better with HER2+ patients (26 correct, 3 misclassified; 90% accurate) in HER2- patients (40 correct, 15 misclassified; 73% accurate) when tested on patients treated with both hormone and chemotherapy. In Dorman et al (2016), it was stated that MAPT expression (which is present in the paclitaxel model) segregated with PAM50 luminal and basal subtypes. For this model, the accuracies of these subtypes are nearly identical to the accuracy of the entire subset. Text describing these results can be found in the third paragraph of the results. Conclusion Comment 4. The discussion is insufficient. It still lacks sufficient context of existing genomics classifiers in the literature. The discrepancy between their algorithm and clinical assays is confusing in revised sentence: “Unlike Mammaprint and Oncotype Dx tests, this model focuses on predicting survival prediction based on gene expression in the tumor, presumably before or during drug therapy.” As written, it appears to disregard the long history of predicting clinical outcome from gene expression involved in developing these classifiers from gene expression data (e.g., van't Veer et al., 2002) into clinical assays based upon expression of smaller numbers of genes. Response: We have removed the indicated sentence, which we agree was insufficient to the comment from the previous iteration of this article: “Must be discussed in the context of existing genomics classifiers for breast cancer (e.g., OncotypeDx and/or Mammaprint)”. We in no way meant to ignore the long history of predicting clinical outcome from gene expression (as well as other genomic factors). A discussion on this topic was not included in earlier submissions as it initially had an imposed word length limit (upon first submission). We did, however, reference other articles which do discuss this topic. In Dorman et al. (2016), which described some of the methodology for initial gene selection that this study was based on, these contributions are well-referenced, including the history of the prediction of clinical outcome from genomic status: “Previous studies have derived associations between the genomic status of one or more genes and tumor response to certain therapies (Duan et al. , 2003; Glinsky et al. , 2005; Hatzis et al. , 2011; Ma et al. , 2004; Rajput et al. , 2013; van't Veer et al. , 2002). Correlations between single gene expression and tumor resistance (Duan et al. , 2003, 1999) do not take into account multiple mechanisms of resistance or assess interactions between multiple genes. ABC transporter overexpression has long been shown to confer resistance, but enzymatic or functional inhibition has not substantially improve patient response to chemotherapy (Samuels et al. , 1997). Multi-gene analytical approaches have previously been successful in deriving prognostic gene signatures for metastatic risk stratification (Oncotype DX™, MammaPrint ), subtypes (PAM50), and efforts have been made to predict chemotherapy resistance (Hess et al. , 2006; Hatzis et al. , 2011). “ In response to Dr. Fertig’s comments, we have added a short discussion with citations of previously published approaches (including MammaPrint and Oncotype DX): “Genomic information has been shown to correlate with tumor therapy response in previous studies 5,12-16 . From these studies, analytical methods have been used to develop gene signatures for chemotherapy resistance prediction 5 , subtypes (PAM50), and metastatic risk stratification (Oncotype DX™, MammaPrint ).” Comment 5. Based on the previous review, the authors include context with other predictions of the METABRIC data in the response to the reviewers. This must also be included in the Conclusion to assess the relevance of their findings in the literature. Response: We have added the indicated text from the previous ‘response to the reviewers’ (modified) to the Conclusions: “We also examined the method exhibiting the best performance in the Sage Bionetworks / DREAM Breast Cancer Prognosis Challenge 17 , which was also phenotype-based, however it produces outcome signatures based on molecular processes, rather than the cancer drugs themselves. While interesting and informative, the results cannot be directly compared.” Please note that the majority of entries in the DREAM project were not fully curated and only exist as source code. Analyzing these files to determine what methodology was attempted by these groups is beyond the scope of our study. A description of the second place of the METABRIC phase of the DREAM challenge is provided in the link below. This link describes how the METABRIC data is trained using a bipartite graphing as input for linear models, boost models, and RankSVM. While they state that RankSVM was the least successful between the three methods, it does not appear that this particular study has been published to the literature. As a result, we cannot fully review their results, and thus cannot be compared to our methodology in the main manuscript. https://sagesynapse.wordpress.com/2012/11/01/breast-cancer-challenge-team-pitttransmed-places-second-for-metabric-phase-of-the-challenge/ Competing Interests: PKR cofounded Cytognomix. A patent application related to biologically inspired gene signatures is pending. The other authors declare that they have no competing interests. Close Report a concern COMMENT ON THIS REPORT Version 1 VERSION 1 PUBLISHED 31 Aug 2016 Views 0 Cite How to cite this report: Tung CW. Reviewer Report For: Predicting Outcomes of Hormone and Chemotherapy in the Molecular Taxonomy of Breast Cancer International Consortium (METABRIC) Study by Biochemically-inspired Machine Learning [version 3; peer review: 2 approved] . F1000Research 2017, 5 :2124 ( https://doi.org/10.5256/f1000research.10141.r16345 ) The direct URL for this report is: https://f1000research.com/articles/5-2124/v1#referee-response-16345 NOTE: it is important to ensure the information in square brackets after the title is included in this citation. Close Copy Citation Details Reviewer Report 03 Oct 2016 Chun-Wei Tung , School of Pharmacy, Kaohsiung Medical University, Kaohsiung, Taiwan Approved with Reservations VIEWS 0 https://doi.org/10.5256/f1000research.10141.r16345 This study proposed prediction methods using SVM and RF classifiers with mRMR selected feature sets from cell line data and demonstrate its prediction ability for outcomes from METABRIC patient cohort. The classifiers with good prediction performance show the usefulness of ... Continue reading READ ALL 