This data note describes an annotation dataset consisting of time indices and annotations describing location and temporal information for each identified shot in the movie Forest Gump. This dataset of movie annotations is intended to be used with the associated functional neuroimaging datasets of participants viewing the movie Forrest Gump. All in all, I think this is an excellent addition to the growing empire that is StudyForrest, one that clearly represents an enormous amount of effort. I have only minor comments: The timing seems to be a bit off relative to the previously released dataset of scenes in the studyforrest GitHub repository. Presumably the annotation for shots and scenes should line up at scene starts but there appears to be consistent offset of about 12ms. For example, the last scene (“School bus stop”) starts at 6944.96 in the scenes.csv and 6944.84 in the attached dataset for shots in this paper. Moreover, the shots in this annotation don’t quite line up with the shots.csv on the github repo. The ~12ms offset is too large to be a single frame. It appears the authors switched from Advene to Shotcut for movie segmentation and annotation, perhaps therein lies the source of the mismatch? Could the authors expatiate on their method of identifying shots and cuts? If memory serves, in previous datasets they used an automated method to identify shots that was subsequently edited by hand. In this dataset, it appears all shots were identified by hand. Where all cuts identified? Or are there special cases were two cuts appearing in close succession were considered a part of one shot? For instance, in an action heavy scene you could presumably get an overabundance of cuts, but that level of granularity isn’t really useful (nothing changes) and potentially these could be combined into a single shot. If every cut was indeed identified and annotated, then my sincere condolences to the coder! Although it is extremely generous of the authors to provide python code for generating descriptive data and associated figures, I’ve examined this code file and unfortunately this reviewer simply cannot support the premature use of Python 3… You can pry 2.7 from my cold dead hands. ;) Finally, I would like to again thank the authors for openly sharing this wealth of data with the community. These annotations and the associated imaging data represent a generous sharing of valuable resources, one that I have no doubt will be useful to many researchers interested in the neuroscience of naturalistic cognition.