In the paper, Tosadori et al. describe a Cytoscape app for creating random networks according to different random models and comparing them with one or more input networks on the basis of different topological metrics. The main goal of the app is to help the user in the creation of a benchmark for validating some properties of a real network or a dataset of real networks. I found the app very interesting and I think that the paper is suitable for being indexed. However, there are several major issues, especially regarding the potential applications of the tool and the statistical part of the app, that need to be addressed before indexing. The actual usefulness of the app is not fully explained. In the Abstract and in the Introduction the authors point out that the app should serve as a framework to validate some numerical results of one or more input networks, but it is not clear how the results of comparing values of topological attributes of real and random networks can be exploited by the user to draw conclusions. I would suggest to insert (for example in the Introduction) one or more examples of usage of this tool. For instance, an interesting application of the tool could be the following: generate different random networks (one or more for each random model) with a similar number of nodes and edges of the real network, then compare these networks with the real one according to some statistics (for example clustering coefficient) in order to find the random model that best fits the input network. This can tell a lot about the features of the network and how it has been generated. The statistical module of the app allows to compare two distribution of values on some topological property of the nodes (for example centrality) by using the two-sample Kolmogorov-Smirnov test. The aim of this comparison should be carefully clarified. Is the aim to establish if topological properties are maintained with respect to the random model used? Does it make sense when such a value is obtained comparing only a pair of networks, the real and the random ones? Let’s consider a set of N networks generated using the preferential attachment and compare them to a real network according to the values of some metric M. The reviewer expects that will be sensible variations on the Kolmogorov-Smirnov distance. It would be more reasonable to give the user the possibility to compare expected values of some metric in ensembles of real and random networks. In some context, this kind of analysis can be preferable and would result more robust. Among the random models, the authors presented a new model called Multiplicative Model. It is not clear from the text how such a model works. There is a picture in the paper that shows three networks generated with three different weighted arrays, but it is not clear how these weighted arrays are generated. Which are the input parameters of the model? Please clarify how the weights are determined. It is not clear i) if the user has to provide a minimum value X and a maximum value Y and then weighted arrays are generated by randomly picking one value within interval [X,Y] for each node or ii) if just has to provide a text file with one weight for each node and generate a random network with exactly that sequence of weights. By using the app, it seems that a text file is required but it is not clear what should be its content. In general, authors should describe more clearly the model both in the paper and in the documentation of the app. It looks like the Multiplication model is not properly working: I tried to generate a random network using the Multiplication Model starting from an input network of N nodes. As a parameter for the model, I loaded an input file with N rows and one number for each row (in each row there is 0 or 1 as weight). A window appeared saying which was the maximum number of edges admitted for the network. However, at the end of the process, a random network with exactly the same number of nodes and edges (maybe a copy) of the input network was created without any error or warning message. I expected as output a network with a different number of nodes and edges. Please clarifiy this point. In the Abstract and in the Introduction authors claim that there are no tools for generating and randomizing networks. Actually, there are two Cytoscape apps that authors should cite in the paper: Randomnetworks plugin ( http://apps.cytoscape.org/apps/randomnetworks ) and NetMatch* ( http://alpha.dmi.unict.it/netmatchstar/netmatchstar.html) . Furthermore, since your app implements a comparison part between networks, I would also recommend to cite some other Cytoscape app to compare networks, such as GASOLINE ( http://apps.cytoscape.org/apps/gasoline ) and DyNet ( http://apps.cytoscape.org/apps/dynet ), remarking the different kind of approach to compare networks that you are following, which is the new research contribution. On page 6, third paragraph, when authors talk about the two shuffling methods (with or without preservation of degrees) they say that users can choose one or both models. Authors should describe which is the effect when both options are selected. What is the maximum number of nodes in a network generated with the multiplication model? In the example at page 3 for a network of 10 nodes and weights in [0,100] is 100*10+10, but in the figure of page 6 it seems to be just the number of nodes multiplied by the maximum value of the range (in the figure of page 6 it seems 7*3 and not 7*3+7). Please clarify this point. In the paper there is no indication of which sizes represent the Lattice Model (Figure 4). I finally deduced this information from the documentation. This should be reported with a sentence also in the main paper. There is a difference between the panel of Multiplication Model depicted in Figure 4 and the Multiplication Model panel present in the Cytoscape App. In the app I found an option called “Graphical version” which is not reported in the paper. Please clarify and make the app and the paper coherent on such a point. When the user generates random networks or run the statistical analysis there is no indication on the status of the computation. It would be recommended to notify the user with logs and progress bars. I tried to execute a pipeline of statistical experiments with different input networks and/or random networks. However, after the first experiment, it was impossible to me to change the set of selected input or random networks for a second experiment. I had to close and open again the app to make other tests. Please fix this bug. In the Statistical analysis panel there is a “Save as” button to select the path where to save output results. However, there is no text field next to the button that indicates the selected output folder. Please insert such a field. 