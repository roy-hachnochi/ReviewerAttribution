As more courses become hybrid courses with an in-person and out-of-class component, this becomes an important area to explore. While the data presented in this paper may be very useful to instructors at this particular institution, it is unclear how the aims of the research paper fill a gap in the science education literature. Further, the analysis of two closed ended response questions and one open ended question does not provide enough data to fully answer the present study aims. I would strongly encourage the researchers develop more complex research questions that are novel to the education community and use more robust qualitative methodologies with a larger sample size. I have included specific comments below. Abstract Please see the line under the Results section of the abstract that begins “in the hypothetical scenario of retaking the course.” The percentages in parenthesis do not support the claim in this sentence. Please clarify. Introduction The authors mention that hybrid courses may accommodate a wider variety of learning styles. I encourage the authors to reconsider their language and further consider the theory behind this statement. There is very little evidence to support that students have learning styles and the theory of learning styles has been deemed as a myth by many in the higher education community. Please provide the grade levels included in the Means et al., 2009 meta-analysis. Please define “adult learners” and reconsider the claim that technology may present challenges to adult learners as this may be specific to a particular age range of students. Someone who is 18 years old in 2017 was likely exposed to technology quite regularly during their education, compared with someone who is 50 years old. It is unclear from the introduction why these research aims are novel and broadly relevant outside of this particular institution. Materials and methods Course format Please explain the difference between lecture and laboratory instruction. Please explain what a clickable index of lecture means. Course survey The aims of this study are exploratory and do not require a research design which includes a comparison group of students. Thus, it seems irrelevant to mention the epidemiology students. However, if the researchers had a reason for including these data from the epidemiology students, then the readers need much more information about these students in order to interpret the data. Please provide more information about how the four categories were developed. Were qualitative research methodologies used? The references below may be useful: Krippendorff, K. (2004) 1 Strauss, A., Corbin, J. M. (1997) 2 What percentage of students answered each closed ended question? What percentage of students clearly answered the open-ended question? Of these responses, how many were able to be coded into at least one of the four categories? Data analysis It is unclear where, if at all, the data from the epidemiology students appear in the paper. Further, if the epidemiology class was used as a comparison group, students who are enrolled in both the biostatistics course and the introductory epidemiology course should be removed from the study. However, it appears that this group of students is not actually begin used as a comparison group. Results Demographics Please explain the difference between the terms travel time and commute time. Course format preferences To properly analyze what format students preferred, the readers need information about what type of format students experienced. For example, a student who experienced in-person, synchronous, and asynchronous classes has the ability to evaluate the three formats against each other. However, a student who has attended all in-person classes can report what they experienced, but not what they prefer because they have not experienced other modes. Describing what mode students engaged with needs to be separated from measuring what mode a student prefers. The “course format preference” question measures whether students prefer in-person, synchronous, or asynchronous courses. However, the “re-take course format preference’” question is measuring whether students want a mandatory in-person class, a mandatory online class or whether they prefer to choose. These questions are measuring very different ideas and this needs to be better explained to the reader. Further, it is unclear which of these questions the open-ended response question is asking students about. Regardless of which question the opened ended question is referring to, open-ended student responses needed to be organized by how students responded to the closed ended question. For example, if the open ended question is asking about student course format preference, all of the open-ended responses from students who identified that they prefer to take a course in person needed to be analyzed together. Analyzing all student responses without taking into account their response to the closed ended question could cause the researchers to miss themes that were specific to a particular preference. For example, I would imagine that students who cite “interactivity” as a reason for attending in person classes may be referring to a different phenomenon than students who cite “interactivity” as a reason for attending synchronous courses. These nuances are important and need to be further explored and explained. The sample size is not large enough for this type of analysis. More data needs to be collected. Are the percentages of preferred reasons endorsed that are listen in Table 1 primary, secondary, or both? How many students reported secondary reasons? Did some students list three reasons? The authors should mention that because this was an open ended question that the percentages are not representative of all students who would possibly agree with a particular reason. I would suggest creating a table with a row per preference category (e.g. interactivity, convenience) and a column which includes a description of the category and a column for a representative student quote that was coded as the particular category. See table 2 in the for an example 3 . Are students really explaining “cognitive advantages” of in-person vs online delivery of material? Please further explain or consider rewording and provide student example quotes. Synchronous/asynchronous viewing patterns of the lecture It is unclear from the stated purpose of this paper why the authors report out the viewing pattern of lectures. These data seem unconnected to the rest of the paper. Discussion and conclusions It is unclear how the results of this study fill a gap in the education literature. References 1. Krippendorff K: Content analysis: An introduction to its methodology. Sage . 2004. 2. Stauss A, Corbin J: Grounded theory in practice. Sage . 1997. 3. Cooper KM, Ashley M, Brownell SE: A Bridge to Active Learning: A Summer Bridge Program Helps Students Maximize Their Active-Learning Experiences and the Active-Learning Experiences of Others. CBE Life Sci Educ . 2017; 16 (1). PubMed Abstract | Publisher Full Text Competing Interests: No competing interests were disclosed. I confirm that I have read this submission and believe that I have an appropriate level of expertise to state that I do not consider it to be of an acceptable scientific standard, for reasons outlined above. Close READ LESS CITE CITE HOW TO CITE THIS REPORT Brownell S. Reviewer Report For: Engagement of introductory biostatistics students in a novel hybrid course format [version 1; peer review: 2 approved with reservations, 1 not approved] . F1000Research 2016, 5 :2624 ( https://doi.org/10.5256/f1000research.10288.r19362 ) The direct URL for this report is: https://f1000research.com/articles/5-2624/v1#referee-response-19362 NOTE: it is important to ensure the information in square brackets after the title is included in all citations of this article. COPY CITATION DETAILS Report a concern Respond or Comment COMMENT ON THIS REPORT Comments on this article Comments (0) Version 1 VERSION 1 PUBLISHED 02 Nov 2016 ADD YOUR COMMENT Comment keyboard_arrow_left keyboard_arrow_right Open Peer Review Reviewer Status info_outline Alongside their report, reviewers assign a status to the article: Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions Reviewer Reports Invited Reviewers 1 2 3 Version 1 02 Nov 16 read read read Sara Brownell , Arizona State University, Tempe, USA Nurbiha A. Shukor , Universiti Teknologi Malaysia, Johor, Malaysia John McGready , Johns Hopkins University, Baltimore, USA Comments on this article All Comments (0) Add a comment Sign up for content alerts Sign Up You are now signed up to receive this alert Browse by related subjects keyboard_arrow_left Back to all reports Reviewer Report 0 Views copyright © 2017 McGready J. This is an open access peer review report distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. 09 Oct 2017 | for Version 1 John McGready , Department of Biostatistics, Johns Hopkins University, Baltimore, MD, USA 0 Views copyright © 2017 McGready J. This is an open access peer review report distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. format_quote Cite this report speaker_notes Responses (0) Approved With Reservations info_outline Alongside their report, reviewers assign a status to the article: Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit. Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions This article is an interesting descriptive study that details student characteristics and learning preferences in three self-selected versions of the same introductory biostatistics class: live, in class sections, synchronous online viewings of the live-streaming live class, or asynchronous viewings of recorded live class lectures. This reviewer appreciates the efforts the instructors made to accommodate anticipated differences in students scheduling needs to potentially offer the class to a wider pool of enrollees. With regard to the study itself, however, it is purely descriptive in nature. It was not designed to test any formal hypotheses regarding differences between the three sections, despite the power computations, and the reference to a comparison group of students in a hybrid-style epidemiology course. (Curiously, this comparison group was never mentioned again after the "Course Survey" section.) The authors should emphasize the descriptive nature of this work up-front (The first sentence of the final paragraph of the introductions section does this well : perhaps just removing the bit about the epidemiology course comparison group will help emphasize this) From a scientific standpoint, the response rate of 55% is problematic, although the norm for survey studies. If there is other, non-survey result information on both the responders and non-responders, it would be interesting to se even a basic comparison of the two groups. The biggest area of confusion for this reviewer is the distinction between "Course Format Preference" and "Retake Course Format Preference" as these were assessed a the same time points. Clearly the response distributions of both items differ, but it is not clear what the implications are. Is it because , for example, some persons prefer the in person option ideally, but for practical reasons (commuting, work schedules etc..) it would be more convenient to take it in a hybrid format if offered again? The distribution of reasons for preference given are ostensibly for the "Course Format Preference" and not the "Retake Course Format Preference", and as such gives little insight as to why preferences would change. As such, though the samples are small, it would be interesting to see the conditional distributions of for both items, separately for students enrolled in each of the three course versions. Additionally, from a qualitative standpoint, knowing why people would choose a different format from their preference when (hypothetically) retaking the class would be informative. As it stands, it is not possible to conclude that students prefer the hybrid approach despite the majority percentage that would retake the course in this format. If the authors can provide some clarity about the distinction between "Course Format Preference" and" Retake Course Format Preference", and which is driving their understanding of student preferences this would be helpful. In closing, the study provides interesting descriptive data, and some insights on how to (relatively) easily allow for a hybridization of a course that is originally an on-campus only offering. This is not to say that it's not a lot or work to pull this off, but the resources (youtube etc..) are relatively accessible. The study, however, does not add any scientific insights regarding hybrid courses as compared to traditional, on-campus or offerings or completely online offerings. 