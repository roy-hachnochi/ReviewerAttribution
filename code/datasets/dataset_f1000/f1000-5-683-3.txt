I enjoyed reading this article, and I liked the fact that it was concisely written. I would only like to share a few comments. The authors of this paper have chosen to exam the peer review process for eLife , which is an electronic journal for the life and biomedical sciences. They note that two papers have previously described the editorial process of eLife ; however for their own study, I think it would have been useful to include a link to the eLife website ( https://elifesciences.org/ ). I was curious about whether or not it was an open access journal, and I looked for the website to obtain this information. More importantly, I also looked to the website, because I wanted to know how many persons serve as Senior Editors or sit on the editorial board of eLife . What is interesting here is that the term “editor” for this journal is stretched to include one Editor-in-Chief, three Deputy-Editors, thirty-two Senior Editors and a 282-member Board of Reviewing Editors. The peer review system for this journal is quite different from the ‘traditional’ journal, but to be more precise, it differs because “Reviewing Editors” are specialists who have agreed to review for the journal on a regular basis, and may in some cases call upon additional ‘outside’ reviewers. What we do not know from this paper, is whether or not two or more of the 282 Reviewing Editors sometimes choose to review the same paper. At the eLife website, the following is noted: “The Reviewing editor usually reviews the article him or herself, calling on one or two additional reviewers as needed”. Are the additional reviewers always from the outside? If not, how would this change the authors’ hypothesis related to the ‘effects of an editor serving as one of the reviewers’? The methods used for the data analysis are explained very well, with the exception of one detail: How did the authors acquire the initial dataset of 9,589 papers? This information is presented in the ‘Acknowledgements’ section, but could have also been added to the Methods section, for more clarity. The graphs related to the authors’ findings are clear and present interesting information, but I am not sure how the citation data were collected from Scopus for the peer-reviewed papers in eLife and whether or not ‘citation windows’ were used for the papers depending on the year in which they were published. Essentially the authors are correct in saying that “ papers accumulate citations over time, and, as such, papers published earlier tend to have more citations ”, hence citation windows are used to correct for this. The highest rates of citation (especially in the life sciences and biomedicine) will appear within three-to-five years following an article’s date of publication. For this reason, bibliometricians usually count citations within this three-to-five year time-frame to determine an article’s initial impact. Since the articles used in this study had been “ submitted to eLife since June 2012 ” the authors should have focus on three things: 1) the involvement of a Reviewing Editor as a peer reviewer or not, 2) the number of days between start of the submitted paper’s acceptance and publication, and 3) the papers’ citation rate following 3-5 years after final publication.