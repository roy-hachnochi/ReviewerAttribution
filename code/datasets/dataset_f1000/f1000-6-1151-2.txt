Thank you for asking me to review this paper. Ironically, but perhaps not surprisingly, this was quite a hard paper to peer review and I don’t claim that this peer review does anything more than provide one (non-exhaustive) opinion on this paper. My views on peer review, which have formed over more than 15 years of being involved in editing and managing peer review will have coloured my peer review here. I think it's useful to regard all journal processes, which includes peer review, as components of the QC which begins with checking for basics such as the presence of ethics statements or trial registration, or the use of reporting guidelines for example, through to in depth methodological review. I don't think that any of the parts of the system of QC, including peer review, are perfect but the system is one component of attempting to ensure reproducibility, itself a core role of journals. The very basic functions of QC are often not given enough emphasis, though they are going to become more important as, for example, other types of publication such as preprints increase in popularity. General Comments This is a wide ranging, timely paper and will be a useful resource. My main comment is that this is a mix of opinion, review, and thought experiment of future models. While all of these are needed in this area, for the review part of the paper, it would be much strengthened with a description of the methodology used for the review, including databases searched for information and keywords used to search, etc. The paper is very long and there is a substantial amount of repetition. I think the introduction in particular could be much shortened - especially as it contains a lot of opinion, and repetition of issues dealt with elsewhere in the paper. The language of the paper is also quite emotive in places and though I would personally agree with some of the sentiments I don't think they are helpful in making the authors’ case eg in Table 2 assessment of pre publication peer review is listed as Non-transparent,impossible to evaluate,biased, secretive, exclusive Or The entrenchment of the ubiquitously practiced and much more favored traditional model (which, as noted above, is also diverse) is ironically non-traditional, but nonetheless currently revered . I think it worth reviewing the language of the paper with that in mind. Although it arises in a number of places I don’t feel the authors address fully the complexity of interdisciplinary differences. The introduction would have been a good place to set this down. There is no mention of initiatives such as EQUATOR which have been important in improving reporting of research and its peer review. http://www.equator-network.org/ I was surprised to see very little discussion of the problems associated with commenting - especially of tone - that can arise on anonymous or pseudonymous sites such as Pubpeer and reddit. There was no discussion of post publication reviews which originate in debates on twitter. There have been some notable examples of substantial peer review happening - or at least beginning there eg that on arsenic life 1 . There are quite a few places where initiatives are mentioned but not referenced or hyperlinked. eg Self Journal of Science. Specific comments Introduction I would take issue with the term “ gold standard ”. In my view many of the issues arising from peer review are that it is held to a standard that was never intended for it. Introduction paragraph 2 - where PLOS is mentioned here it should be replaced by PLOS ONE - the other journals from PLOS have other criteria for review. I am surprised that PLOS ONE does not get more of a mention in how much of a shift it represent in its model of uncoupling objective from subjective peer review, and how it led to the entire model for mega journals. 1.1.1 “ The purpose of developing peer reviewed journals became part of a process to deliver research to both generalist and specialist audiences, and improve the status of societies and fulfil their scholarly missions” I think it is worth noting that another function of peer review at journals was that it was part of earliest attempts of ensuring reproducibility - which is of course a very hot topic nowadays but in fact has its roots right back to when experiments were first described in journals. “From these early developments, the process of independent review of scientific reports by acknowledged experts gradually emerged. However, the review process was more similar to non-scholarly publishing, as the editors were the only ones to appraise manuscripts before printing” There is a misconception here, which I think is quite common. In the vast majority of cases editors are also peers, and may well be “acknowledged experts” - in fact certainly will be at society journals. The distinction between editors and peer reviews can be a false one with regard to expertise. 1.1.2 where publishers call upon external specialists to validate journal submissions. It is important to note that it is editors who manage review processes. Publisher are largely responsible for the business processes; editors for the editorial processes. By allowing the process of peer review to become managed by a hyper-competitive industry, developments in scholarly publishing have become strongly coupled to the transforming nature of academic research institutes. “ These have evolved into internationally competitive businesses that strive for quality through publisher-mediated journals by attempting to align these products with the academic ideal of research excellence ( Moore et al., 2017 )” I am not sure what is meant by “these” in this second sentence, nor what is meant by a “publisher-mediated journal”. Virtually all journals have a publisher - even small academic-led ones. 1.1.3 This practice represents a significant shift, as public dissemination was decoupled from a traditional peer review process, resulting in increased visibility and citation rates ( Davis Fromerth, 2007 ; Moed, 2007 ). Many papers posted on arxiv.org do go on to be published in peer reviewed journals. Are these references referring to increased citation of the preprints or the version published in a peer reviewed journal? The launch of Open Journal Systems ( openjournalsystems.com ; OJS) in 2001 offered a step towards bringing journals and peer review back to their community-led roots. The jump here is odd. OJS actually can support a number of models of peer review, including a traditional model of peer review, just on a low cost open source platform, not a commercial one. The innovation here is the technology. Digital-born journals, such as PLOS ONE, introduced commenting on published papers. Here the reference should be to all of PLOS as commenting was not unique to PLOS ONE. However, the better example of commenting is the BMJ which had a vibrant paper letters page which it transformed very successfully to its rapid responses - and it remains the journal that has had most success http://www.bmj.com/rapid-responses . Other services, such as Publons, enable reviewers to claim recognition for their activities as referees. Originally Academic Karma http://academickarma.org/ had a similar purpose though now it has a different model - facilitating peer review of preprints. Figure 2 PLOS ONE and ELife should be added to this timeline. Elife’s collaborative peer review model is very innovative. I am not sure why Wikipedia is in here. 1.3 One consequence of this is that COPE, the Committee on Publication Ethics ( publicationethics.org ), was established in 1997 to address potential cases of abuse and misconduct during the publication process. COPE was first established because of issues related to author misconduct which had been identified by editors. Though it does now have a number of cases relating to peer review , the guidelines for peer review came much later and peer review was not an early focus. Taken together, this should be extremely worrisome, especially given that traditional peer review is still viewed almost dogmatically as a gold standard for the publication of research results, and as the process which mediates knowledge dissemination to the public. I am not sure I would agree. Every person I know who works in publishing accepts that peer review is an imperfect system and that there is room for rethinking the process. Sense about Science puts it well in its guide: ” Just as a washing machine has a quality kite-mark, peer review is a kind of quality mark for science. It tells you that the research has been conducted and presented to a standard that other scientists accept. At the same time, it is not saying that the research is perfect (nor that a washing machine will never break down). http://senseaboutscience.org/wp-content/uploads/2016/09/peer-review-the-nuts-and-bolts.pdf Table 2. Note that quite a few of these approaches can co-exist. Under post publication commenting PLOS ONE should be PLOS. BMJ should be added here. 1.4 Quite a lot of subscription journals do reward reviewers by providing free subscriptions to the journal - or OA journals provide discounts on APCs (including F1000). Furthermore, some reviewers are paid, especially statistical reviewers. 2.2.2 Hence, this [Wiley] survey could represent a biased view of the actual situation. I’d like to see evidence to support this statement. 2.2.3 The idea here is that by being able to standardize peer review activities, it becomes easier to describe, attribute, and therefore recognize and reward them I think the idea is to standardise the description of peer review, not the activity itself. Please clarify. 2.4.2. Either way, there is little documented evidence that such retaliations actually occur either commonly or systematically. If they did, then publishers that employ this model such as Frontiers or BioMed Central would be under serious question, instead of thriving as they are. This sentence seems to be in contradiction to the phrase below: In an ideal world, we would expect that strong, honest, and constructive feedback is well received by authors, no matter their career stage. Yet, it seems that this is not the case, or at least there seems to be the very real perception that it is not, and this is just as important from a social perspective. Retaliations to referees in such a negative manner represent serious cases of academic misconduct 2.5.1. This process is mediated by ORCID for quality control, and CrossRef and Creative Commons licensing for appropriate recognition. They are essentially equivalent to community-mediated overlay journals, but with the difference that they also draw on additional sources beyond pre-prints. This is an odd description. In what way does ORCID mediate for quality control? 2.5.2 Two-stage peer review and Registered Reports. Registration of clinical trials predated registered reports by a number of years and it would be useful to include clinical trial registration in this section. 3 Potential future models NB I didn’t review this section in detail. 3.5 as was originally the case with Open Access publishing, The perception of low quality in OA was artificially perpetuated by traditional publishers more than anything else - it was not inherent to the process. 3.5 Wikipedia and PLOS Computational Biology collaborated in a novel peer review experiment which would be worth mentioning - see http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002446 2 . 3.9.2 Data peer review. This is a vast topic and there are many initiatives in this area, which are not really discussed at all. I would suggest this section should come out - especially as earlier on it is noted that the paper focuses mainly on peer review of traditional papers. I would also suggest taking out the parts on OER and books. 