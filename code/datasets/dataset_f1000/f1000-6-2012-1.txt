In the manuscript "The rise and fall of machine learning methods in biomedical research" the author has generated a quantitative perspective on the usage of machine learning methods in the life sciences. For some of the methods a hypothesis about the underlying reason for an increased or decrease popularity are discussed. The code for performing the analysis is available on GitHub and - like the retrieved PubMed data - has been deposited at Zenodo. I have several major objections / question / suggestion for the author: I tried to reproduce the analysis using RStudio 1.1.383 with the deposited RStudio project but got the following error when executing the R chunks in the file Machine_Learning_Trends.Rmd : "Error in library(informationRetrieval) : there is no package called ‘informationRetrieval’" The file informationRetrieval.R is located in another subfolder and I guess this just needs proper referencing inside of the project. The author states that he has selected widely used machine learning methods used in life sciences. I would have expected Naive Bayes classifiers in the list of most popular methods. A simple PubMed search for '"naive bayes classifier" OR "naive bayesian classifier' return twice as many hits as for "deep neural networks" (but over a longer time span): https://www.ncbi.nlm.nih.gov/pubmed/?term=%22naive+bayes+classifier%22+OR+%22naive+bayesian+classifier%2 https://www.ncbi.nlm.nih.gov/pubmed?term=%22deep+neural+networks%22 Similar issue for logistic regression: The analysis in the provided file Machine_Learning_Trends.Rmd actually contains the counting of publications containing logistic regression that shows a large (206,619 at the time of writing) and growing number of this but this method has not been discussed in the manuscript and is not displayed in the plots. https://www.ncbi.nlm.nih.gov/pubmed?term=%22logistic%20regression%22 The counting of hits for deep neural networks (DNN) is not done properly. Looking at the code to count the number of hits of different search terms shows that the author use "artificial neural networks" and "deep neural networks" and "deep learning" as search term for DNN (see code selection at the bottom of this section). I think using the search term "artificial neural network" for both ANN and DNN is not sound and changes the story of DNN (a special form ANN) significantly. Either DNN is treated as subset of ANN and only ANN are plotted or DNN and ANN are treated separately and the search term "artificial neural network" is not used for DNN. Furthermore the search term "deep learning" results in numerous unrelated hits before 2010 (e.g. PMID: 8936230, 9165817, 9487168, 10463930). https://www.ncbi.nlm.nih.gov/pubmed/?term=%22deep+learning%22 (then click on the "Result by year" histogram). The authors tries to explain the underlying reasons for the gain or loss of certain ML methods. In Figure 1 one of the publications of the human genome is placed in the year 2000 without any citation. The human draft genome was published in 2001 (International Human Genome Sequencing Consortium, Nature 409, 860–921, 2001, https://doi.org/10.1038/35057062 ) and it would be interesting to see what the author is referring to. The Popularity Rate (PR) introduced here is not plotted anywhere directly but is the slope of edges between the data points of two consecutive years. The author should consider visualizing this measurement of change as well. The curve plotted in Fig 1 A is nearly reassembled by the LRM curve in Fig 1 B. Is the observation in Fig 1 A maybe only an observation of the dominating LRM method? I do not understand why Fig 1 A can actually look nearly exactly like the LRM curve considering the other methods e.g. the PCA curve. Code selection regarding ANN and DNN ``` ANN_hits - get_normliazed_number_of_hits(years = YEARs, query="artificial neural network[tw]", db="pubmed", normalization_value=1000000) NN_term - "(artificial neural networks[tw] OR deep neural networks[tw] or deep learning[tw])" DNN_hits - get_normliazed_number_of_hits(years=YEARs, query=NN_term, db="pubmed", normalization_value=1000000) ``` Minor issues: Figure 1 Style: The different lines are hard to distinguish by color only - maybe consider an additional discriminator (e.g. dashed lines for a subset); Next to Fig 1 C is a lot of white space. Placing the t-SNE subplot to a different location (e.g. the middle of Fig 1 C) would make it possible to use this space more efficiently. Maybe think rearranging the whole figure. Figure 1 C is a subplot of figure 1 B like the t-SNE plot is a subplot of Figure 1 C "de facto" should be written in in italic font The link to RISmed should use the link indicated at the page itself that says "Please use the canonical form https://CRAN.R-project.org/package=RISmed to link to this page." For Linear Regression Model sometimes "LRM" and sometime "LR" is used in the manuscript In order to understand which biological approaches / questions that are influencing the usage of different ML method the association of those methods with certain MeSH term would be interesting. Either as part of this manuscript or a future one. 