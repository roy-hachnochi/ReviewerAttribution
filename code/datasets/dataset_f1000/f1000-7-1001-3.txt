This article represents a unique contribution to what has been written on this topic. Although the core readership for F1000Research consists of scientists, I am sure this article will be read by many non-scientists and many of my suggestions to the authors relate to this point. A general comment: the authors should note that most of the data used for empirical studies of predatory publishing is drawn from Beall's List and Beall's List was and is still controversial [the authors' discussion of Beall's List under Introduction is balanced and articulate]. Essentially, any empirical study of predatory publishing is based on one or two sources of data: Beall's List and/or email solicitations which lead to journals and their publisher websites. This should be made explicit. The data that underlies much of the literature is very fuzzy and subjective. Without cross-checking publisher and journal data (e.g. many predatory publishers claim inclusion in DOAJ and this data point is particularly sticky), and probing the content, the underlying literature is limited. Moher, David et al's 1 study seems to be one of the only studies to examine content and evaluates the methodological design and research protocols of articles but, as the authors note, it gets excluded because of its publication in commentary format! The overall quantification of the literature differentiating empirical vs. editorial is extremely helpful. I found the raw data of characteristics pretty overwhelming and I wonder if the authors could somehow aggregate or otherwise organize the information in a way that makes it easier to scan. I recognize that they have summarized their data in the body of the article. The conclusions clearly address the limitations of the study but what I think would be most important is teasing out where the data came from: publisher emails leading to publisher websites, and/or Beall's List leading to journals and publisher websites. Both are imperfect sources. I would like to see this data used again with more aggregation. I recognize that scoping reviews are meant to be fast so this article's data could be used for further research. Specific comments: Introduction: Agreed that some journals from the Global South provide important regional research but the authors should note that many of these Global South journals market themselves as "international" or "global" and do not focus on regional research because of a desire to cast a wide net. Legitimate, amateurish journals deemed as predatory from this group actually would be more likely to have a scope that is regional and specific as opposed to the multidisciplinary scope of many predatory publishers. The authors should explain far more explicitly what a scoping review is and its purpose. Non-biomedical readers will be unfamiliar with this type of methodology/article. I also am not entirely sure about the use of the word "epidemiological" in terms of discussing the topic at hand: non-biomedical readers may be unsure what exactly is meant. Lastly, as much as it is very helpful to identify characteristics of predatory journals as drawn from the literature, it seems somewhat positivist to use this very limited body of literature which is by its heavy use of Beall's List data as a means to "generate a consensus definition of predatory journals." Until there is more qualitative research and more multidisciplinary and longitudinal research as was done by Shen and Bjork, there are lacunae in the research literature. The recent articles based on the research by this team is, groundbreaking but largely limits scope to biomedical literature. Screening and data extraction The use of implicit and explicit definitions is very important and valuable. Search strategy It is possible that some research from librarians and information science scholars might have been missed. There is also some concern that if the articles are open access, they may have not been indexed in traditional databases. This concern relates to the Data Analysis section as well since newer and smaller open access journals may not have a Journal Impact Factor and be excluded from SCIMAGO. Mapping the data into emergent themes Under the descriptor "persuasive language," the language of predatory journals targets authors and not readers. This should be explained. What is somewhat confusing to me is separating characteristics in the literature based on the authors' perceptions or evaluations of the journals and publishers versus the actual data drawn from the journals and publishers' emails, journals, articles, and websites. Whether or not the author of the underlying articles performed cross-checking is also important. Table 4 Characteristics The characteristic JOURNALS HAVE SHORT PEER REVIEW TIMES isn't mapped to a descriptor but it is a very most important common characteristic of publisher appeals to authors. It typically maps to Poor Quality Standards although not in an absolute manner since obviously large, quality journals can also have quick turnaround. It is unclear to me if because this characteristic lacks a descriptor, it may lose weight in the analysis. I note that JOURNALS HAVE SHORT/RAPID PUBLICATION TIMES is also a NA descriptor. These two facets are closely related. ARTICLE SUBMISSION OCCURS VIA EMAIL this may be a signal of poor standards but is often more a reflection of low budgets and the many amateurish journals that have been lumped into Beall's List. JOURNALS DO NOT CONTAIN ANY ARTICLES the high number of predatory journals without articles is a very important data point that should be emphasized. 