 Comments on the manuscript: Thank you for inviting us to review this manuscript. The authors should be commended for nesting this factorial study within the REFORM study, to provide further evidence on methods to increase response to postal questionnaires. It is vital that researchers conduct this type of nested trial for evidence-based methods research to progress in a cost-effective manner. Overall, we found this to be a well-designed, and well-conducted study. We have a few comments regarding the reporting of the results. Title: We don’t think this is currently the best wording for the title - the “nested RCT” was not the intervention. ABSTRACT Conclusions: The authors say that the evidence for “newsletter reminders” is still uncertain, but we think that the authors meant to say “prenotification newsletters”. METHODS Interventions: The authors could make it clearer to what extent the newsletter was a prenotification intervention; for example, was there a letter with the newsletter explaining that the questionnaire was imminent? Or did text within the Newsletter explain that a questionnaire was imminent? It is currently unclear the extent to which the newsletter warned of the imminent questionnaire, and whether it tried to encourage participants to complete it and return it. Perhaps the Newsletter might be included in the Supplementary material? RESULTS Meta-analyses: In the meta-analysis of the Post-it note interventions (figure 4), there is no evidence of heterogeneity among the studies (I-squared=0%) so a fixed effect model, rather than a random effect model, is appropriate. We expect that the 95% confidence interval will be narrower around the estimated odds ratio of 0.97, consistent with the conclusion that the study found no evidence of a benefit of the Post-it notes on increasing response. In the meta-analysis of prenotification by newsletter interventions (figure 5), there is substantial heterogeneity among the studies (I-squared=92%), so in this case, a random effect model, rather than a fixed effect model is appropriate. We expect that the 95% confidence interval will be wider around the estimated odds ratio of 1.19, consistent with the conclusion that the magnitude of the effect on response of prenotification by newsletter remains uncertain, but that a moderate effect (e.g. OR=1.5) is still plausible. CONCLUSIONS We were not persuaded that a study with 826 participants is necessarily “a reasonably sized trial”. A study powered to detect an intervention effect equivalent to an odds ratio of OR=1.5 from a baseline response proportion of 97% would require 3,826 participants in each arm (80% power), or 5,121 participants in each arm (90% power). However, a statistically significant reduction in response with the prenotification newsletter was observed with the study sample of 826 participants, and so this may stand as the study result without any need for the authors to comment on the size of the sample. In our most recent update to the Cochrane Review (cited in the manuscript), Forty-seven trials (79,651 participants) evaluated the effect on response of contacting participants before sending questionnaires. The odds of response were increased by a half when participants were pre-notified (OR 1.45; 95% CI 1.29 to 1.63). However, there was significant heterogeneity among the trial results (P 0.00001). We have recently updated this meta-analysis, for an MSc Epidemiology dissertation (Woolf, B. 2018, unpublished data). In this update, 103 trials were included. Overall, pre-notification increased response 1.38 (95%CI: 1.27-1.49) (pooled result from a random effect model). However, when studies at high or unclear risk of bias were excluded the 95% confidence interval, for the pooled effect of the remaining eight studies, crossed the null. The meta-analysis also found several factors which explained some of the heterogeneity (e.g., the method of pre-notification, using a different method of delivering the pre-notification than the questionnaire, and the risk of bias of the included studies). However, heterogeneity was still present after accounting for these factors. Given that the method of pre-notification appears to explain study differences, and that this study is only the second to explore the use of Newsletters as a type of pre-notification, it provides important evidence for further understanding this method for potentially reducing questionnaire non-response. Is the work clearly and accurately presented and does it cite the current literature? Yes, however, there are some minor modifications which would make the paper easier to read. For example, the presentation of the experimental conditions, although presented accurately, was not intuitively easy to grasp. We personally find it easier to understand factorial randomisation (especially when more complex than 2x2) if a matrix or decision tree is provided, for example, the one shown below. Condition ________|_________ | | Newsletter no Newsletter _________|________ __|_________ | | | | | | hand printed no hand printed no written postit Postit written Postit Postit Postit Postit Is the study design appropriate and is the work technically sound? Yes Are sufficient details of methods and analysis provided to allow replication by others? Yes. However, it would be useful if the length of time period for which a survey response would be included in the study was stated explicitly. Prima facie , varying the amount of time participants have for their response to be included in the study could change the results of any potential replication. If applicable, is the statistical analysis and its interpretation appropriate? No, we believe that a random effect model, rather than a fixed effect model is appropriate in the meta-analysis of pre-notification by newsletter interventions. In addition, we would prefer to see more detail about the adjustments which were made for the main analysis. The authors present an odds ratio adjusted for gender. The adjustment was made because of a baseline imbalance after randomisation. However, it is unclear if the decision to make this adjustment was post hoc or part of a decision procedure in a pre-specified protocol. With this in mind, it would be useful if the authors presented 95% confidence intervals for the crude proportions of responses in each conditions to aid integration of these results, as well as the crude odds ratio. Are all the source data underlying the results available to ensure full reproducibility? Yes. However, we believe that the study authors should be more explicit about the source and selection methods of studies included in the meta-analyses. Are the conclusions drawn adequately supported by the results? See our comments above 