This is a well-written article that was great to read. I particularly liked the recommendations in Discussion re: whether it was worth doing more SWAT evaluations. It would be good to see that sort of clarity more often. I only have a few comments, which are listed below. Interventions Would it be possible to see the newsletter, or at least the bit relevant to this study? We have the Post-It text but not the newsletters. Management of postal questionnaires I’m guessing that the content of the reminders was the same for all participants regardless of which arm they were allocated to but could you confirm this? Table 1 The gender imbalance does look odd to me. I know that you say that it is due to chance and that is of course plausible but it differs by up to about 15% across the interventions for women and by up to about 15% for men. These percentages amount to 10 - 20 or so individuals in a total sample size of 135-143. I’m not sure that size of difference would come about just by chance although, of course, it could. Are you sure it’s just chance, or a feature of the randomisation/blocking/something else? Table 2 Could you consider giving absolute differences for the primary outcome as well as the OR? ORs are always a bit tricky to interpret. Figures 4, 5 and linked text Two points. I think it would be good to do two GRADE assessments of the evidence included in the two forest plots. This isn’t as hard as it sounds. Depending on the design quality of the included studies (and the current 2018 one is good) my guess is that if the two other studies in Fig 4 are good studies, GRADE is high and for Fig 5 it’s moderate because of inconsistency, though you might pull it down for imprecision too (1.19 with a CI of 0.84 - 1.70 seems pretty wide to me). Regardless, I do think it would be good to say something about the certainty of the body of evidence and then link that to your recommendations in the Discussion. The second point is that I wasn’t sure why you used a fixed effect model for Fig 5 and a random for Fig 4. My guess is that the random effects model is the one to go for (I’d be surprised if the only differences between studies is random error but that interventions, patients, context etc are at play too). Worth thinking about anyway, especially whether the intention was for the two forest plots to use different models. 