This paper systematically examined all published literature (481 papers) that analyzed the Millennium Cohort Study (MCS) across 10 pre-selected domains. The MCS is the youngest birth cohort in the UK and will continue across the life course as others have done successfully, such as the 1958 cohort. The authors did a really nice job highlighting important ethical considerations, including the collection of data but researchers not using it. While the authors list four aims of the paper, it feels more that the paper is about identifying how the MCS papers intersect with these 10 areas. The paper is structured more like a research article, with methods and results, rather than specifically exploring the other three areas. For example, the authors mention that aim four is to “discuss the implications for future survey design”, which should be part of the discussion rather than a separate aim. There are a few other weaknesses of the paper that should be addressed. A challenge is understanding how the 10 priority areas were chosen. While it’s understandable that all topics cannot be explored due to the sheer volume of variables at each sweep, it’s not completely clear how these 10 areas were selected. By consensus of the authors? Through discussion with experts? Policy priorities? For example, another topic could be about inequalities with a focus on poverty as the MCS over-sampled disadvantaged children. Page 10 states “ten priority areas which were selected in conjunction with the study management team”. This information should have been included in the methods rather than the discussion. Furthermore, a study limitation was that other important areas were not included, which would have helped to identify gaps in the literature. In addition, page 6 describes the information extracted from the studies and it would have been useful to have a table of summary statistics with these data mapped across the 10 areas. For example, the SDQ, which was used across the largest number of studies, could have been completed by multiple informants and it would have been interesting to know how many studies took advantage of this aspect. On a related note, data have been collected from partners (primarily fathers), older siblings, and teachers. Due to the ethical issues raised previously about making sure that data are used, it’s important to understand how and whether researchers are using these multiple sources of information. Another limitation is the lack of quantitative data presented in the paper, particularly when describing the results of the review. The discussion of the specific measures in the results is too general and does not provide enough of the specifics that were extracted from each study. I would have preferred that specific information about each measure, such as issues related to cut-off of BMI, be included in the body of the results rather than the section titled, “Specific issues around granularity and data usage”. The authors have raised an important point about differences in cut-offs and what that means for interpretation and implications of results. The authors mention that IOTF-generated thresholds were constructed and included in the dataset, which sounds like a good recommendation to encourage consistency across studies. The paper would benefit from summary statistics, such as: The authors make the statement: “Contrary to our expectations, we saw little evidence of granularity being ‘lost’ in this way, although this is likely a reflection of these data being underutilised.” It is challenging to understand how this was determined – through a quantitative analysis or were there specific criteria? Similarly, it would be helpful if the authors could quantify utilization: “Unusually, data collected from children themselves (at age 7 years) were not well utilised,…” Additional information that would have been useful to quantify: How many studies included children who were singletons versus multiple births. A challenge of many analyses is using twins or triplets and they were often excluded. It raises the question as to whether they should be surveyed at all? How many studies included data on fathers, older siblings, and teachers? How many studies included information on the neighborhood context? A study on obesity could have looked at neighborhood quality and obesity. How many looked at outcomes outside the ‘health’ arena in these 10 areas? Such as social, educational, or behavioral exposures or outcomes? Here are comments specific to each section: Abstract Is “novel” analyses necessary? Is this signifying unique analyses, meaning without duplication? Methods Page 3, First sentence: “through an explicit” Is this supposed to be “thorough and explicit”? Page 5, “albeit with the caveats outlined in the conclusion”. This phrase is not clear – please summarize the caveats mentioned in the conclusion. Page 5, what % of the reviewers matched at different points in the selection process? Since papers were only screened if they had variables related to the topics in Table 1, it seems even more important to provide justification on how these topics were chosen. Another approach could have been to review all studies relating to the MCS (additional 258 in Figure 1) and organize the studies around themes to identify what topics have been examined versus gaps. Results Page 6, “The total number of unique MCS studies identified was 481.” However, why is 481 not identifiable in Figure 1? Discussion In Figure 1, it is not clear how many articles were discarded if the variable of interest was not the focus of the paper. It seems that this could be quantified. Another area to discuss is the ability of the MCS to be used in cross-cohort comparisons – how do the variables compare across UK cohorts or across cohorts from other countries? Data will be utilized by more researchers if they can be compared across multiple domains. 