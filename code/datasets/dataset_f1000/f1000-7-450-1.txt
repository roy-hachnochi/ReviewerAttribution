In this article, Barnett examines the precision with which percentages are reported in the abstracts of journals indexed in PubMed. The article does a good job of explaining the motivation and design of the research and putting its results into context. The data presented in the manuscript supports the major finding of the work (that percentages are frequently presented with more apparent-precision than is reasonable). Because my own expertise relates more to the code used for this analysis than the proper presentation of statistics my review focuses on the scripts use to perform the analysis. The linked code repository is currently lacking a number of files required to perform the analysis. I am sure this is simply and oversight, but I cannot recommend this paper for acceptance until these files are included. In addition, the overall design of the analysis code, which contains hundreds of lines of R code without any user-defined functions and no "high-level" documentation of different sections of the scripts, makes it difficult to sport errors or apply this approach to other datasets. I detail these concerns below. Major issues with code The files 'decimalplaces.R' and 'MultinomialCIsBayes.R' are required to perform these analyses but not included in the repository. Many of the datasets produced by this analysis are only saved in binary formats (excel spreadsheets or serialized R objects). Key data underlying the results presented in the paper should be made available in a plain-text format (e.g. csv for the tables). The README file for the github repository should contain: (a) brief description of the most important files included in the repository and their purpose (e.g. make.data.R, decimal.places.stats.Rmd) (b) A list of R packages required to run this code (c) Instructions on how a user can run these analyses (perhaps pointing out any steps that take a particularly long time, and how they might be skipped) (d) Links to this paper and the Zenodo archive associated with this repository. The file "make.data.R" would benefit from some high-level documentation explaining the motivations for each section of the file, and precisely what is being created by each code block. At present, the comments and the top of each block are very brief and difficult to interpret. For example, the comment # get meta data (loop through smaller numbers)" (appearing on line 101) has no obvious meaning to me. Minor issues with code I suggest you avoid using the aliases T and F for TRUE and FALSE. These are not reserved variables, and accidentally setting them to some other value can lead to unexpected results. The code often uses an idiom like already.saved = T if(already.saved==F) { #do something } I am not sure what purpose this serves, as the value is always hard-coded to TRUE. If the intend is to save users from re-running the data-fetching step it may make more sense to save the data to csv, then check for the existence of the data file before fetching fresh data. The variable "journals2" is defined by never used. Line 146 has "for (a in 1:9000)", hard-coding the number of articles to 9000 (slightly fewer than the number included in the study). A lot of typing could be saved from variables like "ci.phrases" if abstracts where always converted to lower case before matching strings. This would both increase the readability of the code and make it less likely that typographical errors slip into the code. Minor issues with the manuscript. The word "accuracy" is often used to describe the representation of percentages. I think "precision" is a better term for what is being described. In the introduction, the sentence starting "Papers have been criticised for using too many decimal places..." does not cite any criticism. Rentrez now has a paper to cite Winter, D. J. (2017) rentrez: an R package for the NCBI eUtils API 1 . 