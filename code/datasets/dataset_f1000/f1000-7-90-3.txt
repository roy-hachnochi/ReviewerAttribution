This study is an observational investigation of the effect of badges/kitemarks on sharing of data and code. The authors compared one journal that introduced badges in 2009 ( Biostatistics ) to one that did not ( Statistics in Medicine ). The main finding was that badges were associated with an increase in open data publication, although with a considerably smaller effect than that observed in the one previous investigation of this question. The finding is important and may influence publishing policies. The main limitation of this study is that only two journals were included. The authors provide a strong reason for this, namely that Biostatistics is unique in having introduced badges sufficiently long ago to have a period of follow-up of several years. Statistical methods are sound; descriptive statistics are very clear and inferential statistics are appropriate. The choice to use the six months before badges came into effect (the "interim period") as a reference period is arbitrary, and it is not possible for a reader to assess whether six months would capture most papers undergoing review and revision at the time the policy was introduced. If papers took longer, that could contribute to the increasing rates of data sharing observed in the run-up to the introduction of badges, seen in figure 3. Thus, the choice of reference period is likely to yield a conservative estimate of the effect of the policy. Papers were coded by one person only, and that is a minor weakness. My experience with coding articles for open data and similar outcomes leads me to think that the main reason to have two coders in this context is to reduce the risk of error, rather than to handle interrater differences in assessments. It is not likely, in my opinion, that errors in the coding have effects on a magnitude approaching that seen for the intervention. I have cursorily reviewed the data and analysis code also. The data variable names are self-explanatory. The code, written in Markdown, is sufficiently documented with inline headings. However, the code requires some modification before it can be run independently, and this is not documented. For example, on line 18, the code attempts to load the data, by calling a file that is not provided. The data must instead be loaded by opening the provided R workspace file. I suggest that the data be made available in a csv or txt file, which is safer for accessibility in the long term and across softwares. The code could then call this file. The ancillary finding of high rates of broken hyperlinks to data at both journals is interesting, as is the explanation that supplementary data were lost by one of the journals during a platform migration. I have several times advanced the argument that this risk is one motivation for publishing data and code using dedicated repositories, but I have not previously seen an empirical observation such as this one. I suggest that this finding should be mentioned in the abstract. One minor detail: In figure 4, the legend does not explain the difference between panels a and b, as in figure 3. In summary, this article makes an important contribution towards our understanding of effects of badges on publication of open data and open code. I am happy to approve this article. 