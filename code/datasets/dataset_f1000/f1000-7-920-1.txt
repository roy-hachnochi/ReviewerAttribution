The authors provide an appropriate and needed review of a leading platform in post publication peer review and preprints, F1000. They collect information on the country of origin, the "success" at being formally indexed, and survey authors on their experiences with the process (which is rarely shared about any other platform, so this information is particularly needed). My critiques below are all modest points for improvement. "Traditionally, authors have not been able to add such research findings to their curriculum vitae and/or grant applications." The only harm implied by this lag is to the author. This roundabout system is also inefficient for reviewers, journals, and for dissemination to potentially interested readers. "In some scientific fields such as pandemics or humanitarian emergencies, the time to deliver research findings may be as equally as important as research quality, and may be critical to health care provision." The authors should couch this as a balance between two conflicting needs: speed for potentially urgent information and ensuring that health-related information is of the highest possible quality. "Open Science Initiative" I am not aware of a formal "initiative". Recommend revise to: "...new emerging options towards publication are being considered as part of the the "Open Science" movement." An additional benefit of Registered Reports is to address publication bias towards significant or novel results. It might be worthwhile to mention that F1000 itself offers the RR workflow. https://blog.f1000.com/2017/10/12/transparency-meets-transparency/ In the intro, the following citations would provide a bit more context for the reader Survey on open peer review: Attitudes and experience amongst editors, authors and reviewers 1 Altmetric Scores, Citations, and Publication of Studies Posted as Prep 2 And for the section mentioning the rationale for Registered Reports, "Instead of “playing the game” it is time to change the rules: Registered Reports at AIMS Neuroscience and beyond" 3 "Non-responders were contacted periodically if a response to the survey was not received." Please provide your rule for re-contact (e.g. once per week until response was received or four contacts were made). "All positive and negative experiences were independently reviewed by both authors and categorized into common topics. Any discrepancies were solved via discussion." What does this mean? That each free response, positive/negative opinion was scored by this study's authors (since you're describing a survey or authors, please clarify who the "authors" are in this sentence). "with no more than 10% of the remaining articles published representing a different article type" Case report was slightly over 10% (this is obviously a nitpick, but it did lead me to wonder if I was looking at the correct column in the correct table). "The majority of articles published received non-commercial funding" Recommend revise to "The majority of articles published reported receiving non-commercial funding..." "Economic status was classified according to the World Bank list of economies (June 2017)" Please provide a specific link to this list. "For the remaining 20% of articles, the lack of indexing was because peer review was incomplete (n=317), peer review had discontinued (n=36) or the article had been removed by authors (n=3)." Does "incomplete" include both articles that received poor reviews and articles that have received 1 or fewer reviews? Clarify the number of articles that received something equivalent to "rejections". I am casually familiar with F1000, perhaps more so than typical but less so than a frequent reader. It is unclear to me if "peer review ongoing" could ever revert to another status. Were there any articles that received multiple reviews that indicated poor article quality? Perhaps provide a bit more explanation of the F1000 workflow in the introduction and also define these categories a bit more precisely. "29% (n=336), after one revision," There appears to be a math error here, probably should be 23%, but please check. Figure 2, "Recommendation" I think should be revised to "Recommendation by colleague", as all the other titles were self-explanatory (to me), but that one I had to open up the survey to understand what it meant (thanks for providing the survey!). "Authors found the process of nominating and reviewers agreeing to review challenging (n=9)" This sentence seems like you are inferring an opinion by 9 people to the entire author pool. I recommend leading the section "Experiences of those submitting articles to F1000 Research" with opinions that can be reliably noted by larger groups from within your sample, and then mention these small N opinions with appropriate caveats (e.g. "A few authors noted...."). Giving the Ns means you are not misleading anyone obviously, it just reads a bit odd to present this as a common experience. Likewise with the last sentence in that paragraph, "A number of authors [had various complains, n=5 and 2]." "The speed and efficiency of publication (n=11) was the main reason that authors felt the experience was positive" change "main" to "most often noted in the free responses" (if that is what you mean by "main"). "The peer review for about 15% of the articles had either been ongoing for more than a year or discontinued completely meaning that many of these articles may have contributed to the vast quantity of inaccessible unpublished literature (and the potential for publication bias) had these articles been subjected to the standard peer review before publication model." This sentence implies that the rest of the articles would have been published elsewhere if not submitted to F1000. I think that is overly optimistic. I would describe that 15% as a floor of that estimate. Also, this sentiment is likely to be met by a cynical reader (one who is more skeptical about the value of preprints than I am), that this is a good thing, that many published articles, and certainly many preprints, do not "deserve" to be published. I recommend addressing or acknowledging that sentiment here. "There was also a general sense that the F1000 Research platform appeared to be ‘modern’ and yet was potentially ‘less attractive to the early career researcher’ because the need to publish in recognised journals with high impact factors is still considered the standard by the vast majority of researchers and institutes to gain promotion and tenure." ‘less attractive to the early career researcher’ Is that a quote from a survey respondent? State that in this part of the discussion, as that could also have come from other sources discussing the pressures on ECRs to publish in more "prestigious" venues. 