 Summary In “Swimming downstream: statistical analysis of differential transcript usage following Salmon quantification” Love et al presents a combined workflow and benchmark for differential transcript usage. This is a vital paper as there is no consensus on which differential transcript usage tools works better (here addressed by the benchmark part) and very few people are aware of the feasibility of analysis of differential transcript usage – something the workflow can hopefully help with. Of special note is the extent to which open source have been embraced by Love et al – an approach that is commendable (and worthy repeating). In the revised version (version 2) the workflow and benchmark have been separated and the workflow has been simplified which, together with the overview figure and the general improvements makes the article much more readable. With regards to analysis especially the benchmark session have been extended. In summary, the revised manuscript version address the majority of our concerns but we still believe the introduction and benchmark could be improved, as detailed below. Comments The authors have updated the benchmark to use testForDEU instead of nbinomLRT for the DEXSeq analysis (verified at https://github.com/mikelove/rnaseqDTU ) but seem to accidentally have forgotten to correct this in the workflow part of the article (page 17) The introduction lacks: A section describing why differential transcript usage are of interest in the first place. A layman introduction to the terms DTU, DTE and DGE. Here it should also be highlighted that DTU can be analyzed both at transcript and gene level (since it is confusing for people not in the field). A more detailed introduction here would also make the concepts behind StageR clearer to readers not familiar with the subject. The workflow/benchmark still contains large chunks of text that belongs in the introduction/methods. Specifically we are thinking of: The scaling section (page 9) It could be even further highlighted that the difference between “scaledTPM” and the other scaling methods is whether the issue with transcript lengths are normalized away. This could also be highlighted by making a figure like Fig1 in Trapnell et al which instead illustrates the DTU problem. We further recommend that the documentation for tximport with regards to scaling is updated with the descriptions made here. The section regarding the theory behind DRIMSeq (bottom of page 12) (could be with the rest of the theory regarding DRIMSeq (page 7) The section regarding StageR (page 14) The article would benefit from a one or two sentence layman introduction to all the tools (for people not in the field). The DTU benchmark should also include an analysis on unmodified simulated data to test how many false positives are found if there truly are no DTU (which might be the case for some datasets). We suggest comparing samples internally in either set 1 or set 2. To reflect a very common use case scenario the DGE / DTE benchmark should also be performed with 2 replicates. All iCOBRA plots would benefit from zooming in on the y-axis to the min and max of any tool across all samples (currently much of the y-axis range is never used – which just squish all samples together). This is especially problematic for the DGE/DTE benchmark. The section on page 30 describing the results in figure 13 is very hard to understand. Given the success of repurposing DEXSeq to DTU, the good performance of limma/edgeR for DTE/DGE and the recent incorporation of RATS, the current benchmark could also test a repurposing of limma’s (and edgeR’s) differential exon usage test (diffsplice/diffSpliceDGE). This is optional – but it would be a huge step forward for testing differential isoform usage as it would bring a lot of clarity to the field. 