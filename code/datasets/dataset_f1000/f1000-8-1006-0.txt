The authors present sourmash 2, a tool that implements a novel combination of SBTs and MinHashes, which are both fascinating computational concepts; thus, their mix is quite an interesting one. Sourmash 2 enables to perform large-scale sequences-vs-database similarity searches. The article offers a comprehensive guide for many of the software features, with biologically relevant scenarios. This is a useful contribution that is highly relevant to current needs in biology. There are a few technical issues with the current manuscript version that I list below. But otherwise, most of my remarks are for adding some extra perspective. I believe the manuscript can be approved after the technical fixes. Major remarks: A quick recap of the state of the art in containment search would be helpful. Here you claim to use ‘a modulo approach’. Mash screen and containment minhash use different approaches (see e.g. the blog post of ‘Mash screen’). It would be nice if, in this paper, the usage of the modulo approach was put into perspective compared to those two aforementioned methods. In fact, in the blog post cited as reference 8, Ondov writes that “the modulo approach is problematic for metagenomic applications (e.g. finding a virus in a metagenome).” The problem is indirectly mentioned in the manuscript (“can sacrifice some of the memory and storage benefits of standard MinHash techniques, as the signature size scales with the number of unique k-mers”). It would be neat to get the authors’ comparative perspective here as to why using modulo is the better approach. My main comment would perhaps be the lack of comparison with other software. I do not know if this is a requirement for F1000Research in the “Software Tool Article” category. I suppose that sourmash is the only tool that implements SBT-Minhashes, so of course here there is no competitor in that category. It would however be nice to have some indication on whether sourmash is best-in-class in each of the proposed features (the uses cases), or whether other tools already exist and somehow do a similar job. And, the other way around, which areas where sourmash is really the only tool capable of doing X in reasonable time. I do not expect a comprehensive benchmark, but some informal indication would already be appreciated. What are roughly the limits of similarity queries? E.g. sequences shorter than X or having identity below Y% have no chances to be reported. A summary of all the features demonstrated in the main text could be helpful. For instance, reading only the introduction, it is not explicit that a natural application of sourmash is outlier/contaminant detection. Minor remarks: “Sequence Read Archive now contains over 20 Petabases of data1”: seems to be over 30 PB in 2019 according to the plot in reference 1. It is not clear what the ‘LCA’ term stands for in the context of the database format introduced here. Is it the lowest common ancestor? The description of LCA (in section “LCA database”) is imprecise. What does a “named list” mean in this context? A Figure would be helpful to see a small example. A sentence in the manuscript mentions ‘a second database format’. The ‘first format’ is supposedly the SBTMH but it is only implicit that SBTMH is a ‘format’. The introduction mentions a bunch of features implemented in other tools (“Jaccard similarity comparisons, .., k-mer abundance comparisons, decrease runtime and memory requirements, and work on streaming input data.”) Are all of these implemented in sourmash2, or only a subset of them? (It seems to me that most are implemented.) The description of the modulo approach used is imprecise. How is the hash space divided into s equal ‘bands’ (undefined term), precisely? Also, I suppose this somewhat different from the modulo approach proposed by Broder, and clarified in Mash screen’s blog post, but how so? The concept of ‘hash subset retention’ is not well defined. I suppose it is the set of hashes that result from a MinHash computation. Abundance filtering (as in Finch) is not performed in sourmash2, right? Some of the ‘signature utilities’ are self-explanatory. However, what is the difference between ‘intersect’ and ‘overlap’? What is ‘flatten’? Regarding the sentence: “although we recommend using more accurate approaches for detailed comparisons.” To make the paper self-contained, a short explanation would be needed to delineate what sort of concrete use-case(s) is/are meant behind the term ‘detailed comparisons’. The “similarity queries” and “containment queries” sections could benefit from at least one use-case example per query. This is to illustrate the two sections, which are a bit obscure without examples. (I realize that use cases are given later in the codes examples, so perhaps a forward-reference could work, albeit less elegant.) A proposal for similarity queries: ‘find all genomes in the SBTMH (leaves) that are similar to a query genome’. Awkward formulation of that part of the sentence: [..] ‘using a k-mer size of 4, use all 4-mers, and track abundance.’ (although I understood that the k-mer size was 4 and the ‘use all k-mers’ refers to a scaling factor of 1) The “Tetranucleotide Frequency Clustering“ section is quite nice. It should be emphasized however this isn’t really a minhash sketch: all 4-mers are considered. Regarding the sentence “We see that the minimum similarity in the matrix is 0%”, how is that seen? visual inspection of ecoli.comp.matrix.png? Regarding the sentence “This process is repeated until the threshold is reached.”: I forgot.. which threshold? Regarding the sentence “We see that 20.1% of k-mers match 82 genomes in GenBank.”: how is this seen? Also “we see two matches between P. ruminis strains among all matches.” In the output above that text, I see only one match. (I could not test that section due to the missing download URL.) Regarding the software commands: As an important note, one cannot easily copy-paste the command lines as short dashes (-) are converted to long dashes (–). Nevertheless, I still automatically replaced all the dashes and tested all command lines. I’ll report any problem below. Extra ‘\’ at the end of the command: “curl –L –o ecoli–reads.khmer.fq.gz https://osf.io/26xm9/download \”. Missing url in command (and also extra ‘\’ at the end): “[..] unmapped–qc–to–ref.fq.sig https://osf.io//download \” Thus I could not test this part. The streaming operation at the beginning of the MDS section overwrites the file ‘ERR458584.khmer.sig‘ produced before, perhaps make a note of that. The url “curl –L –o genbank–d2–k31.tar.gz \ https:// s3–us–west–2.amazonaws.com/ sourmash–databases/2018–03–29/ genbank–d2–k31.tar.gz“ has extra new lines In the command “sourmash index –k 31 ecolidb \ escherichia–sigs /*.sig”, a space is wrongly inserted after “escherichia-sigs” And also, in the command that follows, one of the ‘\’ is extra and another ‘\’ is missing. The SBT path inside the file ‘fungi-k31.sbt.json’ is wrongly hardcoded. Also, when fixing it, I get “WARNING: this is an old index version, please run `sourmash migrate` to update it.” Although it did end up working. 