Thank you for the invitation to review this well-conducted systematic review. The study under review is very interesting and necessary for the Clinical Practice Guidelines (CPGs) community and for the implementation science and healthcare quality communities. I would like to congratulate the authors for this difficult challenge with some minor comments to contribute to improve the content and message of this necessary study ABSTRACT: Conclusion "There are probably still undiscovered variables that interfere with the use of the CPGs" . That could not be a conclusion from the study, given that the aim of the work was not to study factors and conditions that facilitates the implementation of CPG neither the conditions to change professional behavior. No data on these issues are reported, then no conclusion could be provided. A coherent conclusion could be the need to improve and systematize this kind of implementation studies. Introduction: pag 3, para 4, left column "After an exhaustive search, only two systematic reviews (SR) we found on this topic," It is needed to provide both references RESULTS: pag 3, 4 and figure 1. Study identification and selection. "Of these, we selected 96 studies after assessing the full texts". It is needed, in order to strengthen the transparency and reproducibility of the work, to display in an extended data appendix, the full reference list of rejected originals and reasons to be rejected (96 found minus 9 selected = 87 rejected). It should be clarified what is meant in the figure 1 tab "# 87 of studies to include in other analyzes". Pag 4, left column, para 3, rows 4-6: "When assessing the full-text articles, we found that many were cluster trials" There is no clear reasons to reject RCT clusters studies, when the intervention could be randomized to cluster offices, and the outcomes effect measured at individual patient level. It is a well-accepted methodology in implementation science, given that can control for bias and non-measured variables. (Please see 2 references provided: Eccles and Romero). 1 , 2 Pag 5, Table 1, Rows 2-4 and Column 5: "Certainty of the evidence (GRADE)" It is difficult to understand why the certainty of evidence for the outcomes "time without flow" and "delay to start CPR" are classified differently when, as displayed in the explanations, the bias and systematic errors are the same, and there is not a loss of patients to follow up. It is true that both effects measure score different statistical significance, but with data provided the readers feel with the same certainty (either moderate or low) that one effect is significantly different from the control group, and for the other outcomes (delay) there are not differences with the control group. Pag 6, Table 2, Rows 2-4 and Column 5: "Certainty of the evidence (GRADE)" The same reasoning for the difficulty to understand why are classified differently the certainty of evidence for the outcomes "LDL cholesterol" and "Total cholesterol". Discussion: Pag 7, para 2, rows 7-13 "This fact could lead us to assume that researchers have given more importance to the evaluation of using (or not using) the recommendations in the area of the process, instead of their direct impact on the patient health". Another explanation could be to emphasize that it use to be easier to measure process of care than patient health outcomes. These health outcomes take a longer period of observations than to measure how professionals adopt CPG recommendations. That can explain the "preferences" of researchers. Conclusions The same considerations exposed in the abstract regarding the sentences "There are probably still undiscovered variables that interfere with the use of the CPGs" . That could not be a conclusion from the study, given that was not the aim of the work to study factors and conditions that facilitates the implementation of CPG neither the conditions to change professional behavior. No data on these issues are reported, them no conclusion could be provided. A coherent conclusion could be the needs to improve and systematize these kinds of implementation studies. 