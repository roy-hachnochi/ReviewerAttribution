The authors proposed a novel approach to model the regulatory activity of DNA sequences and, by incorporating the projection layer into a new convolutional-recurrent architecture. The proposed method obtains state-of-the-art performance on the full DeepSEA dataset. In the experiment process, the authors explore what effect the projection layer and dropout rate have on DanQ, CNN and CRNN models, and explore the role of projections in achieving this performance. Meanwhile, applying the global average pool to reduce the number of parameters, which is a method to save training time and memory. The key contribution of this article is that the projection layer and dropout rate are utilized to model regulatory DNA, which provides us a new idea about how to mitigate the disadvantage s of a large first layer. The paper is well-organized and provides new insight into modeling the regulatory activity of DNA sequences, however, there are still some improvements needed. Major comment 1: It is not clear to me how many times the models in Table 1 are tested. Meanwhile, regarding the results shown as figure 1 and figure 2, we usually test more times and give the boxplot of the results, to avoid the randomness. Major comment 2: The authors should descript how to optimize their model, in detail. Major comment 3: It is awesome that the 257 of the 700 learned motifs are obtained by the CRNN-700-projection model. If some of the learned motifs are shown in the main text, this article will be more attracting. Meanwhile, the DanQ model can also be used to extract motifs, this model should be compared to the CRNN-700-projection model. Minor comment 1: Please, ensure what the ‘4’ means, in the penult line of the Introduction. Minor comment 2: Please, provide the expansion of PAC and PFM. Minor comment 3: The flowchart can clarify the authors’ method, why not consider adding the flowchart of your approach. 