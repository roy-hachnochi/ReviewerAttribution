Froussios et al. have presented here a new tool, RATS, for the identification of differential transcript usage from transcript abundance estimates. RATs was benchmarked and compared to the existing tools DRIM-Seq and SUPPA2 across four different datasets. False positive rate, false negative rate, sensitivity and Matthews correlation coefficient were all measured. When considered as a whole, RATs was found to outperform the other tools. Differing results due to the version of the reference genome used are also discussed. This is a nicely presented manuscript, with well thought out comparisons. The tool will make a good addition to existing RNA sequencing analysis pipelines, especially as the field moves towards alignment free methods. The rationale for the development of this tool is clearly stated, as there are only a few tools which carry out DTU detection from alignment-free RNA-seq quantifications. The majority of existing tools for DTE and DTU are designed for use with alignment- and assembly-based methods. Of the existing tools described, each has specific uses, and RATs has been presented as a broad "differential transcript usage" identification tool. The methods of the analysis have been described well, and overall are technically sound. I would like to see an expansion on the description of the statistical method underpinning RATs. Although G-test of independence is cited, a brief description of what this entails and how it differs from existing tools would aid in the understanding of how the tool functions. However, I have some suggestions concerning the comparison of tools and the datasets selected. With regards to the selection of tools for comparison, SwitchSeq and iso-KTSP are mentioned within the introduction as being able to use transcript abundance estimates, however are not compared to. I assume that this is because they are too specialist in their identification of differential transcript usage and/or isoform switching, but I think the decision to not compare to these tools should be more explicit. The authors have not mentioned the recent pre-print from Cmero et al. (2019) 1 which discusses the development of methods for DTU detection from alignment-free datasets using equivalence classes. The paper uses the same simulated datasets for benchmarking of the tool, and should be considered as another tool to compare to RATs. If this is not deemed as an equivalent method, it should at least be discussed in this manuscript. With regards to the datasets tested, the published human data set which is shown here is not directly confirming the accuracy of RATs, as the authors show that the qPCR validation within the original study may be inaccurate, and underlying issues are present due to the reference genome version. Although the dataset is being used to compare RATs to SUPPA and DRIM-Seq, it is not validating the tool. I think that this manuscript would benefit from comparison of the three tools using another "real-life" dataset, which has been validated in some way, to support that RATs is detecting known DTU. Methods for tool development and testing are clearly described, apart from with false positive testing with A. thaliana dataset. The authors should include details on how the transcript abundances were produced for this (using Kallisto or Salmon? Any other pre-processing?). All datasets used are publicly available with accession numbers given. Additional data is provided within published links; however, these would benefit from a simple readme file, which explains the contents of each extended data file so the reader doesn't need to search through them. Within the results, it would be nice to see more discussion on the impact of the bootstrapping information used by RATs. I think that this is a really beneficial part of this tool and this has not been demonstrated enough. It should also be made clearer if this bootstrapping information is obtained solely from Salmon/Kallisto or if RATs implements it's own bootstrapping. Although the testing of the simulated datasets does show that RATs outperforms DRIM-Seq and SUPPA2, I don't feel that as it stands you can conclude that the analysis of the published dataset shows this. When comparing to the published findings, SUPPA2 shows better results with confirmation of the qPCR results. As I've mentioned above, I would find another "real-life" dataset for comparison, or simply re-word the conclusion so that this isn't overstated. 