 General comments: The Harvard Medical Practice Study (HMPS – cited by the authors) used post-discharge chart review to detect care-associated injuries (adverse events – AEs) that occurred during hospitalization. Under HMPS, trained nurses reviewed a random selection of charts. If those nurses discovered what they judged to be care-associated injuries, they flagged those events in the chart as a potential AE. Charts that contained one or more AEs were forwarded to 2 independent physician reviewers. If both physician reviewers judged, for each AE, that event had occurred, then it was reported as a confirmed AE. Those physicians also judged whether each AE was avoidable, and whether each could be considered negligent (substandard) care. The IHI Global Trigger Tool (IHI GTT) built on the HMPS methodology. It attempted to improve the ability of initial nurse reviewers to detect potential AEs, by providing a set of 51 “review triggers,” falling into 7 major subcategories – explicit initial events that, if detected in the chart, chained to examination of other specific events. Initial assessments of the IHI GTT showed much higher detection rates for AEs than did the original HMPS methodology, which itself far exceeded typical voluntary reporting mechanisms. This study reviews the use of the IHI GTT in 44 Sicilian public hospitals across a 3 year time period – June 2015, through June 2018. The study’s authors adapted the IHI GTT to their specific environment. They also added 3 additional review triggers, beyond those included in the original IHI GTT. They focused their analysis on a subset of all charts assessed with their modified IHI GTT: They analyzed only charts for patients hospitalized on medicine, surgery, obstetrics, and intensive care wards. As this study notes, many other groups are using the IHI GTT to detect AEs. This work is useful because it supplies empiric observation of one such use, across a large system of hospitals and an extended period of time. This report has at least 2 major differences from other work in the field. First, only 6.6% of records reviewed had at least one care-associated adverse event. Other studies have shown much higher AE rates. The authors note this in their text, and suggest it may reflect differences in local environments and chart review methods. Second, most other IHI GTT reviews show adverse drug events (medication-related events - overdoses, drug-drug interactions, and allergic or idiosyncratic reactions) as the dominant category of AEs detected. In this study, they are a distant number 3. Why? Specific suggestions: It appears that the entire IHI GTT program assessed a total of 18,008 records from among 105 hospital wards from June 2015 through June 2018. However, this analysis examines only medicine, surgery, obstetrics, and intensive care wards. Those represented a total 89 wards, with a total of 14,706 records reviewed. This is unclear in both your abstract and your text. It would be very helpful to more clearly explain how you derived the CRs included in your analysis. You mention that you had a total of 199 individuals who participated in 71 3-person review teams. Obviously, some people participated in more than 1 team. It is not clear how the 2 initial reviewers shared their work, before their findings were submitted to a physician for final validation. Did they both separately review all records? Did they divide their assigned records between them? Please clarify. In your introduction, 2 nd paragraph, you review alternative methods for detecting AEs, including incident reporting, CR review, and automated administrative data review (e.g., PSIs). Consider adding “prospective (concurrent) clinical trigger systems,” that track possible real-time clinical responses to AEs then track back to see if an AE actually occurred. Dr. R. Scott Evans at LDS Hospital in Salt Lake City, Utah; and Dr. David Bates at Brigham Women’s Hospital in Boston, Massachusetts, developed and demonstrated such systems. Such approaches find AEs that never make their way into a traditional clinical record, and may detect far more events. Under Methods, please change the heading “Sampling selection” to say something like “Sample selection.” More importantly, the frame within which “10 inpatient CRs” were selected monthly is not clear. Working the total number of charts reviewed backward, you were probably sampling “10 inpatient CRs” each month for each of the 44 Sicilian public hospitals. Please clarify. How was record selection balanced across the types of wards (medicine, surgery, obstetrics, and ICUs) in each hospital? Under Results, please add clarity regarding the number of patients that had at least 1 AE during their index hospitalization (975); then break out the number of patients who experienced a single AE versus those who had more than 1 AE during their index hospitalization. Table 1: Please clarify – I can’t understand what you mean by the phrases “CRs with triggers per inpatient wards” versus “CRs with trigger isolated per wards”; or “CRs with trigger” versus “CRs with trigger isolated”. Consider moving the first 2 paragraphs of the section entitled “Rates of triggers” from the Discussion section into the Results section. Clarify your text in the first paragraph of your “Rates of triggers” section. For example, it might read: “In this study, 37.9% (n=5,574) of all CRs examined had at least 1 positive trigger. Of those, 2,778 CRs had a single positive trigger (49.8% of all CRs with positive triggers) while 2,796 CRs had more than one positive trigger (51.2% of all CRs with positive triggers). Consider modifying Table 2: a) Label each of the subsections in Table 2. For example, in your text you cite the Table relative to “general care triggers”. What are “general care triggers”? Presumably you mean the subset of triggers with “C” labels. It would be quite helpful if you put headings on each of the subsections (for C, M, S, P, and I) that labelled the contents of each subsection. b) You are (quite appropriately) approaching AE detection as a screening test with 2 main steps. Step 1 involves evaluation of the initial triggers. Step 2 involves following up on positive initial triggers, to see if a validated AE emerges. This is done in the context of a general review by a trained clinical expert, who can (and sometimes does) detect AEs that fall outside of the trigger system. It would be very useful if you separated the total time spent on CR review into (a) initial assessment of the triggers; versus follow-up analysis of the positive triggers. It would similarly be very useful if, in the 3 rd column of Table 2 (labelled “Times associated with AEs, n (%)” you showed the proportion of positive triggers that yielded a confirmed AE related to/deriving from the initial positive trigger. The Table, as currently constructed, is quite confusing – in 10 instances (C03, C04, C08, C11, C12, C14, M02, M04, I01, I03) the count in 3 rd column is larger than the count in 2 nd column. Presumably, this is because you are not connecting the trigger to derivative AEs (but I can’t really tell, with any certainty). The section entitled “Rates of AEs”, first paragraph, contains the sentence: “It would appear that the percentage of clinical records with triggers increases with the increase of percentage of CRs examined, compared to patients discharged, while the percentage of CRs with AEs remains more stable.” I can’t translate quite what that means. Please simplify and clarify. It may relate to the 2 upper lines in Figure 2, which both appear to be increasing over time. However, you supply no statistical analysis to show that trends over time in the 2 lines are statistically associated, and you offer no reasoning as to why such a relationship may have meaning. Table 3 appears to identify high frequency triggers, then count the number of AEs of any sort that occur in CRs that had a high frequency trigger. It would be much more useful if you tracked each trigger to related or derivative AEs, rather than treating AEs generically. In the section labelled “Rates of AEs” you have a bulleted list. The last item in that list says: “Intensive-care-related triggers have been identified 1,817 times with an AE in 1,924 (i.e., it is very common for triggers to identify more AEs in the same patient)”. I think I get the gist of what you mean, but (a) this sentence needs more clarity; and (b) the main purpose for identifying AEs is to move toward intervention and prevention (better, safer care). In that circumstance, treating AEs as generic items is not very useful. It is necessary to list them by specific causes. In that framing, associating triggers (which are cause specific) with a total generic AE count is not very informative or useful. You might want to rethink your framing. Spelling corrections: In the Abstract, Methods subsection, it should say “300,000 inpatient yearly admission s ”. In the Methods section, it should say “Sample selection,” not “Sampling selection”. In the Discussion section, 2 nd paragraph, it should say “A critical appraisal of the studies and their results is difficult, as the methodolog ies use are heterogeneous,”. In Figure 1, the label for the blue line should say “ Sensitivity (%) ,” not “Sensibility (%)”. In the section labelled “Rates of AEs” there is a bulleted list. The 4 th bullet should say “Surgery- r elated” (not “Surgery-elated”). 