This paper intends to measure journal indices for OA journals, and compare them with the indices of Non-OA journals. The authors used the Scopus database. Although the theme is not new, I believe that the large number of indices calculated by the authors is a useful contribution to the literature. Database: I am a little ambivalent about the Scopus database. It is an extensive one, but to my mind it has two characteristics that need to be kept in mind. First, Google Scholar has, in all probability, overtaken Scopus in the breadth of coverage of publications for indexing (though till about 8 years ago Google Scholar was inferior to Scopus). Secondly, GS is more lax in its selection of journals to index, and it is more than likely that several “poor quality” journals are included. The authors themselves make these observations. I submit that the so-called poor quality of the journals indexed by GS is not really a drawback, and inclusion of these journals is more likely to provide a realistic picture. That said, using the Scopus database is an acceptable choice, and the sampling is large. Statistics: The choice of statistical tests is acceptable. I think that choosing two groups (OA vs Non-OA) is adequate for the objective of this paper. Would a third group, hybrid, have helped? Possibly, but hybrid journals are extremely varied in the number of articles they allow for open access, and I doubt that one hybrid journal, allowing 10% of its articles for free access, can be compared with another that allows 25% access immediately and full access after 6 months. However, I was not able to duplicate the calculations of the authors. The authors state as follows: CiteScore median = 1.19 for OA journals, 1.06 for non-OA journals. However, I calculate 1.2750 and 1.16 respectively, though the differences are still statistically significant. I get different values for the other metrics as well. Perhaps the authors should consider rechecking the values with their statisticians. Methods: Although the methods are described with reasonable clarity, I was unsure of the period covered by the data collection. The data file suggests that the data was collected for journal issues published from 30 April 2018 onwards. Have I understood correctly? I would request the authors to provide this detail in the methods. Results: The authors have recorded data for SJR values but have not discussed the results. There may be no significant differences between the two groups (OA, NOA), but I believe that they must discuss the implication of this result. The median SJR for NOA papers is slightly (but not significantly) higher than that for OA papers. Is this because NOA papers have a higher “prestige”? (Compare with their comments for scholarly output.) Recommendation: The authors should consider: A. cross-checking the results, B. clarifying the time span that is covered by the study, and C. commenting on the SJR results. 