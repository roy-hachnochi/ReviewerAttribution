I really appreciate the opportunity to review this manuscript. The feedback written have been done with respect to the authors and with the aim to improve the manuscript. I hope to have a good reception by them. Simulation research is just starting in Latin America, so I congratulate the authors for the excellent work that they have done. The manuscript initially looks interesting, well written and well referenced. But reading it more deeply, few concerns arises. The majority of my concerns revolve around how the manuscript was written and to have more information about methods and stats. Methods: Did the authors perform an ethical committee submission? This should be stated in this section. Line 5: “Taking a heterogeneity of 50%, with a margin of error of 5% and a level of confidence of 95%, the sample was 140 students”. In order to have the statistical details all together in one part of the manuscript, I would move this part to stats. Ln 7: “For the selection of the sample, randomized sampling was carried out”.I dont understand completely this part. How did the authors the randomization process?. The randomization was performed to assign the instructor for the assessment? I would expect a deeper explanation about how the authors did the selection of participants. Ln 8: “Groups of 7 people were organized for each evaluator in a random manner, with a total of 14 participants per day, ending at the 10th day with the 140 participants”.I would explain the training first and then the assessment. From my perspective methods should be written in order to be clearer for the reader. Ln 41: “Theoretical standardized tools were used for evaluating the course received”.I understand that AHA assessments are standardized. But as a reader I would expect a deeper explanation about the assessment. Did the authors videotape the assessment sessions? Did they do the assessment by direct observation? Did the authors used 2 observers for the assessment? Ln 50: “After 30 days, the theoretical and practical evaluation was carried out once again for each of the participants. Again, I would expect a deeper explanation about the assessment. 1 versus 2 observers? Direct observation versus videotaped? If videotaped, blinded assessment regarding first and second evaluation? Agreement calculation? Data analysis: I would state here how the authors did the sample size calculation. What difference did the authors used to calculate the sample size? Ln 1: “Cohen Kappa index was initially performed to determine the concordance and standardization of the knowledge taught in the intervention”. I am not clear about what type of agreement did the authors calculated with Cohen Kappa? Ln 3: “The result was 0828, which indicates a high agreement between the two instructors; therefore, it was possible to continue with the study”.This should be explained in results. I would use a point in the number 0.828. Ln 8: “Central tendency and dispersion tests were performed, as well as Student’s t-test, one-way ANOVA and ANCOVA”. Regarding Students’ t-test. Did the author used independent or paired measures test? Results: Ln 2: “There were statistically significant differences between the subject groups for the first theoretical test immediately after the ACLS course. It was observed that these differences were between the Emergencies and Disasters and Anesthesiology groups (p 0.05), as well as between the Critical Medicine and the Anesthesiology groups (p = 0.027). No statistical difference was seen between the Emergencies and Disasters and Critical Medicine groups”. It’s difficult for me to understand the differences. Maybe to add a table would be better for the reader. The same for the second theoretical assessment. Ln 16: “There was no statistically significant differences in the first practical examination between the groups when evaluating their practical skills acquired immediately after the intervention of ACLS (p = 0.066)”. Again, maybe add a table. I would add the test that the authors did to perform the comparisons between groups. Table 1: Please include the number of participants per group. Additionally, a dispersion measure should be state for each line. Discussion: Ln 36: “These findings suggest that appropriate intervals and re-training strategies should be differentiated between knowledge and skills, with reinforcement of the latter”. I would discuss the idea of rethink how powerful is the intervention. I understand that ACLS protocols have been done succesfully for years. However, the mission of educators and researchers is to questioning how we are doing it, supported by this interesting new data. Maybe a 1 day course is not enough training to achieve strong competencies. A good score immediately after the course, could be explained by repetition and doesn’t assure a good achievement of competencies. Previous literature supports the idea of skill decay. But 1 month is so short from a practical perspective, that we should rethink how we should train these competencies. 