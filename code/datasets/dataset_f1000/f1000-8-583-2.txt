This paper presents an interesting perspective on rankings with particular attention given to quality vs quantity argument. There is an extensive literature on rankings and research; the authors refer to some of the key texts. The issue of citations is arguably more problematic than referenced here; the problem of citations includes self-citation and poor practice as well as whether it is a meaningful measure of quality. However, there is a wider debate around whether citations are a meaningful or appropriate measure of 'impact' given that policy attention is increasingly on impact beyond the academic community. The authors use examples of research best practice to ask about the extent to which rankings - which predominantly measure research output - are 'genuinely' concerned about the quality of the research or simply the number of papers or the number of citations, etc. This is an admirable attempt to get behind the rankings. As part of the methodological steps taken, the authors encounter a major default with the research data as evidenced by the way in which authors describe their own institutional/university affiliation. This is a major problem for institutions; on the other hand, it can also be one of the cheapest ways to improve in the rankings simply by cleansing the data as well as ensuring that the institutional data supplied is accurate. There are examples of universities which have changed position, up and down, because of this. Surprising how much institutional data is either inaccurate or indeed 'gamed'. The extent of the cleansing problem revealed is nonetheless staggering. The results are particularly interesting, particularly the positioning of China in the country and university rankings. This comes at a time when China is being accused of poor practice, this is a very interesting result. It also reflects the increasing multi polarity of global science. While previous decades saw the EU, Japan and the US dominate, as Leydesdorff, Wagner, Adams (2013) 1 argue, today the number of scientific nations now includes more than 40 nations. This is an interesting finding and may challenge perceptions of the scientific world. The paper gives us food for thought albeit it is unlikely to affect the main rankings - Times Higher Education and QS - or even Shanghai's Academic Ranking of World Universities given the level of complexity. Nonetheless, it asks valid questions about whether what is measured is what we think is measured. 