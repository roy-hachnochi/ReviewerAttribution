It is good to see original studies on low back pain (LBP) from Africa. LBP is a global problem and yet is under-represented in research from countries such as Kenya. This is a generally well-written paper, with appropriate methods and analysis and presentation of results. So the overall opinion is that this is a useful, well-performed and reasonably well-reported study. There are some weaknesses however, and they are discussed below in the hope that they will help interpretation of results and be constructive for future research by the authors. 1. Study rationale: The authors carefully chose a narrow focus for their paper. This study is about LBP in University teaching staff, and the limit of the generalisations made at the end of the paper is that results can be extended to teaching staff in other Higher Education institutions in Kenya. The authors’ main conclusions relate to a proposal that the risk factors for low back pain identified in the study should and could be reduced in these workplaces. This is admirable as a stimulus to local preventive action, but the interest for an international readership would be (a) to consider to what extent the prevalence estimate in this workplace population represents the occurrence of LBP in older Kenyans and Africans more widely, and (b) to know how the findings on the risk factors for LBP compare with and contribute to the extensive global literature on these factors. Such wider objectives would draw out the study’s importance beyond the local occupational setting, but require a more detailed discussion section (see below). 2. Study context: It is rather alarming to read that this observational study of LBP in a random sample of teachers in a University health faculty could take as its case definition low back pain of minimum 24 hours plus visit to health care plus spinal imaging . Given that international guidelines recommend strongly against X-ray for uncomplicated back pain, does this mean that in Kenya most people experiencing back pain will expect to have an X-ray (which would be important contextual information for the paper) OR does it mean that this is a highly selected sample of all those in this population who had LBP (i.e. were there many people reporting back pain who had not had an X-ray and were therefore excluded from the study? – this would be important for study interpretation). 3. Study style: The authors have appropriately and importantly included workplace stress and supervisor support and demographic/lifestyle factors among the potential risk factors for LBP. This is excellent, but much of the introduction and discussion defaults to “physical” explanations of, and mechanisms for, LBP. Chronic LBP is a complex biopsychosocial phenomenon, in which mental health and cultural perceptions play as big a role as mechanical factors, and this could be recognised more explicitly in the introduction and discussion sections. 4. The definition of low back pain: The definition of the area of the back to be included is admirably clear, as is the minimum duration of 24 hours. However it is unfortunate (especially for the estimate of prevalence) that there were no further details on the pain itself and its impact, in order to sub-group the prevalence estimate according to severity. Back pain is so common that, to provide prevalence estimates that are more widely useful for planning, prevention and care, it should be standard practice in prevalence surveys to add a measure of severity and impact, such as that in Von Korff et al, Pain, 2020. 1 (The authors might argue that this was not so necessary for the risk factor component of their study but that is one reason for clearly separating the discussion of prevalence and risk factor components of the study – see comments below). 5. Study design: The authors say at the end of their paper that more research with stronger designs (including case-control) is needed to confirm the results found in their cross-sectional study. I think the authors are underplaying their own design. There is an argument for saying that their study has two components – first, a cross-sectional population survey to estimate prevalence, and second, a population-based case-control study to study associations with LBP. The arguments for suggesting that the risk factor study is a case-control study are: Exposures were compared between those without LBP in the survey who represent a population sample of “controls”, and “cases” with LBP (after exclusion of cases with other causes (injury/infection)). The sample size has been estimated on the basis of exposure data, as for a case-control study, rather than for the prevalence study. The authors have attempted to ensure that, when gathering exposure data, participants were asked to recall exposures in periods prior to the onset of their LBP – a classic piece of case-control design. If these two components of their study were separated, then the authors could usefully critically reflect on the following design points: a. It was good to see a flow diagram of response and exclusion, and a high response rate, for the prevalence study. But what was the size of the total eligible population that provided the basis for stratified sampling for the study population (before exclusions, invitations, and nonresponse)? A small point to note is that the word “aggressive” in relation to following up non-responders is best avoided. It is better to give the details of exactly what was done, including a clear account of how and when people’s non-response is taken as final. b. What was the origin of the questions used in the semi-structured interviews, and had there been any investigation of questionnaire validity prior to the main study? For example, alternative external records on the “lumbar support” seating data might have been sought from departmental purchasing data; repeatability of physical activity recall might have been tested by repeat interviews in a sub-sample of participants; were the interviewers aware of the participants’ back pain status when they asked about the risk exposures? Even if these “safeguards” were not carried out, the authors could consider adding a critical discussion about what they might have added to the credibility and validity of the study. 6, Study analysis: Independent data entry is excellent practice – but some details of how any disagreements were handled would be useful, together with a summary of such disagreements. Medians are fine but it might be better to make a statement about distributions of the relevant continuous variables because looking at them it is unclear why means and standard deviations were not chosen. The authors seem a little uncertain themselves because mean age is quoted in the discussion and median age in methods and results. The analysis of results was nicely structured and followed a clear and appropriate pathway from descriptive to univariable to backwards multivariable models. However there was often a slightly ‘formulaic’ style to the writing of this, which could be avoided and softened by inclusion of some actual descriptive data in the text. Mention should be made that the high prevalence of some exposures means that the odds ratios are likely to be overestimates of actual risk. 7. Discussion: This was the weakest part of the paper and could have been a lot stronger. The section on bias again seemed rather ‘textbook’ in style and content, and does not convey the sense of a rigorous critical discussion of the specific issues raised by this study. More detail from the study itself and more detailed discussion of the individual points would help. The authors raise as a limitation that the outcomes (presumably meaning back pain present or absent) are based on self-report – but it is difficult to see how the presence of back pain could be based on anything else but self-report. So this should rather have been a discussion of what the effects of misclassification of cases and controls might have been. The sentence that states “it is anticipated that the current study’s prevalence underestimates the true burden of LBP in this study population” is decidedly odd, given the initial high response rate. This is where it would help to link the discussion back to the rationale for the study (what population is the prevalence trying to represent? How much bias could an initial 20% response possibly introduce?). The final sentence of the discussion is not convincing.I don’t think it is right to say this is a “hypothesis generating” study – it does not fit with their main conclusion which urges all educational institutions in Kenya to look at how to modify risk factors in the workplace. This is an important conclusion but needs to be reached from (a) careful critical assessment of whether there study has established ‘cause’ or just association, and (b) rigorous comparison of their results with the wide international literature on these risk factors to see if their study is consistent with that literature and therefore strong enough to drive recommendations. Finally there should be a separate conclusion about the prevalence study, with suggestions of how the authors’ methodology might be used as the basis for more research to establish prevalence in other sectors of Kenyan society and why this might be useful to know. The authors are helpfully comprehensive about how their study fits with other prevalence studies in Africa – this is so important - but they could perhaps acknowledge that severity and impact must be added to future prevalence studies in their country. 