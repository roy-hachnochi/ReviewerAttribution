In “Preprints and Scholarly Communication: Adoption, Practices, Drivers and Barriers,” Chiarelli and colleagues present a literature review, commentary, and a summary of attitudes and perceptions towards preprints found by interviewing 38 stakeholders. The interviews convey many commonly-held perceptions about the benefits and disadvantages of preprints, and the authors suggest questions for further exploration and testing. With revisions (clarifying the origin of claims, contextualizing the responses from study subjects, and correcting factual information in the text) this paper will become a very useful addition to the literature. Major comments Design and Subjects: We encourage authors to rely on a more robust review of published literature (including the grey literature) to complement their interviews, as the published literature contains useful context for comments which are obfuscated by the process of anonymous reporting (For example, the sentence, “One preprint service provider observed that only 10% of preprints received comments.” would be more useful to readers if accompanied by a reference with attribution: https://asapbio.org/biorxiv ) Since this work may be of interest to a wide range of readers, we recommend including more detail regarding the chosen experimental design. Please provide justification for the experimental design, for example, why were interviews used instead of a survey? What are the methodological considerations that would be helpful for readers outside of qualitative research to understand: limitations, constraints, advantages over more quantitative methods? Please define semi-structured interviews — how were researchers encouraged to expand on thoughts? Please define “purposive heterogeneous sampling approach.” Please clarify why the sample size is 38. Please provide more information about the subjects to help readers assess relevance: What is their geographical context? How knowledgeable were subjects, and do they bring bias for or against open science into their statements? How did interviewees arrive at their opinions? How much close experience do they have with preprints? Were participants asked to answer only within their own expertise? There are quoted statements that reflect inaccurate understandings and are not always qualified by the author: for example, “relating to whether preprints are seen as an appropriate object for evaluation in exercises such as the UK’s Research Excellence Framework, about which there remains ambiguity. One representative of a university stated: “they’re not acceptable for REF, so they’re not even part of the equation. So it’s the author’s accepted manuscript is the currency we deal with.” (Research performing organisation)” This is inaccurate and misleading (see https://www.ref.ac.uk/publications/guidance-on-submissions-201901/ ) but there is no further commentary from the authors. Please add clarification that the interviewee responses are not necessarily factual. (It would be interesting to compare interviewee opinions with known facts to understand which topics are well-understood.) Clarity of presentation: Please provide more quantitative context to the opinions expressed. For example, for phrases such as “Some researchers” it would be useful to be more specific. Please also be more quantitative in assessment of the themes — it is useful to know if a sentiment was expressed by a majority or minority, as shown clearly in tables of benefits and challenges. Please provide aggregate data of thematic analyses, not just quotes, and use specific numbers and proportionality (Two of Five researchers mentioned X as a benefit). The paper combines elements of a literature review, white paper/policy piece, and a qualitative study. It would be helpful to clarify the origin of ideas by separating the work clearly into Results and Discussion sections. (As one example, under the heading “Financial sustainability and business models,” it is unclear whether the proposed taxonomy was expressed by interviewees or generated by the authors. Similarly, it is unclear whether use of the term “seminal” comes from interviewees or authors.) Readability: Please use active voice and concise language to improve readability. Bring interview questions and list of participants into this report — it is hard to interpret findings while having to continuously refer back to other sources, e.g. the 2019b interview structure paper. Claims: The abstract sets the reader up to expect a review of preprint servers that have emerged since 2013. However, the methods section discloses that coverage of the study is limited to biology, chemistry, and psychology. It would be helpful to readers to state this up front. It is also unclear how this scope was applied in the selection of study subjects. It is difficult to determine if the scope influenced the selection of participants as listed in https://zenodo.org/record/2654832#.XTeUB5NKjs0 – the questions listed at https://zenodo.org/record/3240426 do not seem specific to these three disciplines and the quoted answers in this report suggest interviewees’ responses were not limited to these three disciplines. Please clarify how the scope of the interviews was constrained to the stated subjects, or if not, please revise the stated scope to more accurately reflect the scope employed. The abstract does not reflect the content. The interview responses are summarised in general terms, not related to defined scope or the newer servers. A substantial proportion of this article is review material: either in the explicit literature review section, or as author-contributed content interspersed with summaries of interviewee responses. For example, conclusions listed in the abstract appear to be drawn from the literature review. “Our study is the first using empirical data to understand the new wave of preprint servers” — this is not supported by the study content: no results are specifically related to the newer servers identified in the introduction; quoted excerpts indicate that interviewees responded in general about all servers and disciplines. Furthermore, prior surveys and bibliometric analyses have looked at a subset of these servers, either individually or in groups (eg https://osf.io/5fk6c/ ). 1 Minor comments We recommend making the following amendments to improve the clarity and accuracy of the report. In the Introduction and literature review: The summary of the longer history of preprint efforts across disciplines, would benefit from incorporating and citing ‘The Brief Prehistory of Preprints” (Cobb, 2017) 2 Zuckerberg Foundation should be corrected to Chan Zuckerberg Initiative. Discussion of new servers would be improved with a note as to their current size, and with awareness that not all new ‘preprint’ servers are exclusively for preprint content (many COS servers include postprints that are not possible to easily distinguish from preprint versions). “This paper aims to explore…by investigating current practices, drivers and barriers to [preprint] use.” The interviews indicate perceptions and attitudes but do not reveal actual behaviours or practices. Please clarify how this study examines current practices. Figures and tables: Fig 1: To increase accessibility, please provide as raw text with headings or tags to indicate which stakeholder group you believe is most relevant Literature review: The authors focus on four main issues — how were these arrived at? Was the literature review systematic in any way? Given the emergent phase of preprint infrastructure in biology, chemistry and psychology, and as the authors note that empirical data is lacking, it may be equally valuable to include more grey literature (blogposts, webpages) in this review, given that several of the cited articles are opinion pieces, albeit as editorials or peer-reviewed review articles. Of note, we find personal blogs are a useful source of stories that detail benefits and drawbacks of preprints from personal experiences. "Dis-benefits:" is not a common term, perhaps use “drawbacks,” “concerns,”, “disadvantages” or “potential risks”. When discussing the lack of quality assurance, the authors seem to make an implicit assumption here that journal-led peer review assures quality. It would be fair to contextualise this section with some literature on peer review to understand variety of peer review outcomes on quality of paper and validity of findings. Results: In the discussion of preprints in the medical field, please note that the concerns raised are being addressed by medRxiv. https://www.medrxiv.org/ In the table of business models: Note that bioRxiv uses 3rd party technology, Highwire. “Publisher driven” models are not new; PeerJ is older than bioRxiv, Nature had Nature Preceedings in the early 2000s, and bioRxiv has had J2B preprints since its inception. How does the outsourcing of infrastructure to a third party enable sustainability? Arguably, depending on the third party, this leaves the service vulnerable to changes in service entirely outside its control. Individual authors can still submit to PeerJ. Most publisher-mediated preprint submissions are voluntary for authors (a notable exception being F1000). Regarding the statement of subject preferences: we have conducted a survey on these preferences that may provide additional context: https://asapbio.org/asapbio-funders-workshop The following suggestions may also help improve the paper but are not essential. In the Introduction and literature review: Open Research platforms could be discussed in context of F1000Research, since this is the model they are derived from (in collaboration with F1000). Please clarify the age of PeerJ and Preprints.org in comparison with bioRxiv. PLOS is not the only journal that deposits preprints to biorxiv using the J2B mechanism — several do, please refer to the list of journals offering direct transfers to bioRxiv ( https://www.biorxiv.org/about-biorxiv ). Regarding trust in preprints, it would be relevant to mention or cite the current effort by COS to better understand indicators of trust in preprints: https://cos.io/about/news/center-open-science-receives-grant-alfred-p-sloan-foundation-study-trust-and-credibility-preprints/ . Figures and tables: Fig 1 introduces some interesting questions, however many of these are related to topics that are brought up for the first time in this figure. Table 6: The concern of reputational damage is indeed in the literature; please see point 5 here: https://smallpondscience.com/2017/07/24/whats-up-with-preprints/ Literature: “However, Bourne et al. (2017) controversially extend the definition to include “a paper that has been peer reviewed and…was rejected, but the authors are willing to make the content public”.” — Please provide reasoning or citation as to why this is controversial. Accessibility — note that preprints are not necessarily open access, where they are not provided with permissive licensing, and this is certainly the case for bioRxiv. 3 One potential benefit to ECRs that is not mentioned here is being able to demonstrate productivity to funders and hirers. This would be useful to append to the current paragraph, given it is raised in the interview questions. “There also appears to be little acknowledgement that the claim stands in tension to the one cited earlier that preprints often differ little from final published versions.” — There is only tension if both claims concern all preprints. It is possible for there to be preprints that improve through a lot of feedback as well as preprints that undergo no/very little change. Please use unshared or unpublished instead of “homeless”. We recommend avoiding the term “policy stack,” as there is no dependent relationship among these different groups/stakeholders. Methods: This section ignores the efforts of researchers as change agents. Results: Please providence evidence for this statement: “we note that adjacency between disciplines appears to be playing an important role.” “Many of the participants agreed that preprints servers could be a useful outlet for otherwise ‘homeless’ research outputs, even though this goes counter to the emphasis of many of preprints as early versions of outputs later formally published elsewhere.” — this attitude may reflect a lack of publication venues for such content, not a lack of desire to publish these other outputs in a peer-reviewed destination. 