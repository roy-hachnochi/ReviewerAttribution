 Summary: This was a SWAT within the OTIS trial, an occupational therapist-led home environmental assessment for the prevention of falls in older people in the UK. The SWAT was a two-arm, parallel group study. The primary outcome was the proportion of participants who returned the four-month follow-up postal questionnaire. Secondary outcomes were: time to response, completeness of response, requirement of a reminder letter, cost effectiveness. The conclusion was that personalised texts were not superior to standard texts in any of the outcomes assessed. This is a very well conducted study and the clarity of presentation is to be commended. Answers to main headings for the review: The work is clearly and accurately presented for the most part, and it does cite the relevant literature as well as the current literature. I have added some comments/corrections below to address. The study design is appropriate and the work is technically sound. Though I understand the purpose of the study was to evaluate personalised text messages versus non-personalised messages, I would have liked to see a comparison with those that received reminder letters only. Would this be possible with the current data set? Sufficient details of the methods and analysis are provided for the most part but I’ve asked for a few minor issues to be addressed in the comments below. The statistical analysis and its interpretation are appropriate. Yes, the authors have added information on data availability. The conclusions drawn are supported by the results but they are different in the abstract to the discussion section of the paper. The authors are definitive in the abstract but are less definitive in the discussion section saying the results provide “little” support. Can we really say little support? I think this should be stronger. There is no evidence to support personalised text messages in this study. I understand there were limitations but these are the findings from this study. I’d ask the authors to address the use of the term “little” in the discussion section. Further Comments/Corrections: The reminder letter appears for the first time in the results section and in table 4. This needs to be detailed in the methods section. What justified a person being sent a reminder letter/why were only 21 reminder letters sent? Also, you should add the reminder letter to Figure 1. I expect that their inclusion didn’t affect the results given the small numbers and equal proportions in both groups, however, a re-run of the analysis excluding them, and a sentence to say that it didn’t affect the results. Rather than just present the actual costs of each type of text message in the results section under “cost-effectiveness”, can you present the findings of the analysis from both? I appreciate it’s presented in Table 5 but comment on it. The outcome definition in Table 2 “proportion of questionnaires returned” should be adjusted as its current meaning does not match your intention. It is not the proportion of questionnaires returned to YTU at four months post-randomisation, it is the proportion of questionnaires returned or the proportion of questionnaires distributed at the four-month randomisation period that were returned or as you have in your main text, the proportion of participants who returned their four-month postal questionnaire. It would be helpful if you specified here how long you gave them to return it. I would add…"within x days". Paragraph two of the results section, "…compared with 142 in the standardised text group….” - replace standardised with standard. In Table 5, the heading cost of texts is misleading as it implies that more than one text was sent to each person. Change to “cost of text”. 