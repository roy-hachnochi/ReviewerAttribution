This protocol outlines a project to review methods and tools for data extraction to help automate a step in the systematic reviewing process. This will be done in the context of a living systematic review with the aim of providing guidance to reviewers who may want to semi-automate their work. The objectives of the study are described clearly and are set within the current context of increasing publications. However, it would be helpful, as part of the aim and purpose of the study, to note why the focus is around the data extraction stage specifically. The methods of the study are described in enough detail to be replicated. In terms of the methods, can the authors double check the searching approach for accuracy? The abstract notes searches will be conducted monthly whereas the body of the protocol states every two months. The authors indicated they will update their systematic review when evidence expected to impact is identified however, it would be helpful to include some detail to note how impactful evidence will be defined for people doing similar work. A comment from the authors about their choice of study design for the included papers would be helpful. Identifying RCTs in the context of data science is likely to be challenging so it would be interesting to understand the expectations about the evidence base and how study design could link to the point about impact on the results of the review and need to update. The outcomes listed in the protocol appear to be comprehensive. However, it is not clear if consideration was given to accuracy of the tools identified as that could link to the objective of identifying whether automation is reliable. Overall, this appears to be an interesting study straddling the fields of systematic reviewing and data science. 