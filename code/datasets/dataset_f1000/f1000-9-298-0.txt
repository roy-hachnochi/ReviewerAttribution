This paper is about a generative model for protein folding. The main idea is to use a LSTM Generative Adversarial Network, trained on a dataset of real protein backbone angles, in order to generate novel protein designs. This makes sense, as GANs are regularly used as generative models to learn the probability distribution from samples, from where new samples can be generated. These methods are generally applied to images, but it is possible to apply them to other modalities such as sequences, text, etc. I find that this is a novel application that is a bit outside of the common uses of GANs. Overall the paper looks good in terms of writing and technical content. I am not an expert in proteins, so I will comment on the Machine Learning parts, which are my expertise. The authors propose the use of an LSTM-GAN, but they do not justify why they use it, in particular the LSTM architecture of a GAN, which is not that common. GANs are mostly used as generative models for images, and there are GAN versions for sequential data. My question is then, what is the motivation to use an LSTM specifically? From what I understand, the dimensionality of the problem is fixed, and protein samples do not have a varying number of folds or angles, in which case a sequential model such an RNN or LSTM does not seem to be necessary. A simple multi-layer perceptron (MLP) could work equally well, it could be interesting if the authors tried this or performed an architecture search to justify their choice. The neural network architectures for the discriminator and generator look fine, it would be nice if the authors mention how they reached these architecture, and if any grid/random search was performed. The choice of activation function seems odd, since the sigmoid activation used in hidden layers can lead to vanishing gradient problems, while the current standard are ReLU activations and its many variations. The choice of the MDN also looks odd, since a GAN generator network generally outputs values in the output range directly, while the MDN outputs a probability distribution from where a sample needs to be drawn. I believe both choices have to be justified appropriately. The authors use the Adam optimizer, which is standard and a good choice for a starting problem. There is a sentence in the paper which I find problematic: "The Adam optimiser had an MDN activation through time loss function defined to increase the likelihood of generating the next time step value." The problem here is that conceptually, an optimizer computes a gradient descent step, an optimizer does not have an activation or loss associated with it, so I am not sure what the authors mean here. The authors mention a L2 loss (mean squared difference), but this is not the loss that is used to train a GAN, even for continuous values. The authors mention that for training a GAN, the binary cross-entropy loss is used, but this is similar and not exactly the loss that is used to train GANs. The correct loss actually consists of two loss functions, one for the generator, and another for the discriminator, and both losses use the output of the D and G networks together. A full description of the losses and its variations can be found in Section 3.2 of [1], and I believe the authors should describe the actual loss they used very carefully, including the interaction of the D and G networks into the loss, as it is the core of the method used to generate protein angles in their paper. The description of the algorithm used to train a GAN looks okay, except for steps 3 and 6 since as I mentioned before, the loss used for training a GAN used both the D and G networks, so this should be explicitly mentioned. Step 4 and 5 are not strictly necessary since a GAN can train the D and G networks on the same batch. I briefly analyzed the code linked in the paper, and I am not convinced that the authors are using a Generative Adversarial Network (GAN). The network implemented in the code looks more like an auto-regressive model, and I do not see adversarial training in it. Additional evidence is that in Figure 3 only one loss function is being shown, while as I mentioned before, a GAN uses two loss functions and generally both are plotted in order to visualize training. I believe this is a very important point in order to make the article scientifically sound, but not the only one. I think the authors could also discuss what other learning-based methods they tried. Other methods such as Variational Autoencoders (VAEs) come to mind, which are also able to work as generative models. I believe that many references are missing from this paper, in particular to the ML community. I have already mentioned the GAN tutorial [1], and additionally I would suggest the Adam optimizer paper [2], and the original Mixture Density Networks paper [3]. Please always make sure that you are citing the techniques you are using from another field. [1]: https://arxiv.org/abs/1701.00160 [2]: https://arxiv.org/abs/1412.6980 [3]: http://publications.aston.ac.uk/id/eprint/373/ 