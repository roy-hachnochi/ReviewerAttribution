The authors propose a new computational drug repurposing method based on word embedding for FDA approved drugs based on drug-disease treatment analogies. Acknowledging that the onset of the COVID-19 outbreak requires the quick identification of already known drugs which could be repurposed against COVID-19, the authors propose a relatively straightforward method where candidate drug names are converted into word vectors to enable ranking by their similarity with a treatment analogy vector. The paper is well written and organized. The authors have done a good job in describing the rationale behind the development of their method and give an overview of its design process as well as the testing steps. Nevertheless, several points should be addressed regarding the validation of the method and its performance, benchmarking with respect to other similar methods, and applicability of the method for other diseases. The field of computational repurposing methods is very large and in contrast, the introduction of this article is relatively short and does not contain any comprehensive referenced overview of prior works in this field. My recommendation is that the authors should at least shortly cover the existing methods based on word mining and semantic and discuss how their own method positions itself in this context. Discussing those methods could serve as a starting point for a proper assessment of the performance of the proposed algorithm (see comment below). Below I summarize my comments and suggestions which I hope could contribute to improving the manuscript. The proposed algorithm is based on drug-disease relationships. It might be interesting to take into account the drug-target relationship as well. Indeed, one drug can often interact with several targets and usually, the drug-disease association is established through one specific target. Including the drug- target and disease-target relationships offer additional possibilities to repurpose the drug against a condition for which the drug-target relationship is relevant. The algorithm mainly uses association by keywords. As the authors has noted, this approach has several limitations. It would be difficult to apply the algorithm for finding repurposing candidates for conditions without prior known drugs (This restriction being encountered by many repurposing algorithms). Furthermore, the method might be limited by the vocabulary used. Indeed, it is not uncommon for a condition or a drug to be known by different names in the scientific literature. This issue can be addressed when dealing with formatted databases but it is more difficult to handle with natural language in the literature. By its nature, this method does not take into account all the relevant properties at the genomic, transcriptomic, chemical, structural levels which are of paramount importance to correctly establish the compatibility of a drug-target-disease relationship. For instance, the authors have based their study on the assumption that SARS-CoV and SARS-CoV-2 share common features, which is true but it was also pointed out that some structural and non-structural proteins of SARS-CoV-2 have low sequence similarities with the corresponding ones from SARS-CoV and this may have strong implication on the use of SARS-CoV drug to treat SARS-CoV-2 associated disease. This method is in my opinion would be interesting as an initial approach to reduce the number of potential repurposing candidates which should be included as input data for a subsequent computational repurposing method capable of taking into account the information about chemical/structural and genomic features of the target- drug-disease relationships. As many methods can be relatively costly from a computational perspective, being able to pre-select the initial set of data to be integrated is of interest. It would be interesting to have a more detailed description of how the treatment analogy vectors are built and how the similarities are calculated. The authors have initially a list of 8,561 candidate drugs (after some manual curation) but end up using a reduced list of 5,833 distinct drug vectors. This is a significant reduction in the initial amount of information the algorithm can be applied to. Maybe the authors could suggest alternative methods to be able to keep a higher proportion of the initial list of drugs? Also the table could include the similarity scores of the drugs. The authors decided to list the top 50 drugs, they do not provide a reason why 50 should be chosen as a cut off. Is there any systematic way to define an appropriate cut off for the most relevant results? This should be discussed in more details in the paper. As the assembly of the list of drug vectors requires several steps of preparation, it would be interesting for the readers to have those steps summarized in a diagram. This diagram could describe the key steps for the preparation of the drug vectors from a general perspective (so not only for the SARS-CoV-2 case), with an emphasis on what the user should take care of when deciding to include or not a drug. The article already contains many tables summarising the results of the different experiments. Maybe some of them could be moved in the supplementary materials to give space to this diagram. The main criteria in this paper to assess the method is to look for predicted drugs that are either already known as being effective against SARS-CoV or already taken into clinical trials for SARS-CoV-2. But those criteria are restrictive and not necessarily generalizable to other type of disease. One can assume that many potential repurposing candidates for a given condition are not undergoing clinical trial for a similar condition. It should be also noted that having a drug entering clinical trial is not a guarantee of success considering the relatively high failure rate in this area. It is true that for assessing the results provided by this type of computational method, a literature review is a first step that needs to be followed by in vitro/in vivo validation of the most promising candidates. Before those more expensive validations could take place, what would be the computational or data-based criteria to assess the accuracy of the predictions? The authors could discuss how this method performs compared to other methods based on word embedding and text mining for instance. 