In this paper, the authors introduce SplineNet to learn the conditional NNs. The authors propose a embedding trick to learn the embedded mainfolds and a regularized loss to encourage the maximum information gain. Through experiments on MNIST and CIFAR10, the authors demonstrate SplineNet achieve comparable performance with baselines with much less computation and parameters.  The idea is novel and the proposed method is sound. The ablative study and experimental analysis is helpful to better understand the working principles of the method.  My questions on the experiments: --The authors only conduct experiments on small scale datasets (MNIST/CIFAR) using shallow networks (LeNet). How does it perform on larger datasets such as ImageNet using more complex networks such as DenseNet/ResNet.  --Are the speed-up ratios presented in L249 theoretical or practical?  ============================ Thanks for the feedback. I suggest the authors add the new experimental results in the final version. 