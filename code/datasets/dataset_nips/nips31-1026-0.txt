This paper presents a method to learn a set of 3D keypoints which are category-specific using an end to end training. The interesting aspect of this work is that the keypoints position is a latent representation rather than explicit, i.e. we do not need labelling of the positions for training. Rather, the network is trained by provide pairs of images with ground truth poses.  - Trying to compute automatically keypoints without annotating them is a great idea and to the reviewer knowledge the first time to be presented. One question that might rises is what happens with objects where is not trivial to annotate points, a discussion would be interesting.  - Another point that would require a more consistent discussion is which provide the most keypoint separation i.e. Separation loss and Silhouette consistency.   - I would like to comment why it was not possible to train/compare directly with Pascal3D: http://cvgl.stanford.edu/projects/pascal3d.html  - It would be interesting to check objects for which keypoints are difficult to extract (spheroids or alike) in terms of failure cases and keypoint extracted (against humans). 