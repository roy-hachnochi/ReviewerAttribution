Authors propose an unsupervised domain translation approach for the one-shot case. While there are many proposed approaches for unsupervised domain translation authors claim that their approach is first to deal with the one-shot case. Across several collections and comparisons studies authors showcase that their approach (called OST) outperforms two existing approaches (UNIT and CycleGAN) in terms of translation accuracy, perceptual loss (mainly content and in some instances style difference)  Overall I think that this work presents an interesting and very promising approach for performing unsupervised domain transfer in zero-shot instances when dealing with images. Author corroborate their claims through several studies which showcase the advantage of OST over two existing approaches.   Questions/clarifications/suggestions:  What about other cross domain translation tasks besides images? It would be good to compare the performance of OST on other data types.  Is OST an abbreviation? Authors should tidy up their list of references.  “NLP translation methods” - What other translation method are out there? For better clarity and readability Figure 1 should be shortened and instead authors should give more descriptive details of their approach in the introduction.  For better clarity I would label the axis and introduce a legend in Figure 2.  Users should give more details about the translation correctness study presented in table 3.  Some typos: “The task we term” -> “the task that we term” “circulatory-loss” -> “circularity loss” “Can be serve” -> “can serve” “An horizontal” -> “a horizontal” “Cycle” -> “cycle” In several instances authors use commas rather than parentheses, e.g. “,after augmentation, to B using the transformation T,” -> (after augmentation, to B using transformation T)