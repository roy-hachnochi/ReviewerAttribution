I really liked this paper. The authors present an algorithm that perform blind echo estimation bypassing the messiness of discretization. The algorithm is explained very clearly, the problems are very well illustrated, and the approach is relatively easy to follow.  Some nitpicks:   – I would have appreciated a bit more discussion on the potential practical constraints that this method imposes. E.g., there is a mention that a long N is required, but it isn't clear what the practical limits of this are in a real audio problem.  – As much as I like pyroomacoustics, it isn't the real thing. There is still the open question of whether this can work in real-life. There is certainly no shortage of papers that look good on paper, but never made it to the real-world. It helps to address this point with some experiments.  The major issue:  If this was a paper submitted to TSP or some other selective signal processing venue, I would enthusiastically support it; it is a very good paper. I am having some trouble though seeing how this submission fits at NIPS. There is arguably no machine learning or neuroscience in this paper. The only tenuous connection is the compressive sensing angle, but the narrow application domain is not something that would be if interest to the general practitioner (unlike most of the good CS papers I've seen at NIPS).  Ultimately, I think this is a decision that should be left to the area editor. I think this is a good paper, but I do not think it belongs in NIPS. It would find a more sympathetic audience, and be more appreciated, in a signal processing venue.