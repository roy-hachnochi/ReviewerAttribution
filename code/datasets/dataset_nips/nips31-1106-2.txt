Multi-channel blind deconvolution is a well-studied problem in the literature especially for the case of discrete-time signals and channels.   The main novelty of this work is to consider a dispersive channels with taps with unknown delays and weight, where the traditional quantization (in the delay domain) results in a basis mismatch and degrades the performance.   The authors have combined nonconvex methods, which exists for blind deconvolution in previous works such as "Fast and guaranteed blind multichannel deconvolution under a bilinear system model" by Kiryung Lee, Ning Tian, and Justin Romberg which also provides some initialization technique for the nonconvex optimization, by super-resolution methods (vis root finding).  I have the following comments:  1. paper has a very marginal novelty, basically combining two already known methods, and the performance is shown to be good only empirically without any theoretical analysis.  2. there are some typoes here and there in the paper   (FRI)sampling --> (FRI) sampling guaranteed to converged --> guaranteed to converge   3. the phase transtion plot in Figure 3 is a little bit confusing: increasing the number of delay taps degrades the performance as expected but increasing the number of channels "M" does not show any monotonicity?  4. It seems that the authors have assumed that the number of delay taps $K$ is exactly known for the recovery algorithm. What happens when $K$ is unknown? In super-resolution techniques such as TV-norm minimization this is not a big issue since the number of taps can be also extracted. Is it also true for the proposed algorithm? It would be good if the authors consider the general case for doing the simulations and report the results.  