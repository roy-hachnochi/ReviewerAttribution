The paper proposes what it calls "Diectic Object-Oriented MDPS", in contrast to previously published Propositional OO-MDPS. The advantage of using the diectic approach is that the inference is relative to the grounded context.  The method assumes full state knowledge as well as the semantic classes of each object, but learns the transition probabilities from data.  The experiments show the method working on the taxi problem, with the learned transitions generalize accross different numbers of passengers. This is good, but not particularly groundbreaking. How would a regular model-based approach perform on this task?  The sokoban result is impressive: a model trained on one size of grid transfers to a larger grid with now training. However, the paper does not show how well the VAlue iteration from the transferred model actually performs.  This paper is not at all in my area, so I am not sure of some of the terminology in this work. I am also not familiar what constitutes a "good paper" in this area.   --- After reading the other reviews and author response, I continue to find this work an interesting formalization of a real problem. I have trouble seeing how this formalization would be enacted in a real world scenario. I am in favor of acceptance, but I would prefer to see how the method fares in non-ideal scenarios (e.g. if some approximations need to be made, or there is some uncertainty about the world)