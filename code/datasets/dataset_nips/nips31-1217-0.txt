This paper designs a model for conditional density estimation. It resembles a VAE architecture, where both x and y are given as inputs to the encoder to produce a latent variable w. W and x are then fed to the decoder to produce p(y|x). However, unlike in VAE, x and y are not single data points, but rather sets and the decoder part uses GPs to output p(y|x).  I found the clarity of the paper very low and I wish authors explained the model in Section 3.1. in greater details before jumping to derivations. Figure 1 made me especially confused as I initially thought that the model receives a single datapoint (x,y) just like a VAE. I had to read the GP-LVM paper [20] to realize that x and y are matrices with dimensions (N, Dx) and (N, Dy).   Also, I think it’s a too convoluted model for the problem it is trying to solve and I don’t think I would want to use it or implement it myself because of its complexity.   I found the experimental results not convincing. It seems that Porto taxi dataset might not be a very good choice considering the fact that a simple unconditional KDE model performs so well.  Also, the Omniglot samples in the appendix  are a bit disappointing. I would expect train samples to be better compared to the test ones, but I don’t see a lot of a difference. For heteroscedastic noise modeling, the differences between methods are sometimes very small and it’s not clear how significant these results are. With MNIST it was unclear to me if N=2, 4, 256, 512 is the number of training images per class? If so, then it’s no wonder that CVAE overfits with N=2. But what I find very weird is that log-likelihood for GP-CDE is much better on the test set than on the train set in a few cases. Is there an explanation for it?    To conclude, I think authors do make an interesting extension of GP-LVMs, however I would not recommend the acceptance of this paper before it is written in a clear way such that there is no need to read the GP-LVM paper to understand what GPs are doing there. Also, the experimental results should be much stronger in my opinion.   --------- UPDATE ----------- After reading the rebuttal, I have finally understood how the model works and how the GP is used.  I think it's a nice idea, but I'm still convinced that experiments are weak.