This paper proposed training method for neural module network based on generalised EM algorithm. Based on the proposed method, the modules tends to be specialised and the modules tend to be selected deterministically. Additionally, the proposed training method eased the importance of regularisation for avoiding module collapse.  Training modular neural architecture without additional data or complicated regularization strategy is an interesting and important problem.  Many papers addressed this problem in the name of conditional computation and many training procedures and regularization method has been proposed. At the best of my knowledge, the training method proposed in this paper is not explored before and the experimental results suggests that the method might be an effective way to training such modules.  However, I'm not sure whether the illustrated experimental result is convincing enough. Following lists are some of my concerns: - Reinforcement baselines Performance of reinforcement algorithms are sensitive to detailed implementation e.g. appropriate use of baseline for the log-likelihood value. While usage of baseline might make a huge difference in practice, it is not mentioned in the paper. - Continuous relaxation I think trivial baseline for learning module selection if using continuous relaxation of discrete random variable by using Gumbel softmax tricks.  As this approach makes model differentiable at the initial stage of the training, this could be a strong baseline which should be compared to the proposed model. - Comparison with baseline for Language modeling (Table 1) Language modeling is a task that could be benefit from large number of parameters. Therefore, I believe we need to make sure whether the performance gain is comming from the module selection or simply from larger parameters. One way to confirm this would be running baseline with (M=5, K=5) or (M=15, K=15) and make comparison with EM Modular networks. - Stability of the random seeds I believe studying stability of the algorithm would be necessary to validate the algorithm and facilitate future use of the method. For example, sensitivity to random seeds, effect of using different number of modules and the number of samples for module selection variable could be studied.  [After author response] I'm satisfied with the author response and most of my concerns are resolved. In that I increase my score to 7. I recommend authors to include discussions noted in the author response in the main paper if the paper is accepted.