The authors describe a new framework for approximate inference called Wasserstain variational inference. This framework is based on the minimization of an entropic regularized version of the optimal transport cost through the Sinkhorn iterations. The result is a likelihood free training method which can be applied to implicit models. The proposed method is empirically evaluated on autoencoder models where it improves over two baselines: standard variational autoencoders and autoencoders trained with aversarially learned inference.  Quality:  The proposed method is theoretically well justified. However, I found that the main weakness is the experimental evaluation. The authors do not do hyper-parameter tuning of the different methods. Instead they just report results over an average across many different hyper-parameter values sampled from a prefixed sampling distribution. It is unclear wheather this non-standard evaluation was in detriment of the baselines. I believe a more riguorus evaluation protocol where hyper-parameters are optimized for each method (for example by grid search, or better by running a Bayesian optimization method) on some validation data is necessary. This can be expensive but it should be easy to paralellize over a computer cluster to reduce the extra cost.  It seems that the baselines used by the authors are a bit weak, they just compare with standard VAEs (which are very old for the current pace of research in VAEs) and with a more recent technique which is not properly fine-tuned. I would recommend the authors to consier other alternatives.   The performance metrics used by the authors to evaluate the quality of the different methods seem also a bit arbitrary. The authors could think of computing estimates of the marginal likelihood using importance weighted techniques. Also, how would their method work in the case of non-implicit models?  Clarity:  The paper is clearly written and easy to read.  Novelty:  The proposed approach seems novel and relevant.  Significance:  The theoretical contributions are significant. However, the empirical evaluation of the proposed method is too weak to clearly evaluate the significance of the proposed method.  See my comments above.  Update after rebuttal:  After looking at the new experiments included in the rebuttal, where the authors perform hyper-parameter tuning and compare with additional baselines, I am supportive of acceptance.