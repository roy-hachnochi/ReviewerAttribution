The submission introduces a new normalisation layer, that learns to linearly interpolate between Batch Normalisation (BN) and Instance Normalisation (IN). The effect of the layer is evaluated on object recognition benchmarks (CIFAR10/100, ImageNet, multi domain Office-Home) and Image Style Transfer. For object recognition it is shown that for a large number of models and datasets the proposed normalisation layer leads to a small but consistent improvement in object recognition performance. In Image Style Transfer a systematic difference in performance is more difficult to detect, but examples are shown in which using the new normalisation layer leads to the ability to preserve parts of the content image better (e.g. dark backgrounds).  A nice analysis is performed on the relative weighting of IN and BN in different tasks. First it is shown that the interpolation weights follow a bi-modal distribution. Thus features either use IN to become invariant or BN to retain input variation across images.  Moreover, while for object recognition the majority of features use BN, the fraction of IN usage increases substantially for style transfer as expected from the requirements of the task.  Nevertheless, I have a couple of concerns/questions.  1.) A main concern is that the effect size is often quite small and no analysis is provided how this compares to the variation in performance from running multiple random initialisations. Although the consistency of the improvement over models and datasets makes me confident that there is an effect, I would like to see at least for one model a statistical analysis giving error estimates and evaluating significance of the improvement. Preferably for the results in table 1.  2.) The results should be compared to the Adaptive Normalisation proposed in [1] which learns a linear interpolation between BN and the identity function. Ideally I would like to see 2 more conditions to compare with: one linearly interpolating between IN and identity and one interpolating between BN and identity.    Overall the submission describes a simple change to existing architectures that appears to have a consistent positive effect on model performance for several models and datasets, which can be of interest to the larger Deep Learning community at NIPS.  If the authors can address my questions in the rebuttal, I am happy to increase the score to 7.  Edit: Based on the authors' response showing statistical significance of the improvement and comparison to BN-Identity, I increase the score to 7 and recommend acceptance of the submission.  References [1] Fast image processing with fully-convolutional networks  Q Chen, J Xu, V Koltun - IEEE International Conference on Computer Vision, 2017