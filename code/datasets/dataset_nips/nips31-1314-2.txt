The paper revisits the individual fairness definition from Dwork et al. TCS 2012, which (informally) requires similar individuals to be treated similarly (and assumes that the similarity metric is given), and presents an analysis how such metric can be learned in online learning settings. The authors consider the Mahalanobis metric to be learnt in linear contextual bandit settings with weak feedback, i.e. an oracle identifies fairness violations, but does not quantify them. In authors belief this represent the interventions of a regulator who “knows unfairness when he sees it”. The authors provide an interesting theoretical analysis and a novel algorithm in the adversarial context setting. I find the work application-inspired, but unfortunately not convincing. The presentation can be improved by providing a realistic example of how a regulator provides weak feedback. - I read the authors' response.