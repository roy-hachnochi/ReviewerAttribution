[Summary] This paper proposed to use the graph convolution neural networks for factual visual question answering. The proposed method first retrieve the fact based on glove vector and filtered by relation predicted based on the question. The filtered fact concatenate with question embedding and other visual features are serve as graph nodes and further go through a 2 layer graph convolution network. The refined features are further fed in an MLP to predict the binary label for each entity. The authors performed experiments on FVQA dataset and achieve state-of-the-art performance compare with previous results.   [Strength] 1: Experiment results on FVQA dataset is very good.   2: The proposed framework is interesting and seems general for the factual visual question answering task.   [Weakness]  1: Poor writing and annotations are a little hard to follow.  2: Although applying GCN on FVQA is interesting, the technical novelty of this paper is limited.   3: The motivation is to solve when the question doesn't focus on the most obvious visual concept when there are synonyms and homographs. However, from the experiment, it's hard to see whether this specific problem is solved or not. Although the number is better than the previous method, it will be great if the authors could product more experiments to show more about the question/motivation raised in the introduction.   4: Following 3, applying MLP after GCN is very common, and I'm not surprised that the performance will drop without MLP. The authors should show more ablation studies on performance when varying the number of facts retrieval, what happened if we different number of layer of GCN? 