+ task and proposed model seems novel + good evaluation - evaluation on own task - task not sufficiently motivated  The paper is well written and easy to follow. The task of image manipulation through bounding boxes seems somewhat novel, and the proposed model going from a box input through an intermediate semantic segmentation is new (although semantics has been used before to generate images). The evaluation is extensive and contains several human studies.  Unfortunately, the comparison is not quite fair, as none of the baselines know the identity of the object removed (or the object to be generated). Have the authors considered training class specific baselines?  Finally, the authors didn't fully convince me that drawing labeled bounding boxes is a natural interface for image manipulation. In fact, there are many alternatives that seem more natural at first glance (e.g. drag and drop of existing dataset objective + color adjustment, direct color manipulation, ...). It would help if the authors could provide some additional motivation why this interface is particularly compelling (ideally with some experimental results). Is the interface easier to interact with? Does it give the user more freedom? ...  Minor: * Have the authors considered merging the two streams in fig 2? What does the object stream offer, over a context stream that also produces the foreground mask? * Is the object stream conditioned on the class c? There does this conditioning happen?