The authors propose a new algorithm and its analysis for finding the maximum of a realized Brownian motion. The sample complexity for epsilon optimality is shown to be log^2(1/epsilon) which is better than prior art that has a polynomial dependence on 1/\epsilon. The experiment confirms the claim sample complexity order.  Overall, a very well-written paper with significant development on the problem. I have a few questions and minor suggestions. At least, I think the properties assumed on W can be listed in the supplementary material.  I think the paper could improve readability and clarity even better by properly define Brownian motion (at least briefly) and then citing a good reference to learn about the Brownian motion.  Q: I am not too familiar with Brownian motion. Would the bounded domain ([0,1]) for Brownian violate the assumption the increments must be independent? If we start at 0 and take the first increment at t=1, with some probability we arrive near 1. Then, the increment at t=2 would necessarily be limited since we cannot go beyond 1, and so I feel like the increment at t=2 has to be correlated with the one at t=1. I am sure there must be some resolution. What do the authors think?  (*) minor comments 1. Algorithm 1: the loop must have i <- i + 1 at the end 2. Algorithm 1's Output: "and its value W(hat t_eps) <- ..." => could just leave it with ""and its value W(hat t_eps)" without the RHS. I am not sure what value "<- ..." brings in there. 3. L117 (line 117): The full proofs the ... => The full proofs "of" the 4. L220 (line 220): work as this the ingredient ... => work as this "is" the ingredient... 