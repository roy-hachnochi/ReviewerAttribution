This paper proposes a novel Very Deep Neural Architecture, NAIS-Net, in which non-autonomous blocks are stacked. The paper theoretically demonstrate that the network is Globally Asymptotically Stable, when using the tanh activation function. An empirical demonstration of the stability of the architecture is proposed.   Quality: The technical content of the paper is well explained and the related work section clearly compare this work with the existing literature.  Clarity: The paper is generally well-written and structured clearly.    Originality: The main idea of this paper is very interesting and the results look encouraging.   Significance: The model proposed is very interesting and the empirical stability looks very promising. The question of the scalability is indeed the major concern.   Minor typo:  line 221: the last sentence probably refers to Figure 4 and not Figure 3 line 84: usual -> usually  Minor comment:  Images in Figure 6 are way too small for a printed version...  