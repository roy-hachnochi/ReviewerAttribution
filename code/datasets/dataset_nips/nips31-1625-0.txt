The authors propose a method to quantify prediction uncertainty by placing a Dirichlet prior on the softmax output of a neural net. The idea is to let the algorithm say "I don't know" if not enough evidence is provided for any of the classes. The optimization of the new loss function improves uncertainty estimation while keeping an accuracy inline with other approaches when compared on benchmark datasets. They also show the value for the detection of out-of-samples queries or for robustness towards adversarial setting.  The quality of the work is really good, with interesting modeling ideas which builds upon the Dempsterâ€“Shafer Theory of Evidence (DST) and subjective logic. Theoretical proofs (in short appendix) guarantee the properties of the approach. The authors also compare their algorithm on benchmark datasets to numerically illustrate the performance of the approach. In particular, the algorithm has on-par accuracy as the other models (from recent publications) while being better able to quantify uncertainty and being robust to adversarial settings.  The paper is clearly written and easy to follow. It is well motivated and addresses an important limitation of a lot of classification algorithms, which is novel as far as I know.