The authors provide  a rigorous justification of the statistical physics approaches for studying the learning and generalization capabilities of shallow NN dealing with random data, in the so called teacher-student setting. They also analyze the behaviour of an approximate message passing (AMP)  algorithm. Interestingly enough,  they discuss a regime in which AMP fails and yet a low generalization error is information-theoretically achievable. The existence of this computational obstacle was known; however  providing a rigorous setting is important,  given that the  statistical physics tools appear to be among the most powerful ones to analyze learning problems.