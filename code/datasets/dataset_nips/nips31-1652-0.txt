The paper introduces a novel algorithm with regret guarantees for stochastic contextual combinatorial multi-armed bandits for volatile arms and submodular rewards.   The dependence on dimension of the space of their regret bound is not great and in general constants seem large.  A discussion of these quantities is warranted here.   The main drawback is that there is no comparison to other bounds. It seems that they can instantiate their algorithm to simpler settings that have been analyzed by previous work. How does their bound compare to the regret of previous algorithms in these simpler setting? Do they have any guess at the lower bound?   Splitting the context space by hypercubes seems expensive. Is the algorithm computationally efficient? Please add a discussion on this.   As for the experiments, it would have been nice to have seen results for more than one dataset.   I understand their reasoning for their definition of regret, but is it necessary in their analysis to include the factor (1-1/e)? 