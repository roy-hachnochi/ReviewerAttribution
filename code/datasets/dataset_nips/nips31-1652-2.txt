 This paper studies the contextual combinatorial multi-armed bandit (MAB) problem, where the goal is to select in each round the subset of arms that maximize the expected cumulative reward. The main contribution of the paper is the formulation and analysis of the CC-MAB algorithm, which addresses this contextual combinatorial MAB problem for the setting where the reward function is submodular and the set of arms can change between rounds.    Although the algorithm builds on previously well-studied MAB frameworks, it has a relatively significant contribution by bringing together the combinatorial MAB setting, with the use of contexts, and with the challenging setting of "volatile arms".     The paper is well written and the studied problem is interesting and quite well motivated for real-world applications.   On the other hand, the experiments seem a bit lacking. I wonder why there was no empirical comparison to combinatorial MAB algorithms (for instance, from references [5,7])?  Also, none of the considered benchmarks considers the submodularity of the reward function, thus, as it is pointed out in the paper, they incur obvious reward loss. More details about the comparison of CC-MAB behavior compared to submodular MAB algorithms (for instance, the one proposed in [Chen, Krause, Karbasi, NIPS 2017]) would be appreciated.    Minor comments/typos:  - line 172: performs *the* following steps? - line 221: budge -> budget  =======================  Post author response edit:  I have read the rebuttal and thank the authors for addressing some of my concerns. 