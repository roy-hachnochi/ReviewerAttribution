The paper proposed the recurrent relation network that takes into account multi step reasoning process. Along with the architecture, the authors also proposed the pretty CLEVER datatset which contains questions that needed to be answered via multi step reasoning.   The authors experimented on the several different tasks including natural language Question Answering tasks (bAbI task) , Sudoku and the pretty clever dataset (multi-step Question Answer). The model performed better on all tasks and performed particularly well for Sudoku.     Strength:  1. The multi-step reasoning task the model addresses is an important problem,.  2.  The authors conducted thorough experiments and compared to many other baselines.   3 The authors provided thorough experimental settings in the appendix.  Weakness:   It would be interesting to see how this performs on tasks involving many-step reasoning with languages. Especially for tasks where the answer is not in the context given, but needs to be inferred. An example is "How old is person A?", the context is, Person B is 20 years old, Person C was born 4 years later and person A is 5 years older than person C.  Post rebuttal. I am glad that authors found the suggested tasks useful and thanks for offering to acknowledge me in the final version, I would be happy to be acknowledges anonymously :)    It is indeed interesting to see the results of this task. The model seems to perform significantly better compared to the baseline. It also serves as an interesting  toy problem that analyzes the capability of the model. I am happy with the results presented and I am raising my scores to a 7 in light of the rebuttal.