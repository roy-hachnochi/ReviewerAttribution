    This paper looks at derivative estimation in random design, where the function is sampled from randomly chosen input points rather than at fixed intervals. While previously proposed estimators have primarily been analyzed in the context of fixed design, this paper presents the natural extension of the algorithm to random design and provide accompanying analysis.               A explained by Lemma 1 and the discussion that follows it, a simple estimator in eq (3), which simply computes the local ratio of the difference between output and input variables, has high variance, since the difference between outputs has a noise term with variance 2 \sigma_e^2, and the denominator scales as 1/n, such that the variance of the ratio scales as O(n^2). I'm a bit confused why the authors state that the variance of this method is asymptotically worse for random design? Doesn't the O(n^2) variance of estimate also hold in the fixed design case, such that the high variance is not due to random design but rather simply due to the fact that estimator (3) only computes difference over a single pair of points rather than averaging over many points such that the noise term will affect the estimate greatly?              I think the main contribution of the paper is to analyze the algorithm in eq (5) which was proposed in [21] and [22] for fixed design, but to extend the analysis to random design by specifying the weights in eq (6) and then analyzing the asymptotic behavior of the difference of uniform order statistics (Lemma 1), which is then used to show bias and variance bounds on the estimator as in section 2.2, and show how to select the bandwidth k via a data-driven estimates.               I was confused by the discussion in 2.6 and did not really understand how the discussion related to the previously described algorithms and analysis. Is it proposing a modified algorithm which uses a different kernel for computing the weights w_ij instead of the one presented previously? Just to clarify, does the correlation function kind of impose a gaussian process like assumption, where points that are nearby have noise terms that are more correlated vs points far away are less correlated? and doesn't that make derivative estimation more difficult since locally you will fit to the noise function as well instead of learn the underlying expected function r?  ************************** added after rebuttal *****************************************  Thanks for the clarifications.    