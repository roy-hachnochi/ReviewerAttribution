 This paper discusses learning a general embedding representation to capture semantics in code, which can be used        for multiple tasks. This is very important topic in the field right now, as there is a growing interest in applying learning        approaches to program analysis tasks. The lack of general embedding requires to train a separate embedding network per task;        however, the lack of available labeled data makes this impractical. Therefore, the goal of this work can mitigate this issue,        and accelerates the adoption of deep learning approaches in the classical program analysis world.        While the goal is great, my main concerns about this paper are two-folds. First, the proposed techniques are a bit shallow.       This paper mainly proposes a conteXtual Flow Graphs (XFG), and employs a skip-gram network to compute the embedding. However,       although superficially different, I find that a XFG is very similar to a Program-Dependent-Graph (PDG), which is used in [4]       and have been proved to be effective. The two graphs essentially capture very similar information, and it is unclear what's        the additional bit that a XFG provides. Skip-gram is also a standard technique to compute the embedding unsupervisedly. Thus,       the novelty of this work is thin to me.        Second, the evaluation is not convincing enough. The paper claims that the techniques are proposed to compute embeddings for       multiple tasks, but I find that the evaluated tasks are a bit artificial. In particular, for the three tasks, (i.e., algorithm       classification, device mapping, and thread coarsening factor prediction), it is unclear how much code semantics is needed       to accomplished these tasks? These tasks are likely to be determined by looking at the coding patterns, which can be learned       from the syntax without understanding the semantics. It could be helpful to evaluate some more fine-grained tasks that are        known to leverage semantics information, such as code suggestions, and those evaluated in [4].        Further, the evaluation results for 6.2 and 6.3 are also not convincing that the proposed approach is the best approach in       these tasks. In particular, I find that Table 5 is hard to interpret. If the prediction is among {1,2,4,8,16,32}, how is the       speedup data computed from the prediction and the ground truth?        Last but not least, another recent work in this space is missed:        Xu et al., Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection, CCS 2017       