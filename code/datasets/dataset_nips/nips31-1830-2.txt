The authors address the problem of escaping from saddle points in smooth nonconvex optimization problems constrained by a convex set C. A framework is proposed that allows iterates to converge to an (eps, gamma)-SOSP in a finite number of steps. First, an eps-FOSP stationary point is found using an appropriate first-order method (the authors suggest Frank-Wolfe or projected gradient descent). This stationary point may be a saddle point or a local maximizer, so as a second step, a constrained quadratic program is solved to find an (eps, gamma)-SOSP of the original problem. In addition to assuming the constraint set C is convex, the framework also assumes that a constant stepsize is used and that the necessary QPs can be solved in a finite number of arithmetic iterations. The authors provide an upper iteration bound, a lower bound for the decrease in the objective value for each of the first-order methods, and an extension to stochastic problems when the objective function is defined as an expectation of a set of stochastic functions.  This appears to be a solid contribution, giving a sensible framework for tackling optimization problems where saddle points could be encountered by the first-order method, although I am unsure if saddle points will necessarily be escaped from using the framework (see below). The theoretical results appear to be correct, although I was unable to verify all of the proofs due to time constraints. While there are a number of assumptions that are made that enable the theoretical analysis, most (but not all) of these seem sensible in practical settings.   However, I have a couple of concerns/comments/questions: - The framework does not require that the saddle points are delta-strict (line 121), which implies that the (eps, gamma)-SOSP could still be a saddle point. If this were to happen, what would be the best method to get out of this saddle point? Decrease gamma and try again? It does not seem like this framework actually guarantees an escape from saddle points, unless one decreases gamma to be small enough. - The assumption that the stepsize eta is constant is unrealistic since most practitioners decrease the stepsize as iterates get closer to the solution. How difficult is it to adapt the analysis to the case of variable stepsizes? - How much of the analysis can be applied if stochastic gradient descent (SGD) is used to solve the first-order problem? - The following sentence in the abstract is confusing: "We propose a generic framework that yields convergence to a second-order stationary point of the problem, if the convex set C is simple for a quadratic objective function". So the objective function needs to be quadratic? Because the text makes it seem like we are minimizing over a general smooth nonconvex function. - It would have been nice if there could have been some computational example of the method in action, but I realize there is a lack of space.  Some editorial comments: - Line 32: "... later below)." Either "later" or "below", not both. - Line 34: semi-colon should be a colon. - Lin 43: "proposed". - Line 123: "... approximate local minimum". - Line 145: A sentence should preferably not be started with "i.e.", rather use "In other words" or something along those lines.