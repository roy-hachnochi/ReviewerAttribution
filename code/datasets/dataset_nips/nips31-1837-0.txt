This paper studies the reward manipulation attacks on stochastic bandit settings. Here, the main purpose is to guarantee a successful attack. Theorem 1 and Theorem 2 claim that an attack is guaranteed for e-greedy and UCB algorithms respectively.   In my opinion, the paper could provide more background for the readers who are not familiar with the attacks on bandits. What should the attacker do: e.g force the learner into pulling or avoiding target arms, or worsen the learnerâ€™s regret ...? Besides, they could discuss what could be done to defend against the attacks?  Secondly, the authors can mention before the Theorem1 that it is a typical high-probability statement and the 'failure probability' parameter _x000e_is usually set close to 0 and the theorems involving high-probability statements are abundant in the literature.  Overall, I like the idea in this paper and I'm sure about the correctness of the theorems. If the authors can clarify some points that I've mentioned, this could be a strong paper. It also opens a new research area in the literature.    