Summary:  This paper studies a bandit approach to sequential experimental design. In particular, the authors consider a sequential game with n arms and the goal is to find arms that have higher means than known (pre-specified) threshold with minimum number of samples. This setting is particularly very interesting for online A/B testing platforms where the platform wishes to detect all the arms (options, offers, etc.) that are better than a given baseline, with lowest number of samples (targeted users) while providing some statistical guarantees. The authors consider two different notions for the False Alarm Control, namely False Discovery Rate (FDR) and Family-Wise Error Rate (FWER) and also two different notions for the Detection Probability, namely True Positive Rate (TPR) and Family-Wise Probability of Detection (FWPD) and provide sample complexity bounds for all 4 pairwise combinations. These complexity bounds are explained in Theorems 1-4. Finally, the authors provide some numerical experiments to demonstrate that the proposed algorithm reduces the sample complexity by a large factor (compared to Successive Elimination and Uniform Allocation rules).  Evaluation:  The paper is very well-motivated. In the past decade there has been a significant interest in designing adaptive A/B/n testing problems that bring the ideas from multi-armed bandit (MAB) and frequentist statistics together. This paper clearly connects these two ideas. First, it uses UCB-type algorithms to design efficient adaptive allocation rules. Second, it controls the amount of false alarm and detection probability by using the anytime confidence intervals together with BH selection or Bonferroni-like selection. One important aspect of the proposed algorithm is that unlike top k-arm identification algorithms, it does not need to know k in advance. In other words, it can learn the number of arms that have their mean above \mu_0.  Furthermore, the papers is nicely written. Authors have done a great job in writing; it is very easy to read and at the same time it is very general that can be modified for using in other settings.  I think it would be very nice if the authors could add more simulations to their paper. For instance, it would have been nice to see the number of pulls from different arms in the simulations. Also, simulating some other settings with varying \mu_i (other than the last one) could help with a better understanding of the bounds and the efficiency of the algorithm.  Overall, I believe this is a very nice submission and I recommend this paper to be accepted. 