 I acknowledge having read the rebuttal.   Fairness is a complicated and an important matter. Due to the nature of the problem, there might not be a universal characterization of it, but if a criterion is proposed it should be followed by a compelling story and a reasonable explanation for why we should consider this criterion. This paper provides a new (causal) interpretation of equalized odds (EO), an associative measure that has been used as a framework to talk about discrimination in classification problems. The central point of the paper is to learn a fair classifier by constraining each of the three (causal) components of EO (i.e. direct effect, indirect effect, spurious effect) to be small, and not EO itself. There might be situations where this would make sense but authors don’t discuss it and it is unclear why we should care about it in general.   Another drawback of the proposed procedure is the way new unseen instances are being handled. In a typical supervised setting, we use train data from p(y, x) to learn classifiers or outcome regression models (via a bias/variance trade off) in order to achieve a good out of sample performance. Both train and test data are drawn from the same distribution, otherwise this leads to what is called “covariate shift” in ML. In this paper, to learn a fair classifier, authors propose to minimize a loss function subject to those three fairness constraints, eq (4); this implicitly transfers the problem to some other distribution, p*(y, x) where all the constraints are satisfied (note that p* is potentially different than p). This is fine as far as that goes, but in the experiment, they are computing out of sample performance of the “fair classifier” (using data that comes from the observed distribution). It’s not quite clear why it makes sense to learn a classifier on one distribution, p*, and check its performance on a different distribution, p. There might be multiple fixes to this issue, or a valid explanation why this isn’t a problem at all. The authors do not clarify (nor they seem to understand the fundamental issue).   