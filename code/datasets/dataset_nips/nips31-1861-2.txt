In this paper,  asynchronous momentum stochastic gradient descent algorithms (Async-MSGD) is analyzed for streaming PCA, which is a relatively simple nonconvex optimization problem. The analytical tool is diffusion approximation following Liu et al. 2018. Particularly, the authors show the tradeoff between asynchrony and momentum: momentum has to be reduced when the delay from asynchrony is large. The tradeoff sounds reasonable and intuitive. I like the empirical results on neural networks, which is repeated several times to overcome randomness. I have some comments below.  The main theory part (section 3) is a bit hard to follow. The current version reads like a stack of lemmas and theorems, which lacks motivations and connections between them.   For example, line 171, why ``given lemmas 1 and 2, we only need ...’’? Lemma 1 is saying that iterates are on sphere bounded by stepsize. Since stepsize indicates how far the iterates move for each step, is this conclusion nontrivial?  The analysis extensively used results from Liu et al. 2018, and also some texts. In fact, after bounding the delay \tau, the analysis is almost identical to Liu et al. 2018. I would like the authors to clarify the contribution, and elaborate the difference except in methodology, or emphasize the significance and challenge on bounding \tau.  There are several claims of the paper that I am not fully convinced.  Line 105, ``the asynchrony...can always enjoy a linear speed up...’’ Please explain linear speed up.  A relative issue is that the maximum delay is assumed to be the number of workers, like in Line 205. And the number of workers is directly used to linearly speedup iterations in line 212-213. I am not sure if these are standard assumption for theoretical analysis. In practice, if one worker is really slow, will the delay be larger? Line 216, please explain why Async-SGD is`` faster’’. It is hard to tell for me from the equations.    ========================================================== I update my score after read the rebuttal, and thanks the author for making the efforts. The updated score is based on merging contributions of 4980 into 1861.   The theoretical contribution of 1861 alone is relatively incremental given 4980. I am also not satisfied with the authors' answer to speedup, the reference only show linear speedup for two experiments and does not make a strong claim as the authors.