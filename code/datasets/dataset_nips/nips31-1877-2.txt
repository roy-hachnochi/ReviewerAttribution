The proposed method improves upon the recently developed EWC and SI by incorporating Kronecker factored approximation of the Hessian matrix. Previously, while the diagonal of Fisher information matrix was used to approximate the Gaussian precision matrix of the posterior of the parameter, this work utilizes the block structure of the Hessian matrix. The paper also uses online version of approximation, which is based on the Bayesian online learning, and experimentally show that the proposed method significantly outperforms the two baselines, EWC and SI.   I think to improve the manuscript, it should be better to point out the computation complexity for the suggested method. Namely, for EWC, computing the regularizer simply requires computing the gradient for each parameter, but, for the proposed work, we may need more computation. Clearly pointing out the complexity will make the paper more stronger.   ######### Update after rebuttal  I have read the authors' rebuttal.   Regarding the computational complexity, I think what author's argued in the rebuttal seemed reasonable.   The main reason for my initial rating of the paper was based on the strong experimental result given in Fig.1. Running the experiments to 50 tasks and showing the big gap between the proposed method and EWC/SI, which consist of current state-of-the-arts. But, reading others' comments as well as more carefully checking the references, I also realized that the technical novelty - including the Kronecker factored approximation of the Hessian - is low.   However, I still think the experimental contribution of Fig1 of the paper is still strong and valid to wider community. So, I decided to reduce my original rating to 7. 