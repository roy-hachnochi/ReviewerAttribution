Summary: The main contribution of this paper is the derivation of an "accelerated" gradient descent scheme for computing the stationary point of a potential function on diffeomorphisms, inspired by the variational formulation of Nesterov's accelerated gradient methods [1]. The authors first derive the continuous time and space analogy of the Bregmann Lagrangian [1] for diffeomorphisms, then apply the discretization to solve image registration problems, empirically showing faster/better convergence than gradient descent.  Pros: The paper is well-written. The proposed scheme of solving diffeomorphic registration by discretizing a variational solution similar to [1] is a novel contribution, to the best of my knowledge. The authors also show strong empirical support of the proposed method vs. gradient descent.  Cons: 1) Scope of contributions. Although the title and abstract boast "acceleration on manifolds" and "application to diffeomorphisms", it seems to me that this work *only* studies optimization on the *manifold of diffeomorphisms*, rather than general manifold optimization problems. Therefore, the contributions should be compared against similar work in diffeomorphic registration (e.g. image/shape/surface registration). 2) Missing references and baselines. Given 1), some important related work in efficient computation of optimal transport and applications in image registration is missing. In particular, Sinkhorn-type iterations [Cuturi, 2013] are used to compute the proximal operator of the transport problem for large problems, such as indirect image registration in tomography [Karlsson and Ringh, 2017]. The authors should compare their proposed method against this line of work, both in terms of formulation and empirically. While my knowledge of this field is limited, upon some literature search it seems that the Sinkhorn-type methods are very competitive in terms of time complexity and solution quality. Therefore the authors should include a comparison with such alternative methods. 3) Computational complexity and theoretic analysis. While the proposed method is named "accelerated gradient descent", it is not shown to provably accelerate gradient descent or even converge to a stationary point by the authors' discretization scheme. The authors only propose a discretization method (line 255 and supplementary E) but omit the analysis of its convergence and iteration complexity.  To sum, this work contains some novelty but lacks rigorous analysis of its proposed method; more importantly, it misses theoretical and empirical comparison to some important related work of the same application, making it impossible to judge the significance of the proposed method at this point.  [Cuturi, 2013] Cuturi, M., 2013. Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in neural information processing systems (pp. 2292-2300). [Karlsson and Ringh, 2017] Karlsson, J. and Ringh, A., 2017. Generalized Sinkhorn iterations for regularizing inverse problems using optimal mass transport. SIAM Journal on Imaging Sciences, 10(4), pp.1935-1962.