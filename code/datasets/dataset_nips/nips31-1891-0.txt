The paper presents a method based on probabilistic programming for learning to infere temporal structures of tasks. The paper motivates the method with cases wherein humans can understand whether a task is properly executed or not, before having capacity to demonstrate it (which is the case in many problems). However, in the validation the approached problems do not fall in this description, so more complex problems related to one of the initial motivations of the paper would increase the value of the validation.  The approach has been presented and validated for this concrete simple tasks with high level decisions. So, is it possible to extend or apply the method to tasks wherein the decisions are in lower level, like motor control for robot tasks? how would behave the learning method if the experiments are with problems that have stochastic transitions?  The experiments show results of only one run, however in demonstrations there is always uncertainty and variance,  different users would give different demonstrations in every trial. So it is important to conclude over several repetitions as it is typical in the literature. Human factors cannot be ignored in these methods.  This approach is limited to problems wherein human teachers need to give high quality  demonstrations to obtain good policies. How can be extended this approach in order to reach superhuman performance as the obtained by recent approaches of interactive learning? This discussion would need to aim to different applications with respect to the presented in the paper, since in those cases to provide high quality demonstrations is not a problem.