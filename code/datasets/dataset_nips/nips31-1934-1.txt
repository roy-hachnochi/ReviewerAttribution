This paper shows that adversarial examples that transfer across computer vision models can successfully influence the perception of human observers. This is not a typical machine learning paper, and the main claim is verified empirically through well designed human psychophysics experiments.   The paper is well written and easy to follow. The experiment configuration and reasoning are solid, and the conclusion from the paper is significant and might lead to advance the design of new algorithms and NN architectures to defend adversarial attacks.  Since this is not a typical machine learning paper and more of experimental psychophysics (which is out of my domain), my confidence score isn't very high (3).  The implications of this work could be significant. 