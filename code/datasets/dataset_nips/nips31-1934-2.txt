This paper demonstrate that adversarial examples can be transferred from computer vision model to time-limited human observers.   Although the explorations are interesting, the results are based on the strong assumption of time-limited human. This makes the contribution somewhat limited, and also makes some of the findings questionable. For example, in the experimental setup, the target class “dog” resembles the visual appearance of “cat” more, compared to those false examples with randomly chosen classes. The observation of significant correlation between target class and user reported class could be the effect that dog images and cat images look alike to human vision system if shown for very short period of time. It’s unclear to me whether in all conditions, the source-target pairs are constructed to be visually similar, which caused the human perception bias.   I also found the findings less practically useful, given that human generally perceive the world without time constraint. But I do like the implications of the study for better improving machine learning security by exploring lateral connections.   