The paper describes an online active learning protocol (and a classification algorithm) that involves additional discriminative feature feedback. In other words, unlike the classical online protocol, upon prediction of the class label the learner receives not only the correct label, but also some discriminative feature of the class whenever it errs. In considered learning setting, the feature space is binary and a class is represented by the union of some unknown clusters, where each cluster in its turn represents some specialization of the class (i.e. an attribute) and every two clusters can be discriminated by only one binary feature. The algorithm roughly operates by keeping around instances seen so far and constructing DNFs that representing clusters.  The main contribution of the paper is the mistake bound for an algorithm that learns a subclass of DNFs in the described protocol. This mistake bound in the worst case scales quadratically in the total number of clusters. This seemingly comes in contrast with known results that learning DNFs is intractable, however, given only the label as a feedback. This paper demonstrates that learning is possible, however, in presence of additional feedback. The fact that the number of mistakes is bounded by the square of the number of clusters appears to match known bounds for multiclass online prediction (square in the number of classes).