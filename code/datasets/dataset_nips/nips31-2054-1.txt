The authors describe a novel method for learning deep generative models using variational methods that replaces typical mean field approximations in the wake-sleep algorithm with more sophisticated approximations.  In particular, they suggest an approach in which the posterior distributions are approximated by expectations with respect to a predetermined set of sufficient statistics:  A recognition network is trained to output these posterior distributions for each sample.  The approximate posteriors are then selected to be those distributions of maximum entropy that agree with these expectations.  As MLE of probabilisitc models can be reduced to computing expectations (i.e., the computation of the gradients), the entire procedure can be made tractable without the need of having to actually form the posterior distributions (no partition function computation necessary).  For the most part, the paper is well-written and easy to follow.  General comments:  How are the sufficient statistics (i.e., the T's) selected in the experiments?    There seem like there are a lot of knobs to turn here:  choice of the form of the probability distributions, choice of the sufficient statistics, number of layers in the deep gen. network, etc.  Can the authors comment a bit about how to go about this in practice?  I wouldn't expect that this method (or any of the other methods for that matter) produces the same estimate of the posterior distributions on each run.  Maybe it makes more sense to report average values?  Or are you reporting the best fits as selected using a validation set?  In either case, this needs to be made more clear if the experiments are to be replicated.