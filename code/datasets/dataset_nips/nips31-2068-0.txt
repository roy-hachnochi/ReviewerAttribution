In this manuscript, authors propose to learn the low level features and high level features simultaneously. By learning the sparse low level features, authors claim that they are more robust for the metric learning process. My concerns are as follows. 1. The proposed method may be inefficient for the real-world applications. Both number of examples and dimensionality of features in the experiments are small. Note that when updating $Z$, authors has to enumerate triplet constraints, whose size is cubic in the number of training data. When projecting the updated metric back to the PSD cone, the cost is cubic in the number of low level features. It makes the algorithm hard to handle the real applications. For the test phase, the proposed algorithm also has to obtain the sparse code for each example. 2. Authors didn't mention the size of dictionary in experiments. The size of metric is quadratic in the number of low level features. If the size of dictionary is too large, which is ubiquitous for image classification, the proposed method can be impractical. Besides, authors should report more settings in experiments, e.g., $k$ in k-NN, number of iterations of LMNN, $k$ in LMNN, etc. 3. For the problem in Eqn.6, it can be nonconvex since both of metric M and Z are variables to be solved. So the analysis in Section 2.5 is suspect.  After the rebuttal: 1. Authors applies 1-NN to alleviate the large-scale problem, which is not convincing. 2. The setting in the experiments is not common for DML. Besides, codebook with size of 120 is too small for a meaningful sparse coding.