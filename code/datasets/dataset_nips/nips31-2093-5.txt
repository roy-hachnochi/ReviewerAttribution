The authors present a very interesting work on link prediction in knowledge graphs using embeddings. The main idea is to provide a embedding to a reciprocal relation, which allows the model to be fully expressive while keeping it as simple as possible. The paper is very nicely written and it was a pleasure to read it (which is unfortunately becoming a rarity these days). The authors did a very good field overview, and shown benefits of the proposed approach over a number of baselines. - At first glance and without reading the paper, uppercase E in the title seems like a typo. Not sure what can be done there, but would be good to potentially reconsider the title to avoid that confusion. - Typo: Line 68, "<x, w, x>" -> "v, w, x" - Typo: Line 151, "have and keep up", it is not clear what the authors wanted to say here, please fix. - Some definitions are repeated in the text, such as relation being symmetric. This can be cleaned up. - Line 195 paragraph, from their explanation it is not clear what the issue is. Seems reasonable not to update the same vector for "acted" and "likes", as the relations are quite different (one referring to an actor and the other to a viewer). Would be good to elaborate on this, and either provide a better example or discuss this one further. - Training procedure should go before experimental setting. It is simply not its place there, and I was a bit confused when I reached the experimental section without even mentioning training and loss. Please move it earlier into its separate section, it will result in much more natural paper organization. - As much as I liked 90% of the paper, I am a bit disappointed with the results. This section is quite dry and could be improved significantly. - Line 327, "we might expect", is this corroborate with the data set used, or some other data sets? It is definitely intuitive to be expected, but some concrete example and a bit more grounded discussion would help. - Line 336, I do not understand why did the entity count drop? If we only removed unnecessary relations (such as symmetric ones), why would entities be removed as well. This should be elaborated. - Again, the results are very dry, would be good to provide some examples, good and bad cases. This definitely takes away from the quality of presentation. - One suggestion: Line 342, why use "exp" as a suffix, not sure what "exp" refers to? Maybe use "bk" for "background knowledge", or something like that. Not really relevant, just a minor comment.  ### ### UPDATE FOLLOWING FEEDBACK ###  I would like to thank the authors for their responses. Assuming the authors address my comments (as they said they would) and hopefully add at least a bit of interesting results, this paper definitely belongs to the conference.  I have increased my score from 7 to 8 after I read feedback and other reviews.