Summary of Paper:  A contextual linear bandit algorithm which satisfies the jointly differentially private property is proposed. The central idea is to adopt a changing regularizer in order to combine the classic linear-UCB algorithm and the tree based DP algorithm. The proposed algorithm achieves similar regret guarantee as classic linear bandit. Novel lower bounding results are also provided for general private MAB problems.   Comments:  The paper is well organized and the technical part is generally sound. While the major concern lies on the significance of the studied problem. According to Theorem 5 and 6, the proposed changing regularization approach has a very similar regret guarantee with the classic algorithm. This reflects that employing the jointly DP constraint does not significantly changes the hardness of the original learning problem. The lower bounding results also reflects this suspicion since the the suffered additional regret is also of order O(log(n)/\delta). I feel it’s better to include some discussions of the importance both in theory and practice for this DP contextual linear bandit setting.  I also suggests some improvement for the online shopping example discussed in the introduction. In line 39-41, I am quite confused with the actual meaning of “without revealing preference to all users” since to my understanding, the user preference is only revealed to the system instead of all other users under this scenario. It is better to transform the necessity of privacy to the system side.   ----- after rebuttal ----- I believe the feedback has addressed my main concerns.