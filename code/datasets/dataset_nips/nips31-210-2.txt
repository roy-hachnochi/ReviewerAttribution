The paper proposes a deep architecture for image inpainting that incorporates parallel conv branches and is trained using adversarial loss, a proposed spatially-weighted reconstruction loss and an MRF regularization term. Qualitatively, the results seem clearly better than baselines.  As usual with generative models, it is difficult to evaluate the results quantitatively. There is an ablation study, which would be very useful normally, but since the evaluation is purely qualitative, it is difficult to draw conclusions.  The authors put forward the advantages of the proposed parallel-branches architecture. Maybe it would be useful to compare as well with an inception-style model, where the branches get concatenated after every module and not as here only at the end.  How many parameters for the network? Any particular reason for using 3 branches?    