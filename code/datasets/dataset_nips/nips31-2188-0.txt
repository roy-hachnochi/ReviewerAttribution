This is a fairly complete paper establishing the utility of a way to reduce communication overhead by a simple technique to sparsifying gradients and update a shared memory [in parallel]. It proves a convergence bound and establishes that parameters of the algorithm do in fact have reasonable values, leading to a practical algorithm. Benefits are demonstrated experimentally. The proof is understandable.  Note that just as for another submission, Lemma 3.3 has an 'e_t'. However this time the proof makes sense, because e_t appears in both eq. 15 and 16 (This is a major improvement on the other paper, which I guess has some typo and led to complete confusion when reading through the proof.)  Reading this paper was a pleasant experience, and the technique is fairly simple to implement. Providing experimental demonstrations [even if non-convex] also allows people less interested in theory to appreciate this paper.