This paper studies the problem of matting. Given an image, a matting algorithm outputs a per-pixel mask, describing whether each pixel belongs to foreground (1) or background (0). Solving matting requires a user to *actively* interact with the segmentation system, providing supervision in the form of trimap or scribbles. Such interaction is often laborious and requires expertise (i.e. knowing where to draw is best for the specific segmentation algorithm). This paper simplifies the interaction by freeing users from making decisions about where to draw and the drawing action. Instead, users only have to answer a binary question each time, regarding whether the region queried by the algorithm belongs to the foreground or not.   To come up with the next region to query at each step, the algorithm takes into account regions queried previously, the current matte, and image content. To learn an end-to-end system that takes an image as input and allow a user to interact with a black-box matte solver, this paper seeks out reinforcement learning. Results show that with the same number of steps of interaction, active matting produces alpha matte with better quality while taking less time than an experienced human user.   Here are my questions after reading the paper:  - No negative results are presented in the paper. I am curious what the failure cases are for the proposed method.  - Is a binary answer ever insufficient for a 75x75 region? Does the algorithm ever propose regions that land on a thin-structure (e.g. hair)?  - If I understand the first baseline (i.e. B1 at line 182) correctly, the ideal sequence describes a locally optimal solution, instead of a globally optimal solution. In some sense, that is not an upper bound for the proposed method. Is that right? 