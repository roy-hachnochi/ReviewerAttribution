In the context of time series classification, this paper introduces the Wavelet Deconvolution layer, which is able to learn the filters width of a neural network-based classifier, which is usually tuned by hand through hyper-parameters grid search. Experimental studies on time series are presented, including a pilot study using artificial data, a phone recognition study on TIMIT and a time series classification study on the Haptic UCR dataset. It is shown that the proposed method leads to similar of better results than state-of-the-art systems.   Quality: The paper is correct to my understanding. The experiments are convincing and clearly show the benefit of the proposed approach. Having two different studies on different tasks is very good, showing the generalization capability of the approach on various cases.  Minor comment: in section 5.2, when describing the use of Mel filterbank as input to a CNN, [29] does not use filterbank as input but temporal raw speech. There is also several papers using raw speech as input which have studied the learned filters of a CNN [1][2][3], the authors could discuss that when presenting the frequency responses of the wavelets at the end of section 5.2.  Clarity: the paper is well-written and easy to follow.  Originality: The proposed method is novel and an original application of the wavelet transform.   Significance: This work is definitely significant. Being able to learn several hyper-parameters of a CNN instead of running hundreds of experiments is very important, specially for tasks with no established preprocessing step. The interpretability of the wavelet scales is also a nice addition. The proposed WD layer could be widely adopted.  Overall, this paper is significant and it should accepted for publication.  References: [1] T. N. Sainath, R. J. Weiss, A. Senior, K. W. Wilson, and O. Vinyals. "Learning the Speech Front-end With Raw Waveform CLDNNs". Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), 2015 [2] Z. Tüske, P. Golik, R. Schlüter, and H. Ney. "Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR".  In Proceedings of the Annual Conference of the International Speech Communication Association (INTERSPEECH), pages 890–894, Singapore, September 2014. [3] D. Palaz, M. Magimai-Doss, and R. Collobert. "Analysis of CNN-Based Speech Recognition System Using Raw Speech as Input." Sixteenth Annual Conference of the International Speech Communication Association. 2015.  UPDATE: The authors response clarified most of the questions raised with the paper, especialy the choice of presenting the method using a specific wavelet and the use of the "deconvolution" term, as well as experimental details.  Hence my score remains the same: this paper is signiicant and should be accepted.