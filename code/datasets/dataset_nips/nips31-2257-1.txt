This work develops a prediction method for the output of linear dynamical systems from past observations. The authors measure prediction accuracy in a regret setting. They introduced a class of pseudo-linear dynamical systems in which the output of the next observation depends on the previous tau observations and the entire history of inputs, and they showed that when such systems have poly(log T) many weights they can approximate linear dynamical systems (LDSs). The construction of the pseudo-LDS class relies on the spectral filtering technique introduced by [HSZ17], and the regret proof on the analysis of regularized follow the leader from online convex optimization.   As far as I know the authors offer the first polynomial time algorithm for attaining sublinear-regret for predicting the output of linear dynamical systems without full state observation, i.e. with C not the identity matrix, and without a dependence on the spectral radius of the A matrix. Also, this work relaxes the requirement of A being symmetric, need in previous art [HSZ17], to A being diagonalizable; a difficult extension achieved by considering polynomials that have the phases of A's eigenvalues as roots.   LDS represent a fundamental building block for continuous control problems, and there has been a lot of work recently in trying to develop data driven methods for controlling or identifying such systems from data. One difficulty in analyzing such methods is that the larger the spectral radius of A is the stronger the dependence on previous inputs and disturbances is. However, a larger spectral radius offers a larger SNR so it should not degrade performance. Algorithms and proof techniques that do not degrade as the spectral radius of A increases are valuable.  My only complaint is the writing; it could be clearer, a weakness which decreased my score. Some line by line comments:  - lines 32 - 37: You discuss how the regret cannot be sublinear, but proceed to prove that your method achieves T^{1/2} regret. Do you mean that the prediction error over the entire horizon T cannot be sublinear?  - eq after line 145: typo --- i goes from 1 to n and since M,N are W x k x n x m, the index i should go in the third position. Based on the proof, the summation over u should go from tau to t, not from 1 to T.  - line 159: typo -- "M" --> Theta_hat  - line 188: use Theta_hat for consistency.  - line 200: typo -- there should no Pi in the polynomial.  - line 212: typo --- "beta^j" --> beta_j  - line 219: the vector should be indexed  - lines 227 - 231: the predictions in hindsight are denoted once by y_t^* and once by hat{y}_t^*  - eq after line 255: in the last two terms hat{y}_t --> y_t  Comments on the Appendix:  - General comment about the Appendix: the references to Theorems and equations are broken. It is not clear if a reference points to the main text or to the appendix.   - line 10: Consider a noiseless LDS...  - line 19: typo -- N_i ---> P_i  - equation (21): same comment about the summation over u as above.  - line 41: what is P?  - line 46: typo --- M_omega' ---> M_ell'  - eq (31): typo -- no parenthesis before N_ell  - line 56: the projection formula is broken  - eq (56): why did you use Holder in that fashion? By assumption the Euclidean norm of x is bounded, so Cauchy Schwartz would avoid the extra T^{1/2}.  ==================  In line 40 of the appendix you defined R_x to be a bound on \|x\|_2 so there is no need for the inequality you used in the rebuttal. Maybe there is a typo in line 40, \|x\|_2 maybe should be \|x\|_\infty