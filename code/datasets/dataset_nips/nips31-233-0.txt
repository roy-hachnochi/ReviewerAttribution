In this paper, the authors propose a new network structure with 2 step attentions. The structure is inspired by SENet.  The first step attention is able to capture second-order statistics, and the second attention adaptively allocates features from a compact bag rather than  exhaustively correlating all features. The authors report state-of-art result in image classification and video action understanding.  It is an incremental work to SENet. I think the major contribution is on video classification task. Compare to Non-local neural networks, A2 net is able to achieve better result with much less computation.   However, my concern is, for video classification task, there is no comparison to ResNet-26 + SENet. There is vanilla residual networks result, but if there is ResNet-26 + SENet result, we will have better understanding on the contribution of first step attention. Then we will have better measurement of the overall contribution.  -- Update:  I have read the authors' feedback. According to new experiments, I adjusted the score. 