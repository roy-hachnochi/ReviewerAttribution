The paper aims to extend the "fairness through awareness" framework by assuming that instead of having access to a task-specific distance metric on individuals, the decision-maker can make a small number of queries to an expert panel which could answer a small number of queries. The authors generalize the notion of metric fairness to "metric multifairness," which considers a collection of sets of pairs of individuals and requires that for each such set, the expected difference in scores given to the pairs in that set is not much more than the expected distance between pairs. They show that if this collection of sets is expressive, then this property implies that a large fraction of pairs of individuals satisfy metric fairness. As a result, the authors propose to consider a family defined by some bounded computation to make the sets considered sufficiently rich while also maintaining the ability to efficiently sample the distance metric.  The authors show how to cast learning a linear classifier under metric multifairness constraints as a convex problem and provide convergence guarantees. They also give a postprocessing technique to satisfy metric multifairness for an arbitrary given classifier.  They go on to give a reduction to agnostic learning, showing that if the concept and hypothesis classes can be learned by an agnostic learner, then this can be used to make more efficient use of the metric samples.  Finally, they show that their bounds are tight up to constant factors, and that some learnability assumptions are necessary to make any claims about utility.  The premise of this work is fairly interesting -- learning a metric using guidelines from an expert panel is a compelling idea. On the other hand, it's unclear that the guarantees that they achieve are very strong. It would behelpful to see some explicit examples of concept classes and the particular guarantees they would imply. In addition, it would be good to see experimentally how the guarantee from Proposition 1 plays out in practice: does it result in strong individual fairness for a constant fraction of the population, or does it afford a slightly weaker protection to almost all of the population?  Overall, I think this work is reasonably good, but in order to have stronger feelings about it I'd need to see a more concrete instantiation of the class of comparisons and perhaps some (minor) experimental results demonstrating the effects of metric multifairness. In particular, I don't have a good sense for how many metric queries are needed in practice -- is it something like 100? 1000? While the theory behind this work is nice, to me, it isn't that interesting on its own, and would be made stronger by having some empirical demonstrations to back it up.