The paper studies the problem of fair classification in the framework of ``fairness through awareness" of Dwork et al which requires similar individuals to be labeled similarly by the classifier. Crucially, the work of Dwork et al requires the existence of a similarity metric between the pairs of individuals; an assumption that is ``one of the most challenging aspects" of the framework. This work relaxes this assumption by requiring similar identifiable subpopulations to be treated similarly by the classifier. The authors assume while the metric is not known, it can be queried for specific pairs of individuals by the learner. The authors show under what conditions this relaxed notion of fairness can be efficiently satisfied when the learner's goal is to maximize classification's utility subject to satisfying this new relaxed fairness constraint.  Questions: (1) Does the post-processing approach in section 3.1 come with any formal theoretical guarantees? Woodworth et al 2017 have shown that post-processing to satisfy equality of odds can be highly sub-optimal in the worst case.  Strengths: (1) While the paper is similar in spirit to the work of Hebert-Johnson et al and Kearns et al, I feel like relaxing the fairness through awareness framework is a rather interesting contribution.  (2) The paper is rather well-written and the high level ideas are easy to follow.   Weaknesses: (1) If I understand correctly, the authors assume a realizable setting for the generation of labeled examples i.e. the unlabeled examples are generated by a distribution D and then the unlabeled examples are labeled by a deterministic function. Can the authors clarify if this is the correct understanding? If so, given that the realizability assumption is rather restrictive/outdated, can the authors elaborate how/whether their results can be extended to an unrealizable setting? (2) The authors draw connections to agnostic learning problems to solve the search step of algorithm 1. Agnostic learning is generally hard computationally but regardless have been commonly used/solved in practices. While I strongly believe that theoretical contributions are indeed important, in a topic such as an algorithmic fairness, it would be rather crucial to see how the techniques proposed in this paper fare when dealing with real datasets even if heuristic techniques are used to solve the computationally hard subroutines. (3) The assumption that the hypothesis class is the class of linear functions is rather restrictive. As far as I can understand the constraint in the convex program might not be convex if a different hypothesis class was used.  Typos and minor comments: (1) line (17): attributes (2) line (55): requiring (3) line (83): linear function "with" bounded weights (4) No "." needed in the middle of line 247 (5) typo in line 292/293 -- last sentence of the paragraph (6) the paper uses rather unconventional notation for the ML audience: for example in a typical ML paper delta is used for confidence parameter, epsilon is used for accuracy, n/d is used for dimension and m is used for sample complexity. While this is a matter of choice, the paper would be much easier to read for a NIPS/ICML audience if the standard notation were followed.  ------------------------------------------------------------- I read the other reviews and the author response.  