This paper describes a novel approach to survival analysis, given multiple competing risks, which allows non-monotonic covariate effects. It provides a thorough theoretical foundation, then empirical results, based on both simulation data, and also some realworld data.  The theorem appears correct (but did not check thoroughly), and the empirical results show that your approach appears effective. However, I wondered about the models you compared against, and the evaluation measure.  It is great that you compared your system to several different models. It would be good to compare to other models that allow covariates to have different effects, at different times in the future: Deep Learning for Patient-Specific Kidney Graft Survival Analysis (https://arxiv.org/abs/1705.10245), DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks (http://medianetlab.ee.ucla.edu/papers/AAAI_2018_DeepHit.pdf), Learning patient-specific cancer survival distributions as a sequence of dependent regressors (http://papers.nips.cc/paper/4210-learning-patient-specific-cancer-survival-distributions-as-a-sequence-of-dependent-regressors ), A Multi-Task Learning Formulation for Survival Analysis (https://dl.acm.org/citation.cfm?id=2939857), etc.  Also, concordance (and variants) are only one measure for evaluating survival models. It would be useful to understand how well their Lomax model is wrt calibration measures; see https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3575184/  The nice example in li19-22 describes nonmonotonicness wrt feature values, where both high and low values can be problematic.  Can this model also deal with situations where a single value of a variable can imply a high chance of dying soon, but low chance of dying at a later time?   I had a hard time tracking sec3. Can you start with the diabetes example (li 136-144), and use that to explain the notation and the results?  Would the user need to specify that type1 corresponds to S1, and type2 to S2? Or would this emerge from the data?    Li197: I am puzzled why you exclude censored data from test set. Isn’t that the challenge of survival analysis? (I assume the training data included censored instances.)  Li297: Should explain why the average is over just the uncensored instances  Minor points:  Li12: Lom(..)  vs li 19 Lomax(...)  Li128: “no longer a constant”.  Is this wrt time?    P4: wrt diabetes types: what is risk? Of  event of death? Or hypoglycemic event? Or …  P4: motivate why we need to deal with “countably infinite no. of atoms”?  I thought the components would be known factors… is this to model ???  Li91: Here,  in the embedded equation, is the \lambda = \sum_j \lambda_j?  Eq 3, should the conditioned be  { \lambda_j  }, rather than \sum_j \lambda_j ?  Fig1: shrinkalege_x000c_  ================== The authors did a nice job of addressing most of my comments--I especially like including Brier score (should note that li16 is only over uncensored data). Many measures do deal with some censored data -eg. c-index typically does include instances whose censored time is after the time of an uncensored instance, etc. Paper should explain why such methods don't apply here.  My other remaining concerns are lack of comparisons with other non-proportional models, and the difficulty of tracking some parts of the article,  I am willing to increase my assessment to 6. 