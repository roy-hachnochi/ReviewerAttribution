The paper considered theoretical results on adversarially robust generalization, which studies the robustness of classifiers in the presence of even small noise.  In particular, the work studied the generalization of adversarially robust learning by investigating the sample complexity in a comparison to that of standard learning. Specifically, the study focused on two simple concrete distribution models: gaussian model and Bernoulli model.  For both models, the authors established the lower and upper bounds for the sample complexities. From these results,  they drew the conclusion that the sample complexity of robust generalization is much larger than standard generalization.   The results are interesting and potentially of great interests to machine learning community.  The proof techniques are non-trivial involving delicate properties of Gaussian, Bernoulli distributed random variables.  One possible weakness of the paper is that the results are established based on very special models.    Other comments:   1. In line 178-179, the sample complexity of robust generalization is claimed to be larger than of standard generalization by the square root of d.  Could you explain this more on this claim?  I would think that one should compare the sample complexities assuming the classification errors are at the same level -- the results of Theorem 5 and 6  certainly used different classification errors to derive the sample complexity bounds.     The same comment also applies to the claim stated in lines 229-231.  2. I am not sure if these models are practically realistic. Usually, one will start from the marginal distribution to sample inputs x and then the conditional distribution P(y|x) to sample the outputs y given x.   The Gaussian and Bernoulli models (definitions 1 and 2) used the other way around -- y is randomly drawn and then x is from Gaussian or Bernoulli. Any responses from the authors will be appreciated.   I went through the feedback and I am satisfied with their response, in particular on the special models.   I recommend its acceptance. 