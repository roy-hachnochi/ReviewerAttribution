Two heuristic mechanisms from neuroevolution study have been imported into the recently proposed evolution strategy for deep reinforcement learning. One is Novelty Search (NS), which aims to bias the search to have more exploration. It try to explore previously unvisited areas in the space of behavior, not in the space of policy parameters. The other is to maintain multiple populations in a single run. The authors proposed three variation of the evolution strategy combining these mechanisms. From the simulation results reported in the paper, the proposed method, NSRA-ES, doesn't seem to have a strong disadvantages over the original ES, while it improves its performance in some situations, though the improvements appear only after relatively large number of iterations. If so, one might want to simply restart the algorithm with different initialization. It is not very fair to compare the final performance after a sufficient number of iterations for the proposed algorithm.   The authors say (at the first sentence of sec. 2.2) that optimizing for reward only can often lead an agent to local optima, and NS avoids deception. Please provide an evidence / reference. In many situation the state transition is stochastic and hence the reward is noisy. Then, the estimated gradient is hugely affected by this noise, and the signal-to-ratio will drop at some point. This can be one of the reason that a gradient based algorithm stacks. If so, I am curious to know if the proposed mechanisms are really more effective than just setting a greater sigma (standard deviation of the Gaussian noise to produce a parameter vector) in the ES. See for example, Arnold, D. V. (2006). Weighted multirecombination evolution strategies, TCS, vol. 361, 18â€“37.  The sentence "NS-ES is still able to consistentlly solve the problem despite ignoring the environment's multi-part reward function". I feel this result is quite artificial, and without the modification of the environment done in this paper the result will be different. The authors modification should be very helpful for NS. Otherwise the diverse BC will simply result in searching in a wrong direction.   (Rebuttal) A discussion about the noise standard deviation will be rather helpful to understand the goodness of the proposed method compared with the original algorithm with a tuned parameter. I appreciate that the authors will add an argument about it in the revised paper.