The author proposed semantic 3D reconstruction by learning a multi-view stereo machine and a next best view predictor simultaneously. As viewpoint suggestion is not differentiable, the authors used REINFORCE for training.  It has been a fun read. I think this paper is well-written. Qualitatively the results look nice. The reference is thorough. The system is similar to LSM which was presented in last year’s NIPS, but the authors also takes next best view prediction into account.  I’m on the border for this paper. My main concern is the lack of evaluation. While the system focuses on using neural nets to predict the next best view, its evaluation on viewpoint selection does not include other published methods. For example, how would the selected views compare with those selected by 3D ShapeNet (CVPR 15), as well as its follow-ups? Such a comparison is important to validate the main claim of the paper.  Currently, all results are obtained on synthetic data. It’d be great if the authors can include some results on real data. Usually for real images camera poses might not be fully available. This will pose challenges to the proposed approach. Also, next best view selection is an important problem in robotics, where experiments on real data is crucial and heavily weighted.  Minor: training with REINFORCE is often unstable. How often does active vision actually provides an advantage over random/one-way? It’d be good to include success rates and error bars.  ==post rebuttal== The rebuttal partially addressed my concern. The comparison with one-step greedy view selection is good, but the results are not very impressive. The results on real datasets and a quantitative evaluation of REINFORCE are promised, but not included yet. I'm fine with accepting the paper, if what is promised can be included in the final version, but cannot champion it.