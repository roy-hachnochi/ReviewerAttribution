This paper presents a methodology to accurately estimate a level set of an expensive to evaluate function, with several levels of fidelity/cost available. A new acquisition function is introduced, defining an entropy for the contour location.   I am not aware of many works with multi-fidelity (pertinent for Machine Learning) in this context, but there is a closely related one that should be discussed:  Bogunovic, Ilija, et al. "Truncated variance reduction: A unified approach to Bayesian optimization and level-set estimation." Advances in Neural Information Processing Systems. 2016.  Also, an acquisition function targeting the contour itself is proposed in: Chevalier, C., Ginsbourger, D., Bect, J., & Molchanov, I. (2013). Estimating and quantifying uncertainties on level sets using the Vorob’ev expectation and deviation with Gaussian process models. In mODa 10–Advances in Model-Oriented Design and Analysis (pp. 35-43). Springer, Heidelberg.  For closed form expressions of [15], see e.g.,: Chevalier, C., Bect, J., Ginsbourger, D., Vazquez, E., Picheny, V., & Richet, Y. (2014). Fast parallel kriging-based stepwise uncertainty reduction with application to the identification of an excursion set. Technometrics, 56(4), 455-465.  It would be nice to compare the relative costs of those approaches, with their corresponding approximations.   The contour entropy depends on the parameter epsilon, with a proposed default of 2*sigma(x). Could you show that the performance is not too sensitive to this choice. In particular, a fixed value should still work since the Gaussian predictive distribution shrinks with new observations anyway.  The experiments are convincing, but I am curious about what is the most important: leveraging several levels of fidelity or the acquisition function? Especially, the contour entropy is quite computationally expensive, while simple criteria (e.g., from [13] and [14]) are cheap.  ## Additions after rebuttal The authors’ response to the various points (shared among reviewers) is complete and suggests that the final version will be improved. I thus increased my evaluation score (7 to 8).