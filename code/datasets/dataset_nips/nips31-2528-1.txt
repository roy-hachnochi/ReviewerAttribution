Here is an update following the authors' response.   After reading the authors' response, I strongly feel that this paper should be rejected. My main argument is that this paper is more engineering (indeed a tour de force) than science. My point is that there is a large body of work that has looked at the computational role of recurrent connections (some of it cited, some of it mentioned by the reviewers) and this work does not shed any light on the computational role of recurrent connections. If we look at the actual contributions of the paper in terms of engineering, I do not think the reported improvements are that impressive. We are literally talking about 1% compared to a ResNet-34 baseline which is far from the state of the art. Furthermore -- yes the baseline has 75% more parameters but we are not talking orders of magnitude here. Would the proposed circuit help push the current state of the art? Well we dont know. One potential key limitation brushed under the carpet is that the proposed module come with a very significant increase in run-time complexity / FLOS (at least one order of magnitude more than the baselines) potentially limiting the applicability of the circuits for state of the art very deep architectures.   Regarding the neuroscience side of the contribution. The point that I made in my review is that the neural data are probably far from ideal to test a recurrent model because of the passive viewing and rapid presentation paradigm. It could well be that the dynamics beyond the initial onset is actually trivial and the noise ceiling not all that hard to reach. My review had hinted at several simple feedforward models that need to be considered for baselines (e.g, synaptic depression) to show that the explained variance of their model is not trivially accounted by a time-decay model. The authors claim that they have run a time-decaying model as controls and that they "did not do so nearly as well as task-optimized ConvRNNs". This is up to the referees to decide the validity of this statement and I am unclear why the authors did not submit these results in their rebuttal. Also to be clear, the controls that I mentioned are more than a simple linear decay on the model output but would involve a simple decay of the weights that would translate in a non-linear decay on the neural output.   Overall, the proposed model shows small improvements over non-SOA approaches with a very significant extra cost in FLOPS. In addition, the authors failed to demonstrate that their neural data exhibit any non-trivial dynamics and that the observed improvement in fitting these data could not be obtained with much simpler baselines. Overall, I see this paper as a clear reject and I am willing to lower my score and fight for rating should the need arise.  *** This study builds on previous work by Dicarlo's group that has shown that i) it is possible to optimize hyperparameters of conv nets to yield significant gains in accuracy and that ii) in turn, this yields computational models that fit better to ventral stream neural data. Here the idea is to go one step further and using a similar optimization approach to extend the models to incorporate recurrent processes. Unfortunately, the study falls short on several fronts.   From the network optimization perspective, the benefits of the approach are not quite as significant as those typically obtained with FF / conv nets. Furthermore, there is no clear computational-level explanation that can be gained because the dataset used is uncontrolled (imagenet) and it is not clear how recurrent processes contribute to improvements in accuracy (is it reducing noise? dealing with occlusions? clutter?). Recurrent connections help improve object recognition accuracy but then there is always a slightly deeper network (the number of parameters is of the same order of magnitude) that can perform object recognition with accuracy on par with these recurrent networks. In contrast, the previous cited work used synthetic stimuli and was able to show improvements with recurrent processing under occlusion etc. Here it is not clear what improvement truly is achieved and when. The study seems to be adding more noise than it is helping the field...   Another contribution of the work is that the resulting recurrent networks can then be used to fit -- not just temporal averages of neural signals as done in earlier work by Yamins et al -- but the entire neural dynamics. However, it is not clear from the paper how truly significant this is. For one, the monkey is passively fixating and stimulus presentations are fast -- hence the dynamics could well be relatively ``trivial'' (i.e., initial transient followed by a gradual decay in firing). At the very least, the authors should have provided a few controls on the FF nets. For instance, adaptation and/or synaptic depression on the weights of the FF nets might be sufficient to explain the variance in the neural dynamics and hence recurrent processes are not really needed.