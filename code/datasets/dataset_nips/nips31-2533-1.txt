This paper extends the MAML method by introducing structured randomness to the latent exploration space to perform more effective exploration. The experimental results show that by using a prior distribution for the stochasticity, the proposed MAESN method can adapt to new tasks much faster compared to general RL, MAML and learning latent spaces without fast adaption.  One question is that in the experiments, the test task is from the training tasks with only dense reward being placed with sparse reward. During the training phrase, the model in MAESN could have already ‘memorized’ the tasks according to w_i so it is not surprising that MASEN outperforms MAML. I would like to see results if we use an entirely new task that is never seen by MAESN instead of changing the reward.   Some minor problems: The references of equations in algorithm 1 are problematic where (3), (4), (5) should be (2), (3), (4). In the appendix, there is an empty ‘[]’.