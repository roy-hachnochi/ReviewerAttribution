I believe this is an extension of a ICLR'18 work, which advances adversarial training for increasing the robustness in modeling data distributions, so that adapting the learned models to unseen domains can be realized. Overall, this is a solid work with strong theoretical supports.   However, given this is an extension of the aforementioned work, I do have some concerns about the experiments. While it is very promising to be able to adapt the learning model to unseen domains without observing target-domain training data, some experimental results did not fully support the proposed method. For example, when training on MNIST to adapt to USPS, the performance was actually worse than that of baseline approaches (i.e., no adaptation). The authors did no provide results on the original source domain data, which makes me wonder if the proposed method would fail in describing/recognizing source-domain data (or data with similar distributions/properties).