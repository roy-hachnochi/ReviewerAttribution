The authors introduce an improved optimization model  to the trace norm regularized tensor completion problem. That model combines  some elements of earlier proposed approaches, for example the regularization is a reformulation of the latent trace norm based approach. Via applying square trace norm the authors try to avoid  specific sparse optimum solution. This approach resembles to to a maximum entropy type optimization model realized by a Gini concentration based regularization.    Soundness:  technically correct advanced optimization algorithm    Clarity: clearly written, ease to follow  Originality: the paper is built upon a synthesis of several known techniques       Significance: The manifold based optimization framework sounds very useful     Details:  The proposed new formulation of the problem is mainly incremental. The real value of the paper is  the optimization algorithm which is a combination of different sophisticated techniques. It transforms the original   problem into one which is built onto a tensor manifold constraint, where the manifold turns to be a spectrahedron, a Riemannian quotient manifold of positive semidefinite matrices.   The reason why this transformation into a manifold represented problem is applied has not been explained in the paper. Could this sophisticated algorithm be reduced into a simpler one which might be even more efficient?     The minimax problem in Theorem 1 could be interpreted as a Fenchel duality based  reformulation of the original case. Exploiting the theory of that type of duality might lead to a simpler reasoning than that which is included in the paper.        I have read the author response. I think the paper contains an advanced exploitation of the known techniques, but at limited level of novelty. 