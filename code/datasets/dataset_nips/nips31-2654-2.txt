This is a unique paper that, from a safety perspective, examines the question of whether a classifier output should be trusted.  In particular, it questions the use of confidence scores for that purpose and proposes an alternative.    This general direction falls very much under the "safe fail" paradigm for machine learning espoused in https://www.liebertpub.com/doi/abs/10.1089/big.2016.0051, and is clearly important as machine learning algorithms are increasingly used in high-stakes decision making.  The fact that it uses topological data analysis and level set estimation towards this end is quite appropriate and brings forth some nice theory.  I like that the authors have considered all three of the settings they have in developing their estimation rate results because they build upon each other to get to the most realistic third setting.  The analysis does appear to be correct, and I agree with the "remarkable"-ness of the final results.  The empirical work seems to be done in a reasonable manner and is sufficient for this type of paper.  I like that the algorithms themselves are quite simple and straightforward.  Overall, well done piece of work.