 Summary:  The main contribution of this paper is the proposed multimodal variational autoencoder (MVAE) for learning a joint distribution under weak supervision. The key novelty of MVAE is the use of a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. The authors first present experiments on several two-modalities datasets, and further apply MVAE to problems with more than two modalities.    Strengths:  (1) Clarity: The paper is clearly presented and easy to follow. I enjoyed reading the paper.   (2) Originality: The proposed model is simple but also novel. Firstly, it seems novel to use a product-of-experts inference network to do the posterior inference of latent variables. Each individual expert shares its statistical strength to enhance each other, and can deal with missing modalities naturally, thus suitable for weakly-supervised learning. Second, the proposed sub-sampled training paradigm is also intuitive and interesting.   (3) Significance: I think the paper proposes a nice approach for multimodel learning, especially when dealing with multiple modalities, instead of only two.   (4) Quality: The quality of this paper is also good. Methods are clearly described, experiments are carefully designed, with more details also included in the supplement. However, I also have one major concern listed below.  Weaknesses:  (1) Quality: I think the experiments in Section 5.1 are not carefully designed. As we can see from the title, this paper cares about weakly-supervised learning, and also since the proposed approach will be especially powerful when dealing with missing modalities, I think the experiments in Section 5.1 need more care.   Specifically, in Figure 3, the authors shows the performance of MVAE, using accuracy as the evaluation metric, which is good. However, no comparison with other methods are provided. The numbers in Table 2 & 3 are both for fully supervised learning. I'm wondering how the model performs when compared with other methods, like VAE, BiVCCA, JMVAE etc. in the weakly-supervised setting. And especially, how it performs compared with the state-of-the-art? This set of results should be provided to demonstrate the power of the model for weakly-supervised/semi-supervised learning. We need not only a curve like in Figure 3, but also detailed numbers and compare with others. For example, for MNIST classification, it should be easy to find a lot of baseline results in the literature.   Missing reference:  Variational Autoencoder for Deep Learning of Images, Labels and Captions, NIPS 2016.  I recommend the authors also citing the above paper. This NIPS 2016 paper shares the same graphical model as illustrated in Figure 1(a). Further, the authors considered image-label modalities, and image-caption modalities, and presented results on using VAE for semi-supervised image classification and image captioning, which I think is related to the topic in this submission.   Overall, I vote accept for this paper, and the paper has the potential to be a better one by providing more comprehensive results on weakly-supervised learning.   Minor issues:  (1) Line 73: see the equation in the rightmost of the line, "n" => "N".  (2) Table 3: "marginal, probabilities" => "marginal probabilities"  ---- AFTER REBUTTAL ----  I have read the authors' response and other reviewers' comments, and decide to keep my original score. As agreed by all the reviewers, this work has some novelty inside, and well-presented. The added new experiment on text translation seems also interesting. The authors claimed that they will add detailed numbers and additional baselines in the weak supervision section. This addresses my concern, and therefore, in summary, I prefer to voting for acceptance of the paper.   During the discussion, we noticed that although the derivation of Eqn. (3) has no problem, the claim in Line 73 "This suggests that the correct q is a product of experts" is not precise. Instead of considering x_1, ... x_N as N modalities, if x_1, ..., x_N are N pixels, and are conditionally independent given z, which is the assumption of many VAE models, then Line 73 implies that the most correct q is a PoE which uses one inference network per dimension without sacrificing expressive power. This seems strange, and we think the fact that the factorized true posterior is a PoE does not necessarily mean the variational posterior should also be a PoE, so we recommend the authors changing the claim in Line 73 to something like "the usage of a PoE inference network is more like a theoretically motivated heuristic". 