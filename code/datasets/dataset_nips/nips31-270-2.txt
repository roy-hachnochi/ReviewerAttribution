 This work proposes to accelerate Katyusha for non-strongly convex functions by periodically restart it. This paper is well written and the motivation is clear. My main concern is on its practical performance and experiment.  Empirically, the Rest-Katyusha generally performs better than Katyusha in terms of number of gradient evaluations. However, as shown in Figure 1, they are generally indistinguishable when the objective gap greater than $10^{-6}$ or even $10^{-8}$. In other words, the proposed method is effective most when an extremely accurate solution is required. Do we really need to solve the target problem so accurately in machine learning?  To better show the advantage of Rest-Katyusha, the authors are suggested to test it on more real-world datasets. Especially, for the Lasso regression problem, it is better to use more high-dimensional datasets that is more reasonable in practice. Currently, for the used three datasets, only RCV1 can be consider as a high-dimensional dataset.