Context: It is a classic result that empirical frequencies of actions for players playing regret minimization algorithms converges to a coarse corr equilibrium. CCEs are not necessarily desirable solution concepts because they sometimes admit irrational behavior. For monotone games, it is known that the empirical frequencies converge converge to nash equilibrium for agents playing FTRL. Recently, Mertikopoulos et al proved that the sequence of plays for FTRL converges to nash for games -- they prove something more general that goes beyond concave potential games, in fact.  This work considers that case when each agent can only observe bandit feedback. In such a setting, each agent does FTRL on some estimate of the gradient through a FKM-like one point estimator constructed by a random perturbation. The main result of the paper is that even with limited feedback the dynamics for monotone concave games converge to nash, and they do so at T^{-1/3} rate (for a "strict" variety of the problem).  While the result was not known before, I do not find it surprising. The previous work established analogous rates and results when the agent does FTRL on unbiased stochastic gradients. Given this, FKM estimators can be seen as \delta-biased estimators of variance proportional to dimension. Therefore, it is reasonable to expect that choosing \delta appropriately should result in the same result with worse rates -- that same balance also shows up in standard convex bandit analysis. Even the proof in the appendix mirrors the same when compared to Mertikopoulos et al.  - After the authors' comments. - While the convergence rate analysis in the aforementioned paper does not concern itself with the actual sequence but only the ergodic sequence, it is likely that this is because they don't employ (H4 in the same paper) that the gradients are Lipschitz - the present work does. In the same paper, for instance, with the assumption of H4, the authors have been able to prove convergence (but admittedly not the rate) of the actual sequence.   With regards to the second point, the difference I see is that the previous results are based on regret analysis. But for \beta-strongly monotone games (~strong convexity), the argument must proceed through a recursive inequality of the template -- \Delta(T+1) < (1-\eps)\Deta(T)+ \gamma -- this paper does so. But this change is very expected since even first-order optimization algorithms for SC-functions proceeds through a similar argument.  In this light, I'd like to retain my score. I'd encourage the authors to contrast their work with the previous in a manner that allows a clear comparison.