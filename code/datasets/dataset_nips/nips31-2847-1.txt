This paper addresses the problem of disentangled representation learning in a very specific way, namely with a focus on “interpretability” and “controllability” of the representations -- such that the meaning of the individual (group of) latents can be understood by a human (interpretability), and that the network designer can control what is, and what is not, to be contained in the disentangled representations.   The chosen approach is to start with “readily available” ground truth attribute labels, then carve up the latent representation space in pre-assigned groups, one group per attribute to be disentangled.  Then, to encourage the encoder to actually assign the corresponding attribute encoding only to the pre-selected group -- and not to any other parts of the representation space -- a generator is expected to still reconstruct the image perfectly when the latent representation of that attribute is replaced with that of another image with the same attribute value. This requires a sufficient number of pairs of images for which the attribute values are known and identical.  In addition, for pairs of images for which the attribute values are not known (which can be the majority of the training data), a randomly chosen group is swapped between the encodings, then decoded and the result encoded again, followed by “swapping back” the same group, before again decoding. If the representation is disentangled, then this should results in the original images to be reconstructed after the second stage.   Pros: The idea of swapping latents and using the outcome as a learning signal for disentangled representation learning is a very good one, and I have not seen it presented in publications before. The method clearly works well on the datasets presented, and with the ground-truth label information provided. The visual results of this approach (Figure 2) look very nice, and do reflect desired properties of disentangled representations, namely the compositionality resulting from the possibility to change one semantically meaningful part of the representation independently of all others.   Cons: I have a number of concerns with this approach, or at least with the way it is portrayed. Some of those concerns can be highlighted by revisiting the claimed contributions of this work:  - “Our contribution is therefore the first dual-stage strategy for semi-supervised disentangling.” -- It is not clear to me how this a contribution by itself. - “Also, require limited weaker annotations as compared to previous methods” -- this is obviously only true compared to previous supervised methods, despite the authors pointing out early on that the most prominent successful methods are actually unsupervised - “and extend the single-dimension attribute encoding to multi-dimension ones.” -- I can see nothing in this work that shows that this is actually an advantage per se - “Our method achieves results superior to the current state-of-the-art.” -- In order to talk about superior results, a fair comparison is required. Adding supervised information (even if “weakly supervised”) solves a rather different kind of problem than what fully unsupervised methods try to achieve. I assume this statement is meant to be corroborated by the numbers shown in Table 1, but it is unclear to me how these very different models (with very different amounts of information provided to the networks, with InfoGAN and beta-VAE being unsupervised) can be fairly compared to each other. On that note, I could not figure out from the text what beta-VAE(1) and beta-VAE(6) stand for.   - Line 34: “Unsupervised methods, on the other hand, do not require annotations but yield disentangled representations that are usually uninterpretable and dimension-wise uncontrollable.” The statement that the representations of unsupervised methods (such as InfoGAN and beta-VAE) are “usually uninterpretable” is patently false, and that they are “uncontrollable” is meaningless, as the aim of unsupervised methods is the unguided discovery of disentangled factors, rather than forced assignments of known or presumed factors.    - Line 41: “In this paper, we propose a weakly semi-supervised learning approach, dubbed as Dual Swap Disentangling (DSD), for disentangling that combines the best of the two worlds.” This is a questionable statement, as (already mentioned above) unsupervised disentangling has a different goal than supervised or semi-supervised one. Again, unsupervised disentangling is about discovery of latent factors, even -- and especially -- if they are not known to the designer of the network. This approach cannot discover any attributes that are not provided by ground truth labels and pre-assigned to specific groups of latents.   While the argument seems to be made that attribute labels for pairs of images are generally easy to obtain, it seems to me that the opposite is the case, as soon as we leave the realm of fully synthetic images for which the ground truth is known by design. In fact, this problem is already apparent in this work, in the way the labeled MNIST pairs have to be created via a trained generative model (here InfoGAN) to get access to such labels. Furthermore, for the supervised part to work correctly, the attribute values of matched pairs need to be exactly equal (such as exactly matched azimuth angle, exactly matched color value, etc.) -- a problem that does start to show up even in this work under the term of “disturbed pair”.   Line 243: “In this condition, we can compare part of codes (length = 5) that correspond to digit identity with whole codes (length = 5) of InfoGAN and β-VAE and variable (length = 1) that correspond to digit identity.” -- I have not been able to understand this sentence, which seems to be key for understanding how the quantitative results have been obtained. Generally, the quantitative evaluation section will need to be written much more clearly before the results can be considered convincing to many readers.  