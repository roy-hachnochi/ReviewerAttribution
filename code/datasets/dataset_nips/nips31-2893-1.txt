This work suggests a new creative and efficient way of factorizing full convolutions into 1x1 convolution and parametrizable shift operations for convolutional computer vision models. While this method is similar to depth-wise convolution it gives a new more efficient parametrization that ends up with cheaper convolution models (less parameters), less overfitting and faster training.  The approach is validated experimentally on the CIFAR-10/100 and ImageNet benchmark and is compared with low-resource models like ShuffleNet and MobileNet.  This is certainly a very creative work with a non-obvious idea that leads to considerable improvements of various aspects of the training and evaluation resource usage while improving generalization at the same time.  Low resource computer vision is an increasingly important area and this work provides convincing evidence for the efficiency of this creative methodology.  