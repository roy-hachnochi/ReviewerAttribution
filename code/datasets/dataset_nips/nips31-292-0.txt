This paper presents a parsing-guided deep network for re-posing a person image. In particular, the network takes as inputs a person image and a novel pose and then produces a novel image of the same person in the novel pose. The proposed network consists of two stages. In the first stage, a off-the-shelf human parser is used to segment the input image into parts. Given the part segmentation and the target pose, a pix2pix network is trained to synthesize target part segmentation masks or parsing. In the second stage, the source and target part masks are used to find affine and TPS transformations so that the appearance features of the input image are warped to align with the target pose to synthesize the final output. Results are reported on a fashion image dataset and a surveillance dataset where most of images have the stand-up poses. It also compares a number of recent methods and evaluates results using SSIM, Inception scores and AMT.  +It is an interesting idea to use part segmentation masks to align the input image with the target pose. In order to do that, this paper first trained a target mask synthesis network which could make it easy to synthesize the final image. In terms of using part segmentation for human image re-posing, this paper is closely related to [1]. But there are several differences. First, this paper directly synthesize the target segmentation in a supervised network while [1] learns the part segmentation in an unsupervised manner. Second, [1] uses affine transformation while this paper also uses TPS transformation. Third, this paper warps features while [1] warps pixels directly.  +Results on DeepFashion dataset are impressive. There are much less distortions then previous methods. Evaluations using SSIM, IS and AMT again a number of previous methods also agree with the visual results.  -As said above, this paper is closely related to [1]. It should discuss the differences clearly. It will be great if this paper can compare with [1] in experiments, which will significantly strengthen the contributions. TPS transformation is a novel component. I believe it is helpful for cloth warping. But unfortunately, there is no ablation study for this (with or without TPS).  -The deformable GANs by S. Siarohin et al. in CVPR2018 should be also discussed as it applies part affine transformations to feature maps.  -To make the paper self-contained, it is better to introduce the core algorithm of GEO briefly.  -Pix2pix[10] may not be a good baseline as it is not designed for re-posing. Instead, the analogy-making network used in [Ruben Villegas et al. ICML2017] could serve a better baseline.  -It seems like the input target pose has to have the same skeleton structure as the input person (in terms bone length and proportions). However, obtaining such input pose itself is non-trivial. Directly manipulating the input pose may result in 3D impossible poses. Extracting the pose from another person image will expose a retargeting problem. This could be a limitation that other papers also have. It will be good to discuss it in the paper.  -Some sentences are fragmented. “Applied disentangle and restructure”, “large arrange among”  -It is not clear to me why the proposed method is termed as "soft-gated". This term is only referred in a headline in the main algorithm section, but never formally discussed. -Both DeepFashion and Market-1501 have constrained poses. It will be interesting to test on other datasets with more pose variations such as PennAction.