Summary ======================= This paper presents a stacked semantics-guided attention (S2GA) model for improved zero-shot learning. The main idea of this paper is that important regions should contribute more to the prediction.   To this end, the authors design an attention method to distribute different weights for different regions according to their relevance with class semantic features and integrate both the global visual features and the weighted region features into more semantics-relevant features to represent images.   Strengths ======================= + The method is well motivated. The presentation of the method is clear. + Using stacked attention for zero-shot learning seems to be a new idea (I do not check exhaustively). Although stacked attention network has been presented in [26]. The authors explain the differences in Sec 2.2. + Consistent improvement is shown on fine-grained image datasets such as CUB and NABird datasets. + The ablation study in Table 3 convincingly shows the effect of the proposed attention mechanism.  Weaknesses ======================= 1) The method is reasonable and effective for the targeted task. However, it is not a ground-breaking work as adding attention mechanism to different visual tasks becomes quite common these days.   2) It is not clear if the method would perform equally well on other ZSL datasets (e.g., Animal with Attribute dataset).  3) The benefit of stacking attention is not entirely clear, although positive performance is shown when more attention layers are used. It would be good to discuss what kind of attention has been learned in the two attention stages. Perhaps more heatmap images like Fig 1 can be presented.  4) The following one-shot-learning paper that uses attention is relevant. It also uses attention guided by semantics. In addition, they have multiple attention maps without stacking. A discussion is needed on the differences and why stacking is essential.   Peng Wang et al., Multi-attention Network for One Shot Learning, CVPR 2017.