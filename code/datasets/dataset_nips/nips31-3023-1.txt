The paper studies the interaction between an automated model and a decision-maker. The authors refer to this new model of learning as learning-to-defer and provide connections between this model, rejection learning and mixture of experts model of learning. The paper proposes approaches to solve learning-to-defer and experimentally evaluate these approaches on fairness-sensitive datasets.  Questions: (1) Is there any particular reason for choosing neural networks as the binary classifier versus other methods? The COMPAS dataset has been studied for fairness-accuracy trade-offs in many other previous works with different learning methods. (2) What are the reasons behind picking the specific features as DM's extra information in the experiments? How do these features correlate with the label i.e. how informative these extra informations are? (3) Would the DM-fair (the binary model with DM's classifier that optimizes for fairness) trade-off curve dominate all the other curves in Figures 3.1/3.2? (4) Why is the deferral curve for the rejecting learning different than the deferral curve for learning-to-defer? In particular while the deferral curve for learning-to-defer is intuitive (there is an optimal deferring rate that results in the best accuracy and the accuracy degrades as we move further from that rate in each direction) the deferral curve for rejecting learning is surprisingly monotone!  Strengths: (1) The paper is well-written and it is easy to follow/verify the main ideas in the first 4 sections of the paper (see my questions about the experimental section above and also regarding weaknesses below). (2) The generalization of rejection learning and connection to the literature on mixture of experts is neat and can be of independent interest.  (3) The experimental evidence on how learning to defer adapts to DM's weakest subgroup is interesting and should be emphasized.  Weaknesses: (1) The contributions of the paper would be more significant (or easier to quantify) if the authors compare their approach with many other related work that study the trade-off between fairness and accuracy with respect to equality of odds (e.g. Hardt et al 2016, Zafar et al 2017). Without such a comparison, it's hard to assess the significance of this paper in comparison to the growing literature on fairness in machine learning (see e.g. my question (4) above).   Typos: (1) cam --> can in line 10. (2) extra space before the parenthesis in line 235. -------------------------------------------------------------- I read the other reviews and the rebuttal. The authors have convinced me that these direct comparisons might be difficult given the nature of their model.  I like this paper as it explores novel and natural ideas. I think the paper is still only marginally above the acceptance threshold in its current form.  I really hope that the authors clarify the presentation especially in the  experimental section if the paper gets accepted.