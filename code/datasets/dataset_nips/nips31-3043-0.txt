This paper considers the recently introduced problem of generalized uniformity testing where the goal is to test if a distribution is uniform on a support of unknown size or is it \epsilon-far in total variation distance from all uniform distributions.  The main result of the paper is a complete characterization of sample complexity of this problem. It is shown that this sample complexity is   \Theta( 1/(||p||_3 \epsilon^{4/3}) +1/(||p||_2\epsilon^{2}) ),  when the unknown distribution is p. Note that when p is uniform on n, this sample complexity becomes   \Theta( n^{2/3}/\epsilon^{4/3}) +n^{1/2}/\epsilon^{2})),  which exceeds \sqrt{n}/\epsilon^{2} (the sample complexity of the problem when the support of the distribution is known to be n) if n^{1/4}>1/\epsilon.   The algorithm achieving this bound, first uses estimates for ||p||_2 and ||p||_3 to ensure that they satisfy ||p||_2^4 = ||p||_3^3 (which must be the case if the distribution p is uniform) and define n= 1/||p||_2^2. Then, it proceeds to accomplish uniformity testing assuming that the support is n. When p is indeed uniform, it seems that any standard uniformity test for support-size n can be used and its analysis will go through. However, the technical difficulty arises from the alternative where we might be off in our estimate of support. The main contribution of this paper is to identify appropriate statistic that is robust to this uncertainty.  Specifically, the paper presents a different algorithm for the small \epsilon (n^{1/4}<1/\epsilon) and large \epsilon (n^{1/4}>1/\epsilon) regimes. For large epsilon, it evaluates ||p||_3^3-||p||_2^4 and compares it with \epsilon^2/n^2. An interesting component of analysis of this case shows how to control the variance, which depends on  ||p||_4, ||p||_5. Note that it is not possible to estimate these quantities with the available sample budget. Yet, the proof shows that we can ensure the desired bound on the quantities within our sample budget; an extra check is included in the algorithm to ensure from estimates of  ||p||_4, ||p||_5 that the variance is small as desired.  For small epsilon, we have the usual sample budget of O(n^{1/2}/\epsilon^2). But it is not clear if the usual collision based test can be used here since we don’t have a handle on its variance when p is not uniform. Instead, the authors propose a different test which first takes a sample of length n and ensure that all symbols appear at least log n times. Note that in this regime we can draw n samples since n<n^{1/2}/\epsilon^2. Then, it draws n^{1/2}/\epsilon^2 additional samples and checks if at least half of them are in the previous sample. This estimator is easy to analyze conceptually, but a technical calculation is needed to handle the variance due to the initial random sample.  Overall, the paper is very well-written and the authors have managed to capture all the key ideas in 10 pages. In fact, one might conclude mistakenly that the proofs are not so difficult. The key innovation in this paper is clean division into cases and identification of tests for each of this case. To the best of my knowledge, these proposed tests are new, which is difficult to design in a problem as well-studied as this one.   In terms of the technical correctness, I verified all the proofs except the lower bound proof (which is interesting as well). The estimates for moments are all based on prior work AOST15, and so the results till Claim 2.4 seem easy. I find claim 2.8 very interesting and feel that it maybe useful elsewhere, although the proof is elementary. This applies to all the results, if you see the statements of the technical form, you can prove it. But as mentioned earlier, the authors should be given credit for such a presentation.   In summary, it’s a very interesting paper which completely settles the recently introduced generalized uniformity testing problem. But I somehow feel that it is better fit for COLT than NIPS (since the distribution testing problem considered maybe of limited interest in ML).