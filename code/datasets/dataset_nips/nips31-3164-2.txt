The paper proposed a new learning rate adaptation method. It approximates the currently lowest achievable loss, and derive the stepsize that achieve the loss under a linear approximation to the loss function.  In general, the empirical results look great. Fantastic results are achieved across multiple benchmarks ranging from a very badly conditioned toy task to modern neural networks training. More importantly, almost no tuning is needed across these benchmarks. It is very exciting to see such method come out. However, the paper also has a major weakness. The adaptation rule proposed is exactly the same to Polyak's step length, with a slight change that the update direction in the original Polyak's step length is now changed from gradient direction to a general update direction. See a description of this in the section 4 of the course note: https://web.stanford.edu/class/ee364b/lectures/subgrad_method_notes.pdf. I think the paper should mention this fact and humbly admit it. Instead of rebranding this as a new algorithm, just admitting that this work revisits Polayk's update rule. That being said, it does not degrade the contribution the paper made to demonstrate the effectiveness of this algorithm, with extra design of how to estimate the minimal loss. Another comment I want to make is that although the results look fantastic, there is little discussion in what aspect the method can help improve. It will be great to see some discussion of understanding the adaptation method, at least in some toy task domain, by probing into the properties of the adaptive rule in some way.  Lastly, I do want to see some wall clock time comparisons between your method and the baseline. Such standard comparisons should be done for a optimization method paper.