Main idea: This paper investigates the problem of multi-task learning using the multi-objective optimization.  The objective is a vector-valued loss that is also applicable to use KKT condition to solve. The authors propose to approximate this constraint convex problem by introducing a shared representation function.   Strengths:  •    The writing is straightforward to follow and the motivation, as well as the related work, are clear. •    The geometry visualizations regarding the optimization objective of two-task learning are helpful for the understanding of the general audience.  •    The notations and formulations are neat and corresponding explanations are proper. •    The experiment shows several promising results and the experimental settings are clear and the results are convincing.  Weakness: •    The proposed framework is the incremental work that ensembles the multi-objective learning and constrained convex optimization and fit it into the multi-task learning scenario. The novelty only comes from the problem approximation which only uses very limited space to elaborate the contributions. •    Why the multiple tasks share the same set of examples as the notations state in section 3.1. The different learning tasks could have their own sets of examples and the number of examples could be also very different. Wouldn’t it be the general learning settings of multi-task learning? •    How good is the approximation that only has one backward pass in terms of the theoretical analysis? It would be a strong plus if you prove its effectiveness and efficiency in theory. •    The experiments look solid and but lack the wide range of comprehensive comparison. Several import baselines are missing. Please mention and compare with the important methods implemented in MALSAR [1] to claim the effectiveness of the proposed framework.  Quality: Overall, the writing quality is good, the main idea is clearly presented. Clarity: The notations are well-organized and easy to interpret. Originality: It is an incremental work with limited novelty. Significance: Theoretical proofs are missing, experiments should add more powerful baselines. [1]. J. Zhou. MALSAR: Multi-task learning via structural regularization. 