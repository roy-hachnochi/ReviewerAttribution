Self-Handicapping Network for Integral Object Attention  This paper proposes a new strategy to exploit image background information in attention networks. The use of background priors in semantic segmentation improves the estimation of attention maps. The strategy proposes to exploit a self-building ternary mask consisting of an attention, a background, and a potential zone. To maintain such mask, conditional ReLUs are proposed, which switch activations between positive and negative values depending on a mask status. This is shown to produce better contrasts between potential zones from background areas. Technically, the framework builds a 3-branched network that refines an initial attention map. Experiments are illustrated with a weakly-supervised semantic segmentation. Results indicate an improved segmentation (intersection-over-union) over recent state-of-the-art approaches, using the Pascal VOC dataset.   The paper reads well, provides an exhaustive literature review on weakly supervised learning, focusing on attention network. Practical value of paper has direct high potentials in computer vision applications. Experiments demonstrate superiority of approach with respect to recent state-of-the-art. No obvious flaws in manuscript.   Possibly on the negative side, performance is higher but arguably on the same range of competitive approaches, perhaps showing a significance test on the segmentation results could give a stronger argument. If correct, "self-handicapping" means here "self-erasing". This latter terminology may perhaps be better related with the current literature on adversarial erasing methods? (I am aware of "erasing" networks, but not on any "handicapped" networks)  The authors' feedback proposes to add a figure with best and worst visual results - taking half a page - is a 9th page allowed? if not, the rebuttal loose its value - Furthermore, as mentioned in the review, results are in the same range as competing methods - authors missed addressing this question, on whether the proposed results consistently outperform other method (statistical significance of their results) - they only provides average accuracies - unless this was misunderstood from my side?