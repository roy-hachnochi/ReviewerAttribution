This paper tackles the problem of scene graph estimation, introducing a relational embedding module to process object features and explicitly compare all pairs of objects to improve relationship prediction. Furthermore, the authors show that introduction of features that capture global context and geometric relations further boosts performance.  Strengths: - Each contributed component is well motivated and brings something independent to the table. I think the design of the relational embedding module is pretty reasonable. It directly compares all pairs of object features and then residually updates each of their representations. Further including global image features and explicit spatial features results in a well-rounded feature pipeline for scene graph estimation. - The ablations in Table 2 are appropriate, and the results on Visual Genome are strong   Weaknesses: - L107 claims that the relational embedding module significantly improves object classification, but we never see any results to back up this claim. It would strengthen the case of the paper to report the improvement on object classification directly in addition to the overall scene graph results. - There are a number of design decisions that feel a bit arbitrary. Obviously it is not possible to exhaustively go through and perform an ablation for every single little detail, but some choices seem like they could have used further discussion. For example, in 3.3.1 why is the relational embedding module used twice on the object features? How important is the choice of the hyperparameter r? Why do an argmax over O_4 and convert it to a one-hot representation, what about using it as is and preserving the distribution as is done with l_i (L118)? - There is a lot going on in Figure 1, and to tell the truth, before reading the paper I couldnâ€™t really make much sense of it. Even after reading the paper it is a bit difficult to parse. Rather than fitting everything into one big figure, it might make more sense to break visualizations down into separate stages.  Overall assessment: While I would not say the contributions are necessarily big steps away from existing methods, the overall pipeline is well thought out and laid out clearly enough for the reader. Experiments justify the inclusion of the various proposed components, and final performance is better than the current state of the art. As such, I am leaning towards acceptance.  Additional questions/comments:  - In the relational embedding eqs, why distinguish between multiplying by a parameter matrix and passing through a fully-connected layer? Does a bias or lack thereof make a difference? - A figure illustrating the sequence of operations that make up the relational embedding module (eqs 1,2,3 and then again in 4,5,6) could be helpful since this is a key operation repeated several times. - Some of the tables/figures are far from the corresponding text (the ablation results for example) - How many object proposals are usually considered by the relational embedding module - what is a typical N?  Update: The authors provide a number of good ablations and clarifications in their rebuttal, strengthening my recommendation for acceptance. I will mention that I do not totally agree with L34 of the rebuttal. It is difficult to disentangle what contributes to a final number, and directly reporting object classification performance would still be informative and necessary to back up the claim that object classification is improved with the REM.