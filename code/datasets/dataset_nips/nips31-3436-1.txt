Post rebuttal: thank you for your answers! I would encourage authors to consider experiments with matrix completion with time stamps in the camera ready version and compare to baselines such as Factorization Machines or Neural Networks where time information is ignored. In my opinion this could help to draw the attention of researchers outside of the Bayesian community and increase the significance of the work.  This paper considers the problem of tensor factorization across time. Proposed model combines Hawkes process to accommodate temporal dependencies, with base rate dependent on a function of latent factors equipped with Gaussian Process prior. Gaussian Process has been previously considered in the tensor factorization domain and showed some advantages over more classical multilinear functions. However the addition of Hawkes process while maintaining advantages of GP appear novel to me and more elegant than previous discrete time approaches. Authors take Variational Inference pass, but deriving ELBO is not trivial for the proposed model and as a workaround authors decompose Hawkes process into multiple Poisson processes and introduce additional categorical ("cause") latent variable to arrive at manageable ELBO.  I think this is a good paper addressing a fairly sophisticated problem of stochastic tensor decomposition with a new model and some interesting inference decisions.  Combination of Hawkes process and GP was new to me and interesting to see. Experimental baselines appear strong and experiments demonstrate the advantage of modeling time component and using GP. Overall paper is written well.  On the downside, method is quite slow, but nonetheless experimental results are shown on several relatively big datasets. The other downside is the practical usefulness of the method. Clustering analysis does not appear particularly meaningful (looking at the Tables in the supplement, I can't really relate to the interpretation suggested in the paper), although perhaps the data is to blame (method seems to identify some structure in the toy simulation experiment). Have you tried matrix completion? For example, 100k MovieLens data (for predicting user-movie interactions instead of actual ratings)? I believe timestamp is often discarded, but maybe your model can perform well by taking it into account. It would be interesting to know if the method can compete with black box prediction approaches (i.e. neural networks or Factorization Machines). It is ok if not, since there are other merits, but it could make the story more complete and show limitations of the approach (overall, authors did not really discuss what are the limitations besides run-time).  Experiments show that GP + Hawkes process are better than GP or multilinear factorization with discrete time. What about using discrete time approach and GP instead of multilinear factorization. Is there any prior work that uses GP (for tensor decomposition) in temporal setting?  Typos in lines 55, 377.