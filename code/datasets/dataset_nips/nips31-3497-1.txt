Summary ======= This paper proposes a metric to evaluate generative models. It suggests to use a variational lower bound on the mutual information between the latent variables and the observed variables under the distribution of the model.   Good ==== The most interesting finding of this paper is that the proposed metric sits close to ln(training_set_size) nats for models with low FID on MNIST and FashionMNIST (although not for CelebA or CIFAR), which the authors suggest might be because the models memorized the training set. If the authors understood this result better and provided additional evidence that GANs are memorizing the training set, it might make for an interesting paper.   Bad === The proposed metric is in general not well defined for GANs mapping z to x via a deterministic function. The mutual information is expressed in terms of a differential entropy using densities, but those densities might not exist.  Even if it was properly defined, the mutual information is likely to diverge to infinity for GANs. I suspect that the estimated finite values are an artefact of the approximation error to the posterior p(z | x), and it is therefore not clear how to interpret these values.  The authors claim "any failure to converge for the approximate encoder to match the true distribution does not invalidate the bound, it simply makes the bound looser." Yet if the mutual information is infinite, the bound is not just loose but may be completely meaningless, which seems like a big problem that should be addressed in the paper.  The authors suggest that the proposed metric can be used as a measure of "complexity of the generative model". Yet simple linear models (PCA) would have infinite mutual information.  I would be inclined to change my score if the authors can provide an example of a deterministic differentiable functios g(z) where I(z, g(z)) isn't either 0 or infinity. Of course, adding a bit of noise would be one way to limit the mutual information, but then I'd argue we need to understand the dependence on the noise and a principled way of choosing the noise level before the metric becomes useful.  At a higher level, the authors seem to (incorrectly) assume that the goal of generative modeling is to generate visually pleasing images. Yet this is probably the least interesting application of generative models. If generating realistic images was the goal, a large database of images would do such a good job that it would be hard to justify any work on generative models. For more well-defined tasks, measuring generalization performance is usually not an issue (e.g., evaluating unsupervisedly learned representations in classification tasks), diminishing the value of the proposed metric.