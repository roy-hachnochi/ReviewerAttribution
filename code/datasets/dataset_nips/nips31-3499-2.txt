This paper introduces Prior networks which help distinguish uncertainty in posterior estimates due distributional uncertainty and data uncertainty. This is achieved by introducing an intermediate distribution to represent the distributional uncertainty. This probability distribution is parametrized and the parameters are estimated using a neural network. More specifically the paper discusses this parametrization using Dirichlet distribution and estimates the concentration parameters using the neural network. It uses a max-entropy inspired KL divergence criterion to train the network to distinguish in-domain and out-of-domain samples. The Dirichlet distribution corresponding to the in-network distribution is re-parametrized to simplify specification.  This is a very well written paper with a thorough survey of existing approaches, providing a valuable reading list. Further it provides a detailed introduction to the problem. The presentation is very clear and the authors clearly distinguish their contributions from previous work.  A major assumption in this class of works is that "out-of-distribution" samples are specified. However the definition of out-of-distribution is usually not very clear and can be application dependent. Further the OOD detection performance can significantly vary depending on what is considered OOD  e.g. in speech recognition applications out-of-language, out-of-vocabulary or unknown noise conditions can all be considered OOD depending on the application and as shown in [1] the OOD detection performance significantly varies according to this definition. It would be informative to see how the proposed method performs depending on this confusability between in-domain and out-of-domain detection compared to baseline methods.  Providing a more elaborate description of the training method in section 3.2 would be very informative.   Choosing a different colormap in figures 2{b,c,e,f} and providing a colorbar would be helpful.  "model uncertainty" is used with two different meanings in this paper and it can be confusing as to what it means without careful reading. This even happens in the abstract. I would recommend italicizing the noun to avoid confusion.  [1] Dan Hendrycks and Kevin Gimpel, “A Baseline for Detecting Misclassified and Out-of- Distribution Examples in Neural Networks,” http://arxiv.org/abs/1610.02136, 2016, arXiv:1610.02136.    