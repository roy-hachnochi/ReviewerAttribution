This paper introduces an unsupervised approach to modeling exchangeable data.  The proposed method learns an invertible mapping from a latent representation, distributed as correlated-but-exchangeable multivariate-t RVs, to an implicit data distribution that can be efficiently evaluated via recurrent neural networks.    I found the paper interesting and well-written.  Justification and evaluation of the method could, however, be much better.  In particular, the authors do not provide good motivation for their choice of a multivariate t-distribution beyond the standard properties that 1) the posterior variance is data-dependent 2) it is heavier tailed compared to normal.  The experiment in Sec. 4.3 provides some evidence that this choice is effective, but a qualitative comparison on a single instance is insufficient to draw any real conclusions.  I am not sure I follow the construction in Sec. 4.2.  Is a conditional model learned within each class? If not then I don't follow the model comparison approach to classification.  If this is true, then I don't know that much of the discussion about the limitation of generative models for this task (L:253-262) is really relevant or at least should be revised to reflect the reality that it isn't a fully generative model.  Please clarify.  The goal for the conditional image generation experiment in Sec. 4.1. seems to be a demonstration that samples from the posterior predictive distribution of BRUNO have higher variability when conditioned on more variable inputs.  While this seems like a reasonable property I am not convinced that an experiment dedicated to this is an effective use of space.  Moreover, the authors only present a single qualitative result in Fig. 2., from which it isn't clear that variance of Fig. 2. right is actually lower.  Why not report quantitative results by computing the empirical covariance over (more) samples from the model?  Also, if the authors could not reproduce results from [5] it would be entirely appropriate to state this and report comparison with the neural statistician using results they do have.    Some detailed comments below:  * Aliasing artifacts make Fig. 2 right appear as if there are a couple different input images.  Consider enlarging image or using a vector graphic.  * What are the learned degrees of freedom \nu in Sec. 4.3?  Are they small so that the prior p(z) is far from Gaussian?  How do these compare to learned DoFs for other experiments?  * It isn't directly shown that the assumed MVT covariance leads to exchangeability.  I assume this is straightforward from the Gaussian example and the continuous mixture representation of MVT?  