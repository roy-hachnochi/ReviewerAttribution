The authors present a method to make Importance Sampling SGD more robust. There are a few difficulties with the vanilla algorithm, and one of them is the instability of the importance weights. The authors proposed to address this by introducing a method that estimates the quantities involved.   The authors briefly refer to the earlier work by Alain et al (2016) in their introduction, but make no effort to describe any of that work which is similar to theirs. The authors present their “Oracle SGD” algorithm using the same kind of language as would be used to introduce a novel idea.  The whole paper takes great pains to devise a novel method that makes the Importance Sampling SGD more robust, but at the same time they casually claim that it’s quite reasonable to use the gradient norm of the last layer as approximation to the gradient norm over the whole model. This is stated entirely without reference, and I suspect that it is not even true as a general fact (while it might be true for certain models at a certain time of training on certain data). Otherwise, the “exploding gradient” problem would not be a thing. They could have at least provided a sanity check on their own data and model just to make sure that they weren’t completely wrong about this. This can be done with a batch size 1, at an increased cost for sure, but it doesn’t need to be done more than a few times. If it is indeed true, it does make it easier to apply their method to any model because it’s not so hard to compute the gradient norms on the final layers.  Figure 1 is especially nice and intuitive.  Figure 3 seems to suggest that epochs run faster, but I believe that they are comparing to evaluating importance samples on the whole training set. This is an interesting quantity, but it seems like it would be something that advocates of Importance Sampling SGD would not actually recommend simply due to the fact that it would scale badly with the size of the training set. It would be interesting to compare RAIS-SGD’s speed with other reasonable methods that, for example, run Importance Sampling SGD on only a fifth of the training set (corresponding to a 500% speed increase but possibly not an increase in training quality).