This paper proposes using the language models' log-likelihood score as a discriminator in order to train style transfer generation models. In particular, given a text x, the goal is to train an encoder and a decoder. The encoder extracts vectors z_x and v_x from x, representing the content and the style of x respectively. The decoder should be able to restore x from (z_x, v_x), but generate a stylistically different sentence from z_x and a different vector v_y. The paper proposes to judge the style difference by a language model through its log-likelihood score.  Despite the simple idea, the authors show that it works well on three style transfer tasks, and achieves comparable or better performances than the state-of-the-art adversarially trained models. The results look promising. I agree with the authors that using language model as the discriminator is a compelling approach because it avoids the adversarial training's instability problem.  It was mentioned in the paper that the language model discriminator has its own problems. One of them is that the language model always prefers short sentences. Thus additional length normalization and training hacks are necessary to make it work. The adversarially trained models don't seem to have this problem.   A bigger concern of mine is that the proposed style transfer method could lose the semantics of the sentence more easily than the method of Shen et al. If x is a sentence from corpus X and y' is a sentence from corpus Y whose style is transferred to X. Shen et al.'s method requires the distributions of x and y' to be indistinguishable. In this paper, there is a penalty if y' has the same distribution as y, but there is no penalty if y' has a completely different distribution from that of x. In the extreme case, the total loss can be very low if the decoder learns to restore all the original input by memorizing and copying them, but always generates random strings if the content is paired with a transferred style vector. This doesn't happen in the paper's reported experiments, but I am worried that for harder tasks, given the strong overfitting capability of neural networks, the network would find it easier to learn such a copy-or-random generator than learning the actually useful style transfer model.  Overall the paper is clearly written and has throughout experiments. Therefore I tend to accept the paper.