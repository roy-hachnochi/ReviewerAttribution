This paper is a theoretical look at domain adaptation / transfer learning problems through the lenses of similarity learning. The authors have extended an already established similarity learning theoretical framework to cases where the training and testing distributions differ. The authors rigorously prove the following in this paper:  - A (\epsilon,\gamma)-good similarity for a problem in a source domain is also is an (\epsilon + \epsilon', \gamma)-good similarity in a target domain, assuming the same landmark distribution on both the source and the target.  - They further extend this result in Theorem 2 when the landmark distributions are different in the source and target domains. In this case, the problem in the target domain becomes (\epsilon + \epsilon' + \epsilon'', \gamma) good.   Both \epsilon' and \epsilon'' are formally derived in the paper. The former is a product of the worst margin achieved on some instances and a distance between the source and target distributions. The latter is completely defined by the landmark distributions in the source and target.   The authors also provide bounds for the worst margin including another theoretical results (theorem 3) providing a tight upper bound for the true worst margin when estimated empirically.  I have found this work very interesting, quite rigorous but difficult to read. I felt that the authors were somehow under pressure to compress the content to fit under the 8 page limit. For instance, in Section 3.2.2, I recommend adding a bit more explanation in lines 162 to 165, explaining how the first difference in the equation in line 161 (or right below it; I think that numbering this equation might be a good idea) balls down to applying lemma 1 and imposes \epsilon' in theorem 2. \epsilon'' is derived from the last two terms in this equation on line 161. While things are all clear with the supplement, I think that putting pointers from the submission to the supplement will help the reader significantly. On line 170, I would refer back to \epsilon'' when discussing why it is a good thing to use the same landmark distributions in the source and target domains. In general, adding more intuition behind the precise mathematical construct will certainly help this paper.   The experimental section does illustrate the benefit of model adaptation. However, it would be good to have at least a second use case a bit more complex from the 2D Gaussian one that is proposed with different rotation angles as a way to control the similarities between the source and the target.       Beside these comments/suggestions, let me reiterate that I have found the work quite interesting and sound. 