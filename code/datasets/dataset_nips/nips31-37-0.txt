The authors prove theorems about the accuracy of asynchronous Gibbs sampling in graphical models with discrete variables that satisfy Dobrushin's condition. I am not familiar with this literature, so I'm taking the authors' description of the state of the literature as a given. The authors' results are as follows (let n be the number of variables in the graphical model, let t be the time index, and let tau be the maximum expected read delay in the asynchronous sampler): - Lemma 2. The asynchronous Gibbs sampler can be coupled to a synchronous Gibbs sampler with the same initial state such that the expected Hamming distance between them is bounded by O(tau*log(n)) uniformly in t. Lemma 3 gives an analogous bound for the dth moment of the Hamming distance. - Corollary 1. If a function f is K-Lipschitz with respect to the dth power of the Hamming distance, the bias of the asynchronous Gibbs sampler for the expectation of f is bounded by log^d(n) (plus a constant, times a constant, and for sufficiently large t). Previous results (De Sa et al., 2016) matched this bound for d=1. - Theorem 4. For an Ising model with no external field, still satisfying Dobrushin's condition, the expectation of a degree-d polynomial f under asynchronous Gibbs, say E(f(Y_t)), minus the expectation of the same polynomial under synchronous Gibbs, say E(f(X_t)), is bounded by O((n log n)^((d-1)/2)) (for sufficiently large t). Previous results (De Sa et al., 2016) implied O(n) for d=2.  The supplementary material contains the full paper with proofs (which I haven't checked carefully). The main paper, with the exception of the introduction and experiments, has been imperfectly excerpted from the full paper and does not flow well in some portions (for example, lines 220-224). I'd recommend rereading the main paper to ensure that it flows well.  In the experiments section, the authors run synchronous and asynchronous Gibbs to provide empirical support for Theorem 4. The authors plot the difference between the expectations of a bilinear function under synchronous and asynchronous Gibbs as a function of n; they overlay the curve sqrt(n) (predicted by Theorem 4) and proclaim it a match (see Figure 3). The dots are noisy and don't look particularly like sqrt(n) to me. Besides, the theoretical result is only an upper bound; there's no reason to think it should match.  line 143: It's a result about synchronous Gibbs, but you've written HOGWILD!-Gibbs and t_{mix-hog}; this should be changed.  To summarize, it seems this paper is providing somewhat improved bounds for the bias of asynchronous Gibbs under similar conditions as previous work. The presentation is reasonably clear, and the topic is timely.