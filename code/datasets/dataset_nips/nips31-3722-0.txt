The authors rebuttal was very helpful and could clarify many questions. Especially, the novel contribution of learning a model for treatment effects over time made as improving our ratings.   Treatment response forecasting always suffers from time-dependent confounders, making the exploration of causality very difficult. The standard approach to deal with this problem are Marginal Structural Models (MSM). However, these methods strongly rely on the accuracy of manual estimation steps. In this work, the authors present a new deep learning approach, embedding the concept of MSM into an LSTM framework. They could show that the deep learning approach outperformed the 5 alternative methods (including the state-of-the-art). The paper presents a very interesting approach to an important problem. It is based on profound theoretical knowledge about the specific problem and the network is designed with care. The extensive appendix is worth a comment, including theoretical background information, additional resources as well as details on the hyperparameter optimization.  However, the work is application-driven and the learning methods itself are not new. Additionally, the information on the network architecture is insufficient for reimplementing the method and partially incomplete. I would highly suggest to include a sketch of the whole workflow, including all separate neural networks. All in all, the paper presents a profound work good results that are important for the community of treatment outcome forecasting, but the contribution to the field of neural learning itself is small. I highly recommend a submission as a survey in the relevant research area. In the following we discuss conceptual misunderstandings or unclear formulations which could be improved.   On computing probabilities with neural networks:  In page 2, LSTM, computing probabilities and the keyword robust are used in lines 64- 67, in one sentence, which gives the impression that LSTMs can do that which is actually not the case. Even for binary random variables only point estimates can be sampled which have to collected and post processed to compute uncertainty estimates.  Also in page 4, the need to compute probabilities is discussed. For binary random variables, LSTM with a softmax output layer are used in the paper. The outlook on an extension using variational RNNs refers to a review paper that does not discuss rnns. Actually, computing prob. outputs in rnns is an active research area and I was surprised that the authors refer to existing solutions.   Minors: Notation: Using upperscripts for the patient number Y_t^[i] would simplify the notation. Also using capital letters for matrizes and bold lower case letters for vectors should improve the readability.   p. 4. line 130: are then used to p. 3 line 115-118: missing verb 