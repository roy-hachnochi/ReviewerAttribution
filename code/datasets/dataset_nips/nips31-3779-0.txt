The paper describes a process to generate (grid-aligned) boxes in spaces of arbitrary dimension. The authors show the process obeys many desirable/necessary properties in the construction of Bayesian nonparametric models.  In some regards, I would have fought for the paper to be accepted: I like how simply the model is described and motivated, and the experiments are wonderfully broad and thorough. But the paper makes serious errors on omitting necessary technical components that a paper such as this should have. For example, the model is briefly described in Sec. 3, but nowhere is a likelihood function (joint distribution over the model) provided! Neither are any descriptions of what the posterior distributions look like (or which ones we're interested in targeting), which leads me to my biggest criticism of the paper: The serious misjudgment of the authors to leave any details of inference out of the paper. I believe the only cases where inference details can be relegated to the supplementary material is when the algorithm used is a direct, unaltered application of an existing algorithm, and even then the paper should contain a high-level (technical) description. This is especially troubling for this paper since, as the authors themselves point out, this partitioning model is fundamentally different from those previously presented in the literature (this idea of bounding rather than cutting). Moreover, while reading the paper, I was very interested in the construction of the model, and in my head my main thought was "the most interesting part will be seeing how inference is performed." For example, sampling the start positions and lengths of each interval during the construction is beautifully simple, but when you have data in the grid, and given the position of one interval (on one axis), what does the updated distribution on the interval of a second axis look like? How would it be sampled? These are the most crucial (and meaningful) questions to ask when thinking about Bayesian approaches to inference. An even more sour taste is left in my mouth because the authors decided to instead keep Sec. 3.1--3.3 in the paper. Sure these are interesting results but it is unforgivable to have devoted so much to their description at the sacrifice of details of your inference procedure. I did read the details of inference in the supp (though I shouldn't have to) and it would have been far more useful to have that in the paper and even expanded, arduously.  This is a shame, your work has all the elements of being a great NIPS paper, and I would have fought for it. It really just comes down to what you chose to (and not to) write and how you've organized. I'll discuss with the AE.  More detailed comments:  p. 2, line 42: "budget" is never defined.  p. 2, line 69 "...restricted in discrete arrays.": I don't know what this means.  p. 3, line 94: I wouldn't say the ensembles of the trees are "easy-to-explain". Can you explain what a random forest learns?  p. 3, line 119: How do you sample P( l_k^{(d)} )?  p. 2 & 3: model description: Unless I missed it, I don't see what the "costs" are for. I am assuming that they somehow play a role in the likelihood and thus in the inference procedure...  Sec. 3.2 coverage probability: I'm confused... in what cases or types of construction would the coverage probability depend on the datapoint? IMO, it would be a very unnatural construction if it did.  Sec. 5 Experiments: This is great work. Very thorough and broad and beyond what I normally see in NIPS papers. I like the two demonstrative applications to relational modeling and regression trees. Some additional comments:  p. 6, Paragraph starting line 217: You really should put quick details of these datasets in the text. Such as size and some characterizing properties.  p. 8, paragraph starting line 259: This paragraph makes no sense to me. Read it a few times I still have no idea what it's saying.  p. 8, par starting line 267: What is \alpha?  Small complaint: I don't like the self-descriptions of your model of "parsimonious" or "comprehensive". For example, in the abstract and intro and demonstrably p. 8, line 286. Can't you just say "visually intuitive (given evidence such as in Fig. 5)" or something like that?  Updated review:  My original score of 3 was a strong (and accurate) statement, voicing my opinions about what was not included in the paper, making it incomplete and inappropriate for acceptance. After reading the authors' response, I believe they agree with my assessment and will rectify this in the final version of the paper. If that is indeed corrected, then the paper is a good submission, justifying a score of 7 (in my opinion), which I stated in my original review. I will check back in on the final version and raise an objection to the AE and editors if this is these promises are not kept.