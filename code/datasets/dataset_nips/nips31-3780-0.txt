This paper continues the study of collaboration in the learning and obtains improved same complexity bounds.   Background: The collaborative PAC model, introduced by Blum et al (NIPS’17), considers a setting where k players with different distributions D_is that are all consistent with some unknown function f^* want to (\epsilon, \delta)-learn a classifier for their own distribution. The question Blum et al. asks is what is the total “overhead” over the sample complexity of accomplishing one task, if the players can collaborate. As an example when players do not collaborate, the k tasks have to be performed individually leading to an overhead of O(k). Blum et al showed that in the personalized setting, where different players can use different classifiers, the overhead is O(log(k)) with k = O(d). They also consider minor extensions of their setting to the non-realizable setting where f^* has a small but non-zero error on the distributions.  Summary: This paper obtains an improved overhead for the centralized setting of Blum et al. Their main result shows that they can get an overhead of O(log(k)) in the centralized setting. More precisely, the sample complexity they obtain is: O(ln(k/\delta)/\epsilon * (d ln(1/\epsilon) + k + ln(1/\delta) )). Their second contribution is to extend these results to the non-realizable case. Showing that if the best function f* has error \leq OPT on all distributions then there is an algorithm that returns a single function that obtains (1 + \alpha)OPT + \epsilon on all distributions using a number of samples that also depends polynomially on \alpha. This result is specially interesting in the case of \alpha = O(1) and the centralized setting, since the overhead is now computed based on the agnostic sample complexity.  Overall, I think this is a nice paper. The problem and the setting it studies is a very natural problem. I think the extension to the non-realizable setting is also interesting.  The subject matter of this paper can be of interest to the broader community and can be related to other works including, federated and distributed learning, multi-task learning, and transfer learning.   One minor point is that in Algorithm R1 was discussed by Blum et al. and mentioned to have log^2(k) overhead (see last paragraph section 3 of the Blum et al.). So, the authors should mention this at some point. 