Summary ======= This paper describes an approach to automatically removing a class of objects from images. The approach consists of 2 networks, 1 trained to produce a mask, and 1 network trained to inpaint the masked regions. The mask network is trained to fool a classifier detecting the presence of certain objects in the image, and simultaneously to produce masks whose shape distribution matches that of a segmentation dataset (WGAN). The inpainting network is trained adversarially to fool a classifier detecting modified pixels (LS-GAN).  Good ==== – Combining a masking and an inpainting network to overcome noisy images is a neat idea – The empirical section is extensive, including ablation studies and human evaluations of masks – The approach seems to work well   Bad === – A more elegant solution might have been to also train the mask network to fool the real-fake network (LS-GAN). This would have naturally encouraged small masks and avoided the need to explicitly penalize large masks. It might have reduced the need for a shape prior as well. – Please provide more details on the human evaluation. How many human subjects? Were these naive observers or authors of the paper? – PSNR/SSIM aren't great metrics for evaluating inpainting results since even very good solutions can change drastically at the pixel level. An evaluation with human observers to evaluate inpainting results may have been a better way to spend that resource than to evaluate the mask model's removal performance.