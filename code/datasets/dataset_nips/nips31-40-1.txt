This is a very natural, but still technically involved extension of the conditional GAN principle the viability of which is supported by experimental evidence in the paper.  The author(s) suggest a system that is able to transform images based on textual inputs. One interesting, implicit aspect of this work is that it demonstrates language grounding in actual actions in a procedural manner. The main idea of the paper is based on an text-adaptive discriminator utilizing a simple but efficient attention mechanism. This allows for identifying various attributes of the sentence and generalize from simpler sentences to more complicated ones. This idea allows for utilizing unconditional GAN losses for the discriminator and generator. The results are evaluated quantitatively by human raters using mechanical turk.  This is a very impressive work with strong underlying ideas and impressive results and can be viewed as an important milestone in the application of generative architectures. 