The paper proposes a loss function to help increase the margin of neural networks, which improves generalization and robustness of the model, and empirically shows better performance on MNIST, CIFAR-10 and ImageNet. The paper is well written, and the experiments are sufficient. The model outperforms classical loss such as cross entropy loss, which shows the effect of their loss function. On the other hand, CW attack is not tested in the Adversarial Perturbation experiments, which is more difficult to defend. Similar idea has been implemented in the previous paper "Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation", which weaken the novelty of this paper.