Summary:  This paper shows that a large family of functions, defined as Separable Functions, can asymptotically approximate the discrete matching problem by varying the approximation controlling parameter.  They present Theorem 1 that The optimal objective p^* to problem (2) is equal to the optimal objective p_delta^* to problem (4), in which problem (2) is original graph matching problem in integer domain and problem (4) is the problem relaxed to continuous domain. They define Separable Function (SF), f_theta(x, y), that satisfies there properties mentioned in Definition 1 in Section 4.1, and theta in univariate SF h_theta is defined as controlling parameter. The SF has three fine properties for computation: 1) it shows similar behavior as a probabilistic distribution on two independent variables; 2) it eases gradient computing; 3) we can construct new approximation function via reweighted summation and multiplication of existing Separable Functions. They show that original problem (4) can be asymptotically approximated using SFs as theta -> 0. They analyze the properties of convexity/concavity under such approximations, as there is technique to convert non-convex/non-concave problems into convex/concave ones.  They describe two optimization strategies for generalized graph matching (GGM): Path Following Strategy and Multiplication Strategy. The first one starts by obtaining a local optimum from a relatively tractable problem , then we shrink the value of theta by a factor of two. For the second one, each step amounts to a multiplication x(t+1) = Ax(t) and the objective score over the solution path is non-decreasing, under the assumption that A is positive semi-definite. It is found the multiplicative method converges much faster and hence the overall run time is less compared with the path following method.  They perform experiments on two popular random graph matching datasets, CMU house sequence and Caltech-101/MSRC object matching, with comparison to Spectral Matching (SM), Integer Projected Fixed Point (IPFP), Graduated Assignment (GAGM), Reweighted Random Walk (RRWM), Soft-restricted Graduated Assignment (SRGA), Factorized Graph Matching (FGM), and Branching Path Following Matching (BPM). The experiment shows their GMM methods reach similar performance or outperform other state-of-the-art methods.   Strengths:  - This paper is technically sound with experiment results to support the effectiveness of their approach. - This paper provides novelty algorithms for GMM problems with strong theoretical analysis. - The theoretical analysis and experiments in this  paper is written well and clear.  Weaknesses:  - It may be better to provide asymptotic analysis of running time for both proposed GMM optimization algorithms.  Rebuttal Response:  After reading the rebuttal, the author addresses some comments on computation complexity, convergence criterion, parameter sensitivity, and others. I support accepting the paper, but I will not change my score. 