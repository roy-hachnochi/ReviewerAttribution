The authors propose a novel relaxation approach for the graph matching (GM) problem under a quadratic assignment problem formulation. They relax the assignment using a continuous formulation and then factorize it via a product of what they call "separable functions". These functions are parametrized by \theta with guarantees that in the limit of theta approaching 0 the solution to the original optimization problem is recovered. The authors the propose two optimization strategies one of which involves iteratively restarting from solutions found decreasing theta.  The main drawback of the work is a lack of defense for its merits: it is empirically shown that the approach compares well to state of the art (SOTA) alternatives, but it is not emphasized what are the characteristics that make the approach relevant: is it more efficient? the author hints at this in the caption of a figure where they report that SOTA is one order of magnitude slower; there should be more emphasis on the complexity aspects. Are there classes of graph matching problems that are difficult for some of the competitive approaches that become then better tractable by the proposed approach? The authors use as benchmarks random graphs where they show comparable performances to other SOTAs but do not indicate any advantage of the proposed approach. A sensitivity analysis w.r.t. the few parameters of the method is also lacking (how is the quality of the solution affected by changing theta, alpha and kappa?).  However, disregarding some minor issues with the level of the English language that is overall acceptable, the approach is of interest and worth being presented as it leaves interesting open questions on the best way to solve the new optimization formulation for the GM problem.    After rebuttal: The authors have addressed the computational complexity concern and have justified the merit in terms of how flexible the method is. I support accepting the paper, but would not change the score.