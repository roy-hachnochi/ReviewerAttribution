Summary: The authors consider the problem of optimizing the linear combination of multiple objective functions, where these objective functions are typically surrogate loss functions for machine learning tasks. In the problem setting, the decision maker explore-while-exploit the linear combination in a duel bandit setting, where in each time step the decision maker tests the two hypotheses generated from two linear combinations, and then the decision maker would receive the feedback on whether the first hypothesis is better or the second is better.  The main contributions of the paper is the proposal of online algorithms for the duel bandit problem, where the preference on two tested hypotheses is modeled by a binary logistic choice model. In order to avoid retraining the hypothesis for every different linear combination, the authors adapt the boosting algorithm, which focuses on optimizing the mixture of K different hypotheses, where each hypothesis stem from optimizing one surrogate function.   Major Comment: I find the paper quite interesting in terms of problem model and the analysis, and I am more inclined towards acceptance than rejection. The problem considered by the authors is interesting, since choosing the right mixture of surrogate loss functions is important for machine learning tasks in general. While such a problem of properly balancing loss functions has been considered in the literature, the differentiating feature of the authorsâ€™ problem model is the duel bandit feedback setting. I guess the authors should motivate more on such a setting, for example saying that the duel bandit feedback could be generated from a human agent who makes a choice on the prediction outcomes under two given hypotheses. Nevertheless, overall I still find the problem interesting and worth studying.  The part on solving the duel bandit model seems novel and important to me, though in fact I am not too familiar with the duel bandit literature. The part on boosting very much stems from existing results on boosting. While the boosting part serves as a nice complement to the duel bandit results, the former does not seem to be the main contribution of the paper. The numerical results suggest that the algorithmic framework developed by the authors indeed improves the performance when multiple surrogate loss functions are required to be balanced.   Minor Comments: Line 124: The authors should avoid using the notation \Delta_T in Equation 2, since it contradicts with the definition of \Delta_T in Lines 110, 115. Line 169: It would be useful to spell out what CAPO stands for.  