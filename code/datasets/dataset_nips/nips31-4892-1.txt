The paper present a variational approximation for CTBN structure learning where the variational approximation incorporates parents. I am familiar with both CTBNs and variational approximations but not the literature at the intersection; I have not checked the details of the derivations provided in the appendix.  The paper develops exposition on the star variational approximation, extending mean field approximation [5] by inclusion of parents U with an approximation to the ELBO. Lines 99-101 state this explicitly. I think this could be strengthened with argumentation about (1) the quality of the approximation or (2) contrasting the approach with the mean field approach.  Quality + The mathematical formulation is explicit with main results clearly described and annotated. - Some of the assumptions made are not well justified. For example, under what conditions can we assume the data likelihood of the observation model Y|X  factorizes? Practically is this all/most/few/none? The same line of questioning goes for the product of gammas for the variational structure score. - The statement "only molecular biological network with a ground truth" should be amended--the field of biochemistry has tomes of known molecular networks.  Clarity + the work is presented clearly  Originality + the work appears original and a useful extension to previous mean field approximations.  Significance + the experiments are conducted on simulated data with ground truth [amended] - no experiments using real data are conducted. **The term "synthetic" makes the analysis of the published real-world data sound like simulated data; I suggest removing it for an ML audience.** - the work is limited by assumptions and is tested on small networks (<20 nodes) despite statements of scalability.   [resolved] Should the RHS terms in eq 3 be flipped?   --- I have read the authors' response.  I remain at a 6: addressing the underlying motivations behind the comments and questions posed would lead me to higher score.