This paper considers the problem of "minimax robust hypothesis testing" where we want to decide between two composite hypotheses, each of which is a set of distributions. We want a test with low error (maximum of type I and type II) under the worst-case choice of a distribution from each hypothesis set. (The choice of distribution is unknown to the test.)  This paper specifically considers the case where we are given two empirical distributions Q_1, Q_2 (on R^n), and we define P_1, P_2 to be balls in the Wasserstein metric centered at Q_1, Q_2. The goal is then to construct a test to decide between the composite hypotheses P_1 and P_2 (given a single fresh sample).  The authors use a convex relaxation of the problem in order to give an efficiently-computable test and to prove that it is close to optimal among all possible tests. They also include experiments showing that their method works well on real data.  This paper improves upon prior work in a number of ways. Some prior work has considered variants of this problem, but does not give an efficient way to compute the robust detector (except in one dimension). Some further prior work (by which the current work is inspired) does give an efficient detector, but only for the case where the distributions are parametric with parameters belonging to certain convex sets. The current work, on the other hand, is non-parametric and data-driven, imposing no conditions on the distributions whatsoever.  I think this is a strong paper. It is well-written and contains a substantial and novel result, making fundamental progress on the question of robust hypothesis testing.  EDIT: I have read the other reviews and the author feedback. My opinion of the paper remains the same -- I vote to accept it.