The paper proposes an application of the popular variance reduction construction from the optimization community to stochastic EM (sEM). The authors provide local and global convergence discussions (the latter for strongly concave loglikelihoods); the experiments show some improvement over sEM in latent semantic analysis and LDA.  Quality ===== The work is of good quality. The algorithm and theoretical contributions are solid, especially the proof of theorem 2. The experimental section is very well described and should enable easy reproducibility.  Clarity ===== The writing quality is very good. The motivation and description of the techniques are easy to follow. Minor: - bug in the citation on line 96.  Originality ======== Moderate. The VR construction and local convergence proof are well known; the latter is essentially identical to existing treatments in the optimization literature. The proof of Theorem 2 has some novelty, though the strong convexity assumption makes it intuitively obvious.  Significance ========== Overall I think this paper provides a timely application of the VR methodology to stochastic EM. Though not particularly novel, the VR augmentation does exhibit significant improvement in the synthetic experiments and the NYTimes LDA results. There are consistent improvements over standard stochastic EM in the pLSA/LDA experiments, and the gains over the online EM algorithm are impressive.  Overall I think the paper provides a useful application of the variance reduction method; while there is no great theoretical novelty, the experimental results should be of interest to practitioners.