The paper proposes an approach for approximate inference in discrete graphical models that generalizes collapsed importance sampling. The apprach is online, in the sense that the choice of variables to sample depends on the values already sampled, instead of  being fixed. Moreover, the exact inference portion of the method is performed by knwoledge compilation so the approach is called collapsed compilation and allows approximate knowledge compilation. The method begins by multiplying factors obtaining a Sentential Decision Diagram. When the SDD becomes too large, a variable is deterministically chosen, a value for it is sampled from a proposal distribution that is the marginal of the variable in the current SDD and the SDD is conditioned on the sampled value. This is repeated until all factors have been taken into account. Collapsed compilation is extensively experimentally compared to Edge-Deletion Belief Propagation and IJGP-Samplesearch. The results show that it often performs better on various domains from UAI inference competition and probabilistic logic programming. The method is put correctly in the context of related work such as Lowd & Domingos (2010) and (Ermon et al., 2013; Chakraborty 325 et al., 2014).  The paper provides a very interesting new approach for mixing approximate and exact inference. The paper is overall clear but some information on the heuristics that is now in the supplementary material would be more useful in the main paper. In particular, Sections C.1-3 on compilation order, proposal distribution and variable selection provide important information on the method. You can make room for it in the paper by simplifying Section 2: Theorem 2 shows that the variables that are sampled can differ in different samples so that eq 2 in unbiased. You can simply state the theorem this way without the need to introduce the augmented factor graph whose usefulness is limited if the proof of the theorem is not presented together with it. Moreover, since you consider only deterministic strategies, the presentation may be simplified by discussing only those, without introducing stochastic variables selection policies, that can be put in the supplementary material.  The paper seems technically sound, the proofs in the appendix seem correct with a few minor glitches: 1) the proof of the theorems are limited to binary variables 2) in Algorithm 2, I believe the third return value should be WMC(SDD)/q, not q/WMC(SDD) 3) the first equation in A.2 is missing f(X) 4) def 2: given M samples 5) page 12: X_I is missing [m] in the equations  The paper provides an original approach for combining exact and approximate inference by sampling, integrating collapsed sampling with exact inference by knowledge compilation, using a clever proposal distribution that is close to the correct distribution yet easy to compute. The significance of the method is shown by the experiments, that demonstrate the effectiveness of the approach in comparison with the state of the art.  I have a question that I would like the authors to answer in the response: would it be useful to resuse the compiled factors across samples? It seems to me that it could significantly improve the efficiency.  After reading the other reviews and the authors' feedback, I think all questions put forward by the reviewers were adequately answered, so the paper for me should be accepted.