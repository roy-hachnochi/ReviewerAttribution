Overall this is an interesting, well written article that tackles multi-agent credit assignment in the context of complex multi-agent learning, where the reward structure is not decomposable amongst agents. They experiment in several settings, including taxi fleet optimization and multiagent patrolling.  Overall, I think this is a well written, well structured piece of research that presents some new contributions building on earlier work in the area, such as difference rewards, but now making these ideas applicable when there is a global reward that is no longer decomposable, integrated with an actor-critic MAL gradient approach. It is nice to see that these ideas can now be applied in real-world settings, and I appreciate the fact that the models are based on real-world data.   The authors propose two new algorithms (CCAC and MCAC) that help deal with credit assignment in a multi-agent RL setting that seem to outperform previous algorithms on benchmarks used in literature before. But then the domains used also have applicability in the real world - a police patrol domain and a taxi supply domain.   Rigorous mathematical proofs backing up the claims they make are provided in the supplementary material and the algorithmic construction seem to come out of sound theoretical ideas. 