This paper develops a system that explores new approaches to the problem of using active learning (or play) to learn the structure of an environment and how it can be influenced.  It compares four agents (two loss functions, and three "ablated" agents to test contributions of different features, e.g., an active learning policy versus a random one), looking at loss over time and arguing that one sees state changes that are analogous to developmental changes in human learners.  Despite the clarity of the prose, there was a lot in this paper that I found hard to follow, despite having looked through the supplementary information. That's due in part (but not wholly) to my limited expertise with deep learning. Perhaps most importantly, I don't know exactly how the different parts of the performance comparison (Table 1) worked, and whether the performance of the agents was actually good relative to other approaches, versus just better than the ablated alternatives.  I also felt that if the target audience includes cognitive scientists and developmental psychologists, there needs to be a stronger and more explicit connection between the ideas in the introduction and the design decisions on pages 4 and 5.  As for the technical details, I did not go through them in enough depth to comment one way or another.  I've read the author feedback, which provided some reassurance that the baselines are "serious" and I applaud the authors' decision to clarify and expand connections between the authors' work and empirical research and theories in developmental psychology.