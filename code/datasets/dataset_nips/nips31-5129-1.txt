SUMMARY: The authors address the robust regression problem over a Wasserstein ambiguity set, in line with several recent papers such as the cited papers [12, 15, 16] and also the recent paper “Certifying Some Distributional Robustness with Principled Adversarial Training“ (Sinha et al. 2018). In this study,  the authors focus on a restricted but important scenario: they consider the least-square regression problem and the ambiguity sets is made Gaussian measures in the Wasserstein ball of a nominal Gaussian measure. In particular, this important case allows them provides to devise a distributiuonally-robust Kalman Filter.  They show that the problem is convex and can be solved efficiently with a Frank-Wolf algorithm. The advantage of the method over non-robust Bayes estimation is demonstrated on synthetic data.  Quality: The paper is technically sound. Although the problem addresses an apparently simple case of Gaussian Wasserstein ambiguity set, the resulting optimization is non-trivial (non-linear convex SDP). The authors manage to derive an efficient Franck-Wolf algorithm together with convergences guarantees in in Theorem 3.3. The distributionally-robust Kalman filter is well-described and is a natural application of the proposed problem.   It would have been very nice to see some experiments on real data rather than only synthetic data.   Clarity: The paper is overall well-written, although the introduction is not really clear for a reader who is not expert in the field of robust regression.   I believe the paper would gain a lot by adding some simple visualizations illustrating the problem. For instance, it would be nice for instance to have some visualizations of nominal distribution P together with optimal \Psi and Q in some simple scenarios such as x and y being one-dimensional data. This may also let the reader understand intuitively better the difference in behavior between Wasserstein and tau-divergence ambiguity sets.  Originality and Significance: The paper addresses a particular case of the robust regression over Wasserstein ambiguity sets, when the ambiguity sets is restricted over Gaussian measures. As far as I know, this vanilla case has not been treated in the literature so far but I believe it is an important case to understand and tp be able to solve efficiently. The application to the distributionally-robust Kalman filter illustrates in particular the importance of this problem.  