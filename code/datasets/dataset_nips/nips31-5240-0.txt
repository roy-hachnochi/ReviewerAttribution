Summary This paper proposes a new method called, DeepPINK, for hypothesis testing on deep learning (DL) models. Specifically, knockoff filters are seamlessly incorporated into the DL framework. Superior power and FDR control are shown over existing methods for both synthetic and real data.   Quality The paper is technically sound with both theoretical and experimental support. It would be nice to see comparisons against some existing methods, such as DeepLIFT, without applying knockoff filtering, even if those methods provide no statistical guarantees.  Clarity The paper is clearly written and well organized. Great motivation is provided in the Introduction. The only part that is unclear from the text is whether building knockoffs requires seeing Y.  Originality The idea of knockoff filters is not new, but the DL architecture required to exploit this idea, as proposed in this paper, is new and shown to be critical.  Significance The problem of interpreting DL model is extremely difficult. DeepPINK is by far the best solution I have seen with statistical guarantees on the selected features. I expect this paper to inspire many other researchers.  After rebuttal The authors have addressed my remaining concerns, but I can't increase the score any higher since I already gave it a 10.