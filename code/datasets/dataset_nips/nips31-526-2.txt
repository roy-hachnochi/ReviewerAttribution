The paper describes a new algorithm called deep  BPR+ (Bayesian policy reuse).  It is an extension of the earlier BPR+ algorithm that uses deep neural network.  The algorithm maintains a distribution over returns for different policy-environment pairs.  In each episode, it uses this distribution to compute a posterior over the possible environments and to compute a best response (policy).  When facing a new environment, a new distribution over possible returns is computed as well as a new response policy.    The approach is interesting, but there is one aspect that I find questionable.  The paper proposes to compute a "rectified" belief over the possible environments.  This belief consists of the posterior based on the observed return (which makes sense) times another term that takes into account the history of state-action pairs.  This term is obtained by computing a KL-divergence.  Is there a justification for this KL divergence?  I can see the intuition, but this feels like a hack.  Wouldn't it be possible to use Bayes' theorem to compute a proper posterior  based on the history of state-action pairs?  I also find confusing the presentation in terms of multi-agent systems.  The paper uses the notion of opponents throughout, which suggests that there are strategic adversaries.  However, the paper acknowledges that they use the term opponent also for cooperative settings, which is confusing.  Perhaps even more confusing, the paper eventually confirms that the opponents have fixed policies that are changed once in a while at random.  Hence, the opponents are not strategic in any way.  This means that the paper does not really deal with multi-agent systems since the agents can simply be thought as environments in the sense of single agent problems.  When opponents change policies at random, it simply means that the dynamics of the environment change at random.  To avoid any misunderstanding, it would be better to simply write about environments whose dynamics may change instead of opponents or multi-agent systems that are non-stationary.    The approach is good overall.  This is incremental work that clearly improves and generalizes BPR+ with the use of deep neural networks.  The proposed architecture is reasonable, though not really novel.  The experiments demonstrate the effectiveness of the approach.  The paper is clearly written, but there are many typos.  I recommend to proofread the paper carefully and to apply a spell checker.