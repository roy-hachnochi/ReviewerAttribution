The paper investigated how backpropagation can be implemented in neural systems. The authors studied a local hierarchical circuit with detailed dendritic structure. They showed that the dendrites compute the prediction error to effectively realize BP. This is a very interesting work, agreeing with the predictive coding idea and the related experiment evidence. It proposes a strategy to implement BP much more biologically plausible than others in the literature. The proposed strategy contains two interesting points: 1) the neural circuit does not require separate phases for activity propagation, error encoding, and error propagation, all done at the same time; 2) synaptic learning is driven by local dendritic prediction errors.  Some comments: (1) In the analysis, according to equation (13), interneurons in every layer will get top-down somatic teacher signals from the corresponding pyramidal neurons, which is necessary to make the recursive formation of the predictive error signals propagation. However, in the regression and classification tasks, it seems only the output pyramidal neurons receive somatic teacher input and interneurons do not receive such a top-down nudging signal according to the parameter setting. Rightï¼ŸDose this make a difference for the final performance with and without the top-down nudging signals to interneurons?  (2) In the regression task, the top-down pyramidal-to-pyramidal weights are fixed; in the classification task, the top-down and interneuron-to-pyramidal weights were fixed. Are these setting crucial to successful training?  If so, does this mean that our brain needs some control mechanisms to close or open the synaptic plasticity windows and the learning order of different connection weights types, such as learning the weights between interneurons and pyramidal neurons first and the bottom-up weights followed?   I become more confident with the importance of this study, and decide to raise the score to 9. 