Update: after reading the authors' response, I have increased my overall score to "Top 50% of accepted NIPS papers".  This paper proposes a new loss function to deal with label noise, which overcomes the drawbacks of standard loss functions (non-robustness to label errors) as well as of existing robust loss functions (they lead to very slow training and a drop in accuracy). Moreover, the proposed family of loss functions contains the cross-entropy loss and the mean absolute error loss as particular (extreme) cases.   The paper is well written (although there are many missing determiners, such as "the" or "a") and the ideas are well presented, motivated, and justified. The experiments clearly illustrate the behavior of the proposed loss, confirming that it performs as expected.  Important questions remain about the usefulness and applicability of this type of robust loss function. Namely, in the presence of some dataset, how to infer its level of noise (if any) and how to adjust the parameters (q and k) of the loss? If the dataset is noisy (contains wrong labels), arguably cross-validation  will not be very informative. 