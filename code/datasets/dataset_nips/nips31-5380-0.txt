The paper develops methods for the label ranking problem through structured output learning, where the rankings are embedded to Hilbert spaces in such a way that the inner products of two rankings have direct correspondence to particular loss functions for rankings. With these embeddings, one can learn rankings efficiently through, e.g. vector-valued kernel ridge regression. The authors develop algorithms for the preimage problems arising from the use of the different embeddings. In particular, they propose a new Lehmer embedding that has a fast preimage algorithm as well as extendibility to partial rankings. The generalization performance and algorithmic complexity is further analyzed. In numerical experiments, the methods work well but the improvement over previous state-of-the-art is rather small in general.  Update: I think the author’s response addresses the criticism posed by the reviewer’s well, in particular I appreciate the progress made in the theoretical side, even if the experimental results are not earth-shattering.   