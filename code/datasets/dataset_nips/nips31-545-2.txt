This paper trains a parameterized regularizer for a deep net to encourage transfer among multiple domains.  The MTL architecture uses hard parameter sharing of a lower-level feature network coupled with task-specific networks in later layers; the regularizer affects the training of the task-specific networks.  Overall I found this idea to be simple yet compelling.  The authors do a nice job of developing the idea and the paper is, for the most part, clear.  The experimental results seem convincing.  I do have the following questions:  1.) The method is training the meta-regularizer in a batch fashion, but how dependent is the process on all of the tasks being available up front?  Is it possible to add tasks and still have the regularizer be effective?  (I suspect the answer depends a great deal on issue #2 below.)  Also note that this question does go outside of the scope of this paper, but would be good to think about for the future.  2.) The major question that is left open is how similar the domains must be in order for this method to work effectively.  I would imagine that the domains must be rather similar, but the paper does not examine this aspect, and so it remains a major unanswered question of the paper, and one that truly needs to be addressed in order for this to be a complete examination of this topic.  3.) Section 3.3 seems to imply that you first train all of the task networks, then the meta-regularizer, and then retrain the task networks with the final meta-regularizer.  But these steps could all be interleaved, with the meta-regularizer affecting the task networks, and vice versa.  Was this explored, or are you really just taking one step along the meta-regularizer - task nets optimization path?  Questions 2 and 3 are the major open issues with this work, while Q1 is much more mild and more forward-looking than a criticism.