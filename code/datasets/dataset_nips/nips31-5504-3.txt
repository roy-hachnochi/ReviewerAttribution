The authors proposed a new variational inference method -- a Stein variational Newton (SVN) method. It is based on Stein variational gradient decent (SVGD) method developed in [11], and brings two main contributions.   The first contribution is to apply a Newton iteration that exploits the second-order information of the probability distribution to push forward the samples. To avoid the challenge of solving a large coupled system arising from the Newton iteration, the authors present two approximations -- one dropping a cross term involving the current density function, the other using a ``mass lumping" method to decouple the system.   The second contribution is the design of the kernel (of the RKHS used in the method) by incorporating the averaged Hessian of the negative logarithm of the target density function. Compared to a Gaussian kernel with isotropic structure, this rescaled kernel carries the curvature information of the target distribution which prevents samples from collapsing in high dimensions.   These contributions largely accelerate the convergence of the samples to the target distribution, thus make SVN method computationally more efficient and tractable. The efficiency and tractability are demonstrated by several numerical examples with parameter dimension ranging from low (2) to high (100).   Overall, this new development brings important contribution to the family of variational inference methods; the numerical demonstration is very convincing; the paper is easy to read and well-written. I am confident of the clarity and correctness of the algorithmic development. I also run the code and obtain statistically the same results and conclusions. Therefore, I recommend to accept it after some minor revisions.   1. page 5, Algorithm 2: Changing the step size of the Newton iterations looks important for the fast convergence. A few more details on how the author changed the step size is helpful.   2. page 5, line 174, it is not clear under what technical conditions the g(d)-weighted norm is the square of the discretized L2 norm.   3. Can the author explain why the isotropic kernel takes less time compared to the Hessian kernel, as can be observed from the different number of iterations in Figure 1?   4. supplementary material, page 4, after line 48, should the ``y" be ``x"?  