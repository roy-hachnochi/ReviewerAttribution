ANN have been extremely simplified with respect to biological networks. This paper makes a good step toward testing more ideas from biology. It is a strong paper as is. I would love to see the authors extend the bio-inspired to the connectivity between layers. Not a set 3x3 convolution rather a wider and stochastic set of connections whose weights are then learned.    Thinking about this further it is not clear to me how your skip connection works. As one recurrent pair ping pong back and forth up to four times what is happening to the by pass? Does it wait for the recurrent layers to advance one step before it advances one step?   Regardless of the bypass details your network can be viewed as an ensemble of networks side by side where all receive the primary input and the recurrent processed data step from left to right across the networks. A question I have is why no funneling down of the bypass information is an exact copy of the input the best? 