Review: This paper studies the problem of understanding the limit points of Gradient Descent Ascent (GDA) and an optimistic version of the same (OGDA) for min-max optimization. There are two main results from the paper state that (under certain assumptions) a) The set of initial vectors from which GDA/OGDA converge to unstable fixed points are of Lebesgue measure zero b) The set of local min-max (saddle) points and the stable fixed points of GDA/OGDA satisfy the following (strict) inclusion:  Local min-max \subset GDA-stable \subset OGDA-stable.  A key technical contribution relates to the construction of the OGDA dynamical system and its analysis in order to understand the corresponding limit points.   1. While the paper makes an initial attempt at understanding basic first order methods and characterizing their "convergent" fixed points, as pointed out in the paper and also observed experimentally, there are several initial starting configurations for the OGD/OGDA dynamics fail to converge. In cases where they fail to converge, is it the case that the dynamics cycle through the unstable fixed points? While Corollary 2.3 and 3.3 shows that unstable points cannot be converged to, the paper should indeed make it clear if such cyclical/non-convergent behavior is still a possibility.   2. In several proofs in the appendix, the paper cites lemmas from other papers for completing the proof. In order to make the paper self-sufficient, I would recommend restating those lemmas in the appendix for the ease of the reader.   Overall, this seems to be a well written paper which provides the first characterization of limit points of basic first order methods and raises several interesting questions which are important in understanding the problem of general min-max optimization. 