Update: I have the read the authors' response. As the authors seem to insist on maintaining the current (and in my opinion misleading) framing of the results, I reduced my score by 1. Regarding my comment (1), *any iterative search method avoids its unstable points* - this is how unstable points are defined! Thus Theorems 2.2 and 3.3 are not "important global properties", but merely statements that definitions are self-consistent.  ---  The authors study the limiting behaviour of two first-order methods for zero-sum games, which they refer to as gradient descent/ascent (GDA) and optimistic gradient descent/ascent (OGDA). Assuming favorable function structure, the authors show that local min-max points (i.e. local saddles/Nash equilibria) are attractors for both GDA and OGDA, and that attractors for GDA are also attractors for OGDA. The authors also demonstrate the converses are false: they construct functions with attractors for OGDA which are not attractors for GDA, and attractors for GDA which are not local min-max points. These functions also exhibit initializations for which GDA and OGDA do not converge at all. The authors also apply the stable manifold argument to show that the set of initializations of GDA and OGDA that converge to non-attractors has measure zero.  My opinion regarding this paper is divided. On the one hand, the paper reveals the fact that, even under very favorable conditions, GDA and OGDA can converge to points that are not even local solution to the game they are applied on - this is an important observation and cause for concern considering the recent popularity of adversarial training. On the other hand, the paper buries the said important observation behind unenlightening  formalisms (see more details below). In reading the paper I got the feeling that the authors set out to show theoretically that GDA/OGDA are "good" in some sense, and are trying to downplay the fact that their results indicate the opposite. Moreover, the writing in the paper is unpolished, with many typos and somewhat disorganized presentation.  Weighting the pros and cons above, I lean slightly towards accepting the paper, hoping the authors will improve the presentation in the final version of the paper, and frontload the more novel part of their results. Below are more detailed comments.  1) I do not see the point of the "stable manifold" results in this paper (i.e. Theorems 2.2 and 3.3). In smooth minimization problems, such results are important since they rigorously show convergence to the natural object of interest (local minima). Here, your results rule out convergence to the natural object of interest (local min-max points), and the stable manifold arguments reduce to near-tautologies, as your definition of "(O)GDA-unstable critical point" is tailored to make the stable manifold analysis go through.  2) The results of section 2 are essentially folklore and to some extent overlap with published literature - cf. "Characterization and Computation of Local Nash Equilibria in Continuous Games" by Ratliff et al. (2013).   3) As GANs appear to be the main motivators of this papers, you need to comment on all the assumptions you make that do not hold for GANs. Namely, noiseless gradients, invertible Hessian, and globally Lipschitz gradient are completely unrealistic. I am not sure how realistic Assumption 1.8 is - you should comment on the matter.  4) There seems to be some confusion regarding nomenclature of OGDA. To the best of my understanding this algorithm was first proposed recently Daskalakis et al., who referred to it as "optimistic mirror descent" (OMD). However, a different algorithm called "optimistic mirror descent" was proposed by Rakhlin and Sridharan in 2013. Since the "new" OMD is not a special case of the old one and does not enjoy its theoretical guarantees, I find its name quite inappropriate, and I am happy you do not adopt it. However, when reviewing the literature you should mention past names for the method, and explain why you choose to use a different name.