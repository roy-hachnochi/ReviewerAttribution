The paper presents an image patch sampling protocol for effectively training the Faster-RCNN object detection model. The key idea is to choose the positive image regions adaptively, based on the positions of the ground truth object boxes, and employ a region proposal network to effectively mine hard negative examples. This leads to fixed-size training batches, that include object instances that originally have different resolutions. The main benefit of this adaptive approach is that the relatively small size of the training batches allows faster training (including the batch norm parameters) due to the smaller GPU memory requirements compared to using the standard Faster-RCNN large-image training protocol. The paper reports convincing experimental results, the main point being that the proposed approach allows successful training of Faster-RCNN models in shorter time and with more moderate GPU memory requirements.