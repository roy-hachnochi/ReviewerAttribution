After the author response: I'm upvoting the paper. Looking forward to seeing experiment extensions in the future.  Summary: The paper proposes a "global anchor method" for detecting corpus-level language shifts as an alternative to the more common "alignment method", both leveraging distributed word representations. A proof is provided for the theoretical equivalence of the two methods, but the advantages of the former are highlighted as it allows to straightforwardly compare word embeddings of different dimensionality, along with some downstream advantages in uncovering the finer details of language shift.  In my view, this is a very nice, albeit not well-rounded contribution, where the method exposition gets slightly more prominence than the experiments.  Still, I vote accept: it is a strong, important contribution to the body of work in uncovering language shift and evolution.  Strengths: - Very clear exposition, especially the motivation and the method equivalence proof. - The method is clean and simple, yet expressive. - The experiments are for the most part convincing.  Weaknesses: - With limited space, the paper leaves quite some to wish for in terms of demonstrating the method application in actually uncovering (sets of interesting examples of) linguistic shift. Related work does a much better job at that, and the appendix of this draft does not contribute in this direction. A lot of space is dedicated to method equivalence, which is admirable, but it also shifts the weight of the contribution towards the first part of the writeup.  - Along similar lines, only Google Books and arXiv are used, while related work does more. Altogether this indicates a slightly unbalanced contribution, where the empirical work slightly suffers.  Questions: - Isn't the treatment of the "alignment method" slightly unfair with respect to dimensionality? If the corpora are available for building the embeddings, it seems a triviality to make the embeddings dimensions uniform.