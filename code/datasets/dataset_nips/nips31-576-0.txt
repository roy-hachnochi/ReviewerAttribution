The submission generalizes another algorithm for non-myopic active search from an ICML 2017 paper. The submission proves a theoretical guarantee on the number of targets found with a batch policy versus online. The generalization proposed in the paper is fairly straightforward, and the sequential simulation and greedy approximation strategies for dealing with batch are close to what is often used in Active Learning. Theoretical results are interesting and useful, and the experiments are convincing for the dataset and method proposed. The paper is quite clear, especially for the reader familiar with the topic.  Main concern: * The way I see it, the challenge with non-myopic setting is to choose next examples which would benefit the probabilistic model most (active learning) and at the same time will produce positive examples (search). This paper explores a certain approach to do that, but it is not clear it outperforms more naive and straightforward approaches, e.g. first performing Active Learning, and then search. This might be especially useful in the batch setting: by performing some sort of mix of examples in a batch: part of them go to AL, part to search. Having baselines like that (and method speed trade-offs) in experimental part would be more convincing, as well as having another dataset of a different nature. * Having more specific guidance on how to use theoretical guarantees in practice would be beneficial.  * Is (5) submodular? is there proof?  -- I have considered authors' comments, and they convinced me more in my score, as the authors performed more convincing experimentation and promised to add results to the paper.