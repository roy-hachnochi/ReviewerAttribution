Summary:  This paper studies a policy evaluation problem in distributed cooperative multi-agent learning setting. The authors proposed a double average scheme that converges to the optimal solution at a linear rate. The experiments results show the proposed decentralized algorithm can achieve nearly the same performance as the best centralized baseline (SAGA) and better than that of the other three centralized baselines.    Methodology: - As the authors mentioned, theorem 1 doesn’t explicitly specify the step size and convergence rate, which leads to relatively weak results from Theorem 1. I am curious how does different step size affect the convergence. Intuitively we cannot expect the algorithm converge properly if we choose the step size too large/small.  - Relation to the centralized algorithms. Is it possible that this algorithm connects to certain centralized algorithms when it is a complete graph?   Writing: -    This paper is very well-written. -    There are typos in Line 135, Line 413.      Experiments: The experiments were not sufficiently conducted and discussed.  -    Could the authors show more than two variants on \rho and compare the performance? What if the \rho becomes larger and how will this affect the performance of the proposed method? -    What’s the reason that the proposed algorithm can perform as good as a centralized algorithm when \rho = 0? Could the authors provide some explanations on this? -    Will the algorithm perform same as the SAGA even for different \rho when you have a complete graph? I am curious if the connectivity how the performance changes as the connectivity increases. 