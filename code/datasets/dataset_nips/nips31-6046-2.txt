Update after rebuttal: Score updated.   Summary:  The paper discusses the use of ML predictions to improve online algorithms. The idea is to ensure that the new algorithms are able to maximize the utility of the added knowledge, while degrading gracefully to match at least the performance of the counterpart without ML enhancement when predictions are badly made. The idea is simple, which is nice, but the paper contains some serious issues.   Strengths: Simplicity and clarity in terms of technical presentation.   Weaknesses: Inaccurate statements and ambiguous details that yearn clarification (see detailed comments below). The idea is also not original.  Detailed comments: The problem definition does not need to be limited to the two problems (ski rental and non-clairvoyant job scheduling). The authors could try to define a specific class of online algorithms that solve some specific type of problems, then use the above two problems as illustrations. The numerical evaluation is limited, as the two problem setups are a bit too simple. Due to the simplicity of the algorithms designed, more sophisticated evaluation with perhaps real-life data sets would make the paper stronger. Inadequate related works: The body of works focusing on expected values (or average case) and not worst case, e.g., decision theory and stochastic optimal control, is discussed very briefly at the end of page 2 and beginning of page 3. In this case, the uncertainty is modeled with probability and decisions are made based on whether expected values are maximized.  Statements that are not accurate: Page 1, line 30: ML typically assumes that the model does not change over time, so the statement that ML approaches are “naturally adaptive to evolving data characteristics” is not entirely true. Unclear and needs elaboration: “Online algorithms”: There are many kinds of online algorithms, so authors should be more specific about which type they mean upfront, in the abstract and introduction.   Unclear and needs elaboration: Page 1, line 31-32: Why? Intuitively if the online algo is aware of the performance of the predictor, and takes that into account, e.g., to rely more or less depending on the performance, the result will be better, no?  Page 4, paragraph 3, starting from line 133: What is ‘d’? Needs to introduce ‘d’ before use Page 4, paragraph 3, starting from line 133: Consistency is the competitive ratio in the case of perfect predictor, meaning y = x. Why do you need to consider cases when x < \lambda * b, when y >= b? Shouldn’t x also be >= b when y >=b? Section 3: Reminding what job completion time means in the context of non-clairvoyant job scheduling would make it easier for readers to understand the objective function. Page 6, line 213 “SPJF is monotonic”: This is wrong. Consider the case when n=2, and two instances (3, 7) and (4, 8). Due to bad prediction, in instance 1, SPJF could execute 2nd job first, and 1st job later, with total completion time = 7 + 10 = 17. In instance 2, suppose predictions are good, and SPJF execute the jobs in that order, yielding total completion time 4 + 12 = 16. In this case, the objective value of instance 1 is higher than that of instance 2, although instance 2 has higher execution time than instance 1. SPJF is therefore non-monotonic. 