Post-rebuttal: Thank you for performing additional experiments for the rebuttal. I am satisfied with your answers and so will maintain my score. Good job! ------------------------------- This paper proposes a method for post-processing decision trees for classification so that to improve their training loss. They key idea is the following: given a fixed decision tree from CART, nodes of the tree can be traversed bottom-up, level-by-level, where in each level, every node's decision function can be optimized separately. The node subproblems are standard classification problems, e.g. SVM, and can accommodate sparsity via regularization. This algorithmic trick is due to a straightforward yet useful separability condition stated and proved in Theorem 3.1. The implication of this result is that sparse oblique trees can be learned from a simple CART tree. Oblique trees are known to be hard to optimize, since each node represents a hyperplane rather than a simple split on a single feature. Experimentally, the authors show the merit of the proposed method, TAO, on the MNIST dataset, while the appendix includes additional results on other datasets. TAO is computationally efficient and capable of substantially improving the accuracy of a vanilla CART tree. When emphasizing sparsity, the nodes' hyperplanes become more interpretable.  Overall, I think this is a very good paper. The paper is generally well-written, the problem of improving a learned decision tree is well-posed, the methodology is simple and elegant, and the experimental results are convincing. I have some minor questions/suggestions below.  - Extensions: in line 32, you mention possibly extensions; can you discuss this point in more detail, e.g. non-binary trees, regression? - Overfitting: in appendix 2.2, you mention TAO overfitting and a remedy using cross-validation. Please do perform that experiment so that we can be confident that TAO generalizes well.  Minor comments: - Figure 1: in the bottom-right plot, the numbers for the 7 classifiers overlap, please use clearer markers. Also, the projection onto the boundaries of the plot can be misleading; maybe consider including the exact values in a table in the appendix, for all of those 7 classifiers. - Line 105: about the "exponential cost", while this is correct in theory in the worst-case, it is often not the case in practice. - Line 107: about the strict inequalities and the small constant, I don't believe this alters the feasible region if epsilon is chosen intelligently, as is done in [4].  Minor typos: - Line 183: if a constant -> is a constant