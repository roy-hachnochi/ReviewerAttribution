 This paper proposes a feature learning method using pose information based on GAN. The proposed method (FD-GAN) requires target pose maps and its corresponding real images only in the training stage. The base model of FD-GAN is a Siamese structure with identity verification and several loss functions. The identity discriminator loss aims to distinguish real vs. fake images of the same person. The pose discriminator aims to distinguish whether the generated image matches the given pose by patchGAN[35] structure. The reconstruction loss aims to minimize the difference between the generated image and real images if the corresponding ground image exists. The same pose loss aims to make the appearance of a same person’s generated images in a given pose to be similar. After the learning pose-unrelated person features with pose guidance, the test stage requires no auxiliary pose information.   Strengths:   + The proposed method is a bit incremental but seems to be novel. The DR-GAN[20] seems to be the closest work to obtaining a pose insensitive feature using distillation GAN. Compared with DR-GAN, FD-GAN uses pose maps and Siamese architecture. Recently, several works proposed GAN-based human image generation in the new poses, e.g. [18][19]. This works applied such human image generation to feature distillation for person re-identification in the first time.  + The proposed method requires no pose estimation in the test stage. Some recent methods use pose estimation in an inference of person re-identification to handle pose variations. In contrast, the proposed method requires the pose estimation only when the training stage of the features. It will be practical for real applications since it does not increase computation costs. + Person re-identification results are better than state-of-the-art methods.  + The example that shows the generated person images show the better quality than existing specific person-generation methods [18][19].   Weaknesses:  I have some questions on the experiments. - Missing baseline: Performances when removing L_id, L_pd, L_r and performances when only removing one of the not share E, L_sp, L_v are not evaluated.  - How the experimental comparison with DR-GAN was done is not clear enough since DR-GAN does not use the pose map for input data.  - The proposed method does not require the pose estimation in the inference, so test image does not have pose maps. It is not clear if the visual analysis on Sec.4.4 is the result on training images or test images.  - Why the generated images of Figure 4 (a) shows only one of the [18],[19] for each input image? - Why the [18][19] fails and the proposed method succeed?   Several parts of this paper are hard to understand. -The names “Identity discriminator” and “pose discriminator” are confusing. When reading Fig.2, it looks like these losses are to distinguish different identities and poses. However, Eq.(2) seems to be the loss to distinguish real vs. fake images (of the same person), not to distinguish between different identities. Similarly, the “pose discriminator” is not to distinguish between different poses. - Line29: What is LOSO regularization?   - I suggest replacing some arXiv papers with actual published works.  Response to Rebuttal:  The rebuttal addressed my concerns about the experiments. However, the additional ablation study was only on Market-1501 dataset, and DukeMTMC-reID dataset should be included in the final version. Also, the explanation of identity/pose discriminators should be carefully revised according to the response.   