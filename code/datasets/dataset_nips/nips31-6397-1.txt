The authors present a  framework for image anomaly detection. This method seems to advance the state-of-art by learning a scoring function ns_(x) from which a classifier can be constructed with an anomaly threshold. They also did experiments to demonstrate the idea about causes of the effectiveness.   The authors has verified the performance of their method on sufficient and diverse databases , but the approaches which they compare with are not very new to me, it may be more convincing if the experiments can be conducted by comparing with the latest methods, e.g.,  #1 Hendrycks, Dan, and Kevin Gimpel. "A baseline for detecting misclassified and out-of-distribution examples in neural networks." International Conference on Learning Representations (ICLR), 2017. #2 Liang, Shiyu, Yixuan Li, and R. Srikant. "Enhancing the reliability of out-of-distribution image detection in neural networks." International Conference on Learning Representations (ICLR), 2018.  The authors also analyze the reason why their method are not outstanding on the same datasets, but the method DAGMM they compare with is unsupervised while their method in this paper seems supervised to me. In this sense, this comparison may not be very appropriate to me, or it should be further clarified at least.   The rebuttal seems to have addressed my major concerns in the experiments.