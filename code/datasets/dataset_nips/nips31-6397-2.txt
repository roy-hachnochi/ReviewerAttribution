This work focuses on detecting anomalies in images by identifying  out-of-distribution images. Their approach is to train a multiclass  model to classify different geometric transformations of training images. They claim that such a model can generate feature representation that  is useful for detecting novelties.   Given a set of images, they apply a set of geometric transformations  on each of these images. Next, a model is created to classify the transformed  images based on classification. During testing, each of the transformation is  applied to the test image and passed through the trained model to produce a softmax output.  The score of the input image is the mean softmax output of all the transformations. They compare the performance of their approach against a variety of baselines on different  datsets and show that their method can work better.   It seemed a bit confusing when the work talks about classes in the main paper. There are 2 types of classes  mentioned. 1) The set of geometric transformations, and 2) The classes inherently made  available through supervised labeling of the data set itself.   It seems that if there are k1 types of transformations and k2 classes in the labeled dataset (eg: k2 = 10 for CIFAR10) then anomaly detection is performed separately for each of the k2 classes. This might give substantial overhead as it  seems that this requires training of k2 different models. What are the author's thoughts about directly training a model for k1 transformations using all the k2 classes ? What was the reason for using the 20 class  grouping and not the 100 class version of the CIFAR 100 data? Do the number of classes (k2) in the dataset have an influence on performance? What does that mean for large datasets with a large number of classes. What about datasets that do not have class labels (as might  be the case for real-world data).  It will be interesting to know the influence of each geometric transformation  on the performance. Furthermore, it seems that a very small set of transformations  is utilized (some of which are common transformations used in data augmentation). Is there  a specific reason for choosing these? Can fewer/more diverse transformations be used ?