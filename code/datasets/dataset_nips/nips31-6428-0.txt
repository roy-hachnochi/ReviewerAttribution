Many combinatorial optimization problems are only solvable exactly for small problem sizes, so various heuristics are used to find approximate solutions for larger problem sizes. Recently, there have been a number of attempts to use neural networks to learn these heuristics.  This work is focused on the vehicle routing problem, a generalization of the well-known traveling salesman problem and task of significant real world interest.  The solution explored in the paper is to use standard RL techniques (REINFORCE and A3C) with a slightly modified pointer net architecture. The modification is that the encoder is feedforward convolutional network rather than an RNN, meaning the network is invariant to the ordering of the input sequence.  The empirical results are quite impressive, they find that this approach is able to find solutions superior to that of well-known heuristics and a baseline library of heuristics in 100\% of cases for the larger problem size (200 nodes).  This work is appropriately written and cites relevant prior work. The primary weakness of this work is that it may be of more limited significance. The prior work of Bello demonstrated that RL with pointer networks were capable of outperform OR Tools on the TSP problem. This work is a generalisation of that work (with a minor architectural changes).  There are two questions I have that would merit discussion in the paper.  - Bello et al. use active search (further RL training on a specific problem instance) in order to iteratively search for a better solution. Was this approach tried here / why was it not used here?  - How generalizable are the solutions learned for problems outside the training distribution. For example VRP100 on tasks of size 99 or 101? This seems like an important question for practical applications.  Minor issues: - Although possible rewards mentioned are the negative total vehicle distance or average service time, the reward function actually used is, as far as I could find, never explicitly stated.  - The policy is denoted as both $\pi$ (standard RL notation) and, to emphasize the sequential structure $P(Y|X_0)$. This change seems distracting.  -- The author's response demonstrated some level of generalisation in problem size and explained why they are not using active search (although it would be nice to see this as a baseline). Given the generalisation results I've increased my rating.