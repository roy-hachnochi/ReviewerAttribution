This paper describes a new variational autoencoder with a mechanism for detecting continuous changes in latent environments, which, combined with a "representational capacity" term in its loss function, allows it to learn environment-specific sets of relevant generative factors. The model seems reasonable, and while I'm aware of VAEs that appear to learn cleaner and more easily-interpreted disentangled representations, they're susceptible to catastrophic forgetting. The evaluation supports the key claim that the model is more resistant to forgetting than the baseline, and demonstrates some interesting properties.  The topic is interesting, the writing is generally clear, the key claims seem to be justified, and I didn't see any serious weaknesses in the evaluation. That said, I'm not as familiar with modern VAEs as other reviewers are likely to be. The section on "imagination-driven exploration" could have been clearer, but I believe the paper is likely to interest a reasonably large audience at NIPS even if we set it aside.