The paper proposed a noval and scalable approach to solve the Laplacian K-modes problem. The primary strategy is to adopt another way to relax the original discrete problem and further minimize a upper bound of the objective. The method is guaranteed to converge and evaluated to show its superiority over some benchmark clustering algorithms in both clustering performance and algorithmic efficiency. The statements are clear and content is easy to follow. The technical part is also correct.    My main criticism is about the significance.  -First, I am not sure if Laplacian K-modes energy is a widely used metric for clustering. Laplacian K-modes energy follows a form that simultaneously maximizes weights within each cluster (mode part) and minimizes weights across clusters (Lap part). There are several objectives falling in this category like correlation clustering. However, in experiments, the authors only compare LK objective with some very preliminary objectives NCUT, k-means, k-modes that are in other categories of clustering algorithms (NCUT: balanced min-cut; k-means, k-modes: max weights within clusters). - Second, although the proposed approach has good scalability, the derivation is kind of ad-hoc and all tricks are for scalability. In the first-step relaxation, an entropy term is subjectively added to handle the constrains. With this term, the objective can hardly be a tight relaxation of Laplacian K-modes energy. The proposed approach only holds convergence guarantee while do not has performance guarantee and the trick to obtain such convergence is not difficult to think of. Also, the efficient method to estimate mode is also ad-hoc. I think the proposed method may be useful in some practical scenarios but it is not significant enough for a strong acceptance of NIPS. Hence, I give a borderline overall score. 