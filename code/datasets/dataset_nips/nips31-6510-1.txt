The authors improve upon the Spherical CNNs work by Cohen et al [7] by proposing a neural network architecture that does not require forward-backward Fourier transforms at each layer while keeping the S(3) rotation invariance properties of theoutput. Instead all operations after the initial layer are in the frequency domain which allows the model to be more efficient according to the authors. I like the paper and introduction of new mathematical constructs into the neural networks domain. I also think that the paper is well written. I would have liked to see a complexity comparison w.r.t [7] in O() notation, in FLOPS and in actual CPU time for two architectures (one for [7] one for this paper) of similar accuracy. I think that the math is very involved and a simple table like that would emphasize the contribution in terms of speed up to a practitioner in a better way.    Just a side comment, I think that the application for vision tasks on 3d models is interesting and the method itself is elegant. However, given that most of the sensor data is planar, how impactful do the authors think their architecture is? Also am i correct in saying that most sensor data is planar?