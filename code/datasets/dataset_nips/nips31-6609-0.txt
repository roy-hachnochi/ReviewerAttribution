This paper performs a lifted weighted mini-bucket algorithm.  This is along the lines of other works that seek to lift various inference algorithms (e.g., variable/bucket elimination, belief propagation, etc) so that they operate more efficiently on relational models such as Markov Logic Networks (MLNs).  One distinction here is that they propose an anytime algorithm that starts with the coarsest lifted weighted mini-bucket approximation, and then incrementally tightens the bound by refining the operation, by trading off computation.  The paper appears to be thorough in its presentation, and considers the different aspects of lifting the weighted mini-bucket algorithm. Lifted infernece is quite relevant to the field of probabilistic graphical models, and this paper appears to make an advance in this regard. 