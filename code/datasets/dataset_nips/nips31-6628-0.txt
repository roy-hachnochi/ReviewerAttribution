Summary of the Paper:   This paper describes an extension of the variational autoencoder to take into account correlations among the latent variables z that are used to generate each observed samples. These correlations are modeled through a Gaussian process prior in which the input variables are additional variables related to object or view information associated to each data point. The method is compared with other approaches from the literature that can potentially address these correlations on two datasets.  Strengths:   - Well written paper.   - Complete related work section.   - Nice and illustrative experiments.  Weaknesses:   - The optimization of the proposed method is complicated and not very well described in the paper.   - I have missed a baseline to compare with which does not take into account correlations.  Quality:   The quality of the paper is high.  Originality:   As far as I know this work is original.   Significance:   The results obtained indicate that the proposed approach can obtain better results than the methods the authors compare with. Therefore, I believe that the results are significant.  Other comments:   It is not described in the paper how to optimize and quickly evaluate the lower bound on the log probability of the data. In particular, the introduction of correlations among the z's variables implies that the lower bound is no longer expressed as a sum across the data points. This makes the optimization process more complicated. Furthermore, GPs do not scale well with the number of instances. The authors should provide more details about this has been addressed in the main manuscript. Not in the supplementary material.   I have missed some comparison with a simple baseline to show that these correlations are indeed important. For example, a standard VAE.