This paper proposes a method for modeling 3D convolutional layers that are SE(3)-steerable, i.e. equivariant under rigid motions. The authors develop a theoretical basis for their approach, and show that steerable filters require significantly fewer parameters than equivalent CNNs, since they are constrained to lie on a lower-dimensional manifold and can be represented in a basis for the latter.  The paper is cleanly written and the experiments reasonable, although it would be good to see the performance of 3D steerable CNNs on, say, a version of ShapeNet with shapes randomly rotated, instead of a toy Tetris example. I'm also not happy that the Tetris example tests only 90 degree rotations: why not arbitrary rotations? I did not validate all the math. Assuming the math is correct, I think the method is a useful contribution which addresses the classical problem of designing features invariant to rigid transforms. I recommend acceptance, but would prefer to see some more results on synthetically rotated standard 3D datasets.  == Update after reading rebuttal ==  I thank the authors for doing the experiments I suggested. The conclusions are promising. I continue to be in favor, again with the disclaimer that I have not verified all the math. It would help if someone (R1?) has done this or can do this, in which I case I would be even more strongly in favor.