This is a well written paper that addresses the problem of inserting new objects into an image at plausible locations and scales. The proposed method uses a semantic map to learn so-called "where" and "what" models. The models are not particularly novel, employing conditional GANs but it is interesting how they work together as well as the introduction of the spatial transformer network.  The main weaknesses that the paper does not address the issue of photometric consistency (unless this is somehow automatically handled by the GANs). For example, how does the model ensure that the correct lighting, shading and shadows are produced? The second weakness is that the model is only tested on the cityscapes dataset, which appears to be relatively simple for this task in that the scenes are relatively constrained and the camera viewpoint is fixed. Nevertheless, the paper does not overstate its contribution claiming to "take a first step to address the [...] problem." 