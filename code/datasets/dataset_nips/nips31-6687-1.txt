In this paper, the option-critic architecture is extended to a more general formulation of a multi-level hierarchy where instead of having just two levels (primitive actions and options), it is possible to have multiple option layers of different abstraction. Results on multiple benchmark tasks show that using N = 3 might be better than N = 2 for hierarchical RL learning.  Pros: Studying and exploring a truly general hierarchical reinforcement learning architecture is of great importance. I share a similar view with the authors: although extending HRL to more than two layers seems to be a intuitive and desirable direction, there's not much attention in the field.  The paper is well written and the technical contribution of developing option value function and subgoal policy gradient theorem seems solid. The flow of the paper is easy to follow.   Cons: I'm not fully convinced that "the performance of the hierarchical option-critic architecture is impressive" (line 351). Compared to option-critic, the improvement of N=3 seems marginal. What's disappointing, but also important is the negative result when N = 4 in Rooms env. It basically says that, at least for the simple tasks we have right now, using more abstract options does not yield increasingly better performance. Besides the learning curves, there's no visualization of options learned in a higher level. Showing some option visualization on seaquest game might be helpful.  There's no clear evidence that learning more abstract options is the way to go. I do think evaluating on harder games like Montezumaâ€™s Revenge or continuous control tasks are necessary if we really want to know if HRL using multilevel abstract options works, though this might be beyond the scope of this paper. Another direction is to use grounded options with some human priors for specific tasks so we can examine if the options are learned correctly.  The authors mentioned FuN which decomposes the state space could be an alternative. What's the advantage/disadvantage of building on top of FuN and learn multi-level subgoals, compared to hierarchical option-critic?  Have you tried to use different temporal horizon for the higher level options in the hierarchy?  The paper is very crowded and the figures are hard to read, hope the authors could find away to fix. a tiny thing I noticed: line 194 missing a period after "Appendix".  Overall I think the paper is interesting and worth a larger audience despite the unsurprising experimental results.