Main ideas of the submission: This paper studies the problem of running a prediction market to crowdsource data while providing differential privacy guarantees. This problem has previously been studied by Waggonner et al. NIPS 2015 and Cummings et al. EC'16. Waggoner et al. provided a method for purchasing data while guaranteeing differential privacy. Cummings et al. show that one draw back of any differentially private mechanism is that as the number of participants grows the differential privacy gaurantee causes the mechanism to lose on the total profit it can achieve.   In this paper the authors propose a way to resolve this issue. In particular, if the mechanism charges each participant a fee for participation, then that can be used to bound the amount of money the mechanism pays. The authors provide a mechanism that pays O((log T)^2) where T is number of participants. They further improve this result using a doubling trick often found in online learning. Using this trick, they can provide a mechanism that spends a constant amount of money while maintaining differential privacy.  Quality: The paper is fairly well written and explains the main proof ideas clearly.  Originality: While the ideas used in this paper are not new, the authors show conclusively how they work in this setting.  Significance: The paper solves an open question posed by a previous paper and provides a strong conclusive answer to the problem. 