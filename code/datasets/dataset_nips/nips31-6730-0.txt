This work expands on the algorithm RAI by Yehezkel and Lerner for constraint-based structure learning of Bayesian networks. The RAI algorithm constructs a tree of CPDAGs. Each node of the tree splits the variables into subsets (one descendant and K ancestral subsets) by using conditional independence (CI) tests of order n. Then, the node growths K+1 subnodes by recursively calling the RAI algorithm on the K+1 subsets of variables and n+1 as CI test order. The submission proposes the B-RAI algorithm that leverages bootstrap to allow the algorithm to output a set of highly likely CPDAG rather than the MAP one. Bootstrap is not naively leveraged. Instead, it is integrated in the recursive call of the algorithm. B-RAI constructs a tree similar to RAI except that B-RAI is recursively called S times on every subset, each time on a bootstrap sample of the dataset. This multiplies the number of subnode by S. The resulting structure can then be used to sample "boostrapped" CPDAG at a reduced cost. The resulting scheme is evaluated experimentally. It is compared to a naive bootstrap RAI for efficiency, to state-of-the-art model averaging schemes for structural features scoring on small data sets and to state-of-the-art structure learning scheme for data likelihood on large data sets.  This paper has several strong points. - The experiments are very convincing. They show the advantage of the approach over a naive bootstrap and favourably compare B-RAI to RAI and state-of-art-approaches on two relevant problems on standard benchmarks.  - This suggests this method could become a new reference approach. - The paper is mostly relatively clear and well written.  On the other hand, the details of the algorithm proposed are not clearly explained in the paper. The key ideas are there but the paper is not self-contained. Reimplementing the algorithm cannot be done without at least reading the paper by Yehezkel and Lerner. I would suggest at least clarifying the following points in a supplementary material or in the main text. -- "Each group is independently partitioned", so would it be correct to say that, in Figure 1, n=1, "X^(1)_A1" refers to a different set of variables in each of the 4 partitions drawn? This was not clear to me. -- What are exogenous nodes? -- l 136-137: "First, the nodes having the lowest topological order are grouped into XD" --> Do you mean the nodes having the highest indexes in the topological order? How many nodes should be selected? All nodes without descendants? A set percentage of the nodes? How large are ancestors sets?  Overall, I think this paper is interesting and worthy of publication, but might need to be clarified a bit.  minor comments: - missing whitespace after comma in l115 - l 141: "therefore an sub-tree can further constructed independently"  -------------- Thank you for the clarifications and the answers to my comments.