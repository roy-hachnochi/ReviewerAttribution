After reading the rebuttal and other reviews I decided to raise my score to 6. However I strongly suggest the authors to soften the claim about GRL, since I do not think it has the claimed effect even in theory. For example, even if the exclusive code has a Gaussian distribution which does not contain information of another domain, the generator can still generate images of another domain from it just like an unconditional GAN. The gradient receive by the encoder does not have a clear efffect. =========================== This paper proposes a new method for image-to-image translation. The model consists of two autoencoders, whose latent code is decomposed into a shared component and a domain specific component. The model supports multimodla image translation, generating different output images given the same input.  Pros: 1. The paper is well-written and easy to follow. 2. The idea of multimodal image translation by decomposing domain-shared and domain-specific representation is novel, although the authors might want to consider discussing the difference from some concurrent works [1,2].  Cons: 1. To me, the GRL design does not really make sense. The GRL encourages the encoder to produce embeddings such that the images generated by G^X_d are different from images in domain Y. The encoder could achieve this by arbitrarily shifting its output distribution, for example, adding a bias of 100. The encoded feature will still contain the cross-domain information, but the images decoded from G^X_d will be garbage. Also, Table 2 indeed shows GRL does not improve performance. Is there any theoretical or empirical results to support the use of GRL?  2. The experiments are all done on synthetic datasets. It would be better to extend it to real-world datasets.  3. The method assumes paired data is available, similar to BicycleGAN. However, the advantage over BicycleGAN is not very clear. In Table 1, the performance of the proposed method is similar to BicycleGAN on Chairs dataset, and slightly better on Cars dataset. It could be that the default parameters of BicycleGAN do not work very well on the new dataset. To me it's not very convincing to say the proposed model outperforms BicycleGAN. Evaluating the proposed method on the datasets BicycleGAN originally used (e.g., edges2shoes) would stronger the claim.  [1] Huang, Xun, et al. "Multimodal Unsupervised Image-to-Image Translation." arXiv preprint arXiv:1804.04732 (2018). [2] Almahairi, Amjad, et al. "Augmented CycleGAN: Learning Many-to-Many Mappings from Unpaired Data.", ICML 2018 