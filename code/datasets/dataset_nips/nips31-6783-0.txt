This is a carefully written paper framing learning beam search policies under imitation learning. The key insight to do this is to define a search space over beams rather than outpus, and considering actions that transition between beams. I liked how this idea allows us to conceptualize learning beam search policies and I think it will help other researchers in combining this with imitation learning, which is in my opinion a promising combination. The writing is dense, but very clear.  I understand this is a theory paper. I would nevertheless I would have appreciated some experiments, even on synthetic data to demonstrate the potential benefits of taking beam search into account while learning incremental structured output predictors with imitation learning. Also, it would help illustrate what the various requirements in terms of oracle information and loss calculation might mean for a practical implementation.  A few other points: - It is worth pointing out that the SEARN paper cited actually did use beam search in some of the imitation learning experiments, so the combination exists in the literature but it is under explored. - in equatlon 5, the rewriting of the loss with respect to the transitions does it affect the ability to handle non-decomposable loss functions? Do we assume that the loss increases monotonically? It would be good to clarify this as imitation learning algorithms such as SEARN are often able to learn with non-decomposable loss functions.  - Section 5 mentions a 4th theorem that is not present in the main paper at least.