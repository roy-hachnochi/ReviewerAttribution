Update after rebuttal: the new details added by the authors in the rebuttal helped clarify some of the doubts I have, so I have changed my score accordingly.  -------------------------------- Summary:  The paper presents a deep learning approach to predict some hidden features in a StarCraft game, such as existence of opponent building types and unit types at any location and time in the game. The paper suffers from lack of details on both the game, approach and the experiment setup, so it is quite hard to read. More  Strengths: The paper presents new ideas in applying deep learning in the context of strategy games, which is interesting.  Weaknesses: The paper does not provide enough details on the game and various concepts in the game to justify the design of the proposed infrastructure. Due to the lack of sufficient details on the game to justify and inform the design of the deep network architecture, it is hard to convince readers why the approach works or does not work. The reproducibility is therefore affected. The take-away from the paper or generalization beyond StarCraft is also limited.  Other general comments: - Tables and figures should appear near where they are mentioned, so Table 4 and Figure 4 should not be in the appendix. - Too many papers referenced are from non-peer reviewed websites, such as Arxiv and CoRR, weakening the paper in terms of argumentation. The authors are highly encouraged to replace these papers by their peer-reviewed counterparts - The selected baselines are too simple. They are all simple, rule-based, and myopic, with no attempt to learn anything from the provided training data, which the authors’ architecture makes use of. It would be a fairer comparison should authors have tried to design a little more sophisticated baselines that incorporate some form of learning (via classical prediction models, for example).  Other detailed comments: - Various statements about the game and how players behave/act in the game miss explanation and/or supporting reference     * Page 1, line 31: “Top-level human players perform about 350 actions per minute“    * Page 3, line 86: “... humans generally make forward predictions on a high level at a long time-scale; ...”     * Page 6, line 240-241: “Since units often move very erratically...”: not really, units often move according to some path. This also illustrates why the selected baselines are too weak; they make no use of the training data to try to infer the path of the moving units. - Page 2, line 81: Full state is not defined properly. What are included in a full state? - Page 3, line 96: what are “walk tiles”? - Page 3, line 119: What is “the faction of both players”? - (minor) Figure 4 does not print well in black and white - Page 3, line 131-132: The author refers to the g_op_b task that is introduced later in the paper. It would be better if the authors can describe such concepts in a section devoted to description of the games and related tasks of interest. - Page 4, line 139: “h” is not defined yet. - Page 5, line 208-210: What game rules were used for this baseline? In general, how do game rules help? - Page 7, line 271-276: This part needs more elaboration on what modules are available in the bots, and how they can use the enhanced information to their advantage in a game. - Page 7, line 286-287: The reason to exclude Zerg is not convincing nor well supported externally. The author is encouraged to include a Zerg bot regardless, then in the discussion section, explain the result and performance accordingly.