The paper empirically studies phenomena associated with the principal curvature basis proposed in previous work. There are two main findings: 1) the classness scores are often monotonic on each side along the positive and negative curvature directions, while remain almost constant along the flat direction; 2) the positive and negative curvature directions characterize a subspace on which a neural network relies for classification. This further implies an interesting connection between classification power and sensitivity to adversarial perturbations.  The paper presents interesting and novel observations. It reveals the contradiction between predictive performance and robustness. The experiments of subspace projection (Figures 4, 6, 7) have been designed in a smart way that substantiates the main claim of the paper.  However, there are still many question remaining open. For example, it is not clear what causes such contradiction and whether it is a solvable problem. The authors have not addressed the "why" question even in the intuition level. As a result, although the findings might be interesting, it does not guide future research to devise more robust models. Ideally, I would love to see a better defense strategy coming out of the findings, which will make the paper much stronger.  The presentation of the paper should be largely improved as it is very hard to follow. I would suggest adding formal definition of curvatures and other concepts, and also clearly describe each figure in detail, to make the paper more self contained. In the current version, it is very difficult to interpret the meanings of the plots.