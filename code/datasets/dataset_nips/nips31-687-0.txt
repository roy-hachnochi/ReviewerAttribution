Summary: The paper presents a simple yet effective learning framework for object detection with auxiliary task learning. The proposed framework, ROCK, introduces a residual block that refines the base feature map using augmented representations trained with respect to corresponding auxiliary tasks. Individual decoded feature maps for each task are then fused with the base feature map by element-wise addition and the refined feature map is used for object detection. The paper provides ablation study by breaking down each component from the proposed ROCK method and shows effectiveness of the components. Overall, the proposed framework demonstrates substantial improvement on object detection on NYUv2 dataset.  Strength: - The paper is clearly written and seems complete.  - The proposed method is simple yet authors demonstrates its effectiveness.   Comment: - It would be good to provide some ablation study how to tune hyper-parameters that balances between different loss (e.g., detection loss, scene class prediction loss, depth-prediction loss, and surface-normal prediction loss).  - As the paper presents a connection to LUPI framework, it would be good to provide some results when auxiliary supervision is available at "test" time by replacing encoder of ROCK auxiliary supervision input. This may give a performance upper bound to the proposed framework. - How generalizable the proposed framework and the choice of auxiliary loss to different tasks?