After reading author responses and discussing with other reviewers, I have decided to raise my score. I think the authors did a good job in their response to the points I raised. However, I still think that their should be more emphasis in the paper on the significance of the observations made in the paper which was not clear to me at first. -------------------------------------------------- This paper presents an empirical analysis of some probabilistic generative models, including GAN (specifically WGAN-GP) and VAE. The study relies on probative experiments using synthetic image datasets (e.g. CLEVR, colored dots, pie shapes with various color proportions) in which observations can be explained by few, independent factors or features (e.g. shape, color, numerosity). The paper aims at quantifying generalization in these models through their generated samples under various training scenarios, such as:  -  Training data has a single mode (e.g. only two CLEVR objects in the scene)  -  Training data has two distinct modes (e.g. pie shapes with either 30% or 90% red proportions)  -  Training data has two close modes (e.g. pie shapes with either 30% or 40% red proportions)  -   Other experiments investigate s multiple features vary in training data, such as shape and color in two CLEVR objects. Results show that the models exhibit some general behavior patterns. Notably, these patterns seem to be consistent across different training objectives (GAN or VAE), architecture and hyper-parameters.  Strengths • The paper is clearly written • The paper investigates many interesting questions with well designed experiments  Weaknesses • A fundamental weakness of this paper is the lack of a clear "hypothesis" for explaining observations. While it's interesting to note convolution effect or prototype enhancement, it is not clear how they can be explained or how they could be used for understanding these models and possibly improving them. • While it is interesting to draw similarities between generalization behaviour of probabilistic generative models and results in cognitive psychology, it is not clear what we could conclude from such resemblance. Can we claim we have an "intelligent" model? • The statement that the observed generalization behavior was consistent across different modelling objectives and architectures is unsettling. First, it seems to be based only on 4 experiments (as shown in supplementary materials -- Table 1). What does this tell us about these studied models? Does it extend to different models (e.g. autoregressive ones) or other variants of GANs or VAEs?  In conclusion, I believe this paper presents some interesting observations but lacks a proposal for exploiting these observations, either for improving generative models or evaluating them.