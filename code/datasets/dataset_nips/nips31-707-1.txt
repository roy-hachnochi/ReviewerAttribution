The Authors describe a way to incorporate unequal regularization into training methods of deep learning training in a way that does now spawn a nan value parameters to optimize . I think this paper is of fundamental importance not just from the methodological point of view, presenting a truly new method, but from the fact that it addresses tabular data. Something scarcely done, such it deserves a strong accept   The main point is that by coupling a minimization scheme for a “sudo” loss one can contain the increasing number of parameters. I would be very interested in how does decay of the counterfactual loss over time scale with the number of parameters, is there some of scaling function ? will it be a power law ?  In general I am wondering if the authors performed some sort of dynamical analysis to the counterfactual loss, my intuition tells me that the way the problem is stated there is a shadow lemma and the counterfactual loss mimics some sort of Nekrasov bounded system and thus most of the parameters don’t really come into play. For full disclosure out of curiosity I have implemented and recreated the experiments in pytorch/mxnet/tensorflow, keras and I did not get the exact results but slight deviations from the results the authors report (which are still very very good). Can authors give some more details into the experiments ?  In general results varied between only slightly between different platforms and I am keen to know how exactly did the authors achieve their results, will there be a code publically available  somewhere ?