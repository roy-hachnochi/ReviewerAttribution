This work contributes a new error backpropagation method for spiking neural networks which is capable of learning both weight and axonal delay parameters in a spiking neural network, and establishes a new SOTA on multiple tasks.  This work helps address the long-held challenge in the neuromorphic community of designing a learning algorithm capable of learning (approximately) as well as standard deep neural networks for fixed inputs, but is also capable of learning from time-varying signals which more closely match the native representation of spiking neural networks.  This submission was prepared carefully and clearly, with a thorough set of comparison benchmarks to other standard spiking benchmarks.  The benchmarks further span both image and audio challenges.  Recent work is compared against and referenced, and CNNs and fully-connected architectures similar to those used in the state-of-the-art are used.  The derivation of the modified backpropagation rule is well-described.  Further, a GPU-optimized toolbox will also be released, all bolstering the work's quality, clarity, and significance.  Discretizing temporal history to enable backpropagation and approximating a Dirac function with a more easily-differentiable function is not an entirely surprising approach, but it is used effectively here.  It would be useful to see the rule tested on more difficult temporal data than TIDIGITS, in which the SOM on top of MFCCs provides significant precomputation; similarly, a more thorough examination of learning axonal delays would improve the motivation for adding the additional complexity.  For example, do learned delays in NMNIST correspond to saccade timing, or just play a role in expanding the parameter space for learning?  Finally, some of the choices, e.g. spike rates for true vs. negative classes seem arbitrary.  Why were 180 spikes/sec used in DVS gesture classification for true and 30 spikes/sec used for false classes? The work could be improved by comparing against ANNs on spiking data, and referencing works such as [1] that featurize on top of neuromorphic data to suggest whether the limited performance is now more from the SNN models or the input streams themselves.  However these are small points.  Overall, this work has the potential to strongly impact researchers working in neuromorphic models.  [1] Anumula, Jithendar, et al. “Feature Representations for Neuromorphic Audio Spike Streams.” Frontiers in Neuroscience 12 (2018): 23. https://doi.org/10.3389/fnins.2018.00023. 