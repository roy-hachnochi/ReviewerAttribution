post-rebuttal: I feel the paper does sufficient work to warrant an accept. The main concern is regarding how well the idea of packing works with advanced and stable versions of GAN and also with other inference methods and other generative models. If the authors can alleviate this concern in the next version of the paper that would be great.  Summary: This paper proposes to tackle the problem of mode collapse in Generative Adversarial Networks GAN. The problem of mode collapse is the one when the probability distribution learned by an inference algorithm (in this case GAN) is single-mode as opposed to the true probability distribution that multi-mode. This leads to low-diversity sampling of points from the learned generative model (GAN in this case). The paper proposes a simple solution to this for GAN which is force the discriminator to judge/make decision on multiple samples instead of one as in traditional GAN setting. By forcing the generator to proceed multiple high quality samples the paper claims it reduces mode collapse. The paper also provided a good formalization of the mode collapse problem and an empirical evaluation that shows that their approach leads to relaxes the mode collapse problems in GANs.   Quality: I think this is a high quality paper with a nice new idea and solid formulation of the problem.   Clarity: The paper overall was clear to me except the figure. I struggled to understand Figure 3, a little more explanation would be useful.   Originality: I believe the paper presents original idea, algorithm, formalization and experimental results. I am quite happy with the originality of this paper.   Significance: The paper tackles an important problem to the ML community and presents a nice simple solution to it.   Strength: I think the main strength of the paper is the nice simple idea of packing, that is, to use multiple samples instead of one sample in a GAN setting. I am also impressed by the formalized definition of mode collapse.  Weakness: I think the paper can be improved by comparing/extending its solution to generative models other than GANs. The main question that the paper does not tackle is that the problem of mode collapse is it true for other generative models as well? For which generative model is it less severe. How the PacGAN perform in comparison to those models.   Other minor issues: Some parts of the paper are vague, for example, paper keeps referring to results in a vague manner as … provides novel geometric analysis technique to solve non-convex optimization problems … I did not get this claim at all (how?)   Related work could be pushed to end of the paper (makes it easy to refer to what paper already presented instead of what it will present)  Overall, I am quite happy with this paper.  