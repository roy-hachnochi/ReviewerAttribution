In this paper the authors propose an interesting idea where they aim to overcome overfitting of VQA models to the dataset by using adversarial regularization. The regularization is obtained through two different ways, one by regularizing adversarially on a question only model and second by regularizing by maximizing the answer model to improve by observing the image. The method proposed seems to be correct and the formulation makes sense. The evaluation shows improvements over SAN (Das et al) and Up-Down models  (Anderson et al) for the VQA-CP dataset.  The only problem is that the results provided in supplementary are not clear. From what I could understand, the question only models and the ones improved by regularization still perform inferior to question only model even in the VQA-CP v2 dataset. This implies that the method fails on VQA-CP v2 dataset? I am probably missing something here.  It would be very useful if the authors could clarify the results provided in supplementary during rebuttal.   Further, would the method improve by incorporating a separate attention based regularization as well?  -- After author feedback  The feedback addresses the points raised in the review satisfactorily.