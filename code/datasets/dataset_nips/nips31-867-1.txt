Summary: This paper proposes a method for future frame prediction that consists of a sampling stage in which possible future frames given the past are generated by a set of weight matrices that model future dynamics based on the difference of the previous two consecutive frames. The best candidate future frames are then chosen based on a confidence score computed by an RNN. The sampling stage is then followed by a combination layer that fuses the best candidates into a single future frame. Their objective function consists for a combination of a selection based adversarial training on the generated image that is closest to the ground truth and regression loss on the RNN output scores between the generated future frames and the ground truth frames. In experiments, they evaluate and compare their method in terms of pixel based and human judgement evaluations. They also provide video comparison against the baselines showing the advantage of the proposed method.  Pros: Novel architecture that makes sense Numerically and visually outperforms baselines Paper is overall easy to understand  Cons: Intuition/explanation: Why is \Delta W output instead of simple W for the kernels? Why is a softmax activation used for \Detal W? How do the authors make sure that the \Delta Ws are different? The argument given in the paper is that they are updated in different directions, but there is no concrete evidence that this is actually happening. It would be good if the authors give a better intuition or show evidence of their claims in these cases.  Comparison against SVG: The authors mention that they plot the curve that is an average of 20 samples from that method. Having 20 samples is too little for the average to be significant. How about the authors compare against the best of the 20 samples? Or reduce the number of samples and still compare against the best. If the proposed method is still better against such optimistic baseline, it would be a very nice result, and would high-light the advantage of the proposed architecture.  Ablative studies: If possible, it would be good if the authors can show an ablative study of how each component in the proposed network helps (e.g., instead of combination masks, just average the best samples, no best k samples selection, etc)  Discussion: The authors show some visual analysis of the proposals based on being “rational enough”, “accurate enough”. This analysis is shown on a single example. I believe this analysis should be done in a different (hopefully numerical way), as one example is not very informative. Typos: The paper needs to be proofread. There are a few typos.  Overall, I like the paper, however, there are some issues as mentioned above that the authors should take into consideration.