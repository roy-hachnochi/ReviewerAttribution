== Summary == The paper tackles the video generation problem by a selective sampling mechanism. Image blur and motion deformation are two big challenges in video prediction. Previous video generation work optimizes a hybrid objective, which struggles to balance between adversarial and regression objective. To solve the issue, this paper consider a two-stage framework the decouples the adversarial and regression loss into separate modules. In the sampling stage, a kernel generation network produces multiple convolutional kernels, while a sampler network applies kernels to predict the next frames. In the selection stage, a selector networks finds the top K predictions under the measure of motion precision, while a combiner network composes the final prediction from K candidates. Experimental evaluations are conducted on three benchmark datasets: MovingMNIST, RobotPush, and Human3.6M.  == Quality and Originality == Overall, the proposed VPSS method is a promising solution to the video prediction problem. The proposed 2-stage pipeline improves the prediction quality (e.g., low-level measurements and perceptual realism) to some extent. One drawback is that the proposed 2-stage pipeline is a bit complicated. Furthermore, reviewers do have some reservations on the experimental design. Please address the issues mentioned below in the rebuttal.  == Generating long-term future == As improved image quality is the main contribution of the VPSS method, it would be more convincing to demonstrate the long-term prediction results and compare with existing methods. Reviewer would like to see, for example, the 20 steps prediction results on Human3.6M dataset using the model trained for 10 steps.   == Side-by-side comparisons == Reviewer would like to see the side-by-side comparisons to all baseline methods (DFN/SVG/CDNA/SV2P/DrNet/MCNet) on at least one dataset. The current experimental results look less solid since only two baselines are compared on each dataset. For example, DFN is better in prediction accuracy than VPSS on MovingMNIST dataset.  == Implementation Details == As the 2-stage pipeline is a bit complicated, it becomes non-trivial to reproduce the results. Also, reviewer would like to know whether the proposed VPSS is efficient or not in terms of training time and inference time compared to video prediction baselines.  **** Regarding Author Feedback **** The rebuttal resolves the following concerns: -- Side-by-side comparisons -- Long-term prediction Reviewer 3 agrees with other reviewers that this submission is a good candidate for acceptance. It would be great if the ablation study is included in the final version.   Reviewer 3 does not feel strong motivations to raise the score, as the proposed 2-stage method is a bit complicated. Reviewer encourages the authors to explore a simplified version along this direction as future work.   