The authors analyze the supervised auto-encoder, a model that attempts to output both the target and a reconstruction of the input. They proof uniform stability for linear supervised autoencoders and show, compared to a standard neural network, the performance of the primary task never decreases when introducing the reconstruction loss.  The paper starts by proving uniform stability. The authors do this by showing that the shared parameters ("encoder") don't significantly change with the change of one training sample in the training set. This is a nice theoretical result.  In the second part of the paper, the authors compare the linear SAE to SAEs that contain a non-linearity (sigmoid, relu) and a version that first transforms the data using radial basis functions. They also include a network that just outputs the target (no reconstruction). The results show that including the reconstruction as a loss helps in all three cases. The authors further show extensive experiments on the CIFAR dataset, using an SAE with a deeper architecture. The authors show that including the reconstruction error again has a regularizing effect. Improving the training accuracy significantly.  Under figure 4, the authors mention several results with respect to dropout, l2 regularization and resnet18. I am curious what the exact numbers are and ask the authors to share this in the rebuttal. I am specifically curious about the ResNet18 result (with and without augmentation). Some reported results on CIFAR10 test set are 91% VGG, 92% NIN and 77% Quick-CIFAR, which are all much higher than the results show in figure 4b.  In general I think the paper is well written, with extensive experimentation and attention to detail. However I think the empirical results using deep SAE are lacking and I would not agree that the reconstruction error is "such a simple addition" (figure 3), since it nearly doubles the network size and therefore training time.  The theoretical result is interesting, however I am curious if there isn't a simpler way to achieve uniform stability for a linear NN.   --------------------------  I would like to thank the authors for the extensive feedback and appreciate the additional results.  My main concern with the feedback is the following point: "avoided early stopping (as this conflicts with our generalization claims)". However from the paper line 236, there is no theoretical generalization claim for the deep SAE. I think the simplifying assumptions of a simple optimizer and no data augmentation are fair, but it's unclear if the resnet has overfit with no early stopping. Also given the reconstruction is seen as a regularizer, a comparison with other regularizers would have been nice (better than comparing to not regularizing at all).  I think the suggestion of showing results for increasing number of data points (by reviewer #1) is strong and it's good to see the authors picked up on it in the feedback.  I hold that the experimental section can be much improved, but recognize that the main contribution is the theoretical result. I have therefore increased my score by one point.   