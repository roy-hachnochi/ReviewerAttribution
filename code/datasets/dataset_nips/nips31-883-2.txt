This work proposes LINUCRL which extends previous work UCRL to dynamically capture usersâ€™ preference in recommender systems. The experiments on synthetic and real-world dataset show the proposed method can effectively trade-off exploration and exploitation. The theoretical analysis of LINUNCRL is provided. (1) While Table 2 shows that LINUCRL achieves better performance as compared to baselines, some strong RL-based recommendation baselines are missing. (2) Is this approach also work for the cold-start recommendation, i.e., when the history of action becomes extremely sparse or completely not available?    (3) The advantages of the proposed method are not very clear as compared to existing methods.  I read the response, and some of my concerns are addressed. I keep my score unchanged but I think some RL-based recommendation models could be also considered, e.g., [1] Time-Sensitive Recommendation From Recurrent User Activities [2] Novelty Learning via Collaborative Proximity Filtering