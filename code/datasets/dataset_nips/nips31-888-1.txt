This is an interesting paper that focuses on human decision makers that utilize optimal threshold decision rules, but are biased against protected groups (somewhat similar to https://doi.org/10.1109/JPROC.2016.2608741).  The focus of the paper is to develop bipartite matching algorithms to help reduce the overall bias of the decision making in a sequential decision making setup.    The paper is interesting and quite a worthwhile contribution that should be highlighted.  This is a new perspective on fairness and bias that has not really been discussed before --- although it seems to me that it is a much broader contribution than the specifics of fairness that the authors have couched it in.  The definitions and math all appear correct to me.  The experiments are sufficient to validate the idea, and look to be conducted properly.    My main hesitation regarding the paper is that it may not fully connect to all relevant literature.  Matching algorithms are considered in crowdsourcing task allocation problems (here is one example paper: http://wiser.arizona.edu/papers/YANG-CNF-SECON2017.pdf), and that literature should be discussed.    The general idea of sequential detection and more general decision making, which goes back to the work of Wald in the 1940s should be discussed as it is very much related to this paper.  More broadly, the work should be contextualized within the literature of statistical signal processing.  Line 188: "where and m_z(t)" <--- the "and" seems to be a typo