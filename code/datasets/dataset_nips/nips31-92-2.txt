The paper proposes a novel CNN based architecture generating 2D images of 3D objects. In contrast to existing GAN methods, the proposed approach combines two independent generators: one for 3D shape and another for texture. The first component is a CNN mapping a low dimensional code to 3D volumetric shape. The second component is a CNN mapping 2.5D sketch (depth + silhouette) and a low-dim texture code to the final 2D image. The two components are connected by 3D to 2.5D translator, conditioned by viewing angle, having simple algorithmic solution. The 3D generator and the texture generator are learned from training data, 3D objects and 2D images, which do need to be aligned. Learning of 3D shape generator is based on 3D-GAN [Wu et al 2016] with a slight improvement. Learning of the texture generator uses a technique similar to image-to-image translation learned by CycleGANs [Zhu et al 2017].  The paper is clearly written up to a few typos and points mentioned below. The main novelty is in the proposed CNN-based architecture for image generation which disentangles 3D shape and texture and which can be learned from unaligned data. The experimental evaluation is sufficiently convincing.  Detailed comments:  - Learning of the full model, equ (9), leads to a complicated min-max problem with a complicated objective. It would be useful to see at least an outline of the optimization scheme used. It is also not clear what is the gain from solving (9) as compared to learning both texture and 3d shape models separately.  - The 3d generator is claimed to be learned by Wasserstein GAN, however, the objective function (1) corresponds to the original GAN [Goodfellow 2014]. It is not clear why.  - Description of the probabilistic ray-voxel intersection algorithm (line 135-140) is not fully clear. It requires reference or more details.   - The shape code (line 201) is claimed to be sampled from Gaussian distribution, however, it is not clear why it should follow this distribution. The Gaussian distribution should be probably enforced when learning the 3d shape generator but it is not the case according to the formulas.  - In the ablation study, the texture generator is evaluated by means of Frechet Inception Distance. In addition to this, one could measure (using e.g. Hamming distance) to what extent the texture generator can copy silhouette correctly.  Typos:  - line 88: $z_{shape}$ -> $z-{view}$ - line 173: $G_{shape}$ -> $G_{texture}$ - line 242: " loss, We" 