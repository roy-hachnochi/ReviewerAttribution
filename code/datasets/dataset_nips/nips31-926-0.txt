This paper studies how to inject external human knowledge to neural networks. It proposes a new Symbolic Graph Reasoning (SGR) layer. SGR layer bridges convolution layers and prior graphs. A SGR layer has three components: local-to-Semantic voting, graph reasoning, and semantic-to-local mapping. The proposed method shows improvement in segmentation and classification across multiple datasets: COCO-stuff, ADE20k, and PASCAL-Context and CIFAR-100.   Authors proposed a new layer called (SGR). SGR layer maps convolution feature space to semantic space and propagates (graph reasoning) in semantic space. The evolved features are brought back to convolution feature spaces by semantic-to-local mapping. The authors suggest symmetric normalization for the stability which is a well-known trick in graph analysis literature.   Due to the simplicity of mapping between convolution feature space and semantic space, the graph reasoning is not effective for lower convolution layers as authors observed. The authors may want to plug-in the graph reasoning with more complicated mapping in some applications where lower level convolution features are important. More discussion on mappings will be useful.  The great feature of this work is that knowledge graphs can change the convolution features. If possible, a qualitative comparison between original conv feature maps and evolved feature maps will give more intuition.   Most graph reasoning is quite sensitive to how to build the graph. It was not discussed. The knowledge graphs can be viewed as a transition matrix. Given a knowledge graph, multiple multiplications of transition matrix offline will yield different interpolation effects on the discrete topological space. It will be interesting to see different behaviors of the proposed layer.   In Visual Genome dataset, the relationships between objects are not symmetric. Due to the symmetric normalization in the SGR layer, this knowledge can be incorporated naturally. The main difficulty to handle asymmetric (directed) graph is not properly discussed. From the classical graph analysis literature, lots of tricks can be used to keep ergodicity of graphs and stability of propagation. Extension to asymmetric graphs will expand the operation range of the proposed method.  Lastly, due to the conv1x1, semantic mapping was done pixel-by-pixel. Region/group-wise semantic mapping can make the proposed method more efficient using larger convolution kernel and deconvolution layer. Current construction increases too much overhead. For example, Additional computational cost.  Adding one SGR layer increases 0.5 M parameters in 7.0M network (DenseNet-100).  PSPNet on ADE20K, the performance 44.94 and 81.69 which are better than the best performance of the proposed method in Table 3. Further, DSSPN (ResNet-101) [27], the numbers are different from the original paper. Did you run the baseline again? Please clarify this.   Overall, the SGR layer is a simple and interesting idea. The empirical results look promising. Even if the proposed method is not very efficient, this will allow incorporating human knowledge in CNNs. I forward to more applications and extensions of this work.