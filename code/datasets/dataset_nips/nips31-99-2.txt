This paper presents a case study that illustrates how to build an AI system from existing models, existing software and domain knowledge encoded as rules. This work is mostly motivated by the need to come up with techniques to learn from existing knowledge when limited amounts of data are made available. Using "nuts & bolts", the authors present a technique to build computational pipelines that join these components to solve learning tasks. They claim that learning jointly the entire pipeline addresses potential error propagation challenges that would result from concatenating components learned independently.  The authors illustrate their work within a Newtonian physics setting where they learn to parse problems in this space, extracted from common textbooks.   I have found this work to be quite original and interesting. The experiments are convincing and do illustrate the merit of the approach. However, the paper could greatly benefit from additional use cases beyond the Newtonian physic that is presented. In its current form, it is difficult to parse out parts of the method that are generic and parts that are specific to this use case.   In general, I have found pretty much all figures very difficult to read. They are quite small.   Response to rebuttal:  The additional use case highlighted by the authors is very interesting and would add a lot to the paper. Indeed, the relation extraction from free text use case results that are reported are very impressive. While I understand that this submission is focusing on the nuts and bolt method, I recommend including these results in the paper. Based on this, I have reviewed my assessment for the work (from 6 to 7). 