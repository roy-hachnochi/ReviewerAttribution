This is a well-written and quite interesting paper achieving best-known theoretical results in a well-motivated learning setting. The authors consider a setting in which a subpopulation, sampled from the general population according to a known policy, is labeled, and the goal is to produce a reliable classifier for the general population (counterfactual learning). The algorithm additionally has access to a stream of unlabeled examples from the general population, which it can actively query for labels. The main difficulty in the counterfactual setting is overcoming the high variance that results when the subsampling policy undersamples some features. But directly addressing this variance using standard techniques works poorly in the online, active setting because the minimizer of regularized risk changes with each additional sample, making it challenging to preserve consistency guarantees.  The authors address these challenges using a basket of techniques that are more than the sum of their parts. Instead of regularizing based on the variance, they use the second moment directly for their regularizer. Instead of maintaining the best hypothesis with respect to regularized loss within their candidate set, they ensure that the best hypothesis with respect to prediction error remains in the candidate set. Instead of querying solely based on disagreement within the candidate set, they first sample according to a policy designed to reduce bias resulting from the observed subpopulation. Individually, each modification to existing approaches is fairly minor, but they combine to an algorithm with provably good sample complexity. Furthermore, the authors show how each of their algorithmic improvements is necessary for their sample complexity bounds.  Altogether, this paper represents an excellent foundation for an area deserving of further study.   ===== After reviewing author feedback, I have revised my score slightly downward. I hope this paper is accepted, but I also hope the authors will make a serious attempt to provide intuition for the myriad parameters and bounds they introduce.