Originality: There are previous works that fixes the feature representation while only adapts the task learning part for new tasks. AFAIK there's no previous work using meta learning for this. Quality and Clarity: The idea is simple and well illustrated in the paper, however the experimental protocol is less clear.  1. Does the baseline pretraining mean that the model is trained with iid pretraining and then go over the training set again with online setting? The pretraining baseline having the same name as the pretraining set makes it a bit hard for the reader. (If I understand correctly, the pretraining set means the meta-training set.) 2. In split omniglot (a), is the random batch sampled from the entire pretraining set or just those that are already observed? (b) says sampling a single class, is the training phase a one pass through a trajectory? or does it allow revisiting of the data? It needs to the clarified. 3. Note that class id is implicitly used during omniglot training where a batch is sampled from a single class, which is in conflict with the claim that no task id is used. 4. I assume the first figure of Figure 4 is not very necessary because the training phase use a random batch for meta training, so it is implicitly an iid method, it is not very interesting to see its comparison to the other methods, could even be misleading that the MRCL is performing so close to Oracle.  Limitations: 1. The evaluation with only Omniglot as the real dataset is limited, because Omniglot is known to show a favorable result for meta learning.  2. This method has a training phase and testing phase, in the training phase random sampling from previous data is required, thus the training phase is implicitly an IID method with cross validation. Only the test phase is under valid continual learning setting.  This seems to assume that we could learn on a fixed training set and fixed the representation for all future distribution we encounter. This is not true, the reason why meta learning is successful is that the meta-training set should have a distribution that is similar to the meta-test set. This is incompatible with the continual learning goal that we want to dynamically integrate new knowledge into the network.  Overall, I think the contribution of this paper is to use meta-learning (which basically means learning by cross validation to me) to find a representation that is potentially more disentangled and less prone to forgetting when adapting the prediction layer. This is a valid problem, but limited for continual learning.