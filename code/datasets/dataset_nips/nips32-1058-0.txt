Update after author response: Taking on faith the results the authors report in their author response (namely ability to identify generalization performance using only the training set, results on CIFAR10 and white noise datasets, and the quantitative evaluation of the task-switching), I would raise my score to a 6 (actually if they did achieve everything they claimed in the author response, I would be inclined to give it a 7, but I'd need to see all the results for that).  ========== Originality: I think the originality is fairly high. Although the PHATE algorithm exists in the literature, the Multislice kernel is novel, and the idea of visualizing the learning dynamics of the hidden neurons to ascertain things like catastrophic forgetting or poor generalization is (to my knowledge) novel.  Quality: I think the Experiments sections could be substantially improved: (1) For the experiments on continual learning, from looking at Figure 3 it is not obvious to me that Adagrad does better than Rehearsal for the "Domain" learning setting, or that Adagrad outperforms Adam at class learning. Adam apparently does the best at task learning, but again, I wouldn't have guessed from the trajectories. I would have been more convinced if there were a quantitative metric to support the claim that "the highest-performing networks all tend to preserve representational structure across changing tasks". (2) For the experiments on generalization, I will first note that the claim that "increased heterogeneity among hidden units correlate with improved generalization performance" is on the surface a bit counter-intuitive, because one might be tempted to associate "increased heterogeneity" with a more complex decision boundary, and more complex decision boundaries typically generalize worse. The authors provide an explanation, which is that "in order to memorize scrambled labels, the neural network must hone in on minute differences between images of the same true class in order to classify them differently.  Since most images wonâ€™t satisfy such specific criteria most nodes will not respond to any given image, leading to low activation heterogeneity and high similarities between hidden units". This is an interesting claim, but it would be better supported if the authors explored datasets other than MNIST. This is because a network could also learn to "hone in on minute differences" by learning an extremely complex decision boundary that involves the firing of multiple neurons. In fact, part of the intuition for dropout is to discourage the kind of complex co-adapted firing of neurons that can lead to overfitting. MNIST images are predominantly black, and I am wondering if this is related to the fact that the network learns to memorize MNIST by keeping most neurons silent on most images. Does the same hold true for networks trained to memorize "white noise" images?  Clarity: The clarity of the paper is good. It was an enjoyable read.  Significance: The significance is intermediate. As mentioned, the claims in the Experiments section could use more support. More generally, I did not feel that the authors have made a strong case that M-PHATE can be used to draw conclusions that one would not anyway draw by looking at the validation set accuracy/loss.  Minor comments: - There is a typo with "On the other had". - There seems to be a typo in line 111 where t was used instead of tau. - What is alpha in the formula for K_intraslice? - In line 113, the authors say epsilon is the fixed "intraslice" bandwidth - but epsilon appears in the formula for the interslice kernel, so did they mean to say interslice? - Line 123 mentions the kernel is symmetrized, though I am confused because the formulas for K_interslice and K_intraslice already seem symmetric as they involve taking the magnitude of differences. Can the authors clarify why the kernel is not already symmetric? - Please proofread line 162; the sentence is difficult to parse.