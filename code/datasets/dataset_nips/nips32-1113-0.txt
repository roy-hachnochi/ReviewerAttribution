Originality: The proposed approach using syntactic and lexical diversity modelling within the latent space to generate diverse image captions is novel.  Quality: To establish that the generated captions are diverse, various standard diversity metrics are measured for the proposed method in Tab. 2. Some qualitative results demonstrating diverse captions and diversity conditioned on different visual parse tree probabilities is shown in Fig. 5 and 6. These experiments help justify the core components of the proposed approach.  Clarity: The paper is well written and easy to follow. Careful illustrations in Fig. 2 and 3 are used as an aid while describing the proposed method.   Significance: The proposed method has comparable accuracy to GAN/VAE-based diverse captioning counterparts, and it demonstrates better diversity scores. It is a valuable benchmark for future development in diverse captioning.  Post-rebuttal comments -- The authors add additional experiments to measure edit distance between POS/words when the lexical or syntactic variables are changed, this is a good value add to earlier experiments. They address my concerns on experimental setup for baseline methods and should clarify this in the final submission. I remain positive about the contributions of the paper and maintain my earlier rating. 