This paper proposes to adopt state abstraction method to improve sample efficiency of learning the universal value function approximator (UVFA) for long-range goals. The key idea is building the high-level graph of given MDP by sampling the landmark states, which is uniformly sampled from the state space, and estimating the connectivity (edge) between them. In high-level, the transition between landmark states can be handled by planning on the high-level graph, while the local transition (i.e., current state to near-by landmark or transition between neighboring landmarks) can be handled by UVFA. The proposed method has been evaluated on Mujoco domain including navigation tasks, and significantly outperformed the baseline method: DDPG+HER. Overall, the paper is easy to follow.   However, the main limitation of this paper is the lack of contribution. The proposed method can be seen as a relatively straightforward combination of existing works: UVFA+HER+state abstraction and planning [1], which are missing in the related work section. The idea of building the high-level graph based on the sampled landmark states, and performing the planning (i.e., value iteration) in the graph to find the shortest path to the goal has been already proposed in [1]. The salient differences from the existing works are the landmark sampling, and using the value function as the distance metric between landmark, which is a relatively minor technical details. The followings are the related works that could be included in the paper. [1] Zhang, Amy, et al. "Composable Planning with Attributes." International Conference on Machine Learning. 2018. [2] Folqué, David, et al. "Planning with Arithmetic and Geometric Attributes." arXiv 2018. [3] Liu, Evan Zheran, et al. "Learning Abstract Models for Long-Horizon Exploration." 2018.  Regarding the landmark sampling step, the rebuttal addressed this issue quite well.  I suggest authors to make this point more clear in the paper. I'm increasing my score to 5.    Lastly, the experiment section is relatively light. The author might want to include other baselines such as HIRO [28] (which is already cited in the paper).   Minor comments: - The texts in the graphs are too small when printed out. - In section 6.2.1, “planning” paragraph, what is the actor network in DQN? - In section 6.3, a line break is missing before  “Choice of clip range and landmarks” paragraph.