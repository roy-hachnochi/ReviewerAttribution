[Based on the author feedback, I have upgraded my score. I think the empirical evidence for exponentiated gradient descent (+wipeout) in NAS is valuable for the community. I would suggest that the authors clearly state the limitations associated with the analysis.]  Summary:  The proposed approach for NAS treats architecture choices, i.e., intra-cell node connections as in DARTS (Liu et al., 2018), as selection among "experts". The expert weights are found via EG descent (Kivinen & Warmuth, 1997) that somehow utilizes the standard "back-propagated loss gradient" (line 113) to perform the multiplicative weight updates. It's at this point that I had trouble following the theoretical analysis given that the EG algorithm requires a loss function on the expert prediction to be specified for the development of a regret bound. The paper does not define this loss function (\ell_s() in (2)), and it isn't immediately clear to me what it could be in this context: what is the loss at the output of an intermediate node of a cell in the middle of a parent network during search? Further, the requirement in the main result that this loss be convex in its prediction makes me wonder whether the regret analysis actually holds for the setting of the paper. The experimental results, however, appear to be good enough to at least warrant further investigation into these kinds of multiplicative weight updates. Specifically, the speed of search is fast owing to either the EG descent algorithm, the proposed wipeout operation, or some combination.   Originality:  I can't speak to the application of EG to training neural networks generally, but I thought it was a clever idea in the context of NAS where hard selections among finite sets must be made.  Quality:  For the main result, a convex loss in the forecaster prediction is required. However, the paper also states that explicit loss is not assigned (line 113). I may be missing something simple, but I don't see how the regret bound holds. Can the authors provide the form of this loss function?  The experimental setup leading to the performance comparisons provided in the tables of Section 5 appears to be fair, but this reviewer is not 100% certain.  How much of the speed-up is due to the use of EG vs. EG+wipeout? (It would have been nice to see what the experimental performance would have been without the wipeout step.)  Clarity:  Both the regret bound itself, and the determination of an optimal learning rate require an absolute bound on the loss. What was this set to for the experiments? Also, I don't understand the relevance of the note in line 228 regarding the gradient clipping value. How is this important?