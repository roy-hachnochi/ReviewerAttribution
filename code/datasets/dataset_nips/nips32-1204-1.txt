=== After the author's rebuttal, I decide to keep my score.  The paper proposes a blended matching pursuit (BMP) algorithm, which combines weak-separation oracle, gradient descent and gradient matching steps to solve a smooth convex minimization problem restricted on a linear space spanned by a dictionary. Under various orders of smoothness and sharpness of the objective function, sublinear or linear convergence rates can be established for the proposed algorithm. Numerical experiments on synthetic data sets are conducted to show that BMP can achieve fast convergence and make solutions sparse. Overall, the work is interesting and important in applications with complete convergence discussion and supporting numerical results. However, the proposed algorithm seems the adaptation of the work by Braun et al. [2019] from a convex hull to a spanning linear space of a specified dictionary, which limits its novelty. In addition, computational experiments are insufficient to justify the claimed fast convergence, which requires more in-depth discussions, e.g., the influence of the matrix size $ A$, robustness to the noise, and sensitivity of sparsity levels. Other comments are shown as follows: 1. In the abstract, it claims that coordinate descent-like steps and stronger gradient descent steps which are unclear in the analysis of Algorithm 2. 2. In Problem (1), the domain for the variable $x$ should be changed to $span(\mathcal{D})$ according to the context. 3. In Lemma 2.3., the notation $(R^n)^*$ is a little confusing and could be replaced by another symbol. Likewise, $H^*$ could be confused with the dual space of $H$. 4. In line 231-232, is there any evidence to justify this statement? 5. In Section 3.1, strongly convex cases are skipped in convergence analysis, which should be commented at least.  6. Minor typos: In line 25, "lazified"? In line 40, "reader" -> "readers". In line 163, "Similarly" -> "Similar". 