The authors study the problem of statistical optimization in communication restricted setting where samples are spread among multiple machines and a central entity needs to compute an optimal estimator. Specifically, they study the one-shot model. They provide an asymptotically essentially optimal algorithm to solve the problem. They also adduce empirical results.  The main idea in their algorithm is to use approximate gradients as a proxy for the actual expected loss. Other than that, the algorithm uses discretization tricks to compute a coarse approximation of all the loss of all functions in order to find the best estimate.  The paper is well written in terms of clarity. The problem is certainly of importance, and the solution represents an important milestone in the search for distributed algorithms for the problem because it is nearly optimal. The proof of the communication upper bound requires careful work. The empirical evidence gives a final touch in convincing the veracity of the algorithm.  While the general exposition is clear, the discussion of related work needs to be more thorough. The importance of the problem should be motivated more clearly. Also, the paper has a technical improvement wherein they relax the class of functions that are being studied. The authors need to elaborate on the importance of this assumption. Without that, a reader could construe it to be nothing more than a mild technical advantage.  In conclusion, the problem is important, and the contribution is strong because the algorithm is near optimal. The analysis does not particularly involve new ideas, but it is non-trivial and requires care.    