The submission studies the adversarial online learning in episodic loop-free Markov decision processes. The importance of this work is that it is the first to provide the understanding to an adversarial online learning problem where the transition function is unknown, the loss functions are changing, and each feedback is bandit. The related work clearly describe the line of this research field from fixing an unknown transition and an unknown loss function to the setting studied in this submission. Although the MDPs considered in the submission is L-layered and loop-free, the results and the analysis pave the way for general MDPs.  The main idea is the design of the confidence sets to include the optimal occupancy measure which induces the optimal policy. Two ways to construct the confidence sets are proposed, one with the reachable probability \beta assumption and the other without. The confidence sets are also responsible for producing policies with sufficient degree of exploration. The other idea is the construction of estimated loss functions from bandit feedback, so that an optimistic occupancy measure balancing the trade-off between the loss and the distance to the previous chosen occupancy measure is computable.  Two algorithms are proposed and analyzed. When the MDP satisfies the \beta > 0 assumption, Bounded Bandit UC-O-REPS achieves an O ̃(L|X|\sqrt{|A|T}/^beta) regret. When the \beta > 0 assumption is removed, Shitted Bandit UC-O-REPS achieves a regret bound of O ̃(L^{3/2}|X||A|^{¼} T^{ ¾} ).  Originality. The submission is the first one to tackle the two challenges, unknown transition and bandit feedback, at the same time.   Quality. Rigorous and clear-to-follow proofs of the analysis are provided in the supplementary.  Clarity. The paper and the analysis are self content and well written.  Significance. The submission provides insights and solutions to the bandit online MDP learning. Although the problem instances are restricted to episodic loop-free MDPs, the submission pave the way for general MDPs.  ------------------------------ Update  Thank you for the response. The feedback from the authors is appreciated has been reflected in the overall score for the submission.