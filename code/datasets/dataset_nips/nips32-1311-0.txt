This paper considers the piecewise linear regression problem and proposes a split selection algorithm followed by a pruning operation to capture the underlying partitions of the piecewise linear model. The language of the paper is okay but it is hard to follow the paper at certain points due to the heavy notation. I would recommend the authors to provide a verbal description of the meaning of such equations and inequalities. The main idea of the paper is interesting but I'm not sure if it is enough to be published at NeurIPS. Theoretical results do not really provide any intuition about how well the algorithm will perform when implemented, although I acknowledge that proving such a result is tricky. Given that the theoretical contribution of the paper is not outstanding, I would've expected the experiments to provide more insight about the algorithm. However, the proposed algorithm is only compared against 20-30 year old methods, which does not say much about its performance. I would recommend the authors to see the following more recent articles on tree-based algorithms:  Wang et al. "Local Supervised Learning through Space Partitioning" 2012. Vanli et al. "A Comprehensive Approach to Universal Piecewise Nonlinear Regression Based on Trees" 2014. Ikonomvska et al. "Online tree-based ensembles and option trees for regression on evolving data streams" 2015.  Based on the above reasons, I think this paper is not ready for publication yet. As a side note, the supplementary material contains huge amount of typos, so I would recommend the authors to go over it carefully.