The paper discusses two important lines of works that appeared ten years ago and have become ubiquitous in inverse problems. On one side, the dictionary learning strategy, based on patch sparse coding and then averaging. On the other side, the CSC which is based on convolution filters. A unified presentation of both worlds allows authors to explain the limits of both techniques, and to propose a new CNN with improved performance.   The paper is well written and convincing, and I have only few comments: * in equation (7), I did not understand the (0,infinity) norm notation. I would say it means the level of group-sparsity, but this does not match the description "local non-zero elements". Please clarify this by providing the true definition. * The references should be polished (capital letters are often missing in the titles) * line 32: "cardinality" is often referred to as "sparsity level" * line 64: "show" -> shown