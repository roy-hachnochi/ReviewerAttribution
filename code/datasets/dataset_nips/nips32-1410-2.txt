Pros.  + This paper is well written and easy to follow  + This paper builds on recently proposed algorithms SARAH and SPYDER for non-convex problems. Its main contribution is a novel analysis, which allows stepsize to be constant O(1/L) rather than to be dependent on the desired accuracy \epsilon.   + authors provide different extensions of their method â€“ extension to proximal settings, momentum and methods for online optimization.   + all the rates outperform or match the current state-of-the-art   Cons.  - constant step size 1/2L is enabled due to big minibatch \sqrt{n}, which could be a problem for the practical usage of this new method.  - Experimental results are not appealing since the parameters are chosen neither based on theory nor any tuning. Moreover, there is no comparison to SAGA algorithm, which would be also a natural choice.  Minor: Alg 3.  - Prox (x_k - \lambda_k v_k) is used twice, while the second usage might be replaced by x_{k+1}   *** I have read the authors response and other reviews and decided to keep my score.  I strongly reccomend authors to include minibatch version and to remove stepsize of 1/2L from the definition of the algorithm to avoid confusion and make their work more transparent.