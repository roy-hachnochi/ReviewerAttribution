I have read the rebuttal. The results are technically interesting, in particular I found the result on sample size amplification from 1/n to 1/(n ln n) pleasantly surprising. However, the paper does not provide an end-to-end solution to the problem of detecting DP violation. --------------- The paper investigates the trade-off between accuracy and sample size in estimating differential privacy guarantees from a black-box access to a purportedly private mechanism. Let A be a mechanism and D and D’ be two neighboring datasets. Let P denote the output distribution A(D) and Q denote the output distribution A(D’).  Now checking whether A is (eps,delta)-differentially private can be reduced to a estimating an appropriately defined divergence d_eps(P||Q). Let A be a discrete valued mechanism A whose range is over an alphabet set size S. The first result in this paper is to show that with a simple estimator it is necessary and sufficient for the sample size n to grow as e^eps S to achieve an arbitrary desired error rate (this result marginally improves an earlier upper bound of [12]). The main result of this paper is to show a minimax optimal estimator whose error rate is e^eps S/(n ln n), thus improving the dependence on the sample size from 1/n to 1/(n ln n).  The results relies on a line of recent work on property estimation where the general recipe is to identify the regime where the property to be estimated is not smooth, and use functional approximation to estimate a smoothed version of the property.  The phenomena of effective sample size amplification is technically interesting.  My main concern is the results are narrow in their significance.  In a differential privacy verification application the fact that you have to fix the neighboring dataset D’ is very restrictive, and therefore I do not see any practical consequence of this result for differential privacy (as suggested by the title and introduction).