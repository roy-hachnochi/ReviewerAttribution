Summary: The authors present an extension of Noise2Noise that is able to deal with (in addition to noise) parametric linear image degradations such as blur. As in Noise2Noise the authors require only pairs of coresponding noisy and degraded images. Here, the to images are assumed to be created from the same clean image by applyinng different parametric distortions (such as a convolution with two different blur kernels) and then adding different instanciations of zero centered noise.  The authors distinguish bettween a non-blind and a blind setting. In the non-blind setting the parameters of the degradations are known. During training the authors use their network to process both images and then apply the corresponding other parametric distortion to each of the two processed images. The loss is then calculated as the squared error between the final results. In the blind setting the authors employ a second network to estimate the parameters of the degredation. It is trained in a supervised fashion on simulated training data, which is created from results of the first network obtained during the training process.  The authors evaluate their method on two different datasets for the tasks of reconstruction from compressed measurement and face deblurring. The results are comparable to the supervised state-of-the-art baselines.   Originality: + The manuscript presents an original and important extension of Noise2Noise.  Clarity: + The paper is extremely clear in its presentation and well written.  Significance: + I think the overall significance of the manuscript is quite high. The general idea of applying Noise2Noise in a setting witch includes (next to the noise) additional linear distortions of the image could open the door for new applications. Especially if  the assumption of linearity were to be dropped in future research, such a method might be used to reduce difficult reconstruction artifacts in methods like tomography or super resolution microscopy.   Quality: + I think the manuscript and the presented experiments are technically and theoretically sound. However, there are some open questions regarding the evaluation of the method:  - I find it remarkable that the fully supervised baseline outperforms the other state-of-the-art methods in both experiments. How can this be explained? Is this due to the unconventional architecture (two concatenated u-nets) used by the authors? If this is the case, it seems like a separate additional contribution, which is not clearly stated.  Final Recommendation: Considering that the paper introduces an original, highly significant extension to Noise2Noise and validates the approach via sufficient experiments, I recommend to accept the paper.  ------------------------------------------ Post Rebuttal:  I feel that my questions have been adequately addressed and I will stick with my initial rating.