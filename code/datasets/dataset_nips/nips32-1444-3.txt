Although the problem of exploration in a graph-structured space seems to be a pretty natural extension of the exploration problem initially proposed in other contexts, e.g., game playing environment, their proposed problem setup is not well-studied yet, thus it is a meaningful topic.  However, the novelty of their approach is very minor. The ideas of RL + GNN and RL for exploration arenot new, as stated in their related work. The idea of maintaining a graph-structured memory is not new; e.g., [1] maintains the evolution of the graph structure over time. In particular, RL + GNN + exploration is not completely novel as well; [2] studies the problem of goal-oriented web navigation,  using RL + GNN. Although their formulation is different from the exploration task, they are actually solving a harder problem where the reward could be very sparse.  Regarding the experiments, although the latter two tasks, i.e., program testing and app testing, are real-world tasks, the datasets are still more synthetic than the benchmarks used in previous work on related applications. For example, FlashFill and Karel have simplified grammars that constrain the search space for fuzzing. Why not evaluate on standard fuzzing benchmarks as in [3], and compare with existing neural, RL, and classific fuzzing approaches (you can find comprehensive baselines in [3])? If the authors can demonstrate superior performance on these more realistic benchmarks, the results could be much more convincing.  [1] Daniel D. Johnson, Learning Graphical State Transitions, ICLR 2017. [2] Jia et al., DOM-Q-NET: Grounded RL on Structured Language, ICLR 2019. [3] She et al., NEUZZ: Efficient Fuzzing with Neural Program Smoothing, IEEE S&P 2019.