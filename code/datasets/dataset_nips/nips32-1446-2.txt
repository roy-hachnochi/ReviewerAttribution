[Replies to author feedback] I thank the authors for the provided answers, in particular the extent to which the extensions concerning sample-wise covariate may prove useful.   Originality: the problem of considering test distributions different from the input distributions one is not new, and the originality of the paper mainly lies in showing that it can be achieved for conformal prediction, provided we can find a map from the training to the test distribution (in this case, by estimating a likelihood ratio). I also missed the discussion of relations with techniques such as transfer learning, and also importance sampling ideas (admittedly less connected, but I think relevant nevertheless)  Clarity: the paper is quite clear.  Significance: this is maybe the weakest point of the paper. In particular:  - The experiments are more a proof-of-concept than a demonstration that the method is competitive and applicable. In particular, conformal prediction having been designed to perform instance-wise covered predictions, it is unclear how much the idea of storing shifted observation is realistic? Or could we detect the drift incrementally?   - The interest of the last part, substantiated by Theorem 2, is unclear to me from a practical point of view. I understand this generalizes previous results, but how practical is a setting where each data point may be "drifted" or may come from a different distribution? How could we solve the estimation problem in such a setting? In short, what is the added value of this generalisation (beyond being a generalisation)?   Typos: * P2, L3 after top: for multiple instances OF the same 