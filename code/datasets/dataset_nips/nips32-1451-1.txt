I read the author feedback. Thanks for clarifying how the analysis of the case p=2 is different than prior work. ---------- The paper considers low-rank matrix approximation in l_p norm for any p>=1. One of the popular approaches in this area is to construct a rank-k approximation of an n x m matrix A from a subset of k columns of A. This restriction is natural in practical settings when columns represent data points and we want to find a small but representative core-set of data. While this problem is well understood for p=2, this is not the case for other l_p norms which offer advantages in terms of robustness and sparsity of the solutions. Prior to this work, Chierichetti et al (2017) [13] showed that for any p>=1 a subset of k columns can always be found such that the l_p approximation error is within a k+1 factor of the optimum, while for p=2 Deshpande et al (2006) [14] showed that for p=2 a factor of sqrt{k+1} can be achieved. The results of this paper close that gap by showing that we can achieve a (k+1)^{1/p} factor for 1<=p<=2 and (k+1)^{1-1/p} for p>=2. This matches the best known factors for p=1 and 2 but improves them in all other cases. New matching lower bounds are shown for p>=2. While algorithmic efficiency is of secondary concern in this paper, the main results imply improved guarantees for existing polynomial time algorithms for this task. It is worth noting that the cases of p=1 and 2 are still the ones with primary practical interest, and it would be helpful if the authors found a reference to an applied paper showing the advantages of low-rank approximation with l_p error for, say, 1<p<2 (which I donâ€™t believe they did).   Overall, despite limited practical implications, closing the theoretical gap in l_p low-rank approximation via column subset selection is a nice contribution, and I think the techniques used in the paper, such as using exponentiated determinants as weights and employing Riesz-Thorin Theorem, are very interesting. The paper is also well written.   Questions: 1. The approach of using determinantal weights seems quite similar to that of Deshpande et al (2006) [14] for p=2 (I think this would be worth pointing out and comparing). They suggest using a randomized sampling procedure (which is known to be efficient) that achieves the same guarantee in expectation. Is the same approach possible here? 2. The proof of case p=2 in Lemma 2.2 seems quite involved, even though intuitively this should reduce to the result in [14] (and their proof is rather short). Is the p=2 case of Lemma 2.2 a significant generalization of what was previously known?  Comments: - The punctuation and sentence structure in Lemma 2.3 is rather confusing.