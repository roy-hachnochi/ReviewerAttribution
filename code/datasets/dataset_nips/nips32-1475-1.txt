After Rebuttal:  The clarification of the negative result is still not sufficient. The authors keep saying "difficult" what does that mean? If theorem 4 is only a condition for checking calibrated surrogates, it actually reduces in value. The authors should make a serious effort into making a mathematically coherent impossibility result and not just state this is "difficult".  I also disagree that the excess risk derivations are complicated. Simple application of Pinsker's inequality will transform the excess log loss into a l1 norm distance, which can be easily converted to a excess abstain loss risk.  Before Rebuttal: Summary: The authors consider the problem of multiclass classification with a reject option. Assuming the "cost of abstaining" is a constant, the authors analyze various surrogates and determine whether they are "calibrated" to the abstain loss. There are two main paradigms for building abstaining classifier : 1. confidence based: build a scoring model, and abstain if the scores are not "confident" 2. separation based: build a separate rejector and scorer, and use the scorer to classify all instances that have not been rejected by the rejector. The authors argue that the separation based methods cannot be calibrated, and showstandard confidence based methods can be made calibrated by use of an appropriate threshold for rejection.    Review:  The main contribution of the paper would be an attempt at showing the impossibility of "separation-based" calibrated surrogates. (Theorem 4). Theorem 4 looks correct and indicates some problems with a surrogate that has to be calibrated with the abstain loss, but there is no concrete impossibility statement. Lines 150 to 155, try to make this precise but it is not particularly clear. This should be made into a theorem or a corollary. I am guessing it should be something along the lines of "if the surrogate is convex in r, then it is not calibrated w.r.t the abstain loss". If this is what the authors mean, they should state and prove it instead of asking the readers to look at a statement regarding the derivatives and intuit it.  The section on confidence based surrogates is standard, and cannot be considered an original contribution. It is well known that with a proper multiclass loss, the class probabilities can be estimated, and the form of the confidence predictor is exactly the same as the form of the Bayes classifier. There are some excess risk bounds derived in theorem 7 and Table 1, but these are not particularly original and such bounds can be derived using previously known techniques , (a la Steinwart, Bartlett et al.)  The empirical results are not particularly impressive (or original, as the algorithm proposed is simply standard multinomial logistic regression). The APC,MPC methods have been argued to be sub-optimal in theory and are shown sub-optimal in practice, which is just a little bit satisfying.