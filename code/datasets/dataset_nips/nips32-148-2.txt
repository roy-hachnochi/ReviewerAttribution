Overall I think this paper raises an interesting perspective to understanding adversarial generative models. I think this paper has some value by raising the question and offering some interesting experimental results.   The theory is quite standard, the authors first cite a relationship between differential privacy and RO stability, then cite that RO stability bounds the generalization gap. The short coming is that the theory only analyzes the discriminator, which do not seem much different compared to previous work analyzing classifiers. It would be much more interesting and novel to see an analysis of the joint learning process of generator and discriminator.   Experiments: The experiments show a correlation between regularization, less information leakage and reduced generalization gap. In particular, to show information leakage, the authors propose a simple scheme of using the value of the discriminator output to decide if an image is from the training set. I am actually surprised that such a method could work.   I think some of the claims regarding the experiments are a little strong, as their relationships are not necessarily causal. But of course, it is extremely hard, in almost every deep learning setup to establish strong causal relationship between change of modeling choices and change of performance. So I will not over criticize this point.   The writing is generally easy to read. There might be a typo on line 249 where the \leq should be a \geq.   --------------- After rebuttal Thank you for your response. I would like to maintain my score after the rebuttal, for the following reasons:  I think the proposed theoretical improvement are hard to materialize. For example, it seems that composition of differential privacy will lead to a very loose bound, as information leakage will add up. I do not know if practical results can be obtained.  I think overall the paper is of okay quality, the perspective is interesting, the writing is good. It's not the most novel or surprising paper, but I am happy to see this paper accepted at NeurIPS. 