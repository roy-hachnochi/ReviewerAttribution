Comment following the rebuttal: Dear authors, thank you very much for your response! I've read it and I'm happy to see the initial additional results on ImageNet like the component visualization at the top I think these are really useful. Overall after reading the paper, all the other reviews and the rebuttal, I feel I couldn't raise my score mainly because of the valid concerns raised by the other reviewers.  The paper proposes a new type of recognition model: Given an image, it classifies it by performing a probabilistic reasoning process that considers the existence or absence of various components - indicative aspects of the object, and then combines together the evidence in a probabilistic (and thus potentially more interpretable) manner to output a final classification. The idea is interesting, and multiple experiments are provided to support it. The paper itself is also well-written and clear.  - The related work section mentions prior work about Siamese architectures and Prototype classification, and also mentions that the idea about patches has been explored in past work. It would be great to add at least a brief discussion of how the new model proposed here differs from these prior approaches. - It would be nice to run ablations/variants of the model having e.g. only positive+neutral or only positive+negative, or even negative+neutral, and observe how each of these settings affects both quantitative performance and qualitative behavior. - Another potential direction could be performing any sort of a head-to-head comparison to a standard CNN. It may be the case that standard filters will also in practice learn to recognize the existence / absence of different patterns. Any sort of head-to-head comparison, either of how the filters vs components look, or measuring any numerical properties of them, could provide an important insight into how the new model compares to classic CNNs. - Continuing on this point, in the related work section, the first paragraph explains how standard neural networks can be interpreted as performing similar sort of reasoning where the weight signs indicate whether the reasoning is positive/negative. Then, it says that the use of ReLU is what prevents such an analogy. But using ReLU instead of e.g. sigmoid/tanh is exactly what made CNNs training better and faster and increased their stability [1]. Even though it doesn't have the probabilistic interpretation as in your model, it proved to work extremely well. Going “a step backwards”  in a sense to constrained squashed activations makes me wonder about the scalability of this approach. Indeed there are experiments over ImageNet that explore a variant of the model, which is great, but I think further experiments that compare in this case e.g. learning curves, convergence rates, or again any other additional comparisons with CNNs would be very useful.  - Looking at the examples in figures 3 and 5 makes me wonder to what degree the model may in practice find good clustering of the data and capture each center as a template/component, in which case the model might perform in a sense a bit of a nearest-neighbor search to one of the templates and classify the image to the closest center (?) Then, such an approach will work well when there are few object classes (MNIST, CIFAR10), but I think it is particularly interesting to explore further the behavior of the model when there is a much larger number of object types to recognize. Again, the paper indeed provides some experiments for ImageNet mentioning it gets comparable performance to existing approaches, but here also I think that actually more qualitative experiments over ImageNet would be really useful to understand how the model scales. - For the classification part, why did you choose contrastive loss and not e.g. log-likelihood loss? It would be good to either provide an intuitive explanation for that, or experiments with both types of losses.  [1] Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." In Advances in neural information processing systems, pp. 1097-1105. 2012. 