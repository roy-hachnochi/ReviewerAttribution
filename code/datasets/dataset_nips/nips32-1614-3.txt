The authors provided a proof for the linear convergence rate of the relaxed EXTRA algorithm for synchronous decentralized consensus optimization.   Modifications to existing methods are minor since the same relaxation and additional non-smooth regularization have been used on the same problem in the literature. The contribution is therefore in the proof of the linear rate under the assumption of strong convexity of each local objective function. The proof technique is standard as appeared in related works. Numerical experiments are carried out for a decentralized logistic regression problem.  The contribution of this work is incremental but not significant. The proof requires strong convexity of all local objectives and synchronized communications which are very strict in practice.  -- After response I read the response, but I'm still not convinced by the novelty and significance of this work.   Similar linear convergence rate has been established for EXTRA and decentralized linearized ADMM in the literature, from which the proposed algorithm adopted the main structure. The additional extrapolation and non-smooth convex R (when handled by proximity operator) are only minor changes from the existing method and do not introduce much difficulty in convergence analysis from the optimization point of view.  The significance to the ML community is also limited with the (restricted) strong convexity assumption and synchronous setting. I also disagree with the authors on their claim that the analysis in their work can be used to prove linear convergence rate for asynchronous setting, which is greatly complicated than the synchronous setting due to the excessive randomness in communications etc.