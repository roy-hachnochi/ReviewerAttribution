The paper unifies the work of the multi-modal and multi-domain translation, each existing separately so far.   It provides a novel combination of techniques, so far used to solve each problem alone, in order to solve the unified problem. For example, an adversarial loss is used in the embedding space of the common encoder and a reconstruction loss is used to reconstruct the input from  the common, separate and domain information.   Such techniques are used to achieved disentanglement for 2 domains only in, for example Munit and [1].   In that sense, the novelty exists in combining those existing techniques from previous works in a clever way. However, each part in isolation (style encoder and embedding, etc) is not novel.   The qualitative and quantitative evaluation is very convincing showing that the use of additional domains (and thus additional supervision) can improve disentangled translation. There seem to be a large gap in FID and other scores for semantic image synthesis compared to season transfer. Could the authors comment on why this is? Further, the ablation analysis and comparison to baselines is very thorough.   One concern I have is whether the work is able to perform image to image translation between domains where the difference is not only in style. For example, in the celeba domain, considering domains with different attributes (e.g facial hair, glasses, smile). In this case the facial attributes are common to all domains, and the additional attributes (facial hair, glasses smile) is separate. However, since the separate encoder is constructed so as to model only style/global properties, and the additional attributes are content, how would the translation work in this case? Is this a limitation of the work? [1] should be considered for this case. Could the authors comment on any other limitations of the work?   With regards to clarify, the paper is very well written and clear. The overview in Fig. 3 is also very clear.   As for significance, the work seem important for practitioners, providing superior results to state of the art results so far. For future research, as the underlying ideas used for the solution already exist in previous work (adversarial loss, reconstruction loss, etc), I am not sure if ideas from the work can be built upon and how. Apart from (rather significant) visual and numerical improvements, are there any observations about the results, or new insights that this work provide?  [1] Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer. Press et al. ICLR 2019.  