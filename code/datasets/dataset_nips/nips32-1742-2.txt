While I think that the idea definitely worth it, I have some doubts about the fact that the paper is ready for publication. Indeed, it raises some questions that should be treated. Here is a list below.  1) The node distribution is set as the normalized node degree (as in [48]). This choice should be discussed in more details as it is not obvious and may be redundant with matrix C. Why a node with more connections should have a greater weight than others?  Why the adjacency matrix not enough for enforcing nodes with similar node degree to be matched? Anyway, this choice deserves a detailed discussion in the paper.   2) The method is applicable to non-attributed graphs (this should be mentioned in the paper). Nevertheless, in section 3.1, authors provide a extra term in the GW formulation, C_node, that involves the differences between the 2 node distributions. The formulation then seems to come down to a GW term <L(C_s, C_t, T),T> + a W term <C_node,T> as in the fused Gromov-Wassertein method in [43]. Is this correct? If not, the differences should be highlighted. In addition, would it be possible to consider an other C_node matrix that would involve node labels?  3) Authors consider an entropic version of the GW distance, allowing a faster resolution of the problem. Nevertheless, at least for the graph partitioning problem, considering a non-regularized problem seems to be more intuitive: a node is matched to only one (in most cases) node of the disconnected graph. This is illustrated in figure 1b), where we would have preferred to see the first 3 nodes matching to one node and the 3 others to an other one, instead of having 2 nodes with splitted mass. Authors should justify this choice in more details.  4) the multi-graph partitioning scheme is unclear to me. Does it consists in i) first estimating the barycenter of all the graphs ii) then partitioning the barycenter? In figure 1d), it is not clear what does the transport matrices represent (transport to the barycenter or to the disconnected nodes?). The motivation behind the multi-graph partitioning should also be better explained.  5) A scalable algorithm is given in section 3.2. A discussion about how the results are close of the original solution, and in which cases it can be/should not be used is needed. Indeed, in the experiments, it leads to degraded performances, and this behavior should be better understood.  6) Algorithm in section 3.1 seems to be a direct extension of the algorithm provided in [48]. Originality of the algorithm should be better highlighted.   Minor comments: - page 2 "we propose a GW learning framework to unify these two problems": the method proposed to solve these problems is the same but the two problems are definitely different. - regarding the density \mu: what happens if the graph contains isolated nodes? Are they discarded? - page 3 "the maximum in each row indicates the cluster of a node": what happens if some quantities are equal, as it seems to be in fig. 1b)? - page 3: the derivation of the node distribution \mu_dc is probably the most important quantity to be set and its computation details should not appear only in the appendix - for the graph partitioning problem, how do you choose the K value? - in several parts of the paper, assumption that the observed graphs have comparable size is made. Is this a reasonable assumption?   **** UPDATE AFTER REBUTTAL**** Thanks for your feedback that I read carefully. It adresses some of my concerns (points 3-4-5-6). I believe that the choice of the node distribution, the cost matrix and C_node should be discussed in more details (all of these seem somehow redundant and some insight about how to set "good" definitions should be added).  As such, I modified my score and set it to 6.  