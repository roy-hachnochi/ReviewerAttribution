Positive:   - Overall, I feel that the paper provides an interesting contribution that may help to work toward applying RL to real-world problems where an agent interacts with the physical world, e.g. in robots.  + reproducibility: The authors promised in the authors response to make their code available.   Negative:   - One problem I see with the paper is that it is unclear at this point whether this line of work is necessary because with increased computing power on embedded devices such as robots, the inference time of most methods turns out to actually be neglible (millisecond range or faster). I feel that this point might be alleviated by providing a series of experiments (e.g. in the driving experiment proposed in the paper) where the agent is assumed to be super fast, very fast, fast, not fast, really slow - and show how that impacts the performance of the SAC method.   - another problem with the paper is that it is partially hard to follow the notation and reasoning (see more details below). -> which the authors have promised to improve in their response.   more detailed comments:  line 29: it is hard to udnerstand what the authors mean with "one time-step" here - it becomes clear later that the authors refer to one agent/environemtn step here - but this could also be read as "the agent is really, really fast" -> this is not a big problem though because it becomes clear later (and the figures next to the text also help). Maybe just referring to the figure inline here would already address make this much clearer and prepare the reader better for the rest of the paper.   sec 3, first paragraph: the authors start using u for the action and it is difficult to follow here why a new symbol is used there. Maybe stick with a?   lines 69ff:   - t_\pi is not defined (and I read it as the time it takes to evlauate the policy.   - t_s is not defined (and I don't actually see how it is different from t_pi - maybe just use a single symbol here (there is a bit of discussion about choosing t_s to be larger or smaller than t_pi - but I don't see the point in that  sections 3.1 / 3.2:  This is quite confusing:   Section 3.1 defines RTMRP(E) as an environment that behaves the same with turn-based interaction as E would behave with real-time interaction. Section 3.2 defines TB(E) as ? - and RTMRP(TB(E)) as ?  It feels like this shoudl be TB(RTMRP(E))?   Overall, I do understand that these sections are describing augmentations/reductions that convert real-time RL environments into turn-based environments and vice versa but the description and the notation are quite confusing to me.   Maybe it would be easier to follow if:   E_{rt} is a real time environment  Figure 3/4: could be merged which would make it easier to compare the performance of the "working" SAC with the RT methods.    