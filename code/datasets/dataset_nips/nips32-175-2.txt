The authors propose a new method for inferring vision and language navigation using Bayesian filtering and state tracking .  The paper was well written up to some equation nomenclature and acronyms but still very easy to follow and I think it is indeed innovative to extend the simulator for the purpose of learning as a synthesis of two different fields. This submission would definitely advance the fields, the ability to generate more realistic training grounds for VLN model can present a huge advantage.  The experiments were also truly convincing (nice touch on the videos of the problem). Yet there are a few things I would be happy to have been clarified or that are unclear. The first and I think by biggest question is how does the state rejection mechanism compare to the one of Weib and et el https://arxiv.org/abs/1511.06458. Can one think of the language component as a refined prior ? In the abstract can you please expand on what do you mean by a strong baseline?  Line 134 what are XY ? Line 147-150 is a bit of a mess of definitions and notation   