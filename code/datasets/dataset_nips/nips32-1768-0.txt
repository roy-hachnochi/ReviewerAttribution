post-rebuttal update: I'm increasing my score from 5 -> 6. My main concerns were: - novelty WRT [34]: I didn't update on this; it doesn't seem very novel, but that's not a deal-breaker. - experiments: The new results are more convincing (but still could be stronger). Quality 4 -> 5 Overall 5 -> 6  Overall, this seems like a nice paper, but I found it hard to evaluate given my background. I also with the authors had given some intuition for the theoretical properties of their method. My main concerns are over the originality (it seems very similar to [34]), and the weakness of the experiments.   Originality: 5/10 This paper seems mostly to be about transferring the more general result of [34] to the specific setting of constrained MDPs. So I wish the authors gave more attention to [34], specifically: - reviewing the contribution of [34] in more detail - clarifying the novelty of this work (Is it in the specific design choices? The actor-critic algorithm?  The set-up in lines 532-542 (Appendix)?  Is it just in noticing the suitability of [34]'s results for CMDPs?) Without this help from the authors, it's difficult for me assess the originality and significance of their work. At the moment, it looks to me like a pretty straightforward application of [34]s results to CMDPs.  Quality: 4/10 Overall the paper seems technically sound and well-done.  But the experiments seem like an after-thought and/or purely illustrative, since: 1) they aren't included in the main paper and 2) they don't include multiple trials for significance.  I also didn't find the content in section 5 particularly valuable; I think experiments would have been better.   I'm also not familiar with the setting (LQR), or previous work using RL for LQR (with or without constraints), and the authors' summary didn't give me enough context to interpret the strength or meaning of their results. The abstract and introduction also over-claim, stating that they "apply" the algorithm to multi-agent RL; but there are no experiments for that setting, only description of how it could be applied.  Clarity: 7/10 The paper is mostly quite clearly written, with a few typos. The following should be clarified: - the novelty compared with [34] - the significance of the experimental results - the main baseline being methods with Lagrange-multipliers - the motivations from safety: i.e. this doesn't tackle safe exploration, right? It's for safe execution? How exactly would this kind of method be used to make a safe real-world system?  What problems does(n't) it solve?  For instance, is it possible to verify that constraints will be satisfied?  In practice, do CMDP approaches out-perform incorporating constraints as large negative rewards (when)? Also, *some* intuition for the proof should be given.  This should include both the intuition underlying the proof strategy from [34], and an explanation highlighting the differences and the explaining what the issues are the require modifications to their proof.  Significance: 7/10 The introduction presents a strong case that (in some theoretical aspects) this work represents a significant step up from the standard approach to CMDPs, based on Lagrangian multipliers.  A table summarizing different approaches to CMDPs and highlighting the advantages of this work over previous approaches might be a nice addition. However, without stronger experiments, I don't think the paper presents a strong case that this method will be superior to existing methods in practice.   Some detailed suggestions: - Line 85: "minimize (1)" --> "maximize (1)" - Line 109-110 and line 83 are redundant - Algorithm 2: beta_w/v are not defined; initial values of delta^J/D are not defined - line 201: "and their are" --> "and their derivatives are"  (I think?) - line 261 (right hand side): PF_k --> P_{F_k} - I suggest renaming Q1, R1, Q2, R2 as Q_J, R_J, Q_D, R_D  Some Questions: - Appendix: what's the difference between figure 1a/b and figure 2a/b? - Line 152-153: why can a solution be written in closed form? (explain or reference). - Line 186: how/why does actor-critic "improve the performance further"?  And is the improvement in terms of performance, rate of convergence, both, neither?  And how is the claim (of improved performance) supported? - is finding a stationary point good enough?  why can't we do better? (e.g. local minima?) - What is the state of RL research on LQR?   How does it compare with other approaches? Is studying RL algorithms in LQR interesting practically, scientifically, or both?  Some high level questions: - what are the key contributions of this work compared to [34]? - what are the key challenges for the proof? - what is the point of section 5?  [34] An Liu, Vincent Lau, and Borna Kananian. Stochastic successive convex approximation for non-convex constrained stochastic optimization. arXiv preprint arXiv:1801.08266, 2018 