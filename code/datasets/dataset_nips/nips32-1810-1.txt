Summary: This paper presents an approach for solving machine learning tasks that require the prediction to be presented in the form of a set. The authors propose to use the set encoder (which is composed of permutation-invariant operations) at the prediction phase by finding an output set with an optimization procedure. As the model output is a vector of continuous features for each set element, it can be done by means of nested gradient descent optimization. In order to solve the task of set prediction for external feature vector, the work suggests a combined loss function that encourages the representation of ground truth to be close to obtained features. Results are shown on MNIST and CLEVR datasets and outperform those of an MLP baseline. The proposed approach is a promising new direction in the area of set prediction, although the choice of baselines makes the experimental setup less convincing.  Quality: The paper argues that ignoring the structure might yield suboptimal results for the task of set prediction due to the responsibility issue, illustrating that with a simple example. The experimental setup, however, is not entirely convincing regarding the demonstration of method superiority. In particular,   1. For the experiment on MNIST there are no quantitative results to evaluate the quality of both approaches; if no generally accepted metrics for this kind of task are known, it should at least be possible to use Chamfer loss or Intersection-over-Union score for comparison.  2. Secondly, the baseline approach seemingly underperforms by a large margin in all experiments, especially in the MNIST autoencoding task, thus rendering the claims of superior performance as compared with existing methods less sound. It would help the paper if the authors provided results of previously existing methods more suitable to the task of set prediction, such as simple sequence-to-sequence models (even if the order is arbitrary) based on recurrence or self-attention or approaches like (Rezatofighi17). 3. For the MLP baseline on MNIST dataset, it appears that the main issue resides in the inability of the model to predict a discrete mask with high quality; it might be useful to compare both methods on the task of fixed cardinality set generation.  4. Additionally, although the paper uses FSPool for encoding the input set, there is no comparison with FSUnpool, which was proposed in the same work as FSPool for decoding a set from its representation. Furthermore, sorting the features in the encoder and not restoring the order in the decoder can be harmful for the training process; can that be one of the reasons for poor performance of the baseline model?  Originality:  To the best of my knowledge, the method of predicting a set with the use of an encoder and iterative optimization is a fairly novel idea. The authors also provide proof of permutation invariance of the gradient of any permutation-invariant function, which was not shown before in relevant works on the subject.  Clarity: Overall, the paper is well-written and clear; the authors provide a detailed description of the experiments which should be enough to reproduce the results.  Significance: This work provides a unique approach to the problem of set prediction for autoencoding as well as generating a set from external representations, such as those obtained by CNNs on images. Right now it is not entirely evident whether the idea works better than currently known methods in practice, but I expect a more thorough experimental comparison to clarify that.  (Rezatofighi17) Rezatofighi, S. Hamid and G, Vijay Kumar B. and Milan, Anton and Abbasnejad, Ehsan and Dick, Anthony and Reid, Ian. DeepSetNet: Predicting Sets with Deep Neural Networks. ICCV 2017.  ---------------------------------------------------------------------------------------------  I would like to thank the authors for addressing my comments. The answers to most questions are clear and give enough details for a better understanding of the approach proposed in the paper. Provided that the authors add the stated experimental results (metrics on MNIST dataset, results of LSTM baseline on all datasets, ablation study with poolings other than FSPool) and address all questions raised by the reviewers in the final version of the paper, I will raise the score of this submission.   I would especially like to see the quantitative results on MNIST for the fixed size set prediction task in the final version. Even though it is simpler than the problem considered in the paper, currently the MLP baseline seems unsuitable for variable size set prediction, which harms the credibility of this experiment.