# Originality The paper clearly explains the previous work. It builds upon the success of GLUE, and combines it with (1) new desiderata for task selection, (2) new governance, and (3) human baseline evaluations.  # Quality The key claim in the paper was that SOTA LMs perform much worse on SuperGLUE than humans do. This claim was well supported by the experimental results in the paper.  # Clarity The authors clearly explained how they evaluated the humans and the models to form their baseline, as well as the criteria used in selecting the baseline.  # Significance This is the most difficult and comprehensive benchmark that I have seen for LMs, and I expect that it will help drive further research progress for the community.