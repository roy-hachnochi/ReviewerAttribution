This paper introduces metrics for quantifying the fairness of a personalized intervention (with binary treatment & outcome) that are analogous to fpr/tpr in the classification setting. They show how these metrics are identifiable under the assumptions of strong-ignorability and monotone treatment response (treatment is never harmful).   Developing appropriate measures of fairness for personalised interventions is an important questions, with significant potential application and this paper is well structured and clearly written. The identification results themselves are not particularly novel as similar results have been proven in other settings, but the context is new.  I have read the author response and other reviewers comments and maintain that this paper is worth accepting because:  ML systems recommending personalised interventions in sensitive settings, such as improving educational results or reducing recidivism are widely encountered in practise in areas where we are concerned with fairness. So this paper represents an important attempt to extend existing fairness metrics to this more complex setting.   While I think it the appropriateness of quantifying fairness in terms of metrics that are not identifiable without monotonicity assumptions (even with unlimited randomised experimental data) remains up for debate, this is a debate that is worth having within the NeurIPS community. This paper is well written and argued and represents a good starting point for that debate.