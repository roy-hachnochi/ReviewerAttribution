After reading the author's reply, my review is unchanged; I still support acceptance. (I'm not sure including an image which contains a lot of text at half the font size, plus new plots, is appropriate to include in the author's reply, but I would let it slide here.)  The main reasons for my unchanged score: 1. Even though this work doesn't push the state of the art on a new task, it presents useful and interesting information, which really is the goal of research.  2. While I don't think these exact results will hold on more difficult datasets, or those in other fields (like text classification), I do think similar trends would exist. 3. While the authors don't speculate on how their results could be used, their experiments were conducted well enough that I believe they will be useful to future researchers. For example, I'd like to see a paper following up on this which does an indepth analysis of the types of structures learned using such masks, which would lead to better neural model structures. Similarly, I'd like to see a paper analyzing the initializations, and leading to better initialization schemes. These both seem beyond the scope of this work, but would build directly upon it.  My original review is below. ===================================  This work is original, as I don't believe these mask criteria have been analyzed before. That said, this work doesn't draw connections to the rich history of pruning methods, even though many are similar (perhaps that should be another paper altogether, though). The quality of the work is fairly high, though there are a few missing experiments (like the trained performance of the supermasks). I believe future work will build upon the results in this paper, and that it is significant.  It's good the authors include detailed descriptions of the models used in the appendix, instead of just relying on referencing previous work.