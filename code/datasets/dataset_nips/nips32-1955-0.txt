Originality: Many, if not, all of the techniques have been previously proposed. However, to the best of my knowledge, combining these techniques to scale energy-based models to modern deep network architectures is a novel contribution. Energy-based models are far less popular than other forms of generative models. While some recent energy-based approaches exist (e.g. auto-regressive energy machines), this paper demonstrates a new degree of empirical success.  Quality: The paper is thorough. The authors present a comprehensive set of experiments, with multiple downstream applications. Various metrics are evaluated for quantitative comparisons in each case. This is above and beyond what is expected. The one aspect that I feel is lacking is a larger discussion about the drawbacks of this approach. In the supplementary material, the authors discuss the training time and inability to evaluate log-likelihoods. It would be helpful if some of this discussion also appeared in the main paper.  Clarity: Overall, the paper is clear. The discussion of energy-based models and training techniques (Section 3) is clear and helpful. Some additional technical details would have been useful. For instance, the paper would benefit from a comparison of the number of parameters, sampling time, training time, etc. Some details regarding the experiments were also unclear, particularly the set-up / training procedure for the robot hand trajectory experiments. Iâ€™m also not very familiar with the adversarial examples literature, and I found the adversarial robustness section (4.3) somewhat difficult to follow.  Significance: The empirical demonstration of good generative performance with energy-based models on modern image datasets is significant. This may help to re-open this family of models as another option for generative modeling. Currently, these models are not very popular within the community. The other most significant aspect of this paper is the demonstration of improved out-of-distribution evaluation as compared with other methods. This is a recently discovered phenomenon, and the fact that these models do not suffer as much as other families of models could open directions for further study.  ---  Updates:  I'm satisfied with the author response and increase my score to 9.