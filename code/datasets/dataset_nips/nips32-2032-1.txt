The proposed approach emits ultrasonic pulses and records the reflected echoes with multiple microphones. The audio input from the microphones is converted to  spectrograms by using short-time fourier transform. The spectrograms are given as input to an encoder-decoder neural network architecture which is inspired by bat's auditory system and which is trained to output a volumetric voxel presentation of the scanned objects.   The paper presents also a dataset where different objects are recorded with a custom-made echo scanner which can be rotated around the objects. The shape (and pose) of the scanned objects is known during data acquisition and can be used as a ground truth for training the network.   I think that this paper addresses an interesting problem area which is apparently not much covered in machine learning previously. The proposed approach seems novel and contains lots of innovative design choices from experimental measurement setup to computational signal processing architecture. The obtained results look good. Since I am not an expert in the field of ultrasound or bats, I am a bit cautious to give strong recommendation. 