1. Originality. As some of the definitions of calibration error, plugin estimator and debiased estimator, etc. were already proposed before, the authors' main contribution lies in their putting the existing works and definitions together to form a more complete statistical framework for estimating and evaluating the calibration error. The other contribution is that the authors propose a new calibration method by first fitting a scaling function and then binning the scaling function outputs and prove that it has better properties in terms of sample complexity and measurability.  2. Quality. The claims in the paper are validated by experiments on 2 image classification datasets, CIFAR-10 and ImageNet. The authors provide code for reproducibility. One of my concerns is that the authors claim that the theory is presented for binary classification setting, while the experiments are performed on multi-class classification. It is better to conduct experiments on binary classification as well to validate the error bounds given by the theorems and extend the theorems to multi-class settings.  3. Clarity.  3.1 The notations are confusing and contain some typos. The authors should give a clear definition first for the notations used in the theorem/definition. Definition 2.2-2.3 should state clearly the expectation is taken over which distribution. M(X) used in Definition 2.2 and 2.3 is not defined. Definition 2.3, in the bracket should be top-label calibration error Definition 2.4 P(j) should be P(k) in my understanding Definition 3.1 misses a term that the authors want to define. It is better to define I_j again. Definition 4.2, it should be alpha >= 1.   4. Significance. The authors provide a more complete statistical framework for estimating and evaluating the recalibration error. The theorems and the methods are likely to be used and compared by future researchers working on uncertainty calibration. However, one of the limitations is that this framework requires the well-balanced binning property holds, but this may not always be satisfied on real data.