The main issues of the paper are in the training of the meta quantizer (most of which is discussed in section 4.2).  - In eq. (8) the term \partial \tilde{W} / \partial \phi is needed in the backward phase. However, from the solution setup description provided by the authors, \tilde{W} occurs before \phi in the computation graph. I fail to see how \partial \tilde{W} / \partial \phi can thus be computed, or even what it represents. A clarification from the authors would be appreciated. Note, it could be that auto-differentiation does not crash when this gradient is called (and this could explain why the method runs) - however, that is not enough evidence, a deeper explanation on what the term means and how it is computed is required.  - Still in eq. (8) there seems to be a chicken-egg problem. The term \partial L / \partial \tilde{W} is replaced by M(...), the output of the meta-quantizer. This means that the dependence on the loss function L is suppressed and the updates based on the gradients computed in eq. (8) do not in fact operate to minimize L. The authors should clarify how the meta-quantizer is linked to the loss function.  - This brings me to my next point: should the loss function of the base network be used for training the meta-quantizer? This seems not to be very well thought about. The two networks have different tasks, and the meta-quantizer is a regressor. A convincing discussion is needed to address this issue which I think is the main weakness of the paper as it stands.  - Finally, I would like to point out to the authors that there are many writing imprecisions that severely harm the quality of the paper. For instance, some symbols are utilized without being defined/introduced (e.g., the boldface 1). The notation is inconsistent: for instance L is used to denote both the number of layers and the loss function. There are some typographic mistakes, e.g., 'outperforms' does not require a hyphen, and the same applies to 'fully connected' etc..  Post Response Comments: I thank the authors for their response. The feedback from the authors has helped me better articulate my issue with the proposed method, which I believe is very serious. Indeed, in the rebuttal, the authors show at line 22 how the computation occurs: "phi -> delta W -> W tilde -> W hat -> L". Clearly from Figure 1 in the rebuttal document, the link between W tilde -> W hat is a quantization operation, which is non-differentiable. So, back-propagating gradients from the output of the main network to the meta quantizer suffers from the same problem of non-differentiability the authors so vehemently claim to have solved. Further, note that the rebuttal provided strongly disagrees with a key claim in the main paper on line 140: "Therefore, M_phi is connected to the final quantization training loss, which receives gradient update on phi backpropagated from the final loss... MetaQuant ***not only avoids the non-differentiability issue for the parameters**** in the model, but also...". Obviously, this backpropagation goes through a non differentiable step along the way (W tilde <- W hat) and so the problem is not solved, it is simply delegated from the main network to the meta-quantizer making the contribution void. I have therefore decided to decrease my score by one point (from 5 to 4).