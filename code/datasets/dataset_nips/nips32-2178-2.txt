1. It would benefit the reader if the result is stated for the general norm for beta, instead of merely mentioning "the framework is general enough to extend to other norms".  2. What is the relationship between the KKT point of the problem (2.1) and the global solution of the original problem? In particular, if we get an eps-optimal solution of (2.1), what is the optimality gap of the original DRLR problem?  3. DRO typically works better the empirical risk minimization when the sample size is relatively small. Several numerical experiments use a large dataset such as MNIST. Can you run the experiment with a much smaller subset of the data and make corresponding comparisons?  4. What is the information-theoretic lower bound of the DRLR problem? This is related to the last sentence in the conclusion section.  5. A minor comment: can you state the problem in terms of the original variables beta, lambda, and s, as it facilitates the reader?