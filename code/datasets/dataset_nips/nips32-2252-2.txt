Originality: The proposed classes are new but are minor modifications of existing ones. Quality: Technically sound. Clarity: It was easy to follow the argument. But the authors must be clear in the statement of theorems. For example, in Theorem 7, can we use a single choice of parameters to achieve 2-approximation or we have to change parameters depending on the input graph? Significance: As I mentioned above, I'm not sure the main results are very interesting. Why do we want to identify the best approximation ratio we can obtain with a DNN when we know that it won't be better than those of known approximation algorithms? Also, it is not clear how to learn parameters to achieve the claimed approximation ratio.  Line 8: As "GNN" is not a well-defined term, it does not make much sense to say "no GNN can perform better than ..."