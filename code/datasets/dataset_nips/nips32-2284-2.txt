The paper is clearly and well written, with appropriate examples and proofs. It touches an important topic and provides a solution with convincing empirical results.   A few concerns/questions:  1. In the pixel perturbation method, the authors propose the idea of removing the last k important features instead of the k most important, motivated by the fact that black pixels can cause high-frequency edge artifacts. I would like to see 1) a better explanation of why the least k features cannot cause high-frequency edge artifacts, and 2) some experiments that make a direct comparison between the 2 versions to back this up empirically.  2. The 2 examples are both showing the downsides of input gradients, while the other methods are not as much illustrated or discussed. For example, Grad-CAM, which is arguably the second best after the proposed FullGrad, is only mentioned in the experiments with no description or discussion. Are these methods suffering from the exact same issues as input gradients or from different issues? 3. The authors mention the sanity check by Adebayo et al. and that in theory FullGrads should fully pass this test, however, does this really happens in practice? For example, they also admit that some signal from the fully connected layers is not fully taken into account (line 236). Would be good to see quantitative results on the existing sanity check.   A couple of typos: 102: different --> I think it was meant "same" 155: and well as --> as well as 173: Here "we" discuss 