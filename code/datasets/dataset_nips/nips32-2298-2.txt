Summary:  The paper considers a problem of learning a teacher agent for IL, where a teacher agent aims to find demonstrations that are most informative to an IL agent. Critically, the IL agent has some preferences on its behavior which makes learning from teacher’s optimal demonstrations not appropriate. The paper formulates such an IL agent as maximum causal entropy IRL with preference constraints. The paper then proposes 4 approaches to learn the teacher agent: 2 approaches for known preferences and 2 approaches for unknown preferences. Evaluation on a grid-world task shows that the proposed approaches learn better policy compared to a naïve teacher that is not aware of the IL agent’s constraints.  Comments: Overall, this is an interesting paper; It considers an interesting learning setting that is very different from the usual IL setting, and it presents technically sound approaches that come with performance guarantees.   However, I am reluctant to give higher score due to limited practicality since the proposed approaches require reward functions to be linear. Also, the experimental evaluation is done in a small grid-world task which is very different from the three examples given in the introduction.  ===== I read the rebuttal and the other reviews. My opinion of the paper remains unchanged, and I vote to weak accept the paper. 