Overall, I like the idea and the task is also interesting.  - For CelebA dataset, the authors choose “smile” or “not smile”. How is the other attribute cases such as young-aged or blond-black? - As the metric, classification accuracy for condition might be a metric for comparison. - As the authors said, a flow-based model such as Glow can generate high-quality images. But the generated face images are difficult to be high-quality. Could FUNS deal with higher-resolution datasets such as CelebHQ? If not, what is the main advantage of the FUNS against GAN or VAE-based I2I models? - Ablation study is required with respect to losses and modules.  Minor Liu et al. [1] is a Flow-based I2I model performing conditional image generation. Even if [1] was published after NeurIPS deadline, I recommend revising the Introduction because the authors claimed their work is the first flow-based I2I in the Introduction. This work was referred in Section 3.1.   Line 96 in page 3, merginalizing → marginalizing    [1] Liu et al. Conditional Adversarial Generative Flow for Controllable Image Synthesis. CVPR 2019.   [After rebuttal] I carefully read the other reviewers' comments and author feedback. The authors alleviate most of my concerns. Even if the classification accuracy is not competitive, the overall performance looks promising, considering the diversity from LPIPS score.  Therefore, I update my score to 7.