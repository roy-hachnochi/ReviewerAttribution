Update:  I have read the author response and am satisfied with the commitment to elaborate on \beta and \pi and to simplify the Stan PE code with a "pseudo-extended" function.  -------  # Overview  Sampling from multi-modal distributions is a challenging problem especially in multivariate regimes. This paper presents a new MCMC sampling method called pseudo-extended MCMC that uses an instrumental distribution to projects the data into a higher-dimensional space where the modes are connected, making it easier for the sampler to mix. A default instrumental distribution based on tempering is provided. Technical details are complete. The method is compared to existing baselines showing efficacy on three benchmark datasets.  # Clarity and Quality  The paper is very well-written.  The paper is well-placed within the existing literature. Related methods (pseudo-marginal MCMC and continuously-tempered HMC) are appropriately cited and compared to at a technical and intuitive level, as are several sampling baselines.  The experiments are easy to understand and comprehensive.  The appendix contains a deferred proof, a description of the algorithm, and further experimental details and plots.  Code is given for each experiment showing how the authors used Stan to implement the sampler and some of the baselines (and references to the code for RAM, EE and PT).  Overall I believe this is a high-quality submission and I recommend for the paper to be accepted.  # Questions  1. The paper focuses on HMC sampling.  Do you believe that PE can be used in MH sampling or in SMC sampling? With discrete variables?  2. After Eq(8) it is mentioned that \pi(\beta) is an arbitrary user-chosen target and later than \pi(\beta) and g(\beta) are set equal to 1 for the experiments.  Could you please provide intuition on what role \pi(\beta) and g(\beta) play, with respect to characteristics of the inference problem? From Fig. 2, \beta plays a key role.  How do you recommend setting \pi and g to best estimate \beta?  3. Could you please explain briefly how the models you wrote in Stan ensure that the sampler implements Algorithm 1 from Appendix B?  4. Looking through the Stan programs, the PE sampling code tends to be longer and more complicated.  Have you thought about ways to reduce the complexity of the sampling code so that there is a clearer separation between modeling and inference?