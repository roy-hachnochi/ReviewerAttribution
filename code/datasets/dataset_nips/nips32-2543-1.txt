This paper proposes using Bayesian linear regression to get a posterior over successor features as a way of representing uncertainty, from which they sample for exploration.  I found the characterization of Randomised Policy Iteration to be strange, as it only seems to apply to UBE but not bootstrapped DQN, With bootstrapped DQN, each model in the ensemble is a value function pertaining to a different policy, thus there is no single reference policy. The ensemble is trying to represent a distribution of optimal value functions, rather than value functions for a single reference policy.  Proposition 1: In the case of neural networks, and function approximation in general, it is very unlikely that we will get a factored distribution, so this claim does not seem applicable in general. In fact, in general there should be very high correlation between the q-values between nearby states. Is this claim a direct response to UBE?  Also the analysis fixes the policy to consider the distribution of value functions, but this seems to not be how posterior sampling is normally considered, but rather only the way UBE considers it. A straightforward approach to posterior sampling would consider a distribution over optimal value functions, rather than being tied to any specific policy. It is confusing that this analysis is presented as being standard in posterior sampling literature.  Proposition 2: While yes, you can easily change your value function to maintain the same policy, and thereby breaking any constraint that your value function may satisfy, this does not mean that it is a good idea to get rid of propagation of uncertainty. The key issue to consider is what happens as your posterior changes. Is there a consistent way to update your distribution of value functions that keeps it matching the posterior sampling policy as the posterior is updated with new data? This proposition only holds for a fixed policy, but PSRL is not sampling from the posterior of models according to a fixed policy. So even if the sampling policies match, they only partially match the true sampling policy of PSRL, which seems quite limited. This limitation is mentioned later on in the paper, but it is unclear why proposition 2 is a desirable quality to have in the first place. Wouldn't one want to match the true sampling policy of PSRL, even at the cost of violating proposition 2? Also the proposed Successor Uncertainties algorithm still propagates uncertainties, so it's even more unclear what the purpose of this proposition is.  The experimental results in chain and tower MDPs are quite promising for SU. It seems to show that SUs gracefully scale down to tabular settings. The results in Atari do seem to show improvement over bootstrapped DQN.  Overall, the idea of using Bayesian linear regression on successor features seems to be a promising direction for research, and the experimental results back this up. However the theoretical analyses are confusing and not well motivated.  **Update after rebuttal** Thanks to the authors for willing to clarify the definitions and propositions. With more clarity and motivation, I am willing to move to a 7.