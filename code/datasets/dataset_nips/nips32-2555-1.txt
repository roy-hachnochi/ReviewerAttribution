AFTER REBUTTAL  I thank the authors for their careful consideration of our remarks, I believe the paper will benefit from all these comments and am confident the authors will be able to improve it accordingly. ____________________________________________  The theoretical contributions of this paper for entropy-regularized OT are : - getting rid of a bad exponential factor in the previous sample complexity bound by Genevay et al - extending that result to unbounded domains for sub-gaussian distributions - a CLT for entropy-regularized OT, based on the proof for the standard case. The theoretical part is overall clear and well written, although: - briefly introducing F_sigma would improve overall readability (e.g introducing it as the set of functions with bounded successive derivatives) - it would be nice to state more clearly (in the abstract or intro) which additional hypotheses you use to improve existing results (subgaussianity + quadratic cost hypothesis). I believe it is not essential to get rid of the exponential bound, but required for the extension to unbounded domains?  A couple of typos: - line 136 : should be v instead of u in the second term - line 140 : should be v instead of u - line 166 : theorem 3 instead of 2  Regarding the application to entropy estimation, I feel that it would benefit from a little rewriting and some clarifications in the experimental section. - prop 3 : what is Z_g? I an guessing the normalization constant for phi_g. - equation 13 : I understand here that S is the entropic OT where the cost function is c(x,y) = g(x-y) but it should be stated more clearly (maybe introduce S_c to  insist on the dependence of S on the cost function).  In the experiments, in figure 1, should the legend read epsilon instead of sigma_g? I am confused.