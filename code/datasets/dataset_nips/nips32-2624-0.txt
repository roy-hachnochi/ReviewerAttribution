Label smoothing has become somewhat pervasive in various ML application areas (e.g., MT), but has mostly been thought of as a regularizer. The present work suggests a number of other properties of label smoothing that challenge this assumption, e.g., that label smoothing causes representations to cluster around class templates, that label smoothing improves model calibration, and that label-smoothed networks make worse "teachers" for knowledge distillation. These are important empirical/theoretical findings that are not obvious and should be interesting to a fairly broad audience. The paper is clearly written and the experiments are well designed to support the above claims.