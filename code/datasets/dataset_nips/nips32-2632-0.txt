Establishing ownership of a DNN is an important problem especially given the resources and IP involved in training accurate models. The paper identifies gaps in previous efforts based on watermarking, and proposes a new method that is robust to attacks.   Overall I liked the paper. It explains the key observation driving the design, and then discusses a few ways for embedding passports during training that create a dependence between the models performance and the passport input.   I do have the following questions/concerns.  1) In definition 1, is D_t a pre-defined dataset i.e. known at training time? If it is not known at training time, it is unclear how M_t is computed. And if it is, is it also known to the attacker?  2) Is epsilon_f also known during training? If it is not, how does training guarantee Proposition 2, II? It appears that epsilon_f is set after training based on model performance (line 273), which seems very ad hoc.  3) The experiment to evaluate robustness to persistent reverse engineering attacks (where the adversary is assumed to have access to the training dataset) is not entirely satisfactory. The paper only explores one way of reverse engineering passports i.e. freezing training weights. There may be other ways of training e.g. freezing weights, maximizing distance from original passport, and minimizing accuracy loss. More broadly, is there an alternative way of show robustness without constraining what the adversary can do. 