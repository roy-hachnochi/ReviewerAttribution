The paper:  - shows an important weakness of the current watermarking methods, namely the    fact that they are prone to ambiuity attacks,  - offers an analysis of the issue investigating the requirements that have to    be fullfiled by any method that should withstand such attacks,  - proposes such a method based on "passport layers" which are appended after    convolutions.  Overall the paper is well structured and the method is explained with enough detail to probably allow reimplementation. The text is clear enough with the exception of the experiments section, which would require some additional attention from the authors. Details follow below.  Concerning the method I would be interested in seing how much does the performance (accuracy) suffer because of including the passports (no passports vs. the V1 setting) and because of the multi-task setting (V2/3 vs V1).  In general a comparison of the three proposed settings V1, V2, V3 is missing from the experiments/discussion.  Specific comments to the experiments follow:  - It is not clear whether the experiments use V1, V2, or V3?  - It is not entirely clear what the Table 2 shows. I guess the numbers in   parentheses are the accuracies either on the source task or after fine-tuning   on the target task, and the numbers in front of the parentheses is the   fraction of cases when the signature withstood the fine-tuning. Either the   table headers or the legend should be improved. (Also please make the left   and right tables symmetric in how the numbers are shown - with or without the   "%" sign.)  - In Fig. 4 legend, please specify the performance metric (accuracy?) instead   of writing "DNN performances".  - Consider reformulating sentences in the "Experiment results" section to make   understanding the experiments easier. Especially paragraph on fine-tuning   (L245-53), or sentences like "In this experiment..." (L255). Sometimes one   has to search for the meaning as in the sentence "This type of weight   pruning..." (L256) where it is not clear which special kind of weight pruning   (if any) is refferred to. In subsection 4.2, it is not entirely clear what   the "fake2" attack consists of, please clarify.  - In Fig. 5, it would be helpful to specify what does "valid" and "orig" differ   in.  - Figures use too small font that makes reading them hard (especially Figs.   3 & 5). Please adapt the figures. 