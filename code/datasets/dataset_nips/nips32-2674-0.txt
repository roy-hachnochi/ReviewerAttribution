The task of demixing a balanced two log-concave densities with the same and known covariance matrix seems restrictive.  The authors did not discuss whether the results apply to unbalanced mixtures of two log-concave densities, nor did they discuss the implication of requiring covariances for the two being the same or the knowledge of covariances.   The works builds on previous works on global convergence guarantees via EM for a balanced 2 GMM (or mixture of 2  truncated Gaussians) with known covariance, as well as following up works on mixture of 2 linear regressions and mixtures of 2 1-d laplacian distributions. The methodological contribution is to modify the M-step. However, the technical difficulty of proving convergence or providing finite-sample analysis compared with previous works is unclear.   The incentive of using EM algorithm is unclear. It is well known that global convergence of EM has been established for mixtures of two  densities (not more than two). However, there are other methods such as spectral and tensor methods that are guaranteed to converge to global optima for mixtures of more than two. So the question is why not consider the spectral methods? How does the least squares EM compare with, say tensor methods?   The robustness analysis under model mis-specification is under a restrictive setting where the ground truth densities are log-concave and the fitted are Gaussians. I am curious in what happens if the ground truth densities are not log-concave. If the theoretical analysis is difficult to be established, can you show some experimental results?   The theoretical analysis seems sound, however it would be nice to show some experimental results.    ================ Comments after author response:  After carefully reading the author's response, I am more convinced about the technical challenges involved in this paper. I would leave my score unchanged though since I think adding some experiments and a more general model misspecification analysis would make the paper much more impactful.  