This work builds significantly on the results from [Braverman et al 2018] by reducing dependence on the form and structure of buyers value distributions, very much in line with the prior-free and prior-independent thread in AGT.  The paper first considers menus of prices, and shows in a rather unrealistic mechanism that the full welfare can be extracted, without knowing the distribution exactly, just the support, and that the number of options is essentially tight. [Braverman et al 2018] gave a similar algorithm, but with dependence on the distributions and more importantly the existence of a distribution in each round. These approaches rely very heavily on the mean-based no regret learning, as there are easy improvements in policies if the learner isn't restricted to mean based.  Focusing on mechanisms that are likely to be used, they give a decreasing reserve price for use in a first price auction. [Braverman et al 2018] had given a decreasing reserve price according to an LP that depended explicitly on the value distribution; this work provides a decreasing reserve price just based on the support of the distribution.   As it is building directly on Braverman et al 2018, it is not introducing any significant new models, but it is making the approach significantly more robust, as well as illustrates an approach for eliminating prior dependence that may be interesting in other dynamic settings.  The paper is generally very well written.