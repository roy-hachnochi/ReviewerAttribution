1. The originality of this paper is not much. The two models proposed in this paper are the deep level network (DLN) and the hybrid model DeepGLO. The DLN is just a combination of two temporal convolution networks. One network models the rolling mean of a time series and the other one models the residual part. The DeepGLO simply combines a global model and a local model by a linear combination. Both of the ideas are not very original. 2. The authors emphasize the difficulty of normalizing data and show that they are dealing with this problem. However, the proposed model does not completely solve the problem. First, the proposed DLN only separates the mean and residual of time series, but the scale of the mean and the residual can still be large and is still a problem for neural networks. Therefore, the proposed model does not have the ability to solve the problem. Second, as shown in Table 2, the experimental results on the unnormalized data are not significantly better than those on the normalized data. Consequently, the authors are suggested to reconsider whether they should emphasize that they have solved the problem of normalization. 3. The organization of Section 4 and 5 is hard to follow. The reason could be that it is written in a bottom-up manner. The paper first introduces the local model, the global model and then the hybrid of the two. The problem is that some symbols in Algorithms 2 is not yet introduced when readers are reading that part, which may confuse the readers.The authors are suggested to move Section 5.2 forward. That is, introduce the whole model before explaining each part of the model. This will make the methodology clearer. 4. The sizes of the figures, tables and the font in the captions are too small, and they are difficult to read (Although this does not affect the current evaluation of this paper). It would be better to make the figures larger and just use the normal font size for captions and tables.  