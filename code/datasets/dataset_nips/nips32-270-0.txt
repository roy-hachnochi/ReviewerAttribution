Update: The F-score results and the naive baseline shown in the rebuttal are good. I agree with R3 that an experiment with more camera variations should be added, which is also promised in the rebuttal. ---  The paper presents a new method for single image 3D reconstruction. The method generates a signed distance function, which contains the surface as the zero level set. Implicit representations have very recently become popular for this task but the presented network architecture makes good use of this representation. The method works similarly to Occupancy networks, IMNET and DeepSDF. Given an image of an object, the method maps a 3D position to a signed distance value.  To improve the reconstruction of details, this paper uses the camera pose (estimated by another network) to project each 3D position to the image plane and look up local image features generated by a VGG encoder. Making use of this local feature look-up distinguishes this work. The decoding stage then combines two SDF values generated by decoders processing the local and global features separately.   Originality:  The approach estimates the camera pose(i) and combines an implicit representation(ii) with an explicit look-up of local features(iii). None of these three components is new but the combination is very sound and the paper shows that it can improve the quality and generalization with this approach. This is in contrast to approaches which miss something, e.g. neglect camera geometry or use convenient grid representations that do not scale.  The paper cites recent and highly related works sufficiently. The section can be improved by explaining the (dis)similarities between the local features used in Pix2Mesh and this work.   Quality: The overall quality of this paper is good. The figures are helpful and qualitative examples give a good impression of the quality of the results and the outcome of specific experiments. I liked the experiments which explain the design choices in more detail (Sec. 4.3 and Fig. 8). Further, the experiments include comparisons between the GT camera pose and the estimated camera pose, which point out the dependency on the camera parameters of this approach.  I miss a comparison with a naive baseline replacing the second decoder stream by adding to the SDF based on the projection to a foreground (add 0) or background pixel (add inf) in the image. While this baseline cannot add to the reconstructed volume it can generate holes, which would add detail.  The quantitative evaluation uses common metrics such as IoU and CD; this is OK but does not do a good job on highlighting the advantages of this method, which is reconstruction of details. Consider using the F-score for the evaluation (see Tatarchenko et al. “What Do Single-view 3D Reconstruction Networks Learn?,” CVPR 2019).    Clarity:  The paper is well-written and gives enough information to implement the method.  A minor issue are the statements about "infinite resolution"(l46) and "continuously sampling"(l209) could be misunderstood and written clearer to point out that this approach allows to freely sample the SDF.    Significance:  This work succeeds in improving the visual quality of single image reconstruction methods and the experiment with multiple views shows how this work can be extended and its ideas be used in related tasks. Quantitatively the work is on par with other related methods, which could be a limitation of the evaluation metrics. My biggest concern is the missing naive baseline, which would give us more information about the significance of the local feature decoder.  Taking everything into account, I tend towards accepting this work.      Questions:  Is the signed distance approximately euclidean for the output of both streams?  What does the signed distance function look like only for the local stream? Does it add only the details or does it contain the whole object?  Minor mistakes: l.40: 'A' SDF l.58: To the best 'of' our ... l.147: grou'n'dtruth 