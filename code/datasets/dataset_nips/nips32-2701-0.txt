The paper considers a Bayesian decision theoretic formulation of the problem of minimizing the number of queries to identify the desired number of positive instances (instances with positive labels), given a probabilistic model of the labels in the dataset. This formulation is motivated by the material and drug discovery problems. The problem is properly formulated and contrasted with the recently suggested budgeted-learning setting, where the goal is to identify the largest number of positive instances given a fixed budget on queries. Further the authors show that the optimal Bayesian policy is hard to compute and hard to approximate. However, further assuming certain conditional independence the policy can be approximated efficiently using the negative-poisson-binomial distribution, for which the authors propose computationally-cheap expectation estimates.The resulting policy is compared to several other alternatives, and it is shown to obtain overall superior performance in both material discovery and drug discovery datasets.  Quality: Most of the material presented in the paper is sound and the experimental results are convincing. The proof for the main theoretical statement is provided in the supplementary material, but I didn’t check it. There are however some gaps that are not completely satisfactory in the main text. Specifically, it is about the approximation of the expected value of the NPB distribution discussed in section 4.2. A single set of experimental results suggesting that the proposed estimator ACCU’ is accurate is insufficient in my opinion to use, given that its accuracy is central to the policy choice. Obtaining some sort of bounds is important. On the other hand, it is also not completely clear to me why the \epsilon-DP is computationally expensive in the first place. After all, a single evaluation of the instance is assumed to be expensive (time, resources, etc.), so spending more time to accurately getting the policy should not be a bottleneck. Another option would be estimating the expected value by sampling. There are lots of exponential tail bounds that give solid guarantees, wouldn’t this work?  Regarding the experiments, I don’t see enough information about the details of the posterior probability model, beyond a short mentioning that it is based on a k-nn. A detailed model should be explained somewhere in the text (main or supplementary).   Furthermore, there are no details regarding how the ENS is modified to match the CAES setting in the experimental setup. This is particularly interesting as it is important to know if there are relatively easy ways to map one problem to the other, despite the opposing arguments put forward in the introduction. On that note, I would suggest to revise this argument (the third paragraph in the into). Why is the problem not one-to-one? Does it even matter?   Originality: As far as I know this work is original, starting from the suitable problem formulation and down to the algorithmic implementation. It certainly adapts ideas from prior work but they are sufficiently different.  Clarity: The paper is overall well written.  Significance: I believe that the work presented is sufficiently significant and will be beneficial for suitable search problems that are not very unique in the general scientific community. It provides a new problem formulation that is more suitable to those search problems, the algorithms are implemented, discussed and compared on two interesting real datasets. Also, the difficulty of approximating an optimal Bayesian policy for a general posterior model is an important (though not surprising) theoretical result.   Misc:  Line 129: What is “n” in O(n^t)?