The paper is well structured and is easy to follow for the most part. The authors proposed to approximate the expected remaining cost via the expectation of a negative Poisson binomial (NPB) distribution. The proposed nonmyopic algorithm, ENCES, aims at minimizing the approximated expectation of the corresponding NPB distribution. Note that this is an approximation because the conditional independence (CI) assumption does not always hold.  Can the authors please justify, either empirically (on small toy dataset) or theoretically, how well the NPB expectation approximate the true expected cost?  In addition to the query complexity, it will be useful to see the time/computational complexity of the competing algorithms, e.g., how much more expensive is ENCES than the (one-step) greedy algorithm?   == post-rebuttal comments:  Thanks a lot for the clarification on the conditional independence (CI) assumption.  One comparison I would like to make is against variational inference, which also makes independence assumption for the approximate distribution -- however, VI tries to find the closest approximation in a parameterized family. In contrast, here the conditional independence may not hold and hence it's hard to provide any guarantees on the performance based on the proposed search heuristics. I think this is still a reasonable heuristic to run (and a good one given the experimental results), while there is still room for improvement on the theoretical aspects. 