i. Novelty and significance: The problem addressed in the paper seems new and the proposed "BaSE" algorithm seems novel for the purpose. The technical contribution of the paper seems sound as authors analysed both minimax and adaptive regret of their proposed algorithm with pre-specified (hence fixed), and (more natural and challenging) adaptive batch sizes, and also prove a matching lower bound guarantee, establishing optimality of their proposed method.  ii. Clarity on some results:   a) Its confusing that as opposed to what is claimed in Cor 1, I do not see how Thm. 1 recovers the optimal regret O(\srt{KT} bound of classical MAB framework (i.e. when M=T), unless of course T \to infty which is an asymptotic guarantee. --- A thorough derivation of Cor. 1 statement would be appreciated.  b)I am also surprised with the matching lower bound statement (Thm. 2), as for M=T it definitely seems to be higher than the classical \Omega(\sqrt{KT}) lower bound for MABs -- what am I missing?  c) Intuitively, the learner is supposed to have better control for the data-driven grid setting --- It is however reflected from the analysis that the regret bounds obtained for the two setting are exactly similar (Thm. 1 and 4 or Thm 2 and 3). Why is that -- an elaboration of Line 154-157 would be useful.  iii. Experiments: Its however slightly disappointing that it does not provide any empirical studies to validate the theoretical guarantees.  iv. Organization and presentation: The paper is overall well written and easy to follow.  