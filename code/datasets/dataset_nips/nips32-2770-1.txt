The authors propose to learn a custom similarity metric for CNNs together with adaptive kernel shape. This is formulated via learning a matrix M that modulates the application of a set of kernels W to the input X via f(W, X) = W' M X. Structural constraints can be imposed on M to simplify optimization and minimize the number of parameters, but in its most general form it is capable of completely modifying the behavior of W. Although at test time M can be integrated into the weights W via matrix multiplication, during learning it regularizes training via matrix factorization. In addition, a variant is proposed where M is predicted dynamically given the input to the layer via a dedicated subnetwork.  A comprehensive ablation analysis is provided that demonstrates that basic version of the proposed approach performs marginally better than a standard CNN with a comparable number of parameters on CIFAR-10, but the dynamic variant outperforms it by 1%.  On ImageNet a 1.5% improvement is demonstrated on the top-1 metric, but a very weak model is used as a backbone (10-layer CNN without batchnorm).  Finally, the proposed approach is adapted to the few-shot learning scenario. To this end the basic variant of the model is pretrained on base categories, and the matrices M are fine-tuned on the novel categories with MAML, while the actual CNN kernels remain fixed. This approach outperforms the state-of-the-art LEO method by a statistically significant margin while being much simpler.  The paper is well written, and is relatively easy to follow.  Overall the approach is interesting but I have several concerns regarding the evaluation (see Improvements).  The authors have addressed my concerns as well. Given the results of the additional experiments requested by R1 I'm also ready to recommend the paper for acceptance. However, I would like to point out that, like for most similar approaches, the performance improvements seem to diminish as the network depth increases. In addition, the results in Table 1 in the rebuttal indicate that the meta-learning part of the few-shot learning approach is of a marginal importance. I would appreciate if the authors toned it down in the camera-ready version.