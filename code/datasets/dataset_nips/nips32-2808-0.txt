**Originality**  The proposed framework is original and interesting but it was recently introduced by authors of (23), so it is not a contribution of this paper.  It's an incremental work from (23) which provides enough improvement, in particular the method to estimate the number of component.     **Quality**  The paper is of good quality. There is no theoretical results. The claims are well supported by numerical experiments and performances are compared to standard frequency estimation methods. The described method is completed and ready to use.  Authors give an honest evaluation of their work in term of performances. Yet, when using neural network one important aspect is the ressources required for training which can differ significantly from ressources required by non-deepnet-based methods. For that reason, when authors mention running time (l217-218), I think it's a bit unfair to other methods. For a fairer comparison and considering that a network should be trained on artificial data before being applied to a specific dataset, authors should mention training time and energy consumption (or CPU number/GPU type).    **Clarity**  The paper is very well written and well organized. It is easy to read and it seems easy to reproduce.  Minor correction: the function FR shouldn't be in italic in the text.   **Significance**  The results are out-performing state-of-the art methods. The main idea (learning-based techniques on artificial data) could be very useful to the signal processing/data analysis community but it was proposed in the recent paper (23).  === Authors Feedback === Other reviewers and authors' response convinced me that this work was a significant improvement of existing reference (23) which was my main concern. Therefore, I increased the score. 