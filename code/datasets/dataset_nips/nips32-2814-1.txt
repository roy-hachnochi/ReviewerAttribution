The algorithm is also simple: the basic idea is to choose an element randomly and estimate its frequency by further sampling enough elements. Repeat this process to estimate E[-log X], which is the entropy. A more sophisticated algorithm is built by dividing [0,1] into several subintervals, and estimate the conditional entropy within each subinterval and combine them in the end. The savings come from the intuition that a large frequency can be estimated with fewer samples. Overall, the algorithm is neat and simple, easy to implement.  Minor comments:  Line 60: “denoted by S(H,k,eps,delta),”  -- insert “by” and add a comma at the end of the phrase Line 71: Do not use citations as subjects. Say instead “Paninski showed … [43]”. Such bad style occurs a lot in this section. Line 76: “denoted by H(X^n)” -- insert “by”. Line 107: delete “bit” in “eps = 1 bit” Line 115: At -> In Algorithm 1, line 5: Do you mean S += …? Please edit the typesetting Algorithm 3, line 4: Does the symbol of + above = mean +=? Please use the same notation throughout the paper Algorithm 4, line 4: Is it ESTINT(N_i, x)? 