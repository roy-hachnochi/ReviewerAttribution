On its own, the paper assigns text space inefficiently. While simulated data is fine (in context) it should not take space from essential Methods description. The baseline method is described in one short and incomplete paragraph, insufficiently described apart from a couple of perfunctory references (one of which, as several other references, is incompletely listed). The architecture window does not suffice and it is left to the reader to piece together how the forecasts are computed from data, end-to-end.  Several mentions of 'rolling window' is not a sufficient description of train/validation/test procedure. What was it? Depending on the exact details, the evaluation procedure can result in overfit. What was the loss function used in training (it appears only briefly in the 'training curve' Figure).  Results are incomplete. For the M4 dataset in particular (which has a test set), there are known accuracy results in the literature which can be compared with the R_0.5 result. They should be included.  There are scant or no details given on how alternative methods (Arima, TRMF, DeepAR) have been set up (lag length, metaparameters) or how the metaparemeters of the proposed method (in particular the kernel size) has been chosen *prior* to any ablation studies  Finally, while the stated goal is computational efficiency, not running time is reported, nor the actual software/hdwre architecture that implemented the main method.  Minor details, for improved clarity:  the methods section is minuscule: less than 10 lines on Page 3. Expand  Deep neural networks have been proposed to capture shared information across related time series for accurate forecasting.   how were baseline metaparameters (kernel size, h) chosen before ablation study? Figure 5 suggests NN was trained iteratively over the same data  ARIMA performs significantly worse than the simpler method (ETS) which suggests seasonality was not used  in what software / environment was main method and improvement implement and how fast did these run?