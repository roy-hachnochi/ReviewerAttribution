The paper considers the ridesharing setup (think Uber, Lyft for instance). Private drivers are linked with passengers through a mobile app. The authors study fairness in the allocation of a set of riders to a set of vehicles. A standard solution would try to maximise efficiency, i.e., maximise some aggregate measure of pairwise affinity between rider and vehicle (for instance, minimise total time to serve the request). The authors propose an alternative solution that instead optimises for a predetermined level of fairness (for instance, an upper bound on the time to serve any request) while still attempting to maximimise efficiency. The authors then show that the proposed algorithm provides a lower bound on efficiency which is optimal within the proposed model. Finally, the authors empirically study a public dataset of New York taxi trips, and conclude that significant improvements in fairness could b obtained with very small loss in efficiency.   I think this is a good paper for a few reasons: - It is clearly written and easy to understand. - It is technically sound, and the proposed solution is very simple and directly implementable without anything more than a linear assignment solver. - It addresses a problem of great importance: machine learning objectives have historically been focused on the mean or median of a distribution, whereas here we see an attempt to improve the "worst-off" individual in an allocation problem, in line with the notion of fairness proposed by Rawls.  - It provides further evidence of a very important finding I've seen elsewhere: often when you introduce fairness constraints the loss in efficiency is negligible. Whenever this is true, organisations have the capacity to do much greater good without affecting their profitability (and as such buying a very cheap insurance policy against potential future public retaliation due to unfair treatment or certain customers).   