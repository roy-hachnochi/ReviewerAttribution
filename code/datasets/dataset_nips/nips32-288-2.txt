- The paper proposes a unifying framework, named vGraph (note: there are a few other, unrelated, approaches in the literature that share this moniker), for simultaneously pursuing node representation learning and community detection.  The key insight is two learn two embeddings per node, one which captures the community assignment, and one which captures the graph topology.  Moreover, a simultaneously learned embedding of the communities ties these two embeddings together in the probabilistic framework.  - You are implicitly defining communities based on assortativity.  It would be interesting to explore whether different choices of $\alpha_{w,c}$ and $d$ in (9) would allow for other community structures (e.g., disassortative communities or core-periphery communities) to be uncovered.    -In all of your examples, $K$ (the number of communities) is relatively small and the communities recovered (at least upon first inspection) appear to be relatively balanced.  Is your method effective in situations with many small  communities (large $K$)?  - For your methodology, when an oracle $K$ is unknown, how is it chosen?    - In Section 2, subsection "Community Detection," you cover two groups of methods, matrix factorization-based methods and model-based methods, and claim that the computational complexity of these approaches is high. There are a bevy of other approaches (e.g., modularity optimization methods such as the Louvain method and Clauset, Newman and Moore's greedy modularity maximizing algorithm) that scale well and show excellent performance on real data applications. Moreover, the Louvain method (from Blondel et al. 2008) runs on graphs with order $>10^8$, and thin SVD based matrix factorizations can be applied to networks with millions of nodes using only relatively standard grid-based computing resources.  - In deriving your probabilistic model and ELBO lower bound, you only consider a single $(c,w)$ pair.  How are you aggregating over all edges?  The model effectively extracts two node embeddings, one capturing communities and one capturing the edge structure, with the community embeddings tying the two together.  Are the final node embedding $\phi$, $\varphi$ or a concatenation of the two?  - Please list citations for the real data networks used in your experiments in the main text.  The networks cited from [1] in the supplementary do not appear to be available at [1] anymore.  -On the real data networks, what is the runtime of vGraph (for example, on Dblp-full) and competing models?  There is no mention of the scalability of your approach.  -Can you modify vGraph to incorporate nodal attributes?  - Regarding Table 3, both NMI and Modularity can be computed for clusterings with $K'\neq K$.  In the setting when $K$ is unknown, how would your approach compare to approaches that automate this model selection (i.e., the Louvain method)?   - Often, clustering is an inference task with multiple (equally correct) truths (see, for example, Peel, L., Larremore, D. B., & Clauset, A. (2017). The ground truth about metadata and community detection in networks. Science advances, 3(5)).  It is hard to judge the effectiveness of your approach based on its ability to recover a stated "ground truth," when the communities recovered by competing algorithms may be equally correct for recovering different (still true) communities.  - In the classification experiment, what classifier are you using on the node-embeddings?  (minor typo: vGraph is not best performing on  9 out of 12 datasets; there are only 6 datasets).