Originality: This is the first approach that I know of which attempts to train on the network architecture independently of the weight values.  Significance: The relationship to neuroscience is somewhat remote, synapses in the brain do have different connection strengths. The significance of the empirical results is rather low as their resulting network architecture looks rather shallow and the task involved seem to be solvable with shallow networks trained other evolutionary-like algorithms.   Clarity: The language is quite good. However, many technical details are not spelled out. I think the description of the algorithm l. 123 to 129 is not sufficient to understand the algorithm.  Quality: I think that it is unfortunate that the authors do not analyze in more details their training algorithm in comparison to other approaches, or variants of their own algorithm.   -------- Second review ----- I am glad that the positive reviews of the other reviewers got me to look again at the paper.   After another reading, I do find that the originality of this work should be valued a lot more than I did it in my first review.  It is still hard for to me know if the performance reported is trivial or satisfactory as a proof of concept.  Despite this, I change the "overall score" of my review.   One big improvement is that the authors promise to add a pseudo code in the supplements I hope that the details of the algorithm will make it more accessible. I also think it would be great to discuss somewhere what is new in this algorithm in comparison with the NEAT framework.