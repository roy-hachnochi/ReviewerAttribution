The paper is fairly interesting in terms of motivation, but the actual execution perhaps isn't mature enough the way it has been presented. --  since this is a new fairness criterion, a more detailed discussion of its merits would be helpful (even if it is non-rigorous). in particular, it is unclear why the disparity is only measured in one direction (over-emphasis of higher relevance item) with the direction based on relevance rather than group identity? Ideally, fairness critera would be defined in a way that is cognisant of historical/natural directions of bias, and therefore checks over/under-emphasis based on group identity rather than utility (which is dealt with separately). given that, this paper is more of a "diversity" metric rather than a "fairness" metric  -- the experimental results are a bit confusing, not least because some of the axes measure D and others measure -D. In particular, figure 3 (right) seems to suggest that the post-processing method has a configuration where increasing the NDCG score also decreases the disparity? Isn't that a good thing?  -- the kinds of experiments presented are all over the place-- the yahoo dataset and the german credit dataset show entirely different types of experiments, which makes it difficult to assess  -- in figure 2, the dashed and the solid lines (train and test results respectively) seem suspiciously close to each other. but since the authors have provided code (that i did not check) i am willing to give them the benefit of the doubt on this one.  -- the simulated data experiments, while mildly interesting, is too much of a toy experiment to take too seriously  otherwise, the paper is fairly clear and reasonably well-motivated and includes most of the relevant references. this can be a pretty good paper with some improvement, but i don't think it is there just yet.