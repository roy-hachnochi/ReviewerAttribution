The paper introduces a new method for model-parallel training, where layers of a model are distributed across multiple accelerators. The method avoids locking in the backward pass by using stale gradients during back-propagation. I'm not aware of any prior work that took such an approach. Furthermore, the authors provide theoretical claims and empirical results to demonstrate that their method has convergence properties similar to conventional SGD, despite using stale gradients. The lack of effective model-parallel training is a major roadblock for scaling up model sizes, and the proposed approach promises to overcome this issue.  Minor: 74: the notation grad f_{l_x_{i(t)}} is not used in equation (6). It would also be useful to remind what this notation means next to equation (8). 84: should be "any ... method" 116 or 127: it would be good to say that proofs are in the supplementary material, rather than leaving it unstated whether the authors have proven the key theorems. 