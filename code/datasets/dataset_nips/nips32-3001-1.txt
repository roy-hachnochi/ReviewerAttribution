After rebuttal:  Thanks the authors for addressing my concerns. I read the authors' feedback and other reviews. This work has some contribution on the theoretical side but I believe its empirical contribution is limited. The experiment is simple and the algorithm might not work very well in general. I'll keep my original score. -----------------------------------  This paper studies the finite horizon value iteration problem with linear approximation given a generative model. This paper is clearly written and easy to follow. The author proposes an algorithm and then prove a sample complexity bound for the algorithm. Finally, some experiments on the toy models are shown to support the theoretical result.   The AVI problem has been studied for a long time. There are mainly two types of guarantees needed for the convergence. One is the bounded inherent Bellman error and the other is the contraction of Bellman update. The main idea of this paper is to balance the generalization and compactness in LAVI. The algorithm will run backward. At timestep t, the agent uses the generative model to draw the backup values and timestep t+1. Then it solves an optimization problem to obtain the interpolation coefficient \theta of each anchor point in timestep t. The sample complexity will be low if the amplification factor and the number of anchor points can be controlled. The result will hold even under infinite inherent Bellman error.  Major: 1. The idea of trying to balance the compactness and generalization is new to me.  2. The sample complexity is polynomial on the number of anchor points K, the length of horizon H, and the amplification factor \bar{C}. However, the limitation is that \bar{C} seems usually to be exponential. Although Prop 1 shows a specific case that \bar{C} is small, the number of anchor point seems not controllable. Usually, the smaller the amplification factor, the larger the number of anchor points. My major concern is that the final sample complexity might still be exponential. 3. This paper does not consider the selection of anchor points. I agree that finding the anchor points are generally hard. Suppose a set of (probably good) anchor points are given in the last timestep H, is it possible to design an algorithm to automatically find the anchor points from timestep from H-1 downto 1? Iâ€™m also interested that whether the result of this work can be extended to the infinite horizon case since a closely related work Yang and Wang [15] considers discounted infinite horizon MDP. 4. In the theoretical part, the result holds for the continuous state space. However, the authors only investigate the discrete state space in experiment. Does the algorithm also work empirically in the continuous state space?  Minor: 1. Line 178: in not unexpected --> is not unexpected 2. Line 252: Fig. 5 --> Fig. 2