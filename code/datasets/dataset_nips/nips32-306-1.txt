This paper proposes a strongly conditional network for generating images from semantic maps.  How impacted is this network by small changes in the input map - for example given 3 sequential frames of a video (as segmentation maps) - is the model consistent in assigning colors and structures? Or do small changes in the geometry of the semantic objects have a large impact on the output? This is mostly curiousity, as having smoothness inherent in the model has large potential for video applications. Some amount of qualitative results comparing to other models were shown, but showing the important regions of the input conditioning, and the influence of input perturbations on the model output could also lead to valuable insight - using something like GradCAM or related methods may be possible for checking the importance of input features.  In 4.3 (qualitative worker analysis) there could be more detail (variance across labelers / uncertainty / statistical significance) rather than a pure percentage preference. How many workers labeled the 500 images?  Given that this is largely a (very impressive) empirical paper, it would be nice to see a larger exploration of ablation on various components, or some larger intuition on how and why the network was designed how it was. The empirical results are convincing, and the demonstrated experiments are thorough - though more ablations can add greater insight, the current experiments seem sufficient given the high quality of the model.  I strongly encourage the authors to release their code, as the community should be able to use, improve, and extend this work in interesting new ways - perhaps doing some "in-the-wild" ablation studies along the way.  Feedback post-rebuttal: My score remains unchanged primarily because I had no major criticisms of this paper to begin with - the response didn't fundamentally change my perception of the work.  The author's comments clarified some of my key questions, thank you for the explanations. 