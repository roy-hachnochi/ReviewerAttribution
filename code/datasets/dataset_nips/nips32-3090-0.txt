Strengths: I found the authors’ formulation of network pseudo-depth to be a very interesting and potentially useful metric for comparing artificial neural network models to neural data. I think their finding (displayed in Figure 2) that the number of sampled neurons had to be around at least 1000-2000 for the VGG-16 pseudo-depth to be consistently estimated, and that this finding holds when comparing representations against another network (VGG-19), demonstrates a potentially useful rule-of-thumb for adequate population sizes in neural data. Furthermore, their finding that mouse visual cortex is more parallel after a few stages of hierarchical processing starting at around area VISp, could be useful for building better task-driven models of mouse visual cortex, and indicates an important distinction with the traditional, hierarchical primate ventral visual pathway.  Weaknesses: I would have liked to see more analyses of the robustness of the pseudo-depth metric with different networks, especially those not in the VGG family. I am aware that the Allen Institute has compared VGG-16/19 to their mouse data, and therefore, this is likely why the authors chose this model to begin with. However, I don’t think the Allen Institute’s choice of model is particularly well-motivated, and given both the anatomy and the results of this paper, likely not a very good model of mouse visual cortex anyway (not to mention not a very good ImageNet model either). I would have liked to see comparisons with shallow ResNet models or even AlexNet. Furthermore, while their current analysis of the pseudo-depth metric they introduce seems to indicate needing at least thousands of neurons in order to make robust quantitative comparisons between features, it is not clear to me what further neuroscience knowledge we have gained beyond what we expected from the anatomy of mouse visual cortex (namely, that these pathways are more parallel than hierarchical). Given that they are finding that the pseudo-depth of mouse visual cortex corresponds roughly to the middle layers of a VGG-16, it would have seemed more relevant to compare an AlexNet or similar shallow convolutional neural network architecture to their neural data and for their analysis of the robustness of pseudo-depth.  Without offering a potentially better solution for artificial neural network models of mouse visual cortex beyond what has already been known (e.g. using a VGG-16/19 and having their findings agree with rough anatomical considerations of mouse visual cortex), their only novel finding is the use of their pseudo-depth metric and their finding that thousands of neurons are necessary to make robust comparisons (with the caveat that they only tried this on two neural networks). I think this result on its own is interesting.