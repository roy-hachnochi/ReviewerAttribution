Overall, the paper made significant contribution to both the reinforcement learning community and optimization community. The proposed algorithm is a variant of non-convex SAGA algorithm introduced by [1]. The novelty comes from their proof for the non-convex but strongly concave case.   There are several issues which should be addressed:  1, Recasting the policy evaluation as a primal-dual optimization via the Fenchel duality technique is not new. In fact, [2,3,4] have already exploit this reformulation. First, these related work should be referred appropriately.  Given these existing work, this contribution in the paper is relatively straightforward.   2, The choice of the \beta plays a vital role to establish the convergence rate. In fact, the finite-step convergence rate highly depends on the choice of \beta. In the proof in Appendix, the beta should satisfy the conditions in Eq. (a0), (a3), and (a4). However, the existence of \beta satisfying such conditions is not explicit checked. Without the existence of such beta, the convergence rate proposed in the paper is not valid.   In sum, this is an interesting work to exploit the advanced optimization technique for reinforcement learning problem. However, there are several conditions in the proof should be treated carefully and rigorously. I am happy to raise the score if the authors can address my concerns.  1]  S. J. Reddi, S. Sra, B. Poczos, and A. J. Smola. Proximal stochastic methods for nonsmooth nonconvex finite-sum optimization. In Advances in Neural Information Processing Systems, pages 1145–1153, 2016. [2] B. Liu, J. Liu, M. Ghavamzadeh, S. Mahadevan, and M. Petrik. Finite-sample analysis of proximal gradient TD algorithms. In Conference on Uncertainty in Artificial Intelligence, pages 504–513, 2015. [3] Dai, Bo, He, Niao, Pan, Yunpeng, Boots, Byron, and Song, Le. Learning from conditional distributions via dual embeddings. arXiv:1607.04579, 2016. [4] S. S. Du, J. Chen, L. Li, L. Xiao, and D. Zhou. Stochastic variance reduction methods for policy evaluation. In International Conference on Machine Learning, pages 1049–1058, 2017.