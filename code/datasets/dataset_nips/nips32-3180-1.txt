I think this is a strong and interesting submission. The presented model, named "Neural State Machine"  deviates from the existing approaches to visual question answering by doing 'a sequence of computations' that resembles 'a sequence of reasoning steps'. However, definitely, there are some resembles with the already existing approaches towards visual question answering. E.g., there are approaches that were using outputs of classifier as a knowledge representation, semantic parsers as computational and compositional methods to derive an answer,  and use classifier uncertainty to represent concepts (e.g., "A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input"). There are also similarities to graph neural networks in the terms of compositionality, and computability (message passing). However, still the method seems to diverge significantly from these to consider it as a novel. Moreover, the results on GQA are quite strong. The following paper "Language-Conditioned Graph Networks for Relational Reasoning" comes to my mind in terms of the graphnet-equivalent of the Neural State Machine, but it performs significantly worse than the latter. However, this could be a result of different vision representation.  It is worth mentioning that GQA is semi-synthetic (questions are synthetic), and hence there is a possibility to 'game' the dataset. Therefore it is nice the authors also provide strong results on the VQA-CP dataset, proving their point.   In overall, I think this is interesting submission, with reasonable novel model and strong results.