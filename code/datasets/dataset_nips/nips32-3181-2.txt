This paper proposed a new theoretical framework for analysing the regret of gradient based meta learning algorithms and derived a few variants of algorithms to learn the initialisation and learning rate. It provides rigorous analysis about the online regret and how it depends on the similarity of tasks, number of gradient descent steps, number of tasks, etc. It provides a nice tool to select the update rule for the model initialisation and choosing the step size. It also provides an approach to analyse the bound and convergence rate of the excess transfer risk. However, I'm not familiar with the literature on online learning and its application on the meta-learning setup. Therefore, I'm not able to comment on the advantage of the proposed method compared to existing approaches.  In the experiment section, the improvement of ARUBA over Adam is relative small for the reptile algorithm while the improvement on the FedAvg algorithm is a lot more significant. Could the author comment what factor leads to the big difference between these two experiments? 