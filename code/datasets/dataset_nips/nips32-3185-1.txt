The paper is nice to read, the proofs are sound and the literature seem to be well cited. On the negative side, the different regret bounds proved in this paper improve existing regret bounds in very specific setting (depending on n, S, and the total number of experts) and some of them may not be optimal (such as the one on bandits with sparsity). This might thus only interest a small niche of experts only.  Other comments: - Some discussion should be made somewhere about the optimality of the bounds. What is known to be optimal and what is not? - About the bandit feedback with sparsity: it would be nice to add figures that compare the rates of the existing bound and the one of Thm. 8 to better understand when this one is better and when it is not. In particular, it is stated that this is the case when S and K are very large. But only S needs to be large, since the assumption $T>S>max{T/K^3,K^5/T}$ is enough which can be satisfied for small K.  - About the existing results for the stochastic setting (see line 47-52): when reading this paragraph, I am not sure if the existing results refer to best-of-both-worlds results only or to any results for switching regret in stochastic environment. Does there exists any results for tracking a small set of experts for stochastic losses? - I am wondering if an algorithm such as Coral (see Agarwal, Luo et al. 2016) could be use in the sparse bandit setting to improve the rate to sqrt{T} instead of T^{2/3}. 