Originality  The use of self supervision for this particular application is novel as far as I know. The idea of incorporating the self supervised transformations during inference (outlier scoring) adds additional novelty.   Quality   Clarity The motivation for inlier priority seems overly complicated. This already seems intuitive (there is a lot of calculation to conclude that the expected norm of gradients will be proportional to ratio of inlier/outlier) and it feels as if it can been motivated in an even simpler way, or perhaps leave the mathematical rigor to supplementary material. The paper is clear and introduces both outlier detection and self supervision to the unfamiliar reader. However, I do feel that the paper could cite more self supervision papers (right now it only has 2: the immediate methods used) and at least once call it the popular name “self supervision” once. I suggest this to bring this paper to the attention of that community since knowing that there is an application for their work could inspire them use this benchmark. This would increase the mutual benefits between the two communities (self sup and outliers).   Significance I think this is an interesting new application of self supervision. The experimental results look compelling on established benchmarks (although I was not previously familiar with them). From my perspective (familiar with self supervision but not the outlier detection), this looks like a significant contribution, both for connecting the areas but also for the method itself. 