Pros:  1, The proposed rational polynomial spectral filter is novel and interesting.  2, I like the summarization and the comparison of different spectral filters in terms of functional forms, complexity measures, etc.   3, The paper is clearly written.  Cons:  1, I appreciate the authors' efforts in pushing forward the graph convolution by designing new spectral filters. However, from the current writing, I feel like there is a gap between the claimed new technique and practical benefits brought by the technique. For example, when you introduce and motivate the Cayley filters and the rational polynomial spectral filters in general, could you be more specific and provide more intuition on why “narrow frequency bands” is an issue practically, how these filters resolve this issue, and why improved localization would lead to better empirical performance.  2, I think an in-depth discussion and experimental comparison with the recently proposed multi-scale spectral graph convolution [23] is necessary since: (1) they use the neural networks as the learnable spectral filters which have better data-adaptive capacity; (2) they can cheaply compute the spectral convolution with very a large localization range.  3, In terms of experiments, I strongly discourage authors to only report performances on the small citation networks using the fix spit. As discussed in several recent works, e.g., [1], the ranking of different models dramatically changes when the split changes. I suggest authors either choose other larger datasets or report the performances over multiple random splits and/or decreasing the proportion of labeled nodes.   4, The experimental comparison is unfair to other methods. It is not surprising that adding dense connections improves the performance for many models. However, most of your baselines do not exploit this trick. I would suggest removing the dense connections and just compare the newly proposed spectral convolutional networks with the other methods. You need this experiment as an ablation study to clarify the core contribution. I did not see any empirical analysis on the claimed improved localization contribution. I suggest adding an ablation study to compare against other spectral filters, which have less controlled localization and same settings otherwise, e.g., Chebyshev filter.  5, What is the definition of learning complexity?  [1] Shchur, Oleksandr, et al. "Pitfalls of graph neural network evaluation." arXiv preprint arXiv:1811.05868 (2018)  ================================================================ Authors' rebuttal addressed most of my concerns on experimental comparison. One suggestion is that it would be more elegant and efficient to improve the coefficient optimization via amortized inference since it is costly to perform such an optimization per layer. I have changed the score accordingly.