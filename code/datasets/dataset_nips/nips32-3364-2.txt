This paper proposes a new information theoretic loss function, L_DML, for training deep neural networks robust to noisy labels. Specifically, this paper first proposes a new information measure, DMI (Determinant based Mutual Information), which is a generalized version of mutual information. Based on the relative invariance of DMI, this paper proposes a noise-robust loss function called L_DMI, which is theoretically justified. Experiments on synthetic and real-world noisy datasets demonstrate the effectiveness of the proposed L_DMI on defending diagonally dominant and diagonally non-dominant noise.   Pros: 1) The proposed information measure DMI, and robust loss function L_DMI, are both theoretically justified.  2) The proposed L_DMI loss function is easy to implement. 3) Empirical results on synthetic and real-world noisy datasets show that L_DMI outperforms other baselines.   Cons: 1) The results on Fashion-MNIST show that the proposed method is not sensitive to noise patterns (i.e. class-independent and class-dependent noises), and noise amount (with probability from 0.1 to 0.9). However, it is unclear why converting Fashion-MNIST to two classes instead of using the original 10-class setting. Can explain more about that? To maintain consistency, the comparison with more baselines (i.e. LCCN, GCE, and FW) should also be provided. 2) For CIFAR-10 dataset, the proposed method is only evaluated by adding noise to similar classes. The evaluation on the uniform noise is missing.  3) For Dogs vs. Cats, why the experiment setting is not consistent with Fashion-MNIST, which is also two-class case? Specifically, the evaluations on uniform noise and ‘dog->cat’ noise are missing.   Minor issue Line 283: “neutral networks” -> “neural networks”  Overall, this paper proposes a new noise-robust loss function for defending label noise. The proposed method is both theoretically and empirically sound.  