The idea of generating surrogate tasks or datasets for evaluating HPO methods is quite interesting, and is especially useful if the target task or model is very computationally expensive to evaluate a hyperparameter configuration, e.g., ResNet.   Unfortunately, the empirical evaluations fail to effectively support the superiority and feasibility of the proposed benchmarking algorithm in practical applications.  --------------------------------------------------------------------------------------------------------- I have read the authors' response, and tend to maintain my score. The authors have addressed some of my concerns, while I am even more worried about the feasibility and practicability of the proposed benchmarking algorithm (cf. Line 30-32). 