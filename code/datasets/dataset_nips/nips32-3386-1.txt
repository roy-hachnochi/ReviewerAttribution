After author response, I am keeping my score the same. The authors have promised to add the most important detail I felt was lacking: whether a cost to communication lead to reduced communication success.  -----------  This paper investigates emergent communication between two agents in a very simple communication game where the referents are power-law distributed. The authors show that naively training the agents with reinforcement learning using policy gradient methods lead to communication protocols where common referents are associated with longer messages, which contradicts Zipf's Law. This is an important observation which serves to delineate artificial agent communication from human communication. The authors then provide an elegant and simple explanation for why this might be the case grounded in the representational capacity of the listener agent, and Figure 3 seems to provide good evidence for their explanation. It is interesting to speculate whether this is caused by a peculiarity in LSTM dynamics, and whether encoders with alternative architectures (such as hierarchical tree-based encoders) distinguish different features.  Further, the authors show that a simple length penalty eliminates the anti-efficient coding behaviour, and results in communication which exhibits a Zipfian distribution. This shows that the conventional view that communication is costless may not be entirely accurate. The authors do not state whether the length penalty affects communication success; this would serve as an interesting comparison.   Finally, the authors investigate the symbol statistics of the resulting communication protocol. This is (for me) the weakest section of the paper, as I do not feel it contributes much to the main thrust of the argument. However, the other two sections by themselves justify acceptance. The discussion points raised by the authors are all worthy of further thought.  Overall, I feel that this paper raises an interesting and important observation. Do we care solely about agents communicating with each other to achieve task success in situations where success is not possible without communication, or do we study emergent communication as a tool to study the evolution of human language? If the latter, then the exact way we define tasks and train our agents can provide important clues about what pressures shaped human language, and this paper proposes and investigates one such pressure: an inherent cost to producing sounds. The paper is clearly written, and deserves a wider audience at NeurIPS.