Relevant references to *linear* numerical optimization papers/textbooks that employ gradient descent to compute orthonormal matrices for the matrix SVD that this method parallels and generalizes are not given, or not clearly shown.  Its main claimed advantage over other scalable tensor decompositions is its ability to extend its algorithm to handle common constraints, such as  non-negativity, but it has not been discussed relative to which other work.  This is a complete piece of work, but it is unclear why is this paper submitted to NIPS and not to a numerical optimization conference/journal.