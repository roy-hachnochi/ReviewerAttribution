 The main motivation of this work is based on the fact that conventional graph kernels loose information in their embedding and/or aggregation steps. While we agree with the authors on this point, it is not clear what is the information lost with the proposed WWL graph kernel. Since the proposed method is based on the WL subtree kernel, then it has the same weaknesses as it. Moreover, it may have more issues, such as the non-uniqueness of the embedding, the iterative operations related to hashing…  The part “To ensure the theoretical correctness of our results…” is confusing and misleading. On a first reading, the reader may understand that the theoretical results are not correct. The authors need to rewrite this part in order to emphasize on the fact that the work with indefinite kernel learning and RKKS is only required when working with the continuous WWL. This is not the case of categorical WWL. Moreover, the results given in Table 1 are equivalent to using conventional definite kernels and RKHS.  It is difficult to understand the assessment when comparing KSVM (in the case of WWL) and conventional SVM (all other methods). We think that it is important to assess the price to pay when using the proposed indefinite kernel with RKKS. This is relevant because many graph kernels have been proposed with the positive definiteness, thus can be easily used in conventional Machine Learning algorithms.  In experiments, it seems that WL-OA and the proposed WWL have comparable performances when dealing with categorical node labels. We think that it would be important to test if a version of WL-OA that takes into account continuous node labels would be also as powerful as the proposed WWL.  All experiments would have benefitted from a comparison with more graph kernels from the literature. This would be more important as baseline that using simple vertex or edge histograms.  In other words, it is not clear how this more complex approach, which may provide indefinite kernels, compares to simple approaches, i.e., the large class of graph kernels.  This is the first time that we read “Reproducible kernel Hilbert space” and “Reproducible kernel Krein space”. It should be “Reproducing”, not “Reproducible” !   -------------------------------------- -------------------------------------- We thank the authors for their positive feedback concerning some of the raised issue. We have updated the overall score accordingly. 