As mentioned above, the proposed oblivious sampling schemes are quite straightforward, and basically rely on (existing) oblivious data shuffling techniques along with some careful replication of data elements. The results appear to be novel, but not particularly original or technically deep. In addition, the schemes seem to work only for the case where k=n/m samples of size m each are needed from a data set of size n. Not clear if/how they might be extended to more general sampling scenarios.   The paper is overall clearly written, modulo a few typos and bugs spread throughout the text (e.g., delta vs delta_f, eps vs eps' on page 4). Some parts need a more thorough discussion and explanation, e.g., the various symbols and formulas in the comparisons with the shuffling approach in Table 1.   The proposed sampling algorithms are empirically shown to provide comparable utility with stronger DP guarantees for noisySGD over two test data sets. Given the limited scope of the experiments, it is not clear that these this can be extrapolated to other data sets and/or learning tasks. 