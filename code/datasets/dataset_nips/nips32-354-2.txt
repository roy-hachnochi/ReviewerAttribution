Strength: The idea of using hard attention for interpretability is novel to the field. Moreover, the design of the representation network limits the receptive field and prevents the model from using global information towards classification, which serves the purpose of interoperability evaluation. (However, this is also a limit which is discussed in the review) In addition, the saccader cell is also a simple yet novel design.  Weakness: This model is only applicable to classification task on limited type images. Due to the design of the representation network, the model could only generate prediction on a patch of the image. The model only selects a fixed number of glimpses with fixed size for all inputs. The final prediction is a simple average across fixed number (T) of patches. This design would fail to apply on many classification tasks, such as pedestrain detection, where the image-level label is determined by multiple small ROIs. Moreover, the global distribution of spatial features is neglected by the model. The model doesn't generalize to classification tasks, such as cancer classification, where both the global features (such as the spatial distribution of radiodense tissues) and local features (lesion border) together determines the label. This model is only evaluated on ImageNet which is not representative.   The pre-training procedure for the saccader cell is questionable. The loss function is designed to force the saccader cell to generate large probability on regions that representation network gives large-value logits. This step introduces a strong bias and creates a self-feedback loop.  (Most of this part has been addressed by author's response.) The experiment design is somehow insufficient. First of all, the author only compares models that fit the framework of this paper (i.e. models that has an explicit glimpse selection mechanism). However, models from other families (such as weakly supervised localization models) are not compared. A simple baseline could be built using a black-box classification network (such as ResNet-V2-50) with some model-agnostic technique (such as Class Activation Map). In addition, in section 4.3, the author declares higher classification performance with NASNet but it's unclear whether this improve comes from the increased model capacity or higher input resolution.