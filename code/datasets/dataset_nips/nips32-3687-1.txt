The paper proposes to transfer information across tasks using learnt representations of training datasets used in those tasks. This results in a joint Gaussian process model on hyperparameters and data representations. The developed method has a faster convergence compared to existing baselines, in some cases requiring only a few evaluations of the target objective.   Through experiments, the authors show that it is possible to borrow strength between multiple hyperparameter learning tasks by making use of the similarity between training datasets used in those tasks. This helps developing the new method which finds a favourable setting of hyperparameters in only a few evaluations of the target objective.  