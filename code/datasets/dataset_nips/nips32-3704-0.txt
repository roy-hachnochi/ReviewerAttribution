The paper proposes a new method for learning a label noise transition matrix from a noisy dataset. Unlike previously proposed approaches (e.g. the forward method) the proposed approach is shown to be less dependent on anchor points, which are defined to be examples that would have a have the output of the softmax extremely focused on the correct class in the noiseless domain. The main idea is to use importance reweighting to account for the discrepancy between the output of a noise free classifier and a noisy one, and to allow learnable modifications to the initially estimated transition matrix. The experiments show modest improvements over the SoA on MNIST and CIFAR-10 under low and medium levels of label noise. When anchor points are purposefully removed, the improvements on CIFAR-10 and 100 are more substantial, illustrating that the approach is less dependent on the presence of anchor points.  Originality: The improvement over the forward method is somewhat incremental, but the idea is novel as far as I know.  Clarity: There are a few language errors in the paper, but overall it is well written and the explanation of the approach is clear.  Significance: While the results on CIFAR-10 look good, the results on CIFAR-100 are a little less convincing, especially in the case of 50% label noise, especially given the overlapping error bars. The results on Clothing1M demonstrate a clear improvement on the SoA.