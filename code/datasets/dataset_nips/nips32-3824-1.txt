Even if the practical applicability of this learning algorithm on current hardware is limited, the theoretical approach and its derivation is certainly relevant to the NIPS community. The paper is well structured, the mathematical notation is well understandable and clear.  Nevertheless I have some (minor) concerns.  I miss a clear presentation of the restrictions on the transition function F and the role of the convergence “assumption” of the first phase. As far as I understood convergence of the first phase requires F’s such that F=d Phi /ds. The propotypical setting seams to state the same with other words, isn’t it. A clear relation between the fixed-point search and Energy-maximization might be obvious in the whole context of EP, but it is not clear enough from this paper.  A discretized version of EP has to be compared to standard RNN approaches, hence also  the relation to other non fixedpoint-converging, standard RNNs should be discussed.  In particular a comparison with LSTM and a comment on the relation with the vanishing/exploding gradient problem and why this is not a problem in view of the fixedpoint search would be nice  UPDATE: Thanks for the additional information in the rebuttal and the clarifications. Congrats to this excellent paper!