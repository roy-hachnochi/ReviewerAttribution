===== Summary =====  This paper studies the bias in the sample mean estimates of actions in a multi-armed bandit setting. More specifically, the authors consider three sources of bias: the adaptive sampling of the arms, the adaptive stopping time, and the adaptive best-arm identification (choosing) strategy. It generalizes and complements the results of Nie et al. (AISTATS 2018).  ===== Strengths =====  [Originality] * The authors provide a different view (to my knowledge) of the bandit setting (the tabular setting). * The contributions build on previous work (Nie et al. 2018), but are more general and do bring something new.  [Quality] * The authors provide several examples and numerical experiments to illustrate/support their claims. * I didn't review appendix proofs in detail, but they seemed sound from an overview.  [Clarity] * The paper is well organized and reasonably easy to follow given the sometimes uncommon notation. [Significance] * If bandits (and RL algorithms in general) are to be deployed more and more (e.g. in adaptive trials, A/B testing), I think that it is essential to understand better the potential bias in the resulting action estimates.  ===== Weaknesses =====  [Clarity] * The writing could be polished.  [Significance] * The contributions could have a broader impact if they were better linked to examples of applications where it is relevant to know the sign of bias. At first sight, it is not clear how learning about the sign of bias, but not the amplitude of bias, can be useful.  Questions: * Is the choosing strategy always adaptive? If not, can you provide an example of non-adaptive choosing?  Minor details: * Some results (e.g. Fig. 2-left and Fig. 3) are difficult to see. Maybe these could be zoomed to really see on which side fall the estimates? * The term "optimism" is already well-known and used in bandits for something else -- it may confuse the reader. * Bad cross-references need to be fixed in the introduction. * Sec. 2.1: Explicitly define A_t and Y_t. * The title could be improved. -------------------------------------------------------------------- I have read the rebuttal -- this is a good paper. Now that you mention it, the title is a nice reply to Nie et al. Linking explicitly the term "optimism" to the "optimism in front of uncertainty" principle should indeed help the reader, in addition to situating the paper w.r.t. the bandits literature (as pointed out by reviewer 2).  Non-adaptive choosing strategy: I agree that they may exist in theory, but they are counterintuitive when speaking about bandits, which typically arise from adaptive experimental designs, therefore aiming at being adaptive by definition. It may be worth mentioning.