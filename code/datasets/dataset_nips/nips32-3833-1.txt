 TL;DR:  I learnt something by reading this paper and I think a lot of people working on bandits and adaptive algorithms should be aware of those results. I am also happy with how they corrected/completed the Nie et al. 2018 paper that was quite unclear to me.  Originality : good. it is an unusual read in this domain (especially when one hasn't read the paper by Nie et al. 2018) Quality : Very good. It is a technically sound paper that defines and solves a precise result; Clarity : good. It is well-written but I would highly recommend to add references to the bandit literature as it is this is the targeted community; I must admit I was a bit lost at the beginning, I wasn't sure we were talking about the same thing. Significance: Okay. I think this is possibly the weakest point because in the end, I don't know exactly which issue(s) this result will solve...  Major comments:  M1. This paper could be of interest to a lot of people in the bandit community which is large and diverse... but for them to know about it, you have to cite them ! This paper has a total of 10 citations, including the paper they correct and a bunch of math papers that look awesome... but nearly no Bandit paper ! As far as I'm concerned, it made the paper pretty abstract as I felt it was not solving any of the problems I care about. And I still think it doesn't really, but it does bring some understanding about all those problems. I would definitely recommend expliciting further the links with the literature and I suggest at the end of this review a list of possible references to add. Typically, for the average bandit person, it feels weird to see UCB / TS / lil'UCB all mixed together and compared because they target really different kinds of problems, namely Best Arm Identification versus Cumulative Regret Minimization. I understand the scope of the paper is wider than those distinctions but that could be made clear somewhere.   M2. So regarding the question of which problem is solved by this paper, I am a bit puzzled. I get that in Nie et al 2018, the message is that there analysis of the bias would allow a practitioner to correct the sample means obtained at the stopping time so that they return a less biased value. But it is not made very clear in your paper that this could be a use case of Theorem 7. Do you think you could make the goal of this analysis a bit more explicit ?   M3. Numerical experiments. To be a fair comparison between UCB and TS, you should use the anytime confidence bonus \sqrt{\frac{2\log(t)}{N_k(t)}} cf KL-UCB-switch: optimal regret bounds for stochastic bandits from both a distribution-dependent and a distribution-free viewpoints (https://arxiv.org/abs/1805.05071) and the MOSS paper.  I mean, otherwise it's hard to explain why you get biases an order of magnitude bigger for UCB than TS. I am not sure if this "fair comparison" would bring more answers or more questions. A general interrogation I have by reading your paper is: Could we get a relationship between the performance of a bandit algorithm (i.e it's regret in general) and the bias at some stopping time ? In the regret minimization setting, a reasonable possible relationship would be: The smaller the regret, the bigger the bias at horizon T, because smaller regret means less exploration and so less data. Similar analysis could be done on the BAI problem. Those are just suggestions for further developments rather than real critics.   minor comments : m1: Section refs on p2 broken    Refs : The Bandit Algorithms book by Lattimore and Szepesvari: contains literally everyting about the bandit literature (if only one, at least this one) @book{lattimore2019book,   title = {Bandit Algorithms},   author = {Lattimore, Tor and Szepesv\'{a}ri, Csaba},   year = {2019},   publisher = {Cambridge University Press (preprint)}, }  Optimal best arm identification with fixed confidence: a different type of Best Arm Identification @inproceedings{garivier2016optimal,   title={Optimal best arm identification with fixed confidence},   author={Garivier, Aur{\'e}lien and Kaufmann, Emilie},   booktitle={Conference on Learning Theory},   pages={998--1027},   year={2016} }  The original Auer 2002 paper that coined the term "optimism principle" as far as I know: @article{auer2002using,   title={Using confidence bounds for exploitation-exploration trade-offs},   author={Auer, Peter},   journal={Journal of Machine Learning Research},   volume={3},   number={Nov},   pages={397--422},   year={2002} }  A very similar effect noticed in management science and decision analysis : @article{smith2006optimizer,   title={The optimizerâ€™s curse: Skepticism and postdecision surprise in decision analysis},   author={Smith, James E and Winkler, Robert L},   journal={Management Science},   volume={52},   number={3},   pages={311--322},   year={2006},   publisher={INFORMS} }  ---------------------------------------------------------------------------------------- Edit after rebuttal :  We thank the authors for their answers to my and other reviewers' questions. We hope the NeurIPS community will get the occasion to learn as much as we had and we look forward to future developments around this idea. 