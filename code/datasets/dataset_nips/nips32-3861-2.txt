EDIT POST-REBUTTAL  I maintain my original score for the reasons already indicated. I think there is value in publishing this work.  ***  This work is in a long line of papers seeking to improve stochastic optimization for variational inference with a reparameterized lower bound. While the particular algorithmic contribution is not a major departure from the state of the art, the careful empirical study, theoretical ground, and discussion in relation to recent works has made me reconsider what I considered obvious before reading--that DReGS was the most efficient method of gradient estimation due to unbiasedness and lower variance. I appreciate this insight.  The writing is very clear, and addresses current open issues in approximate inference.  The empirical results are appropriate, using both synthetic and MNIST data.