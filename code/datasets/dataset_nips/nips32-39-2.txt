The paper presents an analysis of human preferances and understandings of AI performing tasks at four levels of delegation (From fully autonomous to not present at all). The idea is to develop a framework that can be used to gain better understandings of how humans perceive AI. This kind of method could be used to gather insights as AI systems become more capable into how humans perceive them and are willing to use them.  The paper is well written for the most part and clear. I think the results are significant, and the breakdown in terms of the components is very interesting. The case studies further accentuate the points presented. This kind of paper will be of interest to artificial intelligence policy makers.  I have a few suggestions and questions, but I think most of these are easily addressable. - in section 3 its not clear (although it is directly stated) that the items shown in numbered lists are the actual questions asked - maybe put them in "quotes" or italics to highlight this better. - the last paragraph of section 3 threw me off with the "four factors" which I thought were the 4 in the list right above it. This section could be reorganized a bit to handle this and the previous comment - the choice of tasks needs more description. "100 tasks drawn from academic conferences" is not clear, and a better description of the criteria used to select the tasks is needed. If there were not inclusion criteria used then how was this done? - were the questions about the properties of tasks randomized across participants? If not, why not? - was the delegation question always asked after the task questions? Would anything change if it was asked first?  - give a few small examples of tasks in the main text at the start of 4.1 to help situate the reader. - in 4.1 - ""We include all the four factors" - again not clear what this is referring to - be specific. - in 4.1 it wasn't clear on the first read through that each person just evaluated a single task - actually I'm still not sure of this but think so given that each survey took 5 minutes. IN general the procedure could be clarified and it could be made explicit which questions were asked (e.g. number the questions in section 3 as M.1,M.2 for Motivation, D.1,D.2 for Difficulty and then refer to these explicitly in 4.1 - in 4.2 the "degree of AI assistance" -- make it clear this is the delegatability - or use one term only consistently throughout - in 4.2 the notion of "coherent" is not defined - in 4.2 explain the high correlation between value alignment and machine ability - I found tables 3 adn 4 rather hard to look at - it might help to color code each table cell to show larger/smaller - the numbers with decimals are hard to easily compare at a glance.  i have read the author's response and it clarifies the issues I raised. 