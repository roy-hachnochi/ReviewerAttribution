In this paper, the authors study the design of voting rules. The authors consider two aspects of voting rules: i) How well they optimize the social welfare (this is an utilitarian point of view). This is measured by a distortion function (ratio of obtained to optimal social welfare), as is classical to do in related work.  ii) How complex the elicitation rule is. This is measured in terms of (expected, since randomization is allowed) communication complexity (how many bits are needed for an agent to report a vote, or equivalently, log of the number of responses available to an agent).  The aim of this paper is to characterize the optimal trade-off between distortion and communication complexity. In other words, under a limited communication complexity budget, what is the best social welfare that can be achieved, and how does it compare to the unconstrained social welfare. To do so, the authors provide lower and upper bound on this trade-off, that while not quite matching, are fairly close to each other.  Upper bounds are the object of Section 3. There, the authors provide upper bounds for both deterministic and randomized voting rules. To obtain these upper bounds, the authors introduce two new classes of voting rules: i) For deterministic voting rules, the authors consider an algorithm called PrefThreshold that works as follows. The elicitation rule is quite natural: each agent to report their top $t$ alternatives, and to report in what sub-interval (among $l$ of them) their value for each such alternative belongs. The larger the number of alternatives and the finer the decomposition in the sub-intervals get, the better the distortion becomes, but this comes at a higher communication complexity cost. The aggregation rule is also simple and natural: the approximate values from the sub-intervals are used to estimate the social welfare, and the winner is the outcome with the highest estimated SW. To me, this class of algorithm sounds very appealing as it is very natural and could realistically be implemented in practice, via two simple questions: “who are your t favorite candidates?” and “How do you rate them on a scale from 1 to l?” In Theorem 1, the authors characterize the communication complexity and the distortion of the algorithm as a function of $t$ and $l$, then discuss what choices of $t$ and $l$ lead to which trade-off. This allows them to obtain the following upper bounds on what trade-offs are possible.  ii) For randomized voting rules, the authors consider a rule that selects a subset of actions at random and only elicits information from the voters about their valuations for this subset. Such randomization in voting rules has probably more restricted applications (I cannot generally imagine current societies accepting randomness in the outcome of legislative or presidential elections, especially when the voting rules randomly throws away part of the candidates – and possibly your top candidate with some probability -- at the beginning), but I think studying what can be achieved by randomized voting rules and how much one can gain compared to deterministic ones is an interesting theoretical question.  The authors then develop lower bounds in Sections 4 and 5. The lower bounds of Section 4 apply to deterministic elicitation rules and show that i) if the communication complexity is strictly less than log m, the distortion is unbounded, and ii) even when the aggregation rule is randomized, one cannot hope to get sub-linear distortion when the communication complexity is restricted to exactly log m at most. This shows an interesting gap with the implications of Theorem 2 (this is possible with randomized elicitation rules). Section 5 shows general lower bounds on the communication complexity needed as a function of the distortion in Theorem 6; this gives a lower bound on the trade-off between communication complexity and distortion that applies much more widely (for any $d$) than what was known from previous work. These bounds differ by a factor proportional to the inverse of the distortion between deterministic and randomized voting rules; for small distortion, these complexities only differ by a small factor. They then show how these results apply to special cases; in particular, if one is aiming to have at most logarithmic distortion, then the lower bounds for both deterministic and randomized voting rules are within a logarithmic factor of the upper bounds on computational complexity. I.e., in this regime, the bounds provided by the authors are nearly tight.   Put all together, the results paint a fairly complete picture of the trade-off communication complexity in this setting. The results are theoretically solid and interesting and constitute a vast improvement compared to previous work. The only complaint that I have about this paper is that there is no discussion of strategic behavior and truthfulness (could voters manipulate their vote here to get an outcome they prefer, and how much would that impact the social welfare?), but this can be left to future work. To me, this paper is a clear accept.  