The paper proposes a problem of planning in non-stationary environments where the change is gradual. The gradual change assumption is formalized by stating a Lipschitzness assumption. The authors assume that only the model evolution is not known but the agent has access to the current model. Given this along with the Lipschitz assumption, the method constructs a set of admissible MDPs. A worst case value function is defined using this admissible set which can be easily derived from the smoothness property.   For worst case planning with this set, the problem becomes combinatorial in specification as the constraint has to be respected for all time-steps. To avoid this, the authors relax the problem to a case where the constraints are only verified for with respect to the planning timestep t_0. With this, a minimax tree search approach is proposed and analyzed. The proofs are quite simple to understand and to my knowledge have no errors. However, the algorithm description can be a bit more clearer with apt description of the bottom up minimax planning description. A few comments regarding the methods:  1. Since, the Lipschitz assumption is taken over the time indices, the constant has to be quite small for the admissible models to be non-vacuous. Can the authors comment on the plausibility of this assumption? How does it compare with a setting where there is a bounded change assumption. What modification would the authors make for such a setting to RATS? 2. Since, the method is not computationally scalable, it is desirable to have a discussion of where things can be changed. 3. Can any guarantee be given for the relation between the actual objective (1,2) vs the relaxed version (3,4)?  The related work in non-stationary learning problems is very nicely compiled. However, given the risk-aware planning nature of the problem, I think there should be a discussion in related work and experiments by considering methods from the robust MDP literature. The setting is arguably an instance of that where the robust (maxmin) planning needs to be done for the plausible MDP set. Also, the authors state this to be a zero-shot planning. It would be helpful to clearly state what the authors mean by zero-shot exactly in this setting.  Further, apart from the theoretical contributions, a discussion about where this problem is relevant, practical instances and possibly a set of such experiments would strengthen the paper.  ------------------------------- Update: I have read the author response and would maintain my initial rating. The technical contribution here is limited as it is not significantly challenging to apply minimax tree search algorithm to the rectangular uncertainty set after the relaxation. It would be nice to see how the relaxation affects the outcome by comparing with the brute force result in small domains.