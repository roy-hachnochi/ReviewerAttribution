This paper introduces an autoregression model based on the SchNet. The technical parts seem correct, but the experiment section lacks baselines, like the state-of-the-art methods [1].  This paper is well written and organized clearly, yet there are still some points need to be clarified by the authors. In Equation (1), c_i is included in R_{\le i}, Z_{\le i}, so I’m wondering if it is redundant. I guess the authors want to highlight the role of c_i as the focus point, but we actually don’t need it in the final equation, as already illustrated in Equation (4) and Figure 1. According to Section 3, it seems like all the nodes are created sequentially, then what about the loop/ring in the graph? How to generate such a structure when we assume the new points are bonded to  the focus point only? Or if the generation process will generate the same points twice when moving along the trajectory? In line 195, it implies that generated molecules -> SMILES -> bond counts, then what’s the difference with counting bounds directly on the generated graph?  I think the work is a little incremental since the key building blocks come from the SchNet. In addition, the experiment section lacks the baselines like [1]. For the targeted discovery, it would be better to explore more tasks. For example, the remaining 11 tasks in QM9 all share the same molecules, so they can be trained quickly following the same pre-trained model. According to section 5.3, the targeted discovery is obtained by using some heuristics (data filtering), so it would be more convincing to compare the G-SchNet with other baseline methods to show its advantage in this setting.  [1] You, J., Liu, B., Ying, Z., Pande, V., & Leskovec, J. (2018). Graph convolutional policy network for goal-directed molecular graph generation. In Advances in Neural Information Processing Systems (pp. 6410-6421).