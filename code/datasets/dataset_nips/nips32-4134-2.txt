My main concern with this this paper is that, although the authors provide an algorithm that chooses k adaptively, they have introduced another tuning parameter \delta, and there is no guidance on how to choose this in practice.  In the introduction the authors claim that their results are `instance optimal'. However, there is no result that proves the optimality of the bounds.  The `rates of convergence' provided are not rates of convergence in the usual sense. They provide a threshold above which n must be for a given point x to be classified correctly with high probability. This says nothing about the average behaviour over test points x.  The comparison with the standard k-NN classifier in Section 4.2 does not seem fully convincing to me. [CD14] show that the points in \mathcal{X}_{n,k}' are likely to be correctly classified by k-NN, but it is not clear whether there could be other points that are also likely to be correctly classified by k-NN. I think that more work needs to be done here to compare the methods convincingly.   ===========================================================  UPDATE (after author rebuttal):  Thank you to the authors for carefully reading my review. I still feel that there should be more comparison to the literature on kNN classification, but my other concerns have now been mostly addressed. I have changed the score for the submission. 