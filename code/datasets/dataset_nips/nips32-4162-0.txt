This paper deals with the computation of Nash Equilibria in competitive two-player games where the $x$ player is minimizing a function $f(x,y)$ and the $y$ player is minimizing a function $g(x,y)$. Such problems arise in a wide variety of domains, notably in training GANs, and there has been much recent interest in developing algorithms for solving such problems. Gradient Descent Ascent (GDA) is a natural candidate algorithm for finding Nash Equilibrium, but it will provably oscillate or diverge even in simple settings. As such, many recent works have modified GDA or proposed different algorithms or schemes to guarantee convergence.  This paper proposes a new algorithm called Competitive Gradient Descent (CGD), which updates each player's iterates by adding the Nash Equilibrium of a regularized bilinear approximation of the game at the current iterates. CGD requires Hessian-vector products, making it a second-order algorithm. The authors prove that their algorithm is locally stable around critical points for zero-sum games. They discuss how their algorithm relates to other recent algorithms for finding Nash Equilibria, and they also provide a number of experimental comparisons. Unlike other algorithms, CGD does not need to reduce its step-size parameter $\eta$ when the ``interaction'' between the players is large, as signified by the magnitude of $D^2_{xy} f$ being large.  On the positive side, this paper proposes a novel algorithm that seems reasonably well-motivated. Moreover, the paper gives a nice interpretation of how this algorithm compares to other existing algorithms. Finally, the experimental results are reasonably extensive and seem to indicate that CGD may have good empirical performance.  On the negative side, the theoretical results are fairly weak, since they just prove stability near critical points. The authors emphasize how CGD improves when $D^2_{xy}$ is large, whereas other algorithms have poor performance for fixed step-size as $D^2_{xy}$ grows. However, this comparison isn't exactly fair since CGD uses second-order information to explicitly regularize step-sizes by the off-diagonal term, whereas OGDA or extragradient use only first-order information. Moreover, CGD still requires that the step-size is bounded by one over the max diagonal entry of the Hessian, so at least from the theory, CGD will still require step-size tuning. Finally, while it is true that Hessian-vector products are theoretically as fast as gradient calls for neural networks and explicitly defined functions, it is misleading to simply say ``Hessian vector products can be computed at minimal overhead over the cost of computing gradients'' because this is not true in general, for instance when one only has oracle access to the function and gradient.  Overall, this paper is an accept. The algorithm is novel and well-motivated, and the authors do a good job of comparing it to existing results. While the theoretical results are minimal, the experimental results seem well-done and fairly thorough. The paper is clear.  --- After Rebuttal --- I have read the other reviews and the rebuttal. I had no major concerns for the paper, so my rating is unchanged.