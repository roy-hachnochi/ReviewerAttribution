   This paper introduces a new complexity measure for MDPs called maximum expected hitting cost. Unlike the diameter measure is only a function of the transition dynamics, this new measure takes into account the reward dynamics as well. The authors show theoretically that under the same assumptions as previous authors who introduced diameter, this new measure is a tighter upper bound. Furthermore, they show the usefulness of this measure by showing that it can be used to better understand the informativeness of rewards when using potential based reward shaping and they prove theoretically that in a large class of MDPs potential based reward shaping is bounded by a multiplicative factor of 2 on their maximum expected hitting costs.    I enjoyed reading this paper. I appreciated the structure that the authors used in this paper which first introduced all the necessary prior work (related to diameter) cosily but thoroughly enough before introducing their contributions. The practical example (Figure 1) with potential based reward shaping was very useful for me to get a better the intuition behind this work and move it from something purely theoretical to something more practical.     Originality: Good originality. Given that is only a function diameter of transition, it is natural to ask if there is a better measure that incorporates reward and this was well executed by the authors.      Quality: good quality. Theoretical contributions clear and proofs included in the supplementary material.   Clarity: excellent clarity. Related work well presented. Paper is self-contained. Contributions are very clear. Significance: good significance. A tighter upper bound to diameter under the same set of assumptions is introduced while the connections to potential based reward shaping are interesting. Furthermore, this paper may be useful in practice to craft better shaping rewards.   Minor comments:     1. line 180: The recent rise of deep RL also exposes “bugs” in some of these designed rewards - can the authors cite exactly which kinds of bugs they are referring to here     2. line 181: "Our results show that the informativeness of rewards, an aspect of “the complexity of the learning problem” can be controlled by a well specified potential without inadvertently changing the intended behaviors of the original reward". Read in isolation it might appear that this paper proved that potential based reward shaping leaves the policy unchanged, but this was well-known before. What this paper does is enlighten us on the impact of potential based reward shaping relative to the author’s introduced measure. I think the authors should reword this to make their contributions more clear.     3. line 184: "Rewards should be first defined to faithfully express the intended task, and then any extra knowledge can be incorporated via a shaping potential to reduce the sample complexity of training to obtain the same desired behaviors". Again, I find this statement a bit off-topic from the main paper. It is well-known from potential based reward shaping literature that a shaping reward incorporates domain knowledge and has the potential to learn a policy faster if well specified. I do not see this as being tied to the main contributions of the paper. Rather this paper has enlighting us on the maximum positive / negative impact that potential based reward shaping can have.     4. In general, I felt the final discussion did not tie in with the rest of the paper. It felt like it was talking more about potential based reward shaping and its benefits which is not the main work that is introduced by the authors in this paper. I felt the authors should talk here more about their main contributions and how with their new measure we can start thinking about specifying potential based reward shaping in a more formal way rather than relying on intuition about what is good prior knowledge to include in the potential function.    typos:     line 66: aglorithm  -------- Post rebuttal: Thank you for your comments. I recommend acceptance.