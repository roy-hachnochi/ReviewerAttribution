AFTER REBUTTAL ==============  I thank the authors for the clarifications given in the author response, especially regarding the  1-step vs multi-step empowerment. I keep my score and recommend the paper to be accepted.  Originality ----------- The paper seems to be the first to combine reward maximization and 1-step empowerment inside a single objective function. A slightly more explicit placement of the presented work in a broader context of research on empowerment in the Introduction or Motivation sections would be beneficial for the reader.  Quality -------- Theoretical developments and proofs were checked selectively and did not reveal significant flaws.  The basic premise of using empowerment to improve reward maximization may be somewhat questionable. Especially given that empowerment is expensive to compute, perhaps a better argument would be to consider a multi-task setting, where task transfer can benefit from the agent being initially empowered.  Adding a paragraph detailing drawbacks of the proposed approach would be beneficial. For example, learning forward and inverse models may introduce bias and hinder performance of model-free methods. Was such effect observed in the experiments?  Clarity ------- The paper is written clearly and structured well.  Significance -------------- The main contribution of the paper is on the theoretical side. An important question which was not addressed by the paper is how much is lost by only considering 1-step empowerment. Since experiments were carried out in a single-task RL setting, the benefit of using the empowerment were not so clear (see Fig. 2). In general, maybe the whole line or argumentation in the paper can be slightly adapted to better motivate the combination of the reward with empowerment. It seems more plausible to expect gains in a multi-task setting.