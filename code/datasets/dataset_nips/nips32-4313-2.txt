Originality:  The paper gives a new insight over why residual networks work in practice. It follows several prior research to analyze the theoretical part, but the understanding is new.   Clarity: The paper is clearly written and well organized.   Significance:  In terms of understanding, the paper is somehow valuable. But why this understanding is only based on a two-layer non-overlapping convolutional neural networks? It assumes ||v||=1 and using ReLU as the nonlinear active function, what will it be if the assumptions are avoided? I am doubt the generalization of the understanding.   For the convergence analysis, the paper provides some bounds for the convergency, but no compatibles are provided, it is hard to judge the tightness of the results. 