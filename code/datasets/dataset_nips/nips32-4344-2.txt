In this paper, the authors study the problem of quadratic regression, whereby the response is modeled as function of both linear and quadratic terms, rather than the typical linear model. Naively, one would expect the dependence on the dimension of the problem to increase quadratically, and so the objective of this paper is to approximately capture the top entries of a (p^2-sized) gradient in time and space that are sub-p^2, under certain assumptions. Concretely, the authors propose the algorithm Interaction Hard Thresholding (IntHT), a variant of Iterative Hard Thresholding, which can recover a sparse solution (when such a solution is able to model the data well), with sub-quadratic complexity. Experiments done on synthetic data validate the theoretical conclusions.  ====== Strengths ====== This work provides a new thresholding algorithm for the problem of quadratic regression that achieves sub-quadratic dependence on the dimension of the problem. It is also noted in the paper that the results do not follow immediately by previous analyses due to the difficulty of finding the exact top elements of the gradient. Thus, one of the key contributions of the paper is to show that linear convergence holds, even with only an approximate top element extraction.  ====== Weaknesses ====== The main weakness of the paper is that it requires the assumption that there exists some sufficiently good solution that is also sparse. A discussion of how realistic this assumption is would be welcome, as when this assumption does not hold (i.e., only dense solutions suffice), sub-quadratic rates are no longer achieved.   ====== Minor Comments ====== - under “Linear Model” on first page: extraneous “)” - p.7: obtian -> obtain - p.7: “despite the hard thresholding is not accurate?” -> “despite the hard thresholding not being accurate?” - p.7: different bs -> different b’s  ========================================== The authors have addressed my concerns regarding the motivation for the setting.