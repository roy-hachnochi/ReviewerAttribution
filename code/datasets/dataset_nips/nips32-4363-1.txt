In this paper, authors introduce simple yet effective dataset-free heuristics for post-training quantization. Namely, 1. Clipping the activation values in some range which helps to focus on more dense area of values and better quantize them (with less distortion). The range values are determined using mean-square-error between the original weights and quantized weights. 2. Per-channel bit-allocation. Authors propose dynamic number of bits allocation instead of fixing it ahead of time for all channels. This is done by formulating an optimization problem and solution can be obtained analytically. 3. Since quantized weights have different mean and std than the original float32 weights, authors propose to correct those differences.  It can be clearly seen that these heuristics based on statistical information about weights/activations and they can be combined together.  The paper is well orginized and easy to follow. All proofs and derivations are seem correct to me.   Major concerns: - For ACIQ, as authors stated the idea of using clipping is not a new. It is not clear what is the performance compare to other types of removal of outliers (e.g. simply removing all values which are greater than \pm 2\sigma). - Authors apply the proposed methods for channel-wise quantization. What is the performance for other types of quantization (filter-wise, layer-wise)? Probably, some additional experiments and comparisons required to see if the methods are generally applicable. Otherwise, it might be problematic to integrate with other techniques for quantization. - What is the motivation for bias-correction? Empirically, it shows the benefits but it is unclear why having bias in the mean and variance is harmful for quantization and why this correction should improve it?  -----------------------------------------------------------------------------------------------------------  Since authors address most of my concerns, I would like to increase my score from 6->7. Overall, I think that it is a good paper and has a significant contribution to the machine learning community.