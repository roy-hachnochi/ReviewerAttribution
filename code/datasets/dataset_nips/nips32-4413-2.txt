This work tackles the problem of learning the edge weights in general discrete pairwise MRFs, of which the classical Ising model is a particular instance (when the nodes have cardinality k = 2).  A steady body of work has recently addressed this problem and made strides towards structure learning with efficient sample and time complexity.  The paper contributes algorithms to learn both the structure of Ising models (using l_1 constrained logistic regression) and the general case (k > 2, using l_{2,1} constrained logistic regression).  These algorithms are theoretically shown to improve upon the sample complexity of the state-of-the-art.  Further theoretical results show that, when the presented mirror descent algorithm is used during optimization, the time complexity of learning may be made competitive with the state-of-the-art without sacrificing statistical guarantees.  The theoretical results are supported with several experiments, which soundly show that the presented algorithms outperform the state-of-the-art in sample complexity and work with fewer model assumptions than other previous works.  The paper is well written and the results contribute steady progress towards more efficiently solving this particular problem.  As expected, the paper is very theoretical, but the authors did an excellent job of both keeping the main paper readable while doing further heavy lifting in the supplementary.  Furthermore, the extra content in the supplementary was very helpful as a whole (e.g., Section A was very comprehensive, the extra experiments were appreciated, and the breakdown of the proofs was well done). 