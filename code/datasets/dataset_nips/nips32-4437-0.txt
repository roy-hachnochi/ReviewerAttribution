=================================== After Rebuttal ===================================  Thank you for the response and the clarifications.  We still have some concerns about the complexity of the algorithm and its dependence on the iteration count -- in particular in cases where this may scale with the dimension d based on the specified termination criteria. This being said, it would be great to comment on this in the numerical results and include more timing studies to confirm this dependence.  We also strongly suggest that the authors include the extensions listed in the improvement in the final revision.  =================================== Before Rebuttal ===================================  The authors present a novel algorithm with both theoretical analysis and empirical results. We have a few comments and suggestions for the work:  In the introduction, we recommend that the authors also note alternative versions of finding OTM that are not based on solving a linear program (including non-discrete versions of OT based on solving ODEs or finding parametrized maps).   In the description of the numerical method, the authors note that the direction that 'explains the highest proportion of variations in the subspace spanned by the current residuals' corresponds to the direction of maximum marginal discrepancy between the distributions. It would be great if the authors could provide more intuition on the correspondence between these two notions and when they may correspond exactly.  In the numerical algorithms, we also recommend that they authors indicate the dimensions of introduced variables (e.g., \hat{\Sigma}). Is there a requirement that the sample covariance matrix is not rank-deficient, 2n \geq d, in order to compute the inverse Cholesky factor? Lastly, is there a guideline for how to measure the convergence or select the termination criteria in Algorithm 2.  For the computational cost of PPMM, is there an assumption that n >> d that allows for the simplification of the cost of computing the Cholesky factor (otherwise this should add O(d^3) cost)? Could the authors also add a reference or provide more information on the look-up table method that they use to compute the 1D OT map.  In the theoretical analysis, we recommend that the authors present assumption 2 as population level conditions on the underlying random variables (e.g., uncorrelated and tail probabilities) instead of conditions on all samples if possible. Could the authors clarify if Assumption 2.(c) must hold for all r or for a specific index. We also believe that indices i and j should be flipped in line 196. Lastly, we'd like to point the authors to recent work entitled 'Minimax rates of estimation for smooth optimal transport maps' by Hutter et. al. for some results on the convergence rates of OTM.  For the numerical results, could the authors comment on the non-monotonic convergence of the Wasserstein distance in Figure 3 with increasing iteration count. Do the authors suspect the sliced and random methods to perform differently in all experiments? It would also be great if the authors could provide or report the change in variance of the results over the 100 replications that were used to compute the mean performance.  In all experiments the authors also note that they set the number of iterations to scale with the dimension of the OT problem. In practice, did the authors observe continued/stagnating improvement in the error/distances or do the overall maps ever deteriorate (i.e., due to a form of overfitting) with increasing iteration?  Lastly, we have a few minor suggestions for the text: correcting the grammar on lines 5,12,17,51,147,267 and 292, clarifying the notation on line 65 (i.e., the map is usually applied to the random variables and not a transformation of the densities), indicate the dependence on Y on line 100 entering through \hat{\phi}, provide a reference that equality is achieved with the Monge map for the Kantorovich problem on line 97, clarifying the phrase 'when the input is two samples' to indicate two sets of samples on line 140, and defining what is meant by 'binary-response sample' on line 143. Lastly, we recommend that they authors clarify how they are applying PPMM for the Google doodle dataset (i.e., expanding lines 307-310 on how the map is constructed for the different categories of images).