The authors develop a framework for adversarial robustness in graph neural networks where the adversary can change a budgeted number of edges. The adversary is constrained such that they cannot change more than a budgeted number of edges as well as a certain number of edges from the same node.  The authors then want to certify the robustness of the graph neural network from robustness under this threat model of [Klicpera et al., 2019]. This model uses the "predict then propagate" framework: node features are learned in isolation then they are "propagated" by weighting the local features by the personalized PageRank. Thus the graph structure is used in a simpler way than other graph neural networks.  When there is only the "local" budget, the authors develop an exact algorithm. Their approach is based on Markov decision processes similar to (Fercoq et al., 2010). When there is a global budget, the authors write the problem as a quadratic program and relax the problem using the "Reformulation Linearization Technique". They show that many constraints in the relaxed problem can be simplified to a single linear inequality.  Finally they experimentally verify their methods. They show that certain aspects improve robustness, such as increasing the teleport probability in personal PageRank.  The authors mention that [Klicpera et al., 2019] do not use personalized PageRank, however I believe that they do.  To improve clarity, the authors should move the description of the reformulation linearization technique in the appendix to the main paper.  The authors write "the SDP-relaxation [30] is not suitable for our problem since the constraints are trivially fulfilled". It would be interesting and helpful to explain why.  How long does the method based on the reformulation linearization technique take to run? Further, how is the certificate quality when there are no local constraints, only global constraints?  Is it possible to show that adding the global constraints makes the problem NP-hard? It might be possible to also solve this problem optimally.  *** Post Rebuttal ***  Thank you for including the NP-hardness reduction in the rebuttal.