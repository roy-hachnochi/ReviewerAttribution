This is purely a theoretical paper. Although I'm not very familiar with this type of theory, the results seem sound from my review. The paper is quite well written, with just a few minor suggestions below.  My main criticiism of this paper is that it is quite hard to read and follow if one is not very familiar with bilevel optimization for LQR (like myself). After reading the paper it is not at all clear to me why any of these results would carry over to anything outside of LQR; and with that in mind, it seems like there's not much we can learn from these results, outside of the LQR setting.  I think there needs to be more high-level discussion in the paper to give readers not familiar with tihs type of theory a better idea for what is being proved, why it matters, and what we can learn from it. In particular, the paragraph starting at line 298 should be in its own "Discussion" section and expanded.  Some questions: - In line 132, you say "Specifically, it is shown that policy iteration...", do you mean that it's shown in this paper or that it _has_ been shown previously? - In equation 3.1, shouldn't the subscript of I be k? - In line 152: what is \rho? Is it the stationary distribution? Relative to which policy?  Minor suggestions: - line 114: "Viewing LQR from the lens of *an* MDP, the state..." - line 115: remove the "Besides, "  - In equation 2.6, better to use a letter other than Q to avoid cofusion with the Q-value function. - line 120: "... it is known that the optimal action*s* are linear in..." - line 150: "the state dynamics *are* given by a linear..." - line 192: "denote svec(...) by $\theta...$" (remove the first "by") - line 238: "be updated *at* a faster pace." - line 240: "... ensures that the critic updates *at* a faster timescale." - 