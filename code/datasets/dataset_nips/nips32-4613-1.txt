Originality: The paper applies integrates gradient methods to DNNs used for predicting neural activity in the retina for identifying important subunits to build reduced models, which lend them self to interpretation. This is a original contribution with potential in the field. The paper does feel like a follow up to ref. 2, and Figure 1 seems almost a complete reproduction of a figure in ref. 2.   Quality: The analysis presented in the paper is of uniformly high quality, but the paper is so strangely structured, that it dampens my enthusiasm significantly, despite the potential of the method. The Introduction is extremely long, at the expense of a very superficial discussion of the individual parts of the results, which contain the really interesting new bits of information. Also, many interesting derivations, explanations and discussions are in the supplement, for example the justification why the methods works or which information it provides. Also, e.g. the figure caption of Fig. 2 is almost a whole page, containing information which rather should be discussed in the main text. As it is, the papers focusses almost exclusively on the discussion of the “new models” but fails to highlight its methodological contributions. In their reply, the authors promised to restructure the paper significantly; I am not certain, however, whether this can still be fit within the scope of the review process at NeurIPS, or will require so significant revisions, that it will have to be submitted elsewhere for rereview.  Clarity: Together with the supplement, the methods are clear and most model explanations make sense.   Significance: Potentially large, but paper not suited for NeurIPS in its present form.   