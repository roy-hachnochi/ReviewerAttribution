This paper considers a communication efficient distributed optimization algorithm based on ADMM for stochastic optimization. The main idea is to perform multiple steps (can be timevarying) of stochastic gradient updates before the agents communicate, and therefore improving the communication efficiency. The proposed algorithm is shown to converge (in objective value & constraint violation) under a general non-smooth, non-strongly convex settings with O(1/eps) communication rounds and O(1/eps^2) unbiased gradient oracle calls. Other setting such as smooth+strongly convex and non-smooth+strongly convex are also analyzed and presented.  Using multiple steps is however not novel. In addition, a significant drawback for the proposed algorithm is that it is not supported for time varying communication -- which is a major set back with ADMM type distributed optimization. While in overall the paper is well written with several interesting results (e.g., convergence with non-smooth+non-strongly convex problems), there are some outstanding concerns from the reviewer:  -- Communication Efficiency and Comparison to Prior Work This paper counts the number of "outer-loop" as a measure of communication efficiency, especially in terms of its scaling with the desired accuracy epsilon. However, such notion should also be compared in terms of the network topology which is missing in the current Theorems (and is perhaps hidden in the constants that depends on ||A||^2). These notions are emphasized and compared in a few recent work:  Nedic et al., "Network topology and communication-computation tradeoffs in decentralized optimization", Proceedings of IEEE, 2018. Scaman et al., "Optimal Algorithms for Non-Smooth Distributed Optimization in Networks", in NeurIPS 2018. Uribe et al., "Optimal Algorithms for Distributed Optimization", arXiv:1712.00232  It is also important to point out that Scaman et al. have considered using multiple step in primal update to achieve a similar performance as the current paper, i.e., requiring O(1/eps) outer loops to achieve an eps-accurate solution.  In addition to the above work that tackles deterministic optimization, the following work has also considered stochastic optimization problem like the current paper:  S. Pu, A. Nedic, "Distributed Stochastic Gradient Tracking Methods", arXiv:1805.11454  Without using a multiple steps update, they also achieve a similar O(1/eps) rate for strongly convex objective functions. Comparing these methods (at least) numerically is important for improving the current paper.   Overall, the literature review done in this paper seems to be limited to ADMM type algorithms, while missing a lot of advances made in the gradient tracking type algorithms. Note that the latter is also actively researched.   -- Minor Comments  - While it is understood that the constraints "\sum_{i=1}^N A_i x_i = b" can be re-expressed to reflect on the consensus constraints, the application of the proposed algorithms to decentralized setting may still be unclear for non-expert readers. Such formulation should be described clearly in the paper as well. (e.g., in terms of the "A_i" and "b" involved in these settings).    - the authors mentioned that the negative term is (7) is useful for analysis - please expatiate in terms of its intuition as it is not clear in the main paper.  ---- The reviewer has read the response and I agree that the network dependence is more minor than my suggested references, which should be emphasized better in the revision. However, my comment with time varying / unreliable communication is not addressed by the authors. This concern is relevant to the authors response R2Q1, where (4),(5) are claimed to be ignorable if communication fails - there the authors seem to assume that communication failure is an "all or nothing" situation, while in reality communication failure happens only partially in the network. Second, the theory requires setting $K=T$ where $T=O(1/epsilon)$. This can be a huge number and requires knowing $\epsilon$ in advance. 