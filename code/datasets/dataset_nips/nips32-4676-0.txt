This paper addresses weaknesses in structured prediction energy networks, which estimate a scalar score for a set of structured variables, by allowing multiple separate factors to be added together to produce such a score. The extension is non-trivial, requiring different inference algorithms to (locally) optimize the corresponding inference problem while satisfying constraints on marginals shared over factors. It also unifies existing work at the intersections of deep learning and structured prediction.  The extensive experiments in the paper are a strong point. Care has been taken to provide good comparisons. The OCR datasets are constructed to show the benefits of modeling the structured output. Should the x-axis label of Fig 1a be “iterations” instead of training examples? The variability in test performance based on optimization algorithm in Fig 1a is somewhat alarming. Does inference optimization method choice become a “black art” in this approach? Despite this, the performance of GSPEN is at least very similar to (image tagging) or better than (other experiments) the comparison methods.  Overall, this is an impressive paper that addresses key gaps in structured prediction for neural network/deep learning methods that reside between having explicit structural assumptions and allowing flexibility.