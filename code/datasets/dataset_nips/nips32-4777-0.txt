Line 218: missing superscript for Hessian  The idea of using algorithmic stability to characterize learnability is a standard one on learning theory and there have been other definitions of stability which have governed online learnability in the following works: Stability Conditions for Online Learnability  by Stephane Ross, J. Andrew Bagnell, The Interplay Between Stability and Regret in Online Learning by Ankan Saha, Prateek Jain, and Ambuj Tewari, Policy Regret in Repeated Games  by Raman Arora, Michael Dinitz, Teodor V. Marinov, Mehryar Mohri. Maybe it would be beneficial for the paper if the authors briefly discussed the different forms of stability proposed by the above works and how they can be related to Definition 2.1 and Definition 2.2.  Overall the paper is clearly written and the intuition and sketches of proofs in the main paper give enough clarity so that the appendix is easy to read. The proofs seem novel and are really a great combination of simple but insightful ideas. I think the attempt at unifying proofs for first order regret bounds for many different types of  online learning algorithms is an important one and can give more insights about novel regret minimizing algorithms.