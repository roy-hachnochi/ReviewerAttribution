The prototypical parts network presented in this work is original and potentially very useful learning framework for domains where process-based interpretability is critical. The method is thoroughly evaluated against alternative approaches and performs comparable to other state-of-the-art interpretable learning algorithms. The paper is well written, well motivated, and is accompanied by empirical results to validate the algorithmic contributions. Overall, I would recommend this paper for acceptance.   One place for improvement is the discussion of this work in the context of alternative interpretable approaches, specifically the methods that show comparable accuracy. The authors briefly mention the advantage of having parts based interpretability. However, I would appreciate a longer discussion of the difference between this method and, for example, the RA-CNN which performs slightly better. This discussion would provide additional useful context to the prototypical parts network as well as provide an opportunity to discuss tradeoffs of different approaches.   Another place for improvement would bee more thorough exploration of the ProtoPNet architecture and hyper-parameter choices. For example, what is the effect of changing the number of prototypes per class? Do the similarity scores (across prototypes) relate in a meaningful way to the confidence of the final class prediction?    I also wonder if there are some domains where finding prototypical images could be a useful goal in and of itself? Curious what the authors think about this direction.  ========== response to rebuttal ==========  After reading the thorough author response I am have increased my score. I think this paper is a clear accept now.