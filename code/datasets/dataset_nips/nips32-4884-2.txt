In this article, the authors analyzed the performance of a single-hidden-layer neural network model under the random feature (RF) regime, the neural tangent (NT) regime, as well as the fully trained neural network (NN) regime. By considering the tasks of 1) learning a quadratic function of d-dimensional Gaussian data, and 2) classifying a two-class d-dimensional Gaussian mixture, the authors showed that, in the high dimensional regime where the number of neurons N and the data dimension p are both large and comparable, one has NN > NT > RF in the sense of prediction performance, in the infinite data limit. In this vein, this article improves/generalizes the analyses in [25] by covering the neural tangent model, which is a more involved model that is of more practical interest.  This article provides solid analyses on an interesting problem and is already quite polished. I strongly recommend it for publication. Below are a few minor comments that the authors might consider addressing before publication.  **After rebuttal**: This is a solid work on an interesting topic, I vote for accepting. 