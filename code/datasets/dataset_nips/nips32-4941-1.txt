-Originality This paper clearly has originality to some extent as the proposed algorithm for OSCM has a different merit from existing ones. However, it seems for me that the methodologies are not new but the authors carefully combine them to construct algorithms. It would be helpful if you push new idea or technique more clearly.   -Quality Although I have not verified all the proofs, this paper seems technically correct. At least, the results are reasonable. Please modify some unfinished expressions (e.g., l713 in the supplementary material). It also should be stated that all points the algorithm plays (e.g., y_t in Algorithm 1) belong to the constraint set K. The step sizes \eta_k are parameters in algorithm description, but they should be 1/K (or such that their sum is equal to 1) after all so that the algorithm's choice belong to the constraint set. So the current description may be confusing.  -Clarity This paper is well written overall. The authors explain how they construct algorithms step by step. I have the following minor comments.  -- It would be helpful for readers if you define some terminologies such as L_1-Lipschitz and matroids.  -- Please indicate references for Meta-FW and VR-FW in Table 1. -- Does the definition of radius implicitly use the assumption that the constraint set contains 0? -- l106: it is helpful to clarify the task of linear maximization oracles. -- Algorithm 1: step sizes should be depend on k.  -- Lemma 1: the condition "K is down-closed" may be contained in Assumption 5. -- l219: this sentence should be put before l217.  -- Theorem 2: Assumption 5 is also used here. -- Algorithm 2&3: how can we know r and delta? Do you assume that it is given?  -Significance The problems and results in this paper are of theoretical importance. In particular, the idea of reducing the number of gradient evaluations per function is unique. The main negative is that some motivations appear not strongly convincing. For example, what does Assumption 5 mean in application? In addition, I think RBSM (with a matroid constraint) become more acceptable for wider NeurIPS audience if you mention some application.    After the rebuttal: Thank you for your feedback. The application of RBSM seems nice so I raise my score. It will be more convincing with any references for the responsive model (if any).