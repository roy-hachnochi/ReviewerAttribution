This paper examines the use of concept-based explanations rather than feature-base explanations.  The algorithm in the paper, ACE, segments images, clusters similar segmentations, and then provides a list of explanations (salient concepts) by using TCAV.    The paper had very good motivation.  I think that the authors could also motivate the use of concpet-level explanations to mimic commonsense.  For example, in the police van example, the individual features are not as important as the police logo and the general shape of the vehicle.  Even if we are new countries and places with different polic vans, we can still abstract out the higher level concepts (like shape and logo) that distinguish the vehicle as a police type.    The concept-based explanation desirata is a nice, concise section outlining the standards and evaluations for concept-based explanations.  A small point, but the authors may want to distiguish the difference between a saliency property and a saliency map.  When first reading the paper, I was confused whether the properties in the desiderata were types of methods or properties of the output.    The methods secion provides a nice overview and definition of explanatory algorithm.  I found the description and algorithm of ACE to be clear and straightforward.  The authors state that the second step of ACE (the clustering of similar segmentations) can be replaced with a human subject, and I was wondering if this was tested or an effective augmentaion.  That could be a nice sanity check on top of some of these concepts.  In addition, the authors motivate the use of TCAV for a concept score.  Although, they say "any other concept-importance saliency score could be used," I was wondering (1) why they choose to use TCAV rather than another salience score (e.g. Network Dissection) and what other scores could be used (or not) and why.  I was also wondering about the last point about the reliability of CNNs as a similarity metric.  I was left wondering if this method could point out adversarial examples.    There were a few details in the experiment and results section that could be explained further.  For example, why was using 50 images sufficient for extracting the related concepts?  The authors state that this is because "the related concepts of a class tend to be present frequently in the class images," but I was wondering if this is dependent on the dataset.  Similarly, I was wondering why the authos applied ACE to 100 ImageNet classes.  Although I was delighted to see the results in the Appendix.  I think the user study could use a bit more quantification, though.  While I was convinced with the results, I was wondering how similar descriptions were between participants.  Although the authors stated that "77% of descriptions were from the two most frequent words on average," I wasn't exactly sure what they meant across the experiment.  The example was motivating, but I think a similarity score may strenghten the argument.        In summary, I thought this was a nice paper that extended TCAV and promoted the use of concept-based explanations.  Although I found the method and results to be sound, I was left wondering about future work and applications of such a method.  I think the idea of using this to harden existing DNNs is a good one, but I was left wondering how that would be done.  