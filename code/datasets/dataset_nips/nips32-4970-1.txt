Originality: - Using deep learning methods for video compression is still underexplored and poses an interesting research direction compared to current (handcrafted) methods. - End-to-end framework: extension of a VAE with entropy coding to remove redundancy in the latent space -> combination of well-known DL model with previous work on image compression which is here applied on video data - (Uncited) recent work: 'DVC: An End-to-end Deep Video Compression Framework', Lu et al., CVPR19   Quality: - The use of a global encoding of the entire sequence might limit applicability of the approach, e.g., for encoding and transmitting live videos. Furthermore, the current approach seems to be limited to a small fixed sequence length. - The relation of Eq 3 wih Eq 4 is not obvious. Eq 3 only conditions on the z_t up to time t, while Eq 4 accesses all z_t of the sequence for the global encoding.  - Evaluation demonstrates superior performance compared to traditional compression approaches on three datasets with varying degree of realism/difficulty. - Ablation study is provided which demonstrates the benefit of the model components (additional global representation for entire sequence, predictive model).  Significance: - The combination of local and global feature is well motivated and the global feature is shown to have an significant impact on performance. However, the usability of the approach seems limited (small sequence length, global encoding of complete sequence). - The evaluation was performed only on short (10 frames) low resolution (64x64) videos. Superior results compared to traditional approaches were mainly achieved on special domain videos, the improvement on the diverse set Kinetics600 is relatively low and only evaluated within a small range of image quality scores. (Although the authors express their interest to examine the extension to full-resolution videos, it remains questionable whether this approach is feasible due to the high memory/GPU requirements.)  Clarity: - Clear motivation for the approach (high internet traffic for videos required, usage of DL approach as promising alternative to current state-of-the-art) - l. 208, what is the time-dependent context c_t ?  Minor: - If possible, figures should be shown on pages where they are mentioned. - Stated Fig. 5 in section 4.3 is missing or has been wrongly referenced. - first equation (p. 4) is not numbered - check references, e.g.  - Higgins 2016, journal/ booktitel is missing  - usage of abbreviations not consistent