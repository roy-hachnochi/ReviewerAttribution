The authors consider the setting of [1'] where the goal is to find the implicit performance measure that an expert uses for classification. This performance metric is assumed to be a linear function of the confusion matrix (or occasionally a linear fractional as in [1]) and the goal is to find it (or approximate it) using a few queries. The queries are in the form of comparison queries which given two classifiers (or confusion matrices) outputs the classifier that is better according to the implicit score function. This submission extends the analysis of [1] to the multiclass case which poses new challenges.  The algorithm for the diagonal case finds the ratios between one of the diagonal elements (say the first one) and all the other elements. This is sufficient as metric is scale invariant. Finding each of the ratios is a simple binary search problem (though the analysis requires some considerations regarding the geometry of the problem to make sure that the binary search method works).  The algorithm for the general (linear) case is based on binary search and the ideas from the derivative-free optimization approach.  Some experiments have been done. However, no comparisons with any baselines have been made. The authors can at least compare the method with a method that queries randomly and picks the winner (and again the winner is compared with another random solution). I think there are many other better baselines to compare with.   The work of [2] may also be somewhat relevant.    [1'] G. Hiranandani, S. Boodaghians, R. Mehta, and O. Koyejo. Performance metric elicitation from pairwise classifier comparisons. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 371â€“379, 2019. [2] Kane et al, "Active classification with comparison queries"  === The author's response did not change my decision. I still think the experimental section is weak and the paper needs some rewrite.