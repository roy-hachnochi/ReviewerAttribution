Overall, the paper is clearly written, with issues and limitations encountered of data collection clearly described.  The issue of biased dataset is an important one and it is good to see efforts to tackle this. The main significance of the paper is to point out the importance of controlling for biases in the data used for training machine learning models, and perhaps inspires others to do more controlled data collection.  The framework/data is of some interest to researcher working on object recognition.     Strengths: - Clearly written and well organized. - The data collection was thorough and careful, with manually verification of final data.  Weaknesses: - The controls is limited and missing important variation such as occlusion and clutter.  It also introduces biases of its own (for instance, to achieve the different rotations, some of the objects are unnaturally positioned or held by a person). - The experiments conducted on the dataset do not reveal any special insight on how to improve the models or if any of the detectors are more robust than any other.  ---- Post rebuttal: I found the rebuttal to be thoughtful.  The dataset, and more importantly, careful thinking about biases, is of benefit to the community.  I would be happy to see the paper accepted.