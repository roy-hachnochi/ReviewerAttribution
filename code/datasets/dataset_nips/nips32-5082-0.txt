[UPDATE] I am satisfied with the authors' reply about larger scale experiments, mentioned by 2 out of 3 reviewers. While I am only guessing that performance may degrade as a function of dataset scale, it is not hard to imagine advances in GANs which could make that degradation smaller, hence make the proposed method more useful. Further, even in an adversarial setting, it may be possible to guess what kind of inputs are relevant, or extend the method to few-shot or some hybrid approach.  I am positively surprised that features of the student have comparable transferability to the teacher, I was concerned that some sort of overfitting to a teacher's decision boundary was possible, but this does not seem to be the case.  While I agree with the authors that, in most cases, those releasing research models will not go out of their way to vaccinate them against zero-shot distillation, the proposed method could be used to (somewhat) copy and repurpose information stored in hardware model. Take for example Tesla's autopilot which uses several neural networks in it and is trained on tens of billions of images which are not available to the world. In fact, that data is the primary competitive advantage of Tesla in the long run and its acquisition costs Tesla millions of dollars. Since the autopilot needs to drive without an internet connection and inference needs to be extremely low latency, it is surely done on device and hackable. Your method could be used to train a good feature extractor comparable to that on their device. Further, it would not need to be zero-shot, since it's very easy to get a little bit of data.  Overall I am impressed with the work and satisfied with the authors' response. Hence, I am increasing my score to 8.  [OLD REVIEW] Originality: Highly original. Zero-shot distillation using some form of adversarial loss is imaginable, but the actual performance level is quite unexpected, imho.   Quality: Good deltas to previous works, and error bars make the differences more convincing.   Clarity: Writing is clear enough, although some more details are required for those who are only distantly familiar with the GAN literature. The supplementary materials are also on the light side.  Significance: High. I believe this paper opens new avenues for investigation, basically offering a new attack vector against embedded inference devices. 