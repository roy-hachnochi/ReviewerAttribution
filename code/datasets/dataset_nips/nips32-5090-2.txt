The paper is clean. As a non theory person I was able to follow the motivation, the problem set-up and the main result. The intuition that not all queries Q(j,k) needs to be issued conditioned on the past queries due to the fact that we're in a metric space. The bounds looks fine, mostly it is a construction of the confidence in the estimation of Q(j,k), again, under the constraint that Q(j,k) is a metric space with metric-ish properties.  As a piece of technical achievement this paper is just fine. But it can improve in the following sense of story-telling and organisation:  1) we're doing an optimal query problem, namely, querying a noisey oracle Q(j,k) to construct a nearest-neighbor graph G(x_i,x_j). Given this is the setting, I was hoping to see some kind of quantification over the entropy on all the possible nn-graph G, and how the next-best-query you're querying is maximally reducing that entropy (i.e. with this new query, I gain the most information on distinguishing valid nnGraphs from incompatible graphs)  2) It is unclear to me then, which criteria you are using to select the next query Q(i,j) to make. Are you selecting a query that maximally reduce the entropy on the space of possible nearest-neighbor graphs? Or you're selecting the query that maximally reduce the entropy on the pair-wise distance metric Q(i,j) itself? These two are different objects and you'd expect the querying scheme to be different. No doubt this distinction is somewhere in the paper, but it would be good to have it in english form, stated up-front, so a more "casual" reader, tasked with implementing this algorithm could follow.   I was hoping to see a sentence like "We're try to maximally reduce the uncertainty on the space of all possible nn graphs. thus, based on our past K observations Q(j,k)_1 \dots Q(j,k)_K, we compute for all ?? the confidence bound of ?? and query the most ?? pair from the oracle, maximally reducing the uncertainty".  3) it might be good to have some notion of sub-modularity argument. From what I can read this paper uses a bandit-like approach, which is in a sense greedy, picking the most ?? query at each step instead of planning ahead a sequence of K queries that, maybe themselves do not lead to good information gain, but in conjunction leads to huge information gain. Greedy solutions are just fine if your problem is sub-modular, in this case, the entropy gain over the space of nearest-neighbor graphs is sub-modular with respect to the set of queries you are issuing, it might be good to prove this, and then you can easily justify your greedy strategy as compatible to optimal.  So rating is as follows:  Originality: fair. It appears to me that there has not been a paper previously that only assume general metric and noisy reads in the context of inferring nn-graph  Quality: good. Math is clean, theorem is well-written, evaluation is well constructed (although it doesn't really add much given this is a theory paper anyways)  Clarity: poor. No idea what the selection criteria is, and no intuition on why this particular selection criteria is optimal (or greedy-optimal)  Significance: fair. Pretty clean problem, I'm sure someone would find use of it later down the line.