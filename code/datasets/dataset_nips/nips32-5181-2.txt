==================post rebuttal=========================== I'd like to thank the authors' for their detailed responses. However, it seems that they didn't completely understand the questions related to the benefit/importance of opportunistic state-triggered control and the limitation of the numerical experiments. The benefit should be compared to other existing approaches like Nesterov's acceleration and heavy-ball methods, and should be analytical and quantitative, instead of just comparing with fixed step-sizes and simply high-level intuition. And for the numerical experiments, the issue is not just about sizes (like increasing from dimension 2 to dimension 50), but about the generality of the function classes (e.g., at least the authors should consider regularized logistic regression, etc.). These being said, I still like the idea of the paper, and the way they derive the state-triggered step-sizes. However, the limitation in comparisons with other existing approaches and the practical applicability of this approach limits its significance, and as a result I would like to maintain my score. =======================================================  This paper focuses on the ODE viewpoint of the acceleration methods in optimization, and introduces the idea of opportunistic state-triggered control to design efficient discretization of the ODE systems, aiming at preserving the acceleration properties of the (high resolution) ODE systems. Resorting to the Lyapunov function analysis of the corresponding ODE systems and convexity arguments, the authors propose a practical and simple variable-stepsize forward-Euler discretization to the high-resolution ODEs obtained for heavy-ball and Nesterov algorithms recently, yielding an efficient algorithm with convergence rate matching those of the corresponding ODEs. Here the step sizes are decided utilizing the Lyapunov function, as is done in the opportunistic state-triggered control. Finally, some very simple numerical experiments are provided to validate the efficiency of the proposed algorithm.  The originality of the paper is basically beyond doubt, especially in the sense of connecting the opportunistic state-triggered control with acceleration methods in optimization. However, the level of significance of the paper is relatively limited due to the following issues: 1. The authors do not compare the bound obtained in Theorem 3.3 with the existing ones, e.g., those obtained in [23]. What do we actually benefit from the opportunistic state-triggered control, or variable-step size discretization in theory? In addition, do we have to restrict the application of such discretization approaches to high resolution ODEs, as is the case of symplectic discretization as found in [23]? What would happen if we apply the opportunistic state-triggered control discretization to the low-resolution ODEs, e.g., those in earlier papers like [24]? Without answering these questions, the theoretical significance of the new discretization/algorithm is a bit limited.  2. The numerical experiments are too limited. The authors may want to consider some more interesting numerical examples, to showcase the improvement of the new algorithm compared to the existing ones.  The quality of the paper is also generally good, despite the issues mentioned above, which kind of limit the completeness the theory and the applicability in practice related to the proposed approach. The clarity and writing of the paper is pretty good, making it generally an enjoyable reading experience. Some minor suggestions include: 1. In Section 2.2, when defining V, the authors may want to clearly write it as V(X(x,u)), and explain that the derivative in \dot{V} is w.r.t. u, which leads to the first equality in (2). The authors may also want to explain more about what the control u=k(x) serves for, especially given that u disappears in the subsequent sections starting from Section 2.3. Otherwise, this part seems to be a little bit confusing even to a reader with some background in all the related areas. T  Finally, some typos and minor suggestions: 1. Line 69: “[28]” -> “[28], “ — a comma is missing. 2. Line 106: “not” seems to be “now”? 3. Line 117: “criterium” might better be “criterion”. 4. Lines 124-125: the authors may want to mention that g is continuous, since otherwise the definition of t_{i+1} may not ensure no zero-crossing between (t_i, t_{i+1}). 5. Lines 123-130: the terminology “state-triggered”, “event-triggered” (ET) and “self-triggered” (ST) seems to be a little bit confusing, especially given the latter parallel presentation of ET and ST in the algorithm section. However, according to the description of lines 123-130, it seems that ST is a special case of ET, instead of two parallel concepts? And is “event-triggered design” a special case of state-triggered control? If so, what do “event” and “state” refer to, respectively? The authors may want to explain these more intuitively and clearly, so as to avoid potential confusion. 6. Line 189: “with a slight abuse of notation” — this sentence is a bit confusing. If it means that in Section 2.2 g is a function of (x_1,x_2) (same dimension for two arguments), while here the second argument becomes (p,t) (first argument multi-dimensional, and second argument single-dimensional), then this could be stated and discussed earlier in Section 2.2, so that readers understand that g can be more flexible. 7. Lines 190-191: “becomes apparent below” — does it refer to Lines 194-195? If so, then just state it immediate after the claim, not “below”.  8. Numerical experiments: why is ET integrator missing in Figure 2? And what is the observation and conclusion for Figure 3 (the authors seem to only state what is plotted in Figure 3 as it is, without drawing any concrete conclusions or comments)?