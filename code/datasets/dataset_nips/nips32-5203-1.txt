Update after author response: I thank the authors for their very clear response. I think their response very well addresses many of the criticisms that were brought up in the reviews. I especially think that the addition of runtimes will be beneficial to the paper, as this can be a big issue in graphical model learning.  On the various technical conditions: I think that providing more intuition for the technical conditions will be great (which the authors address in their response). I think the paper could be made even stronger by adding a discussion of how these conditions compare to those in the literature.  -----------------------------------------------------------------------------------------  This paper is focused on estimating multiple Gaussian graphical models. The specific focus is on the setting when we have observations from multiple graphical models with the same underlying sparsity pattern in their precision matrices. The authors propose a point estimator to recover both the individual precision matrices and the underlying sparsity pattern. The authors prove a number of theoretical properties about their method and show that it works well empirically, even when their theoretical assumptions are violated.  Clarity: the paper is well written and easy to understand.  Originality: The ideas of grouped graphical model estimation and using Bayesian methods in this area are not new. The specific estimator the authors propose and their analysis of it seem to be new.  Quality: The theoretical analysis of their method carefully states their assumptions and conclusions. In their empirical work, I appreciated that the authors empirically investigate what happens when their assumption of group structure is violated. I do think that the experiments could be made more convincing, though. First, the authors do not include runtimes for their method, so it is hard to say if the non-huge gains in accuracy are worth the computation cost. Second, it would be good to know how the hyperparameters of the competing methods were selected.  Significance: I am not particularly familiar with the graphical model estimation literature, but the authors seem to have provided a good theoretical contribution over other work in the area. My main complaint in this area is that I do not think the characterization of their estimator as "Bayesian" is particularly significant. What is ultimately reported is a constrained MAP estimate that is then thresholded to obtain a sparsity pattern. In contrast, the two Bayesian works that the authors cite in this space ([18] and [22]) actually propose samplers to recover the full posterior. Additionally, it is hard to say that the author's prior has much meaning, given that it places zero probability mass on the sparse solutions of interest. I think this is sort of equivalent to saying the Lasso is a "Bayesian" method.  Small things: - In condition A1, should clarify with parentheses whether log p / n < eta means log(p) / n < eta or log(p/n) < eta. 