The authors propose a mixture of Hawkes process which considers relational information. All event occurrent times of each subject is treated as a mixture of K common Hawkes process, which means the temporal dependency is fully modelled by the Hawkes process. The Hawkes process parameters of subject i have a small deviation to the common K common Hawkes process and the deviation is determined by the likelihoodâ€™s gradient (Eq (1)), which can be learned using a method called MAML. The relational information (if subject i and j are linked) is modelled by the weights of the K common Hawkes process for subject i and j. Variational inference (E-step) is used to approximate the posterior of Z and \pi given the parameters of K common Hawkes process and the data. Then the parameters of K common Hawkes process are maximised. The method is compared with other similar approaches and achieves better performance.  The idea of incorporating the relational information and subject special parameter (MAML) parts are very interesting. The derivations seem reasonable and correct. I would like to accept this paper if the author could address some questions regarding the experiments. 1. Is it standard to compare the log-likelihood in this field? In my understanding, the author are tackling a prediction problem. Is it possible to predict the expected occurrence time of the next event and compare the RMSE? Also since this method is optimising the log likelihood while others are not, the comparison seems unfair. 2. Why all methods are Hawkes process based? Is it possible to compare with RNN? 3. In line 198-199, it is said that only the last time stamp is taken out. Does all other time stamps used in the training? My understanding is that all time stamps should be taken out for the test data. 