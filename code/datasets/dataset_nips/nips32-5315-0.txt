The paper studies an important problem, that is to learn models to localize "rationales" from a corpus of polarized opinions (such as product reviews), all in an "unsupervised" fashion (i.e. without the presence of ground truth rationales). Different from a previous pioneering work [18], this paper tries to further pin down rationales that are class-specific, so that both "pros" and "cons" would be simultaneously identified. To me this is a meaningful extension and the paper is largely well written and easy to follow.  Detailed comments as follows, 1. I wonder if the authors have tried to learn class-specific rationales that are ground-truth *agnostic*. In a potentially simplified setting, you can still have class-specific rational generators (e.g. one for localizing "pro" rationales and another for "con"), but they do not necessarily need to be further tied with ground-truths so as to differentiate between "factual" and "counterfactual" (more on this later in comment 4)?  2. L.183: "For the discriminators, the outputs of all the times are max-pooled ..." - why choose max-pooling-over-time rather than a simple sequence classifier that directly outputs 0/1?  3. Eq.10: cite [18] since this is essentially the same regularizer introduced there?  4. For the baselines, if we adopt the simpler setting as outlined earlier in comment 1, it would be interesting to consider another model that's basically RNP with 2 "class-specific" generators that share parameters and take the class-label as an additional input. It's closely related to POST-EXP yet will benefit from a jointly trained predictor?  5. Why are the sparsity levels in Table 1 and 2 not exactly the same across the three models in comparison? Assuming the three models all make "independent" selection decisions (per L.179), it should be straightforward to enforce a common exact number of input tokens to keep, by selecting the top-K positions?  6. Comparing Table 2 with Table 1, the performance of POST-EXP sees a drastic drop, from consistently outperforming RNP to underperforming. Why is that?  === post author response === Thanks for your clarifications. I believe having some of them in the paper will help your readers appreciate it more and clear away similar confusions. That said, I'm still not quite convinced why a class-specific yet ground-truth-agnostic RNP extension would yield degenerate results - are you suggesting the classification task per se encourages the model to exploit "spurious statistical cues" in the dataset more than the factural vs. counterfactural classification task?