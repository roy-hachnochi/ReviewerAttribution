Originality: The results obtained in this work are, to the best of my knowledge, new. The methods followed are relatively new (especially the ones using the notions of ``tuples" and "cores" to tackle the distributional assumptions on the noise. )  Quality: Both the statements of the results and the proofs I checked appear technically sound and correct. I am though skeptical about the experiments section: the authors discuss and analyze Algorithm 1 for 7 pages and suddenly they implement Algorithm 2 which is an elementary median heuristic. It is interesting that it beats more sophisticated methods, but I am unfortunately not convinced the Algorithm 2 is linked with the averaging argument in the analysis of Algorithm 1, or that it is sufficiently connected with the rest of the paper. I think the authors should address this issue.   Clarity: For the most part the paper is well written and the ideas clearly expressed. I think though some parts of the paper are not up the same standard and are slightly poorly written: e.g. parts of subsections 1.2. and 2.2. seems a little bit rushed; for 1.2. the authors miss to explain at the end of page 3 what is the cardinality of the random sets I_t and the number of them (an important step) and for subsection 2.2. the argument using Cramer Rule which is hiding behind the relatively complex definitions should be clearly explained as it can help significantly the reader.   Significance: I think the methods followed are significant, but I do not consider clear their significance beyond the setting considered. For example, is the averaging considered tied to \ell_1 loss or can it generalize to the \ell_p norm loss? 