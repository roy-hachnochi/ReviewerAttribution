# Strong points * The paper is very well written and the problem clearly described. The illustrations are helpful. * The method is simple to implement, yet innovative and effective. * The experimental results support the proposed method, showing that this architecture achieves very good results with low memory overhead and low latency  # Weak points * The experimental results contain no error bars nor a test for statistical significance. Many improvements over previous results are numerically quite small and it is unclear if these improvements are statistically significant. * The experimental evaluation sometimes appears more like an advertisement for the proposed method than an objective scientific evaluation of the pro and cons of the method. This includes the following points: - No baseline result (e.g. memory) was highlighted in the tables when best. - The grouping in Tab.1 and Tab. 3 appears a bit arbitrary and was apparently done in a way that the proposed method performs best compared to the baselines in each group. - Expressions like "outperforms [...] by a large margin" (ll. 258-259) appear more like advertisement than an objective description - Fig. 4 only compares latency against point cloud based method and memory against voxel based methods which appears unfair. Why not show voxel and point cloud based methods in both graphs? * Apart from Tab.2, the paper does not contain a proper ablation study (e.g. bilinear interpolation vs. nearest neighbor, higher resolution voxel grids in Tab. 2) * I am not a hundred percent confident about the comparison of latency and GPU memory in Tab. 1, 3, 4 and Fig. 4, as the baselines were not necessarily designed / tuned with these metrics in mind. It is hence not clear how much of the improvement is due to the concrete implementation vs. the proposed method. * It would have been nice to have a limitation section that discusses possible future work.  # Questions / additional comments * Missing references (possibly also as baselines): [1,2] * How does the proposed method compare to sparse convolutions  [3]? Maybe it would even make sense to combine the proposed method with sparse convolutions? * It was not clear to me why the memory of the proposed method grows sublinearly with the resolution of the voxel grid (ll. 241-242). Shouldn't the memory requirement also grow cubically (at least asymptotically), since the method in the end also uses 3D convolutions? * Sec. 5.3 only talks about a train and validation set. Is there no test set?  # Overall rating This paper proposes a simple and effective new type of architecture for 3D deep learning. While the paper could still be improved at some place, I believe it is generally well done and should therefore be accepted.  # References [1] Groh, Fabian, Patrick Wieschollek, and Hendrik PA Lensch. "Flex-Convolution." Asian Conference on Computer Vision. Springer, Cham, 2018. [2] Thomas, Hugues, et al. "KPConv: Flexible and Deformable Convolution for Point Clouds." arXiv preprint arXiv:1904.08889 (2019). [3] Graham, Benjamin, Martin Engelcke, and Laurens van der Maaten. "3d semantic segmentation with submanifold sparse convolutional networks." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.  === UPDATE AFTER REBUTTAL === I appreciate the authors' response (ablation study, comparison to sparse convolutions, updated Fig. 4) which answered most of my questions. I was only a bit disappointed that the authors still have not included a test for statistical significance in the rebuttal which would have been helpful given that the numbers are all relatively close. I am also a little bit confused by the statement that "the model has been evaluated 20 times to reduce the variance". Shouldn't every evaluation on the same test set (w/o retraining) give exactly the same result? It would be good if the authors could make this point more clear. All in all, I still believe that this is a good submission that should be accepted.