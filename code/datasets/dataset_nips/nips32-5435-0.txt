EDIT: I have read the author response; and appreciate the proposed improvements for the final version. I do not consider it necessary to change my score, or the review.  The paper provides a new evolutionary strategy (ASEBO) for black-box optimization. The authors point out that ES methods scale poorly with dimensionality by trying to accurately estimate the gradient of the objective. Their method uses online PCA to estimate a subspace of the gradients, whose dimensionality varies during optimization. A factor controlling exploration is estimated using the gradient norm on the subspace and its complement. Experiments with RL tasks and synthetic functions show better performance of ASEBO compared to other ES methods, and commonly used algorithms.  Originality / Quality: The paper presents a novel algorithm for black-box optimization. Both theoretical and experimental results are provided to demonstrate its effectiveness. The experiments are sound, and the authors compare to a number of popular methods in the domain.  Clarity: Overall, the paper is well written and easy to follow. The theoretical results, and their significance, need to be discussed in more detail. This is especially true for Theorem 3.3.  Significance: Given the renewed interest in black-box optimization, and the popularity of ES methods, I believe this work is an important contribution.