It would have been nicer to see more investigation of whether such networks can be trained to learn polynomials of a certain degree -- something more than just what is stated in section 2.3  Another point is that there may be advantages to use activations like sigmoid that have an infinite taylor series as they can be used to approximate polynomial of any degree with one hidden layer. So its well known that a polynomial of degree d in n variables can be *learnt* (not just represented ) using about n^O(d) hidden nodes in a 2 layer network with certain activations that have infinite taylor series.  The writing style keeps the reader interested but it would be better to list the main results upfront somewhere near the introduction. Its harder to get the main results now as many Theorem statements are embedded in later sections.