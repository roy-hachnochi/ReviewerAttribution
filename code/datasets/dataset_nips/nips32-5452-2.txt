originality: Using the denoising (for some reason my autocorrect always wants me to write "demonising") autoencoder framework to model structured object construction as a markov chain where transitions are local edits is in my opinion well justified, and an interesting alternative to the previously described models.  clarity: - I found this paper quite hard to understand (my background is not statistics). For a general ML conference like NeurIPS, I would suggest to write the paper in a more self-contained matter. Going to the preceding, cited work (Bengio et al 2013) was necessary to get a better idea about what the authors did in this paper.  quality: + the disadvantage of the model (expensive sampling) is expressed - The authors yet again introduce a another benchmark for molecule generation. This reviewer has now reviewed 15 papers for molecule generation for NeurIPS, ICML, and ICLR. 14 of them introduce new benchmarks, instead of reusing already established ones created by domain experts. The authors should be required to use the established guacamol benchmark for molecule generation: https://github.com/BenevolentAI/guacamol  - Machine Learning has made most progress when a single benchmark was used in many papers (Imagenet!!!) - the CGVAE paper (Liu, Allamanis, Brockschmidt, Gaunt, NeurIPS 2018) and the DeepGAR paper indicate that a simple autoregressive LSTM model on SMILES strings can outperform those models (even though the SMILES LSTM is probably the most boring model in the world). It therefore should to be added as a baseline, regardless of the outcome of the results. It may also be interesting to look at the reviews of the Liu et al paper https://media.nips.cc/nipsbooks/nipspapers/paper_files/nips31/reviews/4855.html . An implementation of the SMILESLSTM can be found here: https://github.com/BenevolentAI/guacamol_baselines/tree/master/smiles_lstm_hc - this model was first reported in https://arxiv.org/abs/1701.01329   Questions: Could the authors point out how the model can be used for structured object optimisation, that is finding objects with optimal properties?   _______________________ Added after the authors provided their rebuttal:  Thanks to the authors for addressing the questions. I have adjusted my score to 8, and would vote for acceptance, under the condition that the authors add the results of the Guacamol benchmark & baselines, regardless of the outcome (as they wrote in the reply), and add a comment in the outlook on how to employ the model for optimisation tasks.