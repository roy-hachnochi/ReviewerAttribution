My only concern is regarding the training stability. The computational difficulty arises in calculating the integration of $I(x; \phi_\theta)$ in an efficient and reliable way. The authors propose to use importance sampling for approximation. However, it is widely known that importance weighting suffers from extremely high variance in cases where the proposal and target distributions are not a good match, especially for high dimensional cases. \E[p/q] and \var[p/q] could even be infinite in lots of scenarios.  Also, itâ€™s unclear to me about how to select an approximate $q$ in a principal way, since a good setting might reasonably be expected to be dependent on the learning task that is being considered. According to the pseudo-code in Algorithm 1, it appears the number of MC samples at each iteration is just 1. Does the algorithm converge in general, how to choose q? Could the authors offer more insights? 