The authors propose the problem of clustering with overlapping under the semi-supervised framework, or more specifically, using same cluster queries. Flat clustering with same cluster queries has received much attention recently. The authors take a step forward to the case of clustering with overlapping, which is more general comparing to the original problem. I think the importance of this new problem is fairly stated in the paper. The related works section is well-written which gives a clear idea how this work is different from prior works.  The main idea of all the algorithms in this paper is to find a (possibly small) set of representatives first using all possible pair-wise queries from a larger set drawn uniformly at random. Then recover the memberships for the rest elements depending on the result of the first stage. Although the similar idea has appeared in prior works (i.e. [MS17]), which is also cited by the authors, applying it for the case of overlapping clusters with modification for numbers of settings is still novel.  The theoretical analysis for this paper seems to be correct, although I did not read all the details in the supplement. The first contribution of this paper is providing the condition of uniqueness of optimal solution in various settings. I think this is an important step for the follow up works tackling this problem. Various settings for this problem are discussed in this paper. Both upper bounds along with algorithms and lower bounds on query complexity are provided, which is another significant contribution. However, the authors do not make comparison for their upper and lower bounds. It would be more clearly for readers if some remarks of this comparison can be made. Moreover, the computational complexity of these algorithms is not directly stated. The computational complexity is also a critical attribute when we want to judge algorithms. Finally, although the authors give results for both worst-case and model-based, they make neither comparison nor discussion on the query complexity. Intuitively the query complexity for the worst-case scenario should be much higher than the model-based case. However, the results do not seem to match this intuition if \alpha is some constant. The authors should have some discussion on the scale of \alpha and compare the query complexity of worst-case and model-based case.  For the experiment, the authors show that on real-world data, their algorithms require much less queries then their upper bound. Nevertheless, no other method is compared. For example, the authors mention in the introduction that their algorithm should work better then naively apply the low-rank matrix completion, but no experiment support this statement. Also, from the synthetic data in the supplement, there seems to be a huge gap for the upper and lower bound. Since the authors take a log-scale in y-axis it is hard for me to tell whether the upper bound or lower bound is tight or not. It would be great if some discussion can be made for this point. At last, in the reproducibility response the authors claim that they provide the source codes, but I can not find it in the supplement.  [MS17] A. Mazumdar and B. Saha. Clustering with noisy queries. In Advances in Neural Information Processing Systems (NIPS) 31, 2017. ==================================================== Update after rebuttal:  I thank the authors for their response. It clarify all my concerns pretty well. Hence I slightly raise my score to 7 for this submission. Hope that all these nice explanation in the response can be seen in the final version of this paper. 