That these types of techniques are really essential for "developing better and faster SAT solvers" is quite questionable, since the SAT community has been making quite good progress in pushing solvers forward and still are, and the benchmark situation has considerably improved over the years.  Nevertheless, from an academic perspective building generators for real-world like formulas in interesting.  Perhaps the biggest issue with the work is in that it does not really seem to scale. The authors use the 10 *smallest* "real-world" instances in their experiments. Small instances are really not interesting from the perspective of SAT solver development, as most real-world instances are quite huge. In my opinion the authors would need to address at the very least the scalability issues to warrant publication at a major venue.  Regarding the comparison of graph statistics of the generated instances, I do not see what to make of these. It is unclear to me to what extent the instances are *different* from the instances started from. In fact, one could also interpret the fact that solvers rankings do not change as being an artifact of the potential fact that the instances do not really change much. The authors should convincingly argue that the generated instances would be in some sense really (in an interesting way) also *different* from the original instances (slightly confusing a formula can be done without any machine learning, most definitely!)  The "application" of "developing better SAT solvers" seems somewhat absurd to me, as I do not understand what we could really take away from the presented observations, and what is the actual supposed role of the generation technique presented to this.  Finally there appears to be very closely related work presented at SoCS'19: https://aaai.org/ocs/index.php/SOCS/SOCS19/paper/view/18390 The authors should cite this work and explain their own contributions in relations to that work.