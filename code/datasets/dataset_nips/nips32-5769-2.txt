   While many attention applications  are focused on weighted averages    of vector states  from previous time steps as an  input to an LSTM,    this paper is interested n attending not just to the sequence steps    but individual  features in  the input.  The goal  is to  obtain an    interpretable  model  using  saliency   as  a  model  introspection    mechanism.  While in  this settings  traditional saliency  vanishes    beyond a few timesteps in  the past, the proposed solution carrying    all  timesteps with  each  input to  LSTM is  able  to provide  the    interpretability across the input sequence.        It is unclear  from the paper whether the saliency  is computed for    each  timestep  that  the  LSTM  made, or  rather  for  each  input    accumulated and available to the  current time step.  I suspect the    latter, but correct me if I am wrong. If I am right though, then it    makes complete sense why the  proposed trick would work better than    any attempts  for "flowing" the  gradients to the past  through all    LSTM  positions.  However,  the  proposed model  regardless of  the    saliency is now more of  accumulative rather than sequential, where    both  the cell  and  the weighted  input  gradually accumulate  the    sequence. Because  of that difference  in the model  semantics, the    approach may  not be widely  generalizable, although it  looks like    the problem of  highlighting feature importance across  time can be    addressed in this fashion.     It is  unclear why the paper  insists on calling their  input level    attention (A_t) attention  at the _cell level_  Clearly, equation 2    shows  accumulation  of  the  attention  weighted  input,  not  the    attention  weighted  cell  elements.  Probably,  just  a  confusing    naming. Please, consider changing.     1. Please cite the Attention paper by Bahdanau, Cho, Bengio â€™14    2. It is unclear what happens in the paragraph between lines 118       and 119. The unnumbered expression for A_t does not make it       clear whether the matrix that's passed as an argument to softmax       is treated as a flattened vector and all the elements of the       resulting A_t sum to 1 or only those for each feature within a       time-step?    3. Lines 120 and 121 are unclear  as well. W_{M} is called a matrix       but it is a tensor of rxNxh  dimension. Does this mean that M is       flattened to a vector of length r*N and W_{M} is indeed a matrix       of h x (r*N) dimension?  