This paper studies the task of training over-parameterized deep ReLU networks via SGD, and proves a generalization bound which is more general or sharper than several recent ones. The generalization bound has the additional nice property which can distinguish between learning from noisy labels and true ones. The analysis is intuitive and seems to take a slightly different route from most previous works I am aware of, which may benefit the future work on this topic. Therefore, I feel that the paper has enough originality and significance.   The results appear technically sound to me, as the proofs all look reasonable, although I did not check them very carefully. The paper is well written and easy to follow in general.  * After author response: I have read the response, and I am satisfied with it. I still keep my score as “Marginally above the acceptance threshold” and vote for accepting the paper. 