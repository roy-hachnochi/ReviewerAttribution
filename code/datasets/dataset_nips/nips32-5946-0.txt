Originality: The idea is interesting, and to the best of my knowledge hasn't been tested before. However, applying gradient descent to update parameters is not very original.   Clarity: Overall, the paper is well written. Te structure can be improved however. For example, having the related works sections right before the conclusion is quite disturbing.  Quality: The description of the method is sound and technically correct. The experimental section is well designed and fairly assess the method. I particularly appreciate the experiments with noisy labels. However, I have some concerns. Can the authors comment on the importance of the instance weights? Adding a trainable weight per sample can substantially increase the size and capacity of the model. This can make the comparison to the baselines unfair. Moreover, a missing analysis in the paper is to track and try to analyze the parameters in order to check if they actually do what they are expected to, i.e. prioritize the easy samples in the beginning of training and progressively evolve towards uniform importance.  Significance: The experimental results are extensive and show significant improvement over the state-of-the-art models in several settings and for several datasets. This proves the the interest of the method, but again, it is not clear to me how much of this performance gain is due to the curriculum learning mechanism.