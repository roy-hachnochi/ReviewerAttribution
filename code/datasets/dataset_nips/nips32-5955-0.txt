Post-rebuttal: Thanks to the authors for a thoughtful rebuttal.  If the authors are able to find space for the qualitative results, I believe most of the reviewers' concerns were addressed.  I am however wary of adding additional experiments from Pascal 2012 test, even if they were technically done before the submission deadline.  The motivation of this approach is that per-pixel losses don't explicitly capture the structural differences between the shapes of predictions in ground truth. By comparing the mutual information between local patches in the prediction and ground truth, the authors hope to encourage higher order similarities.  Ultimately the results on Pascal 2012 and CamVid show that such an approach can lead to small but significant improvements in IoU over prior approaches based on CRFs and Pixel Affinities, without any added cost during inference.  Along the way they show how to approximately minimize this region mutual information based, with the appropriate downsampling to efficiently train the model with this loss.  One interesting potential advantage of this approach is that since the loss is based on aggregate statistics over small regions, it may be more robust to small labeling errors.  It would be interesting to see if this is the case by artificially perturbing the training data in various ways (coarser polygons, random shifts between GT/image, etc).  Along these lines, it would also be interesting to see the influence of different weight factors (\lambda) between the cross entropy and region mutual information.  In particular, I'd be curious if this loss can work without cross entropy at all?  Further, it would be interesting to consider a loss that is more sensitive to errors in the shape or higher order errors.  For example, something like hausdorff distance between object boundaries might be a suitable metric.