Originality: While learning stable dynamical systems has been studied in previous literature in the context of neural networks, the training of an additional Lyapunov function to guarantee stability of an architecture is a novel contribution.   Some recent related work which could be included is that of Neural ODEs (Chen et. al, NeurIPS 2018) and stability with recurrent neural networks - i.e. Stable Recurrent Models (Miller & Hardt, ICLR 2019).   Quality: The claims are valid and well-supported by theoretical results and empirical analysis. The authors show that their method provably leads to models that are constrained to be stable.  Perhaps one area which could be more thorough is that the empirical evaluation of the method is lacking in the form of baselines. The authors only evaluate against a naive neural network. There are potentially several more intelligent baselines, such as penalizing the Jacobian of the network, or even simply clipping the weights. The authors also refer to prior work on penalized losses for training stable networks, but do not evaluate any of the aforementioned methods.   Clarity: The paper is well-written and well-organized.   Significance: As mentioned by the authors, learning good, stable dynamics model architectures has many downstream applications in reinforcement learning and sequence modeling tasks. 