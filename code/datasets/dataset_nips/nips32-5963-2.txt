Overall I liked the paper. It is well written and the task is interesting.  I have some minor concerns regarding novelty at both the conceptual and technical levels. First, the reference supporting the claim that "incorporating spatial relationships has been shown to improve the performance of object detection" shows a lack of knowledge of important works in computer vision (prior to the deep learning era). For example, Hoiem et al.'s "Putting Objects in Perspective", ECCV 2006 showed the same thing over 10 years ago. Second, the object relation transformer model is a small variation of the standard transformer.  I congratulate the authors on running and reporting statistical tests on their experimental results. They also provide sufficient implementation details to reproduce the models. Providing code on acceptance would help reproduceability further, and the authors should consider doing so.  Some technical/minor comments: 1. In Section 3.2 it is not clear which parameters are shared between different heads and which are unique to each head. The authors should clarify and index the head-specific parameters. 2. In Eqn (6) the normalization in the second log term should be h_m. Moreover, what happens if the objects are aligned horizontally or vertically, i.e., x_m - x_n = 0? 3. L155 "\Sigma_A = with \Sigma" -> "\Sigma_A with \Sigma" 