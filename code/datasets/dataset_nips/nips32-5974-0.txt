Update: Author rebuttal promised to update the paper to address my criticism regarding clarity of methodological explanation. Contingent upon these changes to the camera ready, I have decided to increase my score from a 7 to an 8.  This paper provides a view of generative adversarial networks through the lens of energy-based models (EBM). A slight modification to the original GAN objective falls out of this view, which provides a number of beneficial properties.   Overall, I think this is a strong paper. It addresses numerous deficiencies in current GAN training methodology, namely the difficulty with evaluating the results and monitoring the stability of the training. The fact that the representations it learns are SOTA for unsupervised approaches on CIFAR10 is also impressive  My main complaint is that, after reading, it is not entirely clear to me to what extent this strategy deviates from typical GAN training. Phrases like “we examine GANs through the lens of … “ (abstract) and “GANs can be reinterpeted” (conclusion) are used which seem to imply that the proposed approach does not alter ordinary GAN algorithms and is just a different perspective. However, the proposed approach *does* in fact alter the algorithm (line 72). More confusion is added when Equation 3 is introduced as an “optimization procedure”, when in fact it is merely a value function that does not immediately imply a procedure or algorithm. It would be great if the authors could clearly and concisely state how their method deviates from standard GAN training, as right now this information is scattered throughout the paper.  This paper is also weakened a bit by the exclusion of code, the inclusion of which would greatly improve the accessibility of the work.