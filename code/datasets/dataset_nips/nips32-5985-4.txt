The manuscript considers basic statistical questions regarding reasoning about the expected outcome of a predictive model. Efficiently computing even the expectation (first moment) is a known challenge even for simple predictive models and simple generative models (e.g. logistic regression and naive Bayes distribution). The authors give a pair of generative and discriminative models (family of structured probabilistic circuits) that enables tractable computation of expectations (and higher order moments as well), in some cases approximately, b) provide algorithms for computing moments of predictions wrt generative models and c) show that the utility of the algorithms in handling missing data during prediction time compared to standard imputation techniques on some datasets.  The paper is organized and written well, there are some good technical contributions. But I'm unable to get a good grasp on the overall significance and merit of this work - partly because the authors aren't convincing enough throughout the paper. I'm also not entirely sure if NeurIPS readers are the right audience for this work - not just in terms of applying these results in practice, but primarily in terms of taking the scope of this work forward.   In the problem set up of Section 2, I wasn't entirely sure where the paper was heading towards - for example, why should one be interested in *exact* computation of mean/moments at all, given that the predictive models are already constrained by the availability of training data? Furtheremore, why is this a new problem in ML/computer science? I'd think these are fundamental questions in statistics and inter-disciplinary computational science communities (I don't see references to these in Sec 2).   I also didn't see an exposition of jump from logical circuits to real-valued data/inferences anywhere in the paper (nor at least a hint in the main Section). The paper does cite references to existing work that deal with these issues, but the gist of idea needs to be conveyed in Section 3 to make the ideas grounded and concrete. In fact, the Section is written assuming PSDD is a "given" which is already concerning (of course, the reader might guess that it will be learned from data as well). Not until later in the experiments does the paper give a concrete footing - "Our advantage clearly comes from the PSDD learning a better density estimation of the data distribution, instead of having fixed prior assumptions about the features."  I liked the experimental design and results, but I don't know why the authors don't talk about nor compare to simple density estimation or other statistical tools to compute expectations of (non-linear) predictive functions from training data (even without caring about characterizing the data distribution, i.e.).  --- I've read the authors' response; my stance on the paper is however unswayed. Overall, I like this work for some of the technical contributions, but what I'm still not clear about is why accurately determining the mean/moments is significant from machine learning perspective, as well as lack of comparisons/references to work from Stats community.