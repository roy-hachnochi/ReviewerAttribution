Advantages: This paper considers combining machine teaching with active learning. Under this setting, the active learner decides the instances to query, and the teacher decides the label to return. This paper discloses a non-trivial fact: the active oracle can be sub-optimal even if it generates the label through the underlying true distribution. This reveals the importance for combining active learning and teaching. To my understanding, this is the most significant contribution for the paper.  Furthermore, the Bernoulli bandit (generalized linear bandit in fact) problem is taken as an example to show how effective teaching can be achieved. The MDP-based sequential decision framework is utilized to model the teaching-student learning process. On the high-level, the proposed approach seems to be a reasonable framework to solve this kind of problems.  The most interesting part of the experimental results is that they show that if the student can model the teacherâ€™s behavior properly, then the learning performance can be boosted. Furthermore, they also suggest the potential usefulness of the proposed framework under the human-involved oracle scenario. These two results could be very useful guidance for further studies.  Disadvantages: Writing can be significantly improved. The main contributions are not clearly described, and the algorithmic parts are also not clear enough for understanding. The explanation of why providing labels through the underlying true distribution can be sub-optimal is insufficient.   The bandit algorithm seems not correct. The description of how to estimate theta in line 114-119 is not clear. It seems that they rely on the assumption that the x_t received in all iterations are independent, while this is not true since the choice of arms are decided by the learner. The discussed bandit problem is actually a special case of the generalized linear bandit, I suggest referring to [1] for the Thompson sampling algorithm under this setting.   Overall, the paper discusses an interesting and important problem. The novelty is significant, and it discloses several non-trivial facts. The high-level framework can be followed by future researches. While the writing can be significantly improved and the issue in the bandit learning algorithm should be addressed. This makes my score decreased (if I am wrong about the bandit algorithm, feel free to point it out)  [1] https://arxiv.org/abs/1611.06534   ------ after rebuttal:  I agree with the author response that the bandit algorithm in the paper follows from the general framework of TS. On the other hand, I find no theoretical guarantees of this algorithm under this setting both in the paper or in the literature.   I made a mistake in the review before: the Bernoulli bandit in the paper is not the generalized linear bandit model since the randomness is not from the additive noise.   In spite of the issues of lacking theoretical guarantees, I appreciate the novel insights from the paper, thus I would like to raise my score. I also encourage the authors to include more discussions about the possibilities of further theoretical studies. 