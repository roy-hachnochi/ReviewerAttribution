Originality.  This paper viewed the existing pooling method in a convex combination of local feature activations. Based on this model, the authors explained how the proposed Gaussian pooling is different from existing pooling methods clearly.  Also, this paper proposes to modify the Gaussian distribution such that the pooling value becomes larger than mean based on the knowledge of local pooling. To the best of my knowledge, such pooling functions are novel.     Quality.  The quality of this paper is good. The proposed algorithm is reasonable and technically sound. The experiments are conducted on large-scale datasets and compared with related pooling methods.   Minor problem: The results of stochastic [32] are missing in Table 3.(c) and (d).    Clarity.  This paper is clearly written except for some points described below.   More explanation of the inverse softplus function and iSP-Gaussian distribution would improve clarity. Mainly, why the term exp(x)/(exp(x) â€“ 1) exists in Eq.(10) is not clear enough. It would be better to explain how to derive Eq.(10).   In the experimental section, which layers the authors applied to the proposed methods are not clear. According to the discussion of Global pooling (line 219-), it seems that the poo1 and/or pool2 of Table (a) are used in previous comparisons, but there are no explanations. The fact that this paper is only focusing on local pooling is not clearly explained until this section.   Significance.  The new pooling method is useful for improving the recognition accuracy of various recognition problems. This paper proposes a novel form of pooling by modifying the parameter of Gaussian distribution, which is shown effective than state-of-the-art poolings on the large-scale dataset. Thus, other researches or practitioner can use the proposed method for any algorithms based on CNN. 