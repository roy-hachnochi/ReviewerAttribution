This paper focuses on solving the sparsity issue in the importance sampling of FastGCN and propose a layer-dependent importance sampling schema. However, the main modification is sampling the neighbors based on a defined probability from the union neighborhood of nodes in the upper layer. However, this is a small modification of FastGCN since for a mini-batch training, it is straightforward to improve the sampling efficiency by limiting the candidate nodes to the neighborhood of the nodes in the upper layer. In fact, this is just a trick in the coding implementation of FastGCN in terms of this point claimed by the authors, and cannot be considered as a novel improvement in the level of NeurIPS although you have conducted the corresponding experiments.