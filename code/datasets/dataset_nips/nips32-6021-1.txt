 The proposed model has two networks -  one network to explicitly learn the energy distribution, and a second implicit generation network which is trained by minimizing goodness of fit statistic between the energy distribution and the generated data. The authors demonstrate how Stein operator can be used for training the implicit generator, resulting in a two step training procedure.   Originality: The proposed approach of minimizing the gof statistic between generated data and an energy distribution seems novel. The authors have clearly highlighted their approach in context of prior works on energy-based GANs.   Clarity: The paper is well-written, though some more discussion can be added in the experiments on some additional takeaways and insights. It's not clear if authors considered two different energy functions, one autoencoder based and another RBM based? A comparison of the two doesn't come up in the experiments. T  Quality: Authors experiment with 3 datasets, and compare against 5 baseline method. They report Inception Score, Fr√©chet Inception Distance and Kernel Inception Distance. The examples in Figure 2 generated from the proposed DEAN model seem to be of high quality. It would have been great to see some crowdsourced experiments to judge the quality of generated images. Additionally, there aren't many insights about the method apart from better quantitative measures.   