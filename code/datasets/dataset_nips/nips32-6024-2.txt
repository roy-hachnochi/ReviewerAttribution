The optimal rate for ERM is not the same as the optimal rate for stochastic convex optimization. Similarly the optimal rates for private erm are not the same as the optimal rates for private SCO. This paper resolves the important question about what the optimal private rate for SCO is, and gives algorithms for matching the upper bound.   The main technique in showing the generalization bounds is uniform stability. They extend the uniform stability analysis of SGD to the noisy SGD case to prove that noisy SGD achieves the optimal SCO rate. The non-smooth case is handled by noisy SGD on the smoothed version of the function via the M-Y envelope.   Significance: Significant new results -- worthy of publication Originality: Technically the results seem to follow from standard analysis techniques adapted to the private setting  Clarity: Very clearly written 