Overall, I believe the paper makes a meaningful empirical contribution to scalable training methods of robust classifiers. By finding adversarial examples for smoothed classifiers and modifying the training procedure, the authors significantly improve the accuracy of smoothed classifiers. Smoothed classifiers are of interest since they are scalable and come with a certificate of robustness.   The paper is clearly written.  However, the contribution seems incremental. All the building blocks have been introduced in the past: adversarial training, smoothed classifiers, robustness of smoothed classifiers. The only contribution is the method for finding adversarial examples for smoothed classifiers, which is interesting, but I would have expected more depth. The paper would be significant if they had a theorem that somehow argued that robustly trained smoothed classifiers were somehow optimal in a stronger sense.  Detailed comments.  Is SmoothedAdv different in any way from the standard robust training for appropriate attacks (Madry et al 2017)?  Lines 33-34. "... to substantially improve the previous certified robustness results of randomized smoothing". To me, this suggests that the contribution is theoretical, and the theoretical robustness guarantees are improved. However, the contribution is only empirical. It would be appreciated if the authors could make this clear to the reader.  Lines 118-121. A similar comment as above. The authors don't show that adversarial training improves the robust accuracy of the base or the smoothed classifier. They only observe it empirically for the smoothed classifier, which already comes with a certificate.   Section 2.1 and Experiments. How many monte carlo samples one would need to get high probability estimates of lower/upper bounds on p_A, p_B? What's the probability of your robustness guarantee (for the parameter choices used in the experiments)?  (*) Experiments section: Only the accuracies on examples, where the smoothed classifier made predictions (did not abstain) are plotted. The comparison that seems to be missing is the fraction of examples on which the two smoothed classifiers abstained. If the number is similar, is it always the same set of examples?  Lines 246-247. It would be nice if the authors could add a sentence or two summarizing the results of this experiment, so that the reader would not have to search for it in the appendix.   ******* Update after Author Response:  After reading other reviews and author response, I have raised my score to 7.   While all the ideas seem incremental, overall the work seems to make a significant contribution. I would also like to add that my score increase is based on the following promised paper improvements made by the authors in their response:  - "Our main contribution is not theoretical and we will update the draft to make this more clear."  - "include an alternate proof of the tight certified bound of smoothed classifiers ".