I believe this is an important, significant contribution which warrants acceptance at NeurIPS. While the idea to combine Randomized Smoothing with Adversarial Training may appear straight-forward, the authors had to address a number of technical challenges (like designing a PGD variant to work on randomly smoothed classifier) which they did in a very careful, systematic and clear way. The Appendix documents a lot of the directions that the authors explored along the way.  One suggestion: the performance of the new state-of-the-art certified classifiers on clean samples is a bit hidden (one has to look very closely at Figures 1 and 2). If space permits, I think it would be good to include them in Table 1 & 2 (Cohen et al. had highlighted the standard accuracy of their certified classifiers in such a way). One related question: what was the procedure for picking the "representative" models in Figure 1 and 2?  And one minor comment: l.213: "see <diamond> for explanation"  ---------------------------------------- I've read the authors' response which confirmed my very positive impression of this submission.