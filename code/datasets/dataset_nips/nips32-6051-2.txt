Overall:  I found this paper well-written and convincing. The authors do a strong job justifying the proposed model and positioning it relative to standard models in the field. I have a few questions, but overall, think it is a very strong applied paper.  Questions/comments:  1. Clinical visits are generally irregularly spaced and rife with missing measurements. How was this handled in the context of your discrete time model?  2. Beyond evaluation in the context of this paper, why restrict the model to have the same number of states as an existing disease phenotype scheme? In particular, we cannot assume that the unsupervised model will learn back an existing phenotype scheme and, in many cases, it is not clear that we would want to.   3. Line 159: Similarly, we *hope* that the factorization in (2) produces clinically meaningful disease states, but it is by no means a guarantee.  4. Line 177: This posterior factorization was not been previously discussed. I recommend adding a section in the supplementary material that gives more details on its derivation. Maybe even just a simple three time step example derived from the graphical model would suffice.  6. Line 183: \vec{\alpha}_t --> \vec{\alpha}_{t-1}  7. Figure 4: I'm not sure that the training NLL is very informative here since we would expect a more expressive model to fit the training data better regardless of how well it generalizes. I would recommend a held-out NLL plot instead. Also, are the lines for Mean-Field and Attentive actual NLL values or are they the ELBO?  8. Line 237: The learned transition matrix has non-zero probabilities for transitioning backward from more severe stages to less severe ones. Is the existing CF progression monotonic or does it allow for backwards transitions? If so, this seems like the kind of constraint that could be easily encoded in the model.