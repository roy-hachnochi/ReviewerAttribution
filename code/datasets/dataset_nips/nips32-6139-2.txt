*originality* The paper is very original, and the provided framework extending the standard ELBO to TVO is very elegant. I expect that this paper stimulates a lot of new research in this direction. A natural and good idea.  *quality* The mathematical derivations are very clear and easy to follow. The experimental evaluation is well conducted, but restricted to MNIST only. The used implementation of TVO (based importance weighted sampling) seems to be of limited advantage (number of partitions and particles seem to have a limited impact on the learned model), which is somewhat underwhelming. Also, the effect that more particles in rws, vimco, and TVO leads to worse approximation of the posterior is surprising (Fig. 4), but not further explored. It would be interesting to see the TVI integrand (Fig. 1) for a real example/model/dataset, e.g. estimated with a massive number of importance samples.  In Section 4, it is unclear to me, why both wake and sleep phases are over \phi.  *clarity* The paper is largely clear. The connection to wake-sleep, however, remains somewhat unclear.  *significance* While the experimental evaluation could be improved, the main contribution -- the TVO -- is very refreshing and of high significance.   ************************************************************************************************************************ Update:  As said in my original review, I find the proposed approach refreshing, original and creative. However, a richer set of experiments concerning datasets and models could make the paper quite stronger. Thus, I stick with my original rating (7).