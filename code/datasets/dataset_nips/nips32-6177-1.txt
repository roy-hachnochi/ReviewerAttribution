 - Strength:   This paper is well written and the ideas are clearly presented, which makes the paper easy to follow. The algorithm seems easy to implement and is likely to have some value in practice.     - Weakness:     My main concern is about the problem itself. The proposed method uses ANN to accelerate NN query, and claims achieving some "constant approximation". The "approximation" here means that in each step the two merged clusters differ only by constant times of the minimum "dissimilarity". However, with such relaxation, the output hierarchical tree can be completely different from the exact solution. It is not clear from the paper how to compare the quality of these two hierarchical trees. Obviously, if the two trees are not close,  the acceleration would not  make much sense.  Although  the proposed algorithm runs faster, it may not achieve the desired goal.         The paper does give some empirical evidence (Table 1) to suggest that the approximate solution is of "good quality". But the experiment is conducted only on a few small datasets and thus not very convincing. There are a few papers discussing how to define a suitable objective function for the HC problem (e.g. [1] and [2]). I   would like to see some discussions and comparisons with those approaches.     - [1] Sanjoy Dasgupta. A cost function for similarity-based hierarchical clustering. STOC'16    - [2] Vincent Cohen-Addad et al. Hierarchical Clustering: Objective Functions and Algorithms. SODA'17 