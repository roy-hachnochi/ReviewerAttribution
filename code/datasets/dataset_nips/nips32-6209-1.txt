Following the author rebuttal, I am updating my review to acknowledge the theoretical contribtions in this paper that are not present in 5637.   The paper is well-written; claims are justified; results are clear.  This paper considers the class of zero-sum linear-quadratic games. The authors demonstrate that the stationary points of the control policy space are the Nash equilibrium of the game. The authors propose three nested gradient methods for policy optimisation in such games, with theoretical proofs of convergence and empirical results in small domains.  Although not identical the theoretical work is largely the same as that presented in 5637. The only additional contribution is to analyze the algorithmic variants on toy problems.  Two of these methods can be approximated in a model-free setting, although no results are presented for this case. 