Originality: I have seen a presentation/workshop paper on the same topic (I believe by the same authors) in the ICML2019 workshop on generalization in deep learning. Other than that, I am not familiar with earlier work presenting similar counterexamples showing UC cannot explain generalization.   Clarity: The paper is mostly clear and easy to read.   Quality: The proofs of the main theoretical results are correct. The results seem to be quite useful and informative. I believe that the paper is of relatively high quality. There was one point of confusion for me regarding Pseudo-Overfitting. Clarifying this concept and the framing of counterexamples presented with respect to this concept would be required (but possibly not sufficient) for me to increase my ranking to "Top 15%". From my understanding the counterexamples provided *do* pseudo-overfit, while the paper mentions (and purports to demonstrate in appendix B)  that deep networks do not pseudo-overfit. This confusion casts doubt on the relevance of the counterexamples to actual models used in practice. I think that this could be clarified further by the authors.  Significance: The work is significant as it informs theorists that certain tools may not be useful in their research. This is significant, IMO, to warrant acceptance at NeurIPS. It does not, however, provide an alternative set of tools for theorists to use when UC is not necessary. This would be required for me to consider this a "Top 5% paper". I imagine that the counterexamples presented in this work could become "standard text book examples" in the future since they are clear and easy to follow, and also readily demonstrate the phenomenon of interest. 