Overview: This paper studies the thresholding bandit problem, under an alternative definition of regret to that which has been considered previously in the literature. The authors then provide an algorithm specifically tailored to minimizing this regret (up to some potentially enormous constant factors). They provide an analysis of the regret of this algorithm and demonstrate experimentally that it outperforms algorithms developed for minimizing a different regret definition. However, I would have liked to see more discussion and comparison of the performance of the different algorithms under different regret definitions and details of the parameter choice for their algorithm.  Comments: - I don’t find the motivation for the need to consider aggregate regret particularly convincing. - Given that there is a lot of discussion about the simple regret, it would be good to include a definition of it, and discussion of how they relate to each other, e.g. does one imply the other? - In the discussion of Locatelli et al. (2016), it is stated that the algorithm is parameter free then that it takes parameter epsilon. - The uniform sampling method introduced in line 69 seems very naive so I am surprised it is only a factor of K worse than the proposed method. - Although space is tight, I would have liked to see at least some discussion of the best arm identification problem. - I think the discussion of the optimization problem in the case where the gaps are known is nice. It is also nice to see how this motivates the algorithm used. - The outline of the proof of Theorem 1 would be much better placed next to Theorem 1 rather than its current position in the introduction (lines 107-118). It also seems like a fairly standard analysis with the only interesting aspect the avoidance of a union bound. - A lot of the constants seem quite arbitrary (e.g. why do we need alpha<=8 and T>40?). - The constant in remark 2 is enormous. The authors should at least attempt to optimize it to give a meaningful result rater than making ‘no effort’ to do so. - How should alpha be chosen? In remark 2 it is 1/20, whereas in the experiments it is (somewhat arbitrarily) 1.35. - How are a and b chosen in Lemma 19? It seems somewhat un-intuitive that for large values of b, the distance between the empirical mean and expected value is large but the constant in front of the exponentially small probability more or less stays the same. - why is this analysis applicable to other areas but the analysis of MOSS not (line 267)? - I would like to see the aggregate regret of the APT algorithm of Locatelli et al(2016) and the simple regret of this algorithm for comparison. - In Figure 1, why is APT given with lots of different parameter settings where as their algorithm is only given with one. - In Figure 3 of Appendix F.3, the range of alphas considered is quite small. What happens if we set alpha=1/20 as in remark 2? - It would be good to see confidence bounds on the experimental results to see if the differences in performance are significant. - I would like to experimental results for the simple regret considered by Locatelli et al (2016) .  Clarity: Often, the paper is difficult to read and care should be put into proof-reading to eliminate typos/grammatical errors. The introduction could also be significantly improved.  After rebuttal: Thank you to the authors for providing a detailed rebuttal that addressed most of my concerns. I was particularly pleased to see a discussion of the relationships between the two regrets, the difference between their analysis and that of MOSS and the significance of the suboptimality of the uniform sampling method. I have therefore raised my score. For the final version, I hope that the authors will work on the readability of the paper and add more details about the choice of alpha.