The paper considers the thresholding bandit problem, where aggregate regret is minimized instead of simple regret (errors on all arms, instead of at least one). A new algorithm is proposed for the slightly modified setting. The paper derives the aggregate regret bound for the algorithm, which roughly matches the lower bound provided in the appendix. Experiments on synthetic data show that the algorithm performs better than some existing algorithms (which were designed for slightly different variant of the problem).  Minimizing aggregate regret (as opposed to simple regret) seems to make sense in some scenarios. Consequently, it does warrant additional analysis. Given that the existing algorithms were designed for different problems it is difficult to assess the improvement in performance (regret bound or empirical). The theoretical analysis contain sufficient new elements (including the variable confidence level bound) to be considered worthy of publication.    The article is well written, and the split in content between the main submission and the appendix is also reasonable. Maybe, the lower bound could be stated in the main part as well.   Update after the author response:  I appreciate the authorsâ€™ effort, in particular the discussion on simple and aggregate regret and the additional experiments.