Although the paper is a good attempt at this space, and the messages should be echoed wide in the community, the paper could benefit from various improvements. Specifically, I am unsure if some of the performed experiments are supportive of the claims made in the paper. Details are as follows:  Line 79: Authors discuss evaluating interventional distribution. But if the structure learning part is correct, then the learned distribution will also be correct as long as the parameterization is known or for discrete variables. Am I missing a point here? After reading the rest, I guess authors are concerned about approximately learning the structure, and then depending on whether strong or weak edges are omitted can be determined by such an evaluation. It may help expand this discussion here a bit too.  Can you elaborate a bit more on untested influences in line 176.  Line 245: The data proposed in the machine learning challenges mentioned here is already used in the cause-effect pair dataset of Mooij et al.  Section 4.4: Please explain this experiment of generating synthetic data on the learned network in more detail: How many samples were in the real data, how many samples did you generate synthetically? The mentioned algorithms can perform poorly if the number of samples are small, which is a different problem than using synthetic data.  " Structural measures also implicitly assume that DAGs are capable of accurately representing any causal process being modeled, an unlikely assumption" This issue is much more complicated than authors imply. Once we remove the assumption that the underlying graph is acyclic, the modeling changes drastically. So, if an algorithm that is based on a set of well-defined assumptions including the assumption that the underlying graph is acyclic, outputs a cyclic graph it is a clear error and should be avoided. It is a different point to encourage assuming cyclic models and developing algorithms for that, but that is at the modeling phase, much before evaluation. Please elaborate this part as the quoted sentence can be misleading, diminishing the significant difference in modeling cyclic vs. acyclic systems.  The TVD vs. structural distance plot is interesting. Is the TVD calculated only on the observational distribution.  AFTER REBUTTAL: I would like to thank the authors for their detailed response. Although it clarified many points, I still believe the reason for seeing multiple outcomes from the causal inference algorithm is probably simply using insufficient number of samples, rather than synthetic vs. real data. I hope authors investigate this point better.