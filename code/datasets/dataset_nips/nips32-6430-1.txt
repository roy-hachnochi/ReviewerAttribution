In their manuscript entitled, "Debiased Bayesian inference for average treatment effects", the authors present a new class of Bayesian model (or, as they phrase it, choice of [stochastic process] priors) for estimating average treatment effects (across a population) given only observational data not from an RCT (i.e., the canonical causal inference setting in social science or population health).  The insight brought to this problem regards the structuring of the model to introduce a posterior de-biasing correction based on theoretical insights from the Bayesian asymptotics literature.  From my point of view---having worked extensively with Gaussian process & Dirichlet process models and having read widely on the asymptotics of these processes---I was very pleasantly surprised to see here: (i) the identification of a connection between the ATE estimation problem in a semi-parametric Bayesian setting and this particular branch of the asymptotics literature, and (ii) that the authors were able to successfully transfer the insights from the asymptotics back to the practical problem to achieve a more effective model.  Moreover, the presentation is very clear (modulo my concern that I find sometimes the exchangable use of the terms model and prior to be initially a little confusing).    Although I found no errors in the text I felt that perhaps some discussion on how this model might interact with the (seemingly) increasingly common prior step of automatic causal feature selection could be warranted: e.g. presumably this method suffers from a curse of dimensionality if too many non-important variables are simply thrown into the design matrix, but likewise presumably performance will suffer if important covariates are omitted: is there any way within this model class to diagnose either of those problems?