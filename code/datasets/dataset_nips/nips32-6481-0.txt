I enjoyed reading this paper because it presents a number of important points that are problematic when it comes to deep generative models in a clear manner.   In the related work section, I was missing work on DGM evaluated in feature space, e.g. [1]. Although the approach here has more mathematical rigor, it would be nice to acknowledge that the idea is not totally new.   In the method section, I was not 100 % happy with the introduction of the feature space. Conceptually, what is happening is that you train a structure that looks like this, right:  VAE - data layer - flow-based generative model  - GAN. One could argue that the flow-based generative model alone already suffices to generate data. Is the advantage that the VAE does the generative work and the inverse-layers do not have to be as powerful? Please provide a more rigorous discussion around this and point to relevant related work.   The experiments include enough datasets and the appendix shows actually images that are large enough to see some detail.   Originality: high - both with respect to presentation of the facts and the method Quality: high - well written Clarity: good Significance: good  [1] Hou, Xianxu, et al. "Deep feature consistent variational autoencoder." 2017 IEEE Winter Conference on Applications of Computer Vision (WACV). IEEE, 2017.