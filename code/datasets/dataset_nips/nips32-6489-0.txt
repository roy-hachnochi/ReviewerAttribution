-This paper investigates a better strategy to produce a wide spread of trade-offs among multiple tasks in the multi-task learning setup (as shown in Figure 2) by introducing preference vectors. Based on multi-objective optimization with the vectors, the proposed method can achieve distributed Pareto solutions. It seems to be efficient compared to other existing MTL competitors.   -However, I see the contributions of this paper is incremental and limited as the goal is not that significant and the approaches are mostly based on existing strategies such as [12, 24, 30].  In addition, the approach looks based on a single shared architecture assuming there are correlated tasks, but if tasks are less relevant, I wonder how to consider the tasks in generating Pareto solutions.  -The paper is well-written and easy to follow, but there are a few unclear sentences that do not give clear answers. For example, in the lines of 87-88, why existing work cannot efficiently incorporate preference information and in the lines of 173-175 why the approach in [30] is inefficient and why the sequential gradient-based method can overcome the inefficiency?  -In Algorithm 1, how to evenly distribute the vectors u_iâ€™s? Is it achieved manually or rule-based things?  -Even if the proposed approach pursues an approach for generating widely distributed Pareto solutions (rather than the accuracy itself), experimental results say that the method performs better than other competitors? Is there any analysis on this?  -The first experiment is based on LeNet which is a quite old network so may not show the potential of the compared approaches for the problem. Reporting results using more advanced networks would be better.  ---- The authors addressed most of my concerns even if they did not provide the actual results for my last concern. They should be given in the revised manuscript. From the other reviewers' comments, I would like to stick to my current rating.