== SUMMARY ==  PAC-Bayesian risk bounds are considered by many to be the tightest existing analysis of generalization error. Despite this, there is still a gap between empirical test errors and analytic bounds, and this gap motivates further refinement of PAC-Bayes analysis. PAC-Bayes bounds come in various "flavors," the most popular one being the "little kl" bound, which bounds the KL divergence between Bernoulli distributions with parameters equal to the empirical risk and true risk, respectively. This form is the tightest, but considered by some as not easy to interpret. McAllester showed (COLT, 2003) how such bounds can be converted into a more interpretable bound on the difference of the empirical and true risks. One attractive facet of his bound is that when the empirical risk is small, the bound achieves the "fast" rate of O(1/n) -- thus capturing both realizable and non-realizable learning problems. Later, Tolstikhin & Seldin (TS; NIPS, 2013) derived a bound that accounts for the variance of the empirical losses. Since the empirical variance is often smaller than the empirical mean, their bound could be tighter than McAllester's (or others based on McAllester's analysis of the kl). Unfortunately, with all due respect to TS, their bound lacks the interpretability of McAllester's bound. (Of course, interpretability is subjective; this is simply this reviewer's opinion.)  The current manuscript provides a bound that is similar in form to McAllester's, but includes a variance-like term. This term, denoted V_n in the paper, is the expected mean-squared error between a hypothesis drawn from the posterior and a reference hypothesis -- which could either be deterministic, or drawn from an alternate posterior -- trained on a subset of the data. To be precise, there are two such terms, arising from a split of the data. (Thanks to this splitting, the bound lends itself nicely to data-dependent priors, where you learn a prior on a subset of the data and use the rest to learn the posterior.) Unlike McAllester's bound, this one also has an irreducible term, V'_n, that in the worst case is O(1 / \sqrt{n}). The analysis follows from a modification of Bernstein's moment inequality where the X^2 variable is taken outside of its expectation -- hence the name, "un-expected Bernstein inequality."  == PROS ==  The bound does appear to be tighter than existing bounds. The paper demonstrates this experimentally, which is helpful. It's not always easy to compare tightness just by looking at equations, so it's nice to see the claim supported by experiments.  The form of the bound is, in my opinion, a bit more digestible than TS's bound. Though the variance-like quantity is not as interpretable as the sample variance, it is nice that the bound can be stated in one expression (i.e., without cases), and the paper gives an optimized form of the bound (Eq 1 combined with the Corollary of Theorem 1) which makes it easy to compare to existing bounds.  == CONS ==  The irreducible term is disappointing. McAllester's bound does not have this term, so one would think it would be possible to remove it and achieve the fast rate. Perhaps the worst case upper bound on V'_n is too pessimistic? The experiments indicate that V'_n is on the order of the empirical risk, which could be O(1/n) under reasonable conditions. (McAllester's bound achieves the fast rate in this case.)  While the bound seems to me to be more interpretable than TS's bound, it is not as interpretable as McAllester's. If you apply McAllester's kl analysis to a bound by Maurer, you get a bound that is, empirically, almost as tight as the current one, but more interpretable. If I were a practitioner looking for an "off-the-shelf" bound, I'd reach for the simpler one that is, practically speaking, about as tight.  == PRESENTATION ==  The paper is very well written, which is much appreciated. The authors have taken care to make the theory accessible, starting with a generic bound in Eq 1, and a helpful corollary to interpret their main result. The presentation of the main theorem is a bit dense, but I suppose that is unavoidable.   == DETAILED COMMENTS ==  Line 22: "Standard bounds all have an order ..." This is misleading. Most risk bounds have a term that is O(\sqrt{COMP_n / n}), but only a few have the empirical risk in that term. You can take any little-kl bound and convert it into a bound with that term, using McAllester's analysis. (I think there is also a risk bound due to Pollard with a similar term, but I can't find the reference.)  The form of TS's empirical Bernstein bound is, as I understood it, much different from Eq 1. If the posterior satisfies a certain condition, you get the fast rate; if not, you get the variance-based term. I guess you could combine the terms with an indicator function of posterior -- is this what you mean? It would be helpful if you showed the TS bound in the form of Eq 1. (Apologies if this was somewhere in the appendix and I missed it.)  How critical is data splitting to the bound? Is the bound meaningful if you take m = 0 (or m = n)?  Lines 142 - 144: "... we could use an estimator that ... in the first term." This sentence was unclear to me.  What are constants p and q in Eq 5? Are they used to split the data for cross-validation?  How are p, q, m and n chosen in the experiments?  Stability is mentioned in line 190, but it's not clear how stability plays into the bound. Why is it important that \hat{h}(Z_{<m}) and \hat{h}(Z_{>m}) are close to \hat{h}(Z_{<n})?  Line 200: I think "closer" should be "closure".  == POST AUTHOR RESPONSE ==  The author response clarified some concerns I had -- importantly, that the irreducible term is sub-optimally O(1/\sqrt{n}) in the realizable setting. The authors showed in their response that this term can in fact be O(1/n) in the realizable setting. I strongly recommend that the authors provide this analysis in the paper (if it isn't already there; hope I didn't just overlook this).  == LATE-BREAKING UPDATE ==  Based on late discussion with the area chair, the paper would be stronger if key elements of the analysis (namely, the empirical Bernstein bound and the data-dependent prior construction) were better teased apart and tested in isolation. While I agree with the issues raised in the meta-review, I still think this is a good paper. Accordingly, I am lowering my score from 7 to 6.