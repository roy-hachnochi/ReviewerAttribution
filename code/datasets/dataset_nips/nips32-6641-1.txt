The paper presents a new metric to evaluate generative models by training a classifier using only sampled images. Properly evaluating generative models is an important task and this is an interesting novel idea, however I think this tests more the conditional part of conditional generative models then the generative part and the results should be seen as such.  Detailed remarks: 1) Conditional generative models have a hard time capturing the class, for example  in " Are generative classifiers more robust to adversarial attacks?" the authors get bad classification on cifar10 using a conditional generative model. This was also discussed in "Conditional Generative Models are not Robust" (concurrent work so no need to cite, but might be of interest). It seems that there is a big difference between generative model and conditional generative model and the metric evaluates the latter and should be described as one. Some discussion on the matter is needed. 2) In the same line, it would be important to how the evaluated models capture the class, what is the accuracy of using p(x|y) as a classifier for real data? What is the accuracy of using samples from p(x,y) using a pretrained classifier (trained with real data).