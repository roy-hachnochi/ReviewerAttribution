The lack of novelty is quite problematic. Essentially the central idea of the paper "regenerate training set using a generative model and train a classifier on this data to compare with the one trained on real data and thus evaluate the generative model" was described in "How good is my GAN?" K. Shmelkov et al. ECCV'18 (which is not mentioned in related work at all).  The remaining contributions look pretty weak without the main one. Conditional GANs learn some classes worse than others. FID (IS as well), being a single number, fails to capture this aspect especially for a dataset as rich as ImageNet. Recent likelihood-based generative models actually perform quite well and don't have completely degenerate classes (as their latent space contains reconstructions as well). IS is extremely problematic and does not really account for diversity [23]. Truncation trick inflates IS by directly restricting diversity of BigGAN output and thus degrades CAS. I'd say we already know all this or at least it is unsurprising.  The writing looks pretty good though, the paper is well-structured and easy to read. The main idea is clearly explained, easy to reproduce. But not novel, unfortunately.