     The paper is well written and clearly structured and introduces the necessary background for understanding the full mathematical derivations.  The obtained bound may be instantiated (by setting the parameter \epsilon_B =0) to a traditional generalization bound without adversary. Example bounds are provided for SVMs and for multi layered neural networks. The paper recovers previously published bounds but with another derivation, hence opening maybe new tracks for future works or at least providing a new view of these bounds.     The paper is quite interesting and focuses on a key issue of deep learning, a theoretical analysis of their behavior under attacks. Yet t is difficult to guess how tight are these bounds, and if they might be useful as is for the design or selection of deep networks. For instance how does the bound in (5) for neural networks without adversary behave with the size if the networks ? Does this bound follow empirical observations (that large overparameterized networks generalize well) ?    