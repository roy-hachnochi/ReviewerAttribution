Novelty: The theoretical results and the algorithm are new, and it's clear how they are different from the related work cited in the paper. It's also nice that they reduced this problem to a well-studied one. Quality: Overall, the paper is well put together, in that it presents a problem that was recognized as important, followed by a formalization and solution in a simple case, then the main theoretical result which appears to be sound, then a pertinent algorithm which provides fast solutions, and finally an evaluation of this algorithm in terms of speed and minimal adversarial perturbation. That the procedure can also be used to find features that are unimportant and 'immune' to perturbation is also a point it its favour, tough wouldn't we just be able to identify these by calculating variable importance in a forest? There is one point that I'm not convinced about: the authors rely on the conclusion by previous work that adversarial attacks can have a significant influence on model performance (references 8,12,18). [12] introduces a new type of attack, which as far as I can tell does not affect the results in this paper. However, [8] and [18] introduce methods for strengthening ensembles against adversarial perturbations. How do the bounds hold if these methods are applied instead of standard trees, which is the case for any application where adversarial attacks are expected? The algorithm is applied on [8] (robust GBDT) which is the more recent work. It does seem to be the case that the bounds are much closer to the MILP ones in this case (Fig 2 right). Clarity: The paper is clear and well organized. The main paper introduces enough information for an implementation of the algorithm, but the appendix would be needed to actually replicate the results.  Update following the author response: The authors answered my comments. I liked the feature importance example - perhaps it could be included in the appendix?