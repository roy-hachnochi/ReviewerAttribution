Overall I think the work is interesting but there are problems which make it lower than the NeurIPs standard.   - I think the experimental results are not convincing. The major contribution of the paper is s fast sampling scheme, mostly derived from regression problem. So the verify the effectiveness, it should work well on all different types of gradient based training. Comparing only to SGD is not valid enough to claim the scheme works. Comparing on more different types of ML task is also necessary. In particular, BERT is well known for unstable fine-tuning stage so comparing on fine-tuning downstream tasks are not convincing. If the task is to compare different methods on pre-training stage of BERT and have a significant gain, it will be more impressive.  - From the point of sampling scheme based on the LSH similarity search,  I think it makes sense to compare all different methods in [1] and [2] instead of just LSH. Discussing all sort of methods make the present work more complete and have more research value.   [1]https://arxiv.org/abs/1806.04189 [2]https://papers.nips.cc/paper/7129-a-greedy-approach-for-budgeted-maximum-inner-product-search.pdf