tl;dr: This is a good paper.  I recommend acceptance.  The authors do a good job of motivating their work, and they contribute a nice experimental section with good results.  The ablation study was thorough.  Well done!  ---  Many tasks that might be given to an RL agent are impossible without working memory. This paper presents a suite of tasks which require use of that memory in order to succeed. These tasks are compiled from a variety of other sources, either directly or re-implemented for this suite. They're good tasks.  This paper also presents a neural architecture for using both working memory and episodic memory. The working memory is implemented with an LSTM, not unlike IMPALA. The episodic memory, however, writes memory which is indexed into a many dimensional vector space. The paper claims that this type of memory lasts longer than the LSTM memory.  The authors make a point of saying that none of the models, including the one presented in the paper, are able to do well on some of the tasks. They also show that none of the models perform well on extrapolated tasks (where the difficulty was increased after train time). I think they're doing this to show that their suite of tasks are challenging and worth trying to learn.  There appears to be a marked improvement between agents without episodic memory and agents with episodic memory on the heldout test sets. Also, there is the same improvement between feed forward and LSTM agents (working memory).  They did develop a novel architecture, though none of the pieces are particularly novel. However, their ablation tests successfully show that the agents with working memory and episodic memory perform better than similar agents without episodic memory or working memory at both training time and test time.  Pros: - Generally easy to read - The neural architecture seems sufficiently novel - Need for both working and episodic memory seems well justified. - Thorough ablation tests   Cons: - The formatting for Section 2 is *lousy*. Because figures, figure text, and main text are all over the page, it's hard to keep track of what refers to what. The intro to Section 2 says there are 13 tasks, but it's difficult to keep tally throughout the section. It would be especially helpful if the order of the figures matched the order that the tasks are presented in the main text.  I think the direction is good, the experiments is good, and the overall quality is good. I wish they had another diagram which really showed their claims about generalization. For example, rather than showing all the data for the individual tasks in one, it could be nicer to show a graph which combined the information across tasks, or some handpicked results that demonstrated successes and failures (in addition to the data they have given). I didn't feel like their results had much to do with generalization as much as it had to do with the need of memory for different types of tasks.  Personally, I would have liked more discussion on the need for different types of memory and how their results backed up the theory/intuition.