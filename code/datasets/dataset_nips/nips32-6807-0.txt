This paper studies correlation clustering in an active learning setting where the learner does not query for all the {n choose 2} pairs of vertices. In the standard setting, the algorithm KwikCluster of Charikar et al. achieves a clustering cost of 3OPT where OPT is the cost of the best clustering. Here the cost of the clustering is defined as the number of pairs labeled +1 and put in different clusters plus the number of pairs labeled -1 and put in the same cluster. The main contribution of the paper is a variant ACC of KwikCluster that achieves a cost of 3OPT + O(n^3/Q) where Q is an upper bound on the number of queries made by the algorithm. The authors also prove a matching lower bound on the error of any randomized algorithm that makes Q queries. Next the paper shows that the ACC algorithms also comes with per cluster recovery guarantee when the clusters in the optimal solution are near cliques. This is formalized as the tight-knit condition. Finally, the authors model the correlation clustering problem as an agnostic learning problem over pairs of vertices and show that ERM will achieve a query bound of OPT + n^2eps using n/eps^2 queries. In section 7 the authors show experimental results comparing the performance of ACC as the query budget increases for different values of OPT.  Techniques: --------------- In order to get the active variant, the strategy is to run KwikCluster where at each step a node x is chosen at random. However, as opposed to KwikCluster, only a subset of random chosen points are compared to x. If any of those queries return 1, then x is compared to every data point, otherwise a singleton cluster containing x is output. The number of points to compare at step r is defined by a function f(r), for instance one could f(r) to be r^.2. The proof decomposes the number of mistakes into ones that form a "bad" triangle and can then be bounded as in Charikar et al. The others where (u,v) go together but u or v is output as singletons are unlikely is u belongs to a large cluster.  In my opinion the ACC algorithm and the corresponding lower bound form the key contribution of the paper. The proof technique extends the argument of Charikar et al. in a clever way and the proposed algorithm could be practically useful.  The connection to agnostic learning is fairly standard and the cluster recovery statements make fairly strong assumptions on the graph. In general the paper is well written.