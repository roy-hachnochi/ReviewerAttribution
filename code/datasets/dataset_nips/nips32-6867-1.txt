This paper builds continuous-time models for SGD and stochastic variance reduction methods, by providing explicit expressions of the evolution equations. Based on these expressions, this paper analyzes the convergence rates of the continuous-time models under certain conditions, and shows strong connections in convergence rate between the continuous-time model and its discrete-time counterpart (SGD or SVRG).   Strengths: > The paper successfully builds continuous-time models that take into consideration both a) decaying step-size and b) growing batch-size of the corresponding discrete-time algorithms. And it shows the existence and uniqueness of the continuous-time models.  > The paper provides convergence rates of the continuous-time models, under certain conditions. Convergence rates for the corresponding discrete-time counterparts are also developed.  Weaknesses: >The concept of building continuous-time models (or ODEs) for stochastic optimization algorithms is not novel. Simpler continuous-time models for SGD can be found in the reference [47] [48] of the paper, where the stochasticity of gradient is also represented by Brownian motion. The continuous-time models built in this paper can be seen as extensions of the model in [47].  >Building the continuous-time models in this paper is not technically hard. Compared to the models in [47][48], the models in this paper additionally incorporate time-dependent factors that originate from decaying step-size and growing batch-size, which can be done by simply adding two time-dependent functions.  