The combinatorial (meta- or super-class) idea is interesting: it is reasonable and one easily expects to work well.  In terms of related work, I suggest add 2 related papers. One is ECOC (Solving Multiclass Learning Problems via Error-Correcting Output Codes, JAIR 1995), which is a classic combinatorial method for classification. The other one is PENCIL (Probabilistic End-to-end Noise Correction for Learning with Noisy Labels, CVPR 2019), which is a novel noise handling method.  With regard to the method, the proposed probabilistic way to decipher class from meta-class is simple. Does it have any guarantee (especially with under different hyper-parameters like k' and M)? It is possible that the mathematical underpinning of ECOC could be useful.  For clustering, the current description is pretty terse. For example, I suggest the author(s) may make use of a supplementary material to provide more details (this submission did not have a supplementary material, though).  Finally, why the experiments on WebVision are a small scale / downsampled one? In fact, this is the most important experiment (because it is real-world data). I expect to see how the CombCls method works in reality.  And, I suggest ablation studies in terms of hyper parameters, especially K' and M.  --  The author response addressed most of my questions. The large scale one is missing -- it is reasonable because there may not be enough time to run a large scale webvision experiment during the short rebuttal period. However, I suggest that the author(s) test this method in real-world large scale problems.