In this manuscript, the authors design a brain-inspired convolutional recurrent neural network- CORnet-S that maps the visual ventral pathway to different layers in the network. The CORnet-S model achieves competitive accuracy on ImageNet; more importantly, it achieves state-of-the-art performance on the Brain-Score, a comprehensive benchmark to assess the performance of a model for neural predictivity, behavioral predictivity, object solution times (OST), and feedforward simplicity. The manuscript is clearly written, and is of interest to a broad audience in the conference. However, I do have several concerns for the manuscript:  * The biggest concern is the justification of contribution. First, Brain-Score is proposed in 2018 [1]. Although [1] is a preprint version, but it has been widely cited, so I would argue the contribution of Brain-Score for this manuscript. For me, a novel contribution is the proposal of the OST metric that expands the Bran-Score benchmark from single frame to sequence level. Second, as can be seen in Table 1 in the supplemental material, the claimed state-of-the-art performance largely depends on the OST score, which is unfair to all other models without recurrent connections (as their scores are by default 0). If OST score is not taken into consideration, the performance of CORnet-S is not state-of-the-art anymore, although still competitive. In this case, in order to better justify the contribution, evidence from other perspectives are needed, such as the number of parameters, inference speed, GPU memory usage, etc. Another way the author may consider is to add recurrent connection to other feedforward models with similar depth/number of parameters. If CORnet-S is more efficient than deeper models or performs better than recurrent shallow models, then the contribution can still be justified. At the current stage, however, more experiments/metrics are needed.  * Since OST is a novel contribution of the manuscript, section 4.6 and Figure 6 should be elaborated more clear. For example, why do we need a 80%-10%-10% setting for the CORnet-S setting? How does the 10ms window map to the dots in Figure 6 and how are they measured in the network?  Minor concerns: * Figure 2: What does the red dot mean? * Figure 3: cannot see the superiority of the CORnet-S model. Since the performances are really close, this Figure may not be included.     [1] Schrimpf, M., Kubilius, J., Hong, H., Majaj, N. J., Rajalingham, R., Issa, E. B., ... & Yamins, D. L. (2018). Brain-Score: which artificial neural network for object recognition is most brain-like?. BioRxiv, 407007.  ===========Post-rebuttal============ My concern of the preprint has been addressed by clarification of policy by the AC, so is no longer an issue. As a result the Brain-Score benchmark has become a major contribution. The authors also addressed my concern regarding comparison against other shallow recurrent models (in perfomance, although I am still interested in memory usage/model size, etc). As a result my score is updated from 5 to 8.