This paper introduces 2 methods to make predictions of asynchronous multi-class events. The methods pay special attention to giving confidence values to their predictions. The models model the changing distribution of outcomes given a time in the future, assuming that no other event has happened in the meantime.  The first method (WGP-LN) uses an RNN to output a set of M control (pseudo) points to mode a Gaussian process. At first they describe learning a Gaussian process for each output class, but they discover that  this leads to overconfidence at the control points.  They then proceed to train the RNN to also output weights for the Gaussian process. Since there are a small number of control points (<10) the Gaussian process is fast to compute, and is also differentiable, thus enabling fast training with sgd.  The second method uses the Dirichlet distribution, which is similar in practice, the RNN still outputs a set of Gaussian basis functions and weights. The calculation of loss for this method involves proposed closed-form expressions, which are then approximated with a second order series expansion.  They also define a loss function (the Uncertainty cross-entropy loss) which is more suited to learn uncertainty on the categorical distribution.  Also introduced it a point-process framework which can be used to predict the most likely time the next event is expected.  The related work section seems a bit thin, but I am not an area expert.  They provide many experimental results which show their method consistently out performing other methods. They generate toy examples, and show an ability to predict the evolution of next events, along with the confidence for those predictions. The appendix appears to cover the details of the methods and results.  The supplementary materials also contains an excellent looking iPython notebook containing Tensorflow implementations of the methods and toy examples.  I think the problem described (asynchronous, multi-class event prediction WITH attention being paid to the confidence of the prediction) is of great importance to the community, and these methods appear to be solid contributions. The code may be useful to many.  Provided other reviewers pass the math, I think this is a good paper. 