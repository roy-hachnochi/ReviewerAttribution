Summary: The authors defend in this paper that motion is an effective way to bridge the gap between real and synthetic data. To that end, they use optical flow together with 2D keypoints as input for a network that estimates 3D pose from outdoor images. The system itself is relatively straightforward: they extend HMR with an LSTM and make it process batches of 31 frames containing 2D keypoints and flow. The data is taken from an existing dataset (SURREAL), but is extended to include realistic background motion and occlusions. The system is evaluated on the 3DPW dataset, where they outperform other systems trained without real RGB data, and perform similarly to the state of the art using real RGB. The authors also provide extensive ablation experiments and some qualitative results.  Positive: The paper is well written, reproducible, and the system it describes is simple. It contains a very complete and up to date description of the related work. Although the idea of using motion to bridge the gap between synthetic and real data is not new, implementing it in a deep net is, and achieving results that are pretty comparable with state of the art from outdoor images is new as well. Apart from comparing with a number of relevant systems, the experiments provide an ablative evaluation that informs the reader about which parts of the algorithm are most important.  Negative: As previously mentioned, the idea is not extremely novel. But its application to a working and well performing deep network system is good, so this is a minor negative factor. Apart from there are just minor things: - Which flow method is used? Flownet is mentioned in the paper (line 62) but TVL1 in supp. matt. (line 20) - In the paragraph 78-85 lines, seems like 59 and 69 references are swapped 