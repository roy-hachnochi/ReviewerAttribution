Originality:  This paper is a novel combination of an existing method [7,21] for 2D images, to an existing task (point cloud feature learning).  Given the success of [21], one would expect it also works for 3D representation where the spatial layout is equally or more important, which is confirmed by the results in this paper. The citations in this paper sufficiently cover related work.   Quality:  Most of the experimental results appear to be meaningful and support claimed advantages of this method: architecture-agnostic, avoids reconstruction metric, helps supervised down-stream tasks.   But the comparison to alternative methods in Table 1 is weakened by the fact that model architectures used by the baseline methods are not mentioned. Given the significant gap between PointNet + Pre-training vs DGCNN + Pre-Training, I wonder how much of the improvement simply comes from a better architecture (DGCNN).  For example, FoldingNet which uses a PointNet-like architecture is actually better than this method + PointNet as shown in Table 1.   There's also a minor problem: page 4 L 152 "no limitation is needed on the receptive field size" is not supported by any analysis/results, it would be helpful to mention the receptive field size of the two base architectures studied in this paper.   Clarity:  The paper is well organized and has provided enough details for reproducing this results.   Significance:  This paper is addressing a important problem that has potentially big  impact. However I'm not confident if it is advancing the state-of-the-art due to a concern stated above.  Update after rebuttal:   Thanks for providing the numbers I requested in the original review. Changed my overall scores accordingly. 