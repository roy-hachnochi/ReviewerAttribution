The method, using GANs to map low confidence examples to high confidence examples of the same class is highly original and shows promise as an effective method. The authors also provide a good description of how their work differs from Defense-GAN, and also notes some of the prior work on classifiers with a reject option (although they should also cite some of the more recent work doing so with DNNs e.g. [1]).  The paper is clearly written, however there seems to be some information gaps with regards to network architecture and the mechanism for conditioning on the low confidence image x. Additionally there are several methods existing in the literature for conditioning the discriminator on label information: [1], [2], and concatenation and it's not clear from the paper which is used.  The main drawback of this paper is that the datasets used (MNIST and FashionMNIST) are too toy to allow the reader to draw informed conclusions. The performance of the baseline classifier (from which the rejected images are derived) is extremely poor. There are simple convolutional network architectures that achieve >99.5% accuracy on MNIST compared to the 98% baseline and >95% on FashionMNIST compared to the 87.4% of the baseline used. This makes it difficult to evaluate how much of the improvements shown would be dwarfed by employing a better architecture.  It's also not clear here what how the use of a Bayesian Neural Network interacts with the rejection function. How much different are the rejections if only a single model's confidence score is used for the rejection criteria rather than the median, what about the mean?  Update: The authors have made effort to address my main concern of using a stronger baseline classifier, and training on harder datasets such as CIFAR10. They have also clarified some of the GAN architectural details. I still think that the incremental benefit of using an ensemble for computing rejection thresholds is at best dubious and doesn't obviously incorporate any kind of Bayesian model uncertainty and would like to see this clarified or investigated in the text. However due to the improvements, I will raise my score to a 6.  [1] Geifman, Yonatan, and Ran El-Yaniv. "Selective classification for deep neural networks." Advances in neural information processing systems. 2017. [2] Odena, Augustus, Christopher Olah, and Jonathon Shlens. "Conditional image synthesis with auxiliary classifier gans." Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017. [3] Miyato, Takeru, and Masanori Koyama. "cGANs with projection discriminator." arXiv preprint arXiv:1802.05637 (2018).