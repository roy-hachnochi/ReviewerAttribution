The author(s) developed and elegant architecture to employ GANs to improve the accuracy of the classifiers. They authors have also proposed a baseline implementation for the proposed GWIN architecture. This work can potentially have significant impact in areas in which the uncertain classification and mis-classification  Classification of uncertain observations with increased certainty is a potentially important and useful problem. However, it is also at the risk of increasing the false positive rate. The authors fail to discuss such vital consequences and their experiments focus only on accuracy.  For observations that cannot be classified with high certainty, it is somewhat unreasonable to translate them just for better recognizability under the specified classifier. In order to demonstrate the effectiveness of the proposed procedure, the experiments compare the prediction accuracy on rejected samples, since the pre-trained classifier is not expected to have high accuracy on samples where it does not have the confidence to judge. Also, when comparing with the baseline BNN, the BNN+GWIN has much more coefficients and has additional confident data set training steps. It is unclear whether the higher accuracy is a result of a more complicated model and larger training epochs. Last but not least, for image classification, uncertainty is often induced by noise in observations. So how would the proposed procedure compare with state-of-the-art denoising methods for overall prediction accuracy? On the other hand, if denoising can largely reduce the number of uncertain observations, then the contribution of this work is incremental at most.