The authors present two losses for improving emergent communication, addressing concerns laid out in previous work (Lowe 2019).  One is the concern that the speaker agent may be communicating generic messages and not ones relevant to the particular sitation.  A loss here encourages the agent to send messages that are correlated with their observation, based on maximizing mutual information between them.  A second concern is that the listener agent may not be conditioning their behavior on the communication, and in this case an extra loss   Both constraints are intuitive, and phrasing them as losses doesn't seem to be particularly challenging.  However, as with many issues in emergent communication, such a judgement may gloss over hidden difficulties in a complex optimization problem, and this appears to be the case here, requiring some non-obvious sidestepping to provide losses with better convergence.  We're not supplied detailed analysis of what failed, but at face value, having the losses formulated in a way that has shown to be useful for optimization is a useful contribution to all researchers working in this area (regardless of the conceptual simplicity of the idea).  There are some concerns about the long-term usefulness of these biases, especially of the positive listening loss.  While this bias may make sense in simple optimization problems, in reality, a change in agent strategy is not necessarily indicative of listening, nor is the lack of such change an indication of a poor listener.  I was a bit surprised not to see any discussion about how realistic these loss-motivating assumptions are in the bigger picture.  But this is a minor concern, as we are still very much in the realm of toy examples.  As for the evaluation, overall strong improvements shown for either of the losses over the baseline, and for both losses used together.  I thought overall the experiments were well chosen -- one where the RL environment was reduced to a trivial degree, and one which closer reflects the types of domains used in related work.  Both seem well-controlled.  The baselines seemed a bit too outmatched here and raises the question of whether or not there are some optimization tricks that could have been utilized, rather than setting up difficult problems where the baseline is inclined to fail.  But assuming "worst case", being presented with such a problem where no curriculum learning or reward shaping options are available, the provided methods show improvements both in the percent of good strategies reached, and the rewards collected from such policies.  The paper is also very clearly written, and so while the technical difficulty of the methods presented here is not high, nor are they particularly novel, the paper represents a concise contribution of effective optimization strategies, broadly applicable to the emergent communication literature, and is certainly ready for acceptance at some venue.  Perhaps its greatest shortcoming is simply whether it meets the NeurIPS bar in terms of its novelty/technicality.   Some in-line comments:  L 127: (2) is formulated with trajectories but it wasn't clear if this more general interpretation was useful.  Does this have a noticable effect over a single state?  In general, states and trajectories feel a bit mixed together throughout S3/3.1. L 139/143.2: The loss notation here changes from L_S to L_ps L 143/Alg 1: Inconsistent period usage L 143/Alg 1: Lines 3-12 should be clearly marked as documentary/comments L 143.15: what is the purpose of having the hidden state passed to p_t^i?  In Alg 2 this makes sense as it is required for conditioning on future roll-outs, but in the positive signalling loss too? Fig 2: these are compelling plots but presumably the data samples are chosen at random and from the full label size.  The losses are useful compared to baselines without, but have you considered approaching the problem from the data side?  I would be interested to know if simplifying the problem (in terms of label size), and gradually increasing it / setting a curriculm, would have a positive effect on the baselines.  It appears the baselines are just setup too poorly here, with little effort given to "make them work". L 222: is Tab 1 referenced? L 242: typically not a context for a semi-colon 