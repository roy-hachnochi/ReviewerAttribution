The method is almost trivially simple, scalable and easy to implement, yet the empirical evaluation shows that it performs competitively and often better than all alternatives. This is the best kind of paper!  The task of representing uncertainty over model weights is highly significant -- it is debatably *the* core problem in Bayesian deep learning, with (as the authors point out) applications to calibrated decision making, out-of-sample detection, adversarial robustness, transfer learning, and more.  I expect this baseline to be widely used by researchers in the field, and likely implemented by practitioners as well.  The paper is well written and easy to follow. The method is clearly motivated and cleanly presented. The experimental results are extensive and compelling, and include comparisons to the major alternative approaches from recent literature. I appreciate that the experiments include some 'real' tasks (e.g., Imagenet models) as opposed to the toy problems often used in Bayesian deep learning papers.   One omission I found fairly glaring was the lack of any discussion of the seemingly even simpler baseline of iterate ensembles. If you've got a bunch of SGD iterates lying around, why bother fitting a Gaussian and ensembling its samples, when you could have just ensembled the iterates directly? I'd expect that imposing the Gaussian distributional assumption increases bias and reduces variance, and I could be convinced that in practical situations the bias-variance tradeoff is always in favor of fitting the Gaussian, but I want to see that comparison! Since the main innovation of the paper is to fit a Gaussian to SGD iterates, the question of whether doing so *actually helps* seems quite foundational. Why not include iterate ensembling as a baseline in Figs 2 and 3?  Update: thanks to the authors for your response and the new results, which are encouraging. I'm still not sure I have good intuition for when (and why) SWAG will outperform iterate ensembles -- I would appreciate some discussion on this point in the paper -- but it's good to see evidence that it often does.  I also appreciated Reviewer 3's points re convergence to an isotropic Gaussian -- having not read Mandt et al. closely, I didn't realize that under non-crazy assumptions (i.e., that the data are generated from the model) the scale of the SGD iterate distribution is independent of the shape of the true posterior. Just reading this submission (e.g. section 3), it's easy to believe otherwise; readers would be better served if the paper clarified the gap between the theory and the empirical results. R3 also makes a very strong point that the paper should discuss how the SWAG learning rates are chosen, since Mandt et al. (in the settings of both eqn (13) and section 6.2) indicates that the learning rate is crucial to the scale of posterior uncertainty.  Overall I still favor accepting the paper. Whether or not we consider SWAG a principled Bayesian approximation, it's significant that a simple method performs well at the tasks used to benchmark Bayesian deep learning algorithms, and asking new methods to do better is a reasonable challenge. To the extent that SWAG is a broken approximation, it should be possible to beat it, but in the meantime simple baselines are important. I think this paper will help move the field forward. That said, if it's accepted I encourage the authors to consider softening the Bayesian framing; positioning SWAG as 'merely' a useful approach to quantifying uncertainty seems like a much stronger case.