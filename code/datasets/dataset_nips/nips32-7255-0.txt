After rebuttal: The authors addressed my concerns by explaining their choice not to include a discussion of them modified algorithm was motivated by the aim to keep the paper focused and concise. My recommendation remains accept, 9.  The authors consider a version of the convex MF/dictionary learning problem appropriate for datasets with a cluster structure: they constrain the basis elements to be convex combinations of exemplar data points, where they explicitly attempt to enforce sparse combinations by using l1 penalties on the coefficients, and design the algorithm to select the exemplar data points appropriately from the clusters so that the basis elements lie within the convex hull of the individual clusters.   The problem addressed by the paper is well-motivated, and the intuitions justifying the design of the algorithm are well-explained. The novelty lies in the way the authors use the clustering structure assumed to be present in the dataset to show that their algorithm converges to a stationary point of the convex MF objective. I did not read the proofs in the supplement, but it seems that the techniques used will be of interest to those designing similar non-convex stochastic online algorithms. 