This paper provides an in-depth discussion on the Self-supervised (SS) learning mechanism in GAN training. The theoretical analysis reveals that the existing SS design indulges mode-collapsed generators. This work presents an improved SS task for GAN, which is shown to achieve better convergence property in both theoretical and empirical analysis.   The paper is well-written. It is easy to follow as the logic presents both the motivation and the solution in a clear way.  The analysis regarding the interaction between the SS task and the learning of generator provides insights for other design of GAN training methods.  Empirical results are shown both in the main content and the appendix.   Below are some confusions that the author is better to clarify in the rebuttal.   1. Figure.3 is hard to understand based on the content in Page 5, Line 151-157.  The author may better explain what Figure.3 (a) and (b) shows here, clearly.   2. The paper directly adopts many reported results of the baselines in other papers, e.g. Table 1.  Are these methods compared under the same setting?  Moreover, many results are missing here without explaining why.  I encourage the author to clarify this.   3. As the improved version focuses on tackling the mode-collapse problem here. It is better to presents comparison on some criteria, e.g. the number of modes covered, in the main body of the paper. 