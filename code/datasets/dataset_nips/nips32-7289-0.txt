This work shows how a number of different Markov operators can amplify of the privacy of a DP mechanism when used in post-processing.  First, results about amplification under several different uniform mixing conditions (of varying strengths) are provided.  Next, results about Renyi DP (from which can be obtained results about (eps,delta)-DP) that take into account couplings between measures on the data space are provided; the most basic result yields a decomposition that makes data-processing inequality evident.  This result is leveraged iteratively (inductively) to show that projected SGD + noise on a strongly-convex objective function, run for O(log(d)) more iterations, has the same optimization error as non-private SGD while ensuring privacy for all records.  Finally, post-processing mechanisms based on diffusions are examined; a Renyi-DP guarantee for operators having a symmetric kernel w.r.t. their invariant measure is provided.  Examples are provided throughout, including for Brownian motion vs. Ornstein-Uhlenbeck mechanisms, with superior DP guarantees of the latter established.  The paper is well written, and the numerous examples are both helpful for general understanding and illustrate the relevance of the results.  Theorem 4 (on DP of noisy SGD) is a nice result with a clean proof, but “noisy SGD” is not the optimal algorithm to consider (as SGD already has noise from the gradients); the use of this algorithm is a limitation of the analysis, and it would be nice for it to be eventually removed.  Also, for this result, it may be useful to state instead that it holds for maps \psi_i’s that are contractions, rather than for general Lipschitz \psi_i’s; the bound is vacuous otherwise.  [UPDATE]  Upon closer review of the literature, it appears that the paper greatly leverages the techniques and results of Feldman et al. (2018).  E.g., the purported exponential improvement over their bound in Thm 5 (Thm 23, resp.) in specifically the strongly convex case uses a standard result from convex optimization, which could as well have been used in their (somewhat more streamlined) analysis had they chosen to separately handle the strongly convex case.  The paper does a great job of synthesizing and presenting DP ideas for readers who may be more familiar with diffusion processes than DP, but it is written in a way that suggests that the techniques (rather than mostly the perspective) are new; this is disappointing.  Novel DP applications would go some way towards making up for that.