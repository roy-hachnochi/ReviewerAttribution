Update: I read the authors' response as well as the other reviews and found this quite helpful to clarify some points of confusion (such as the task distribution). I would suggest to further clarify this in an updated version. While I was originally unconvinced whether there was sufficient algorithmic novelty on the Meta-Learning side I got convinced that this paper successfully demonstrates how both techniques can be successfully combined which is a valuable message to the community. I'm therefore happy to update my score from 5 to 6.   ---   - Figure 1: Given that this graphic appears on the first page, I believe that notation should be avoided, especially since none of the values is introduced until section 3.  - Section 3: I'm not sure I fully understand the definition of the meta loss in equation (5). In particular, the summations over time steps seems to indicate that we must store H values $v^w_{t-\tau}$ for each time step during training. Is this correct? - It's not clear to me what the exact training set-up is. The authors mention "meta-training" (e.g. Line 108) without a clear definition of the term. Is the model trained on distribution of tasks? What are those distributions for each experiment? - Line 134: Why are biases missing?  - Line 137: Notation appears incorrect. The function is not taking a set as an argument but is evaluated for each element in the set. - I was somewhat confused throughout the paper why the authors referred to a function approximator as a memory module. I think most people will think of a memory module as a raw storage of information.