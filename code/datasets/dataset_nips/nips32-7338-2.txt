I would like to thank the authors for their response to the reviewer comments. It seems that the general opinion about this paper is positive, so I am looking forward to its camera-ready version.  ---- PREVIOUS COMMENTS ---- The paper proposes a method for graph enhancement based on graph diffusions. First, a diffusion operator is applied on the original graph, which transforms the edge densities. This is followed by an edge sparsification step, where edges with low edge weights are removed. Some links have been pointed out between graph diffusion and filtering and the effect of graph diffusion on the graph eigenvalues has been studied. The proposed graph transformation approach is then shown to provide improvements in performance compared to the original graphs when coupled with various semi-supervised and unsupervised graph-based learning algorithms.  The methodological contribution seems to be humble, however, the paper is well-written and clear and the experimental evaluation is extensive.    Only a minor comment: In the analysis of the effect of sparsification on the eigenvalues, the authors comment that they cannot analyze the change in the eigenvalues analytically. I guess  graph sparsification could be formulated as a perturbation on the matrix S. If edges with weights smaller than epsilon are removed, one can bound the magnitude of the perturbation. Then using standard results from matrix perturbation theory (e.g. Weylâ€™s inequality) it should be possible to bound the change in the eigenvalues.