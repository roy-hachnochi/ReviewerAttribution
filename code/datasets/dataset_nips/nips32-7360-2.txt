The paper is not motivated well. I agree that protecting privacy is important and that differential privacy is a strong and interesting guarantee, but the paper doesn't do a good job in convincing me that private graph sparsification is a relevant topic. How does this paper relate to actual machine learning applications?  The authors claim that their approach provides practical algorithms for computing certain properties with better accuracies than previously possible. That's good, but I don't see any actual application and no evaluation of their approach (except for the abstract list in Table 1). While I appreciate the formal approach the authors took in building up their 41 (!) definitions, theorems and lemmas (to be fair, most of those are repetitions of existing formalism), I don't think that NeurIPS is the right venue for the paper.  I found the description of their main algorithm (Algorithm 1) very cryptic and hard to follow too: I'm getting confused by the 6 or 7 different G's. We get G as an input, then we construct \hat G by mixing G with the so far undefined K_n (from the text, I think it's a fully connected graph). We create some L and that we only use to compute \tilde \tau_i's that we use to form a diagonal matrix (with some probabilities? Why?) D. We then construct another complete graph H with Gaussian edge weights, combine it with \hat G from earlier to get G'; then we need to solve this SDP-1 formula to get \bar G (explained somewhat in the text in the paragraph about G_int, whatever that is); somewhere in there we have a \tilde G' as well. Finally, we run some algorithm from [47] to get \tilde G.  It's very much unclear to me how efficient all of these steps are, particularly solving SDP-1 over all potential graphs \bar G could be very inefficient.  Update: I have read the author's response and it sadly did not help me me in understanding the paper and the relevance of its contributions. I apologize to the authors if my critically worded review or my lack of familiarity with their specific area of work has offended them -- merely citing the same lines I tried to decipher, however, does not make for a helpful response, even if done so angrily.