Originality: the paper contains no original technical work. The original work on MNIST is correctly cited, as is work to related papers by Recht.  Quality: Excellent.  I commend the authors in their very careful detective work in reconstructing MNIST. This kind of careful data provenance on a very common dataset should be rewarded.   Clarity: Very good. I understood how the authors did their example matching, and the comparison experiments are clear.  Significance: The results are moderately important. If you had asked me in 2010 whether we would live in a world where ImageNet has <3% top-5 error, while people still used MNIST as a benchmark, I would have laughed at you. However, that is the world we're in. Given the prevalence of the benchmark, it's important to know how much overfitting there is by the community.  