Update after author rebuttal: I greatly appreciate the authors responding point-by-point to my concerns. I have updated my score to a 7. If the paper is ultimately accepted, in addition to the clarifications the authors made in the rebuttal, I stress that the paper would be improved by clarifying the following  1) The point about direction switching. I am not from a neuroscience/biology background (I believe most of the NeurIPS community is not either) and so the justification here is a little counterintuitive here. The authors might want to consider contrasting this work with existing ways one might (inadequately) represent such behavior (e.g. latent confounders when Gaussianity/linearity is not assumed) -- this could be an elaboration of the comments in the rebuttal. 2) From the rebuttal: "In our simulations under non-zero variance settings, we never observed that the procedure converged to wrong solutions, suggesting that the non-zero-variance case is also identifiable" -- just because a sim didn't obtain non-identifiability, doesn't mean the model is identified. I think the authors' intuition is likely to be correct, however they should consider softening the language around this point.  -------------------------------------------------------------------------- This paper is well-written. There are some points the authors should clarify in review and in a future draft to enhance the manuscript. Details of my personal confusions below:  0) What is the relation between the present work and the causal relational modeling literature (e.g. Arbour, Marazopoulou, and Jensen 16, Marazopoulou, Maier, and Jensen 15, and other works from David Jensen and associates)? Is "relational" used in the same sense here?  1) In general, how is this approach different from learning a DAG-based model where there is a cluster indicator variable that indexes the rest of the graph? In my mind this would help with statistical concerns (i.e. you can "lump" all subjects together) to learn one graph rather than several graphs (one per group).  2) In the abstract: "...due to possibly omitted factors that affect the quantitative causal effects." To be clear this refers _only_ to missing edges and not unobserved variables (e.g. latent confounders) instead/as well?  3) "in healthcare, individuals may show different responses to the same treatment". In line with #1 above, this seems more like a distributional notion rather than needing a model that learns separate graphs for separate groups, no? Existing causal effect estimation (more or less developed than discovery is up for debate) tends to be more suited for handling a single non-parametric graph for the purpose of identification and then placing assumptions after identification has been obtained. Would it be valuable for discovery methods to try to follow this approach (at least in the vein of learning a single unified graph that represents the distribution of subjects)?  4) "In addition, they do not allow opposite causal directions..." Following #1 and #3 this seems like a weird thing to allow for in the proposed model. Can the authors please clarify why they permit edge direction to switch among subjects? I'm not familiar with areas in the causal literature that have considered this case and as is, the justification seems light.  5) Sec 2 paragraph 1 (and Conclusion) -- I agree that adding a treatment of partial observations ("hidden confounders" etc) seems challenging. Can the authors please give a high level discussion of the steps they might take towards allowing that behavior in their model?  6) Eq. 1: what's p_l in the middle summation? It doesn't seem to be defined  7) "However, the limited sample size from each individual limits statistical efficiency or even makes discovery impossible" -- is there a formal characterization/proof of this? I understand that statistical identification is challenging. E.g  as n -> 0 you have a tougher and tougher time but is there a formal characterization of "impossibility" in this setting?  8) Below Thm 1: "we allow that across different groups, some causal directions are reversed" -- along with earlier comments, how does this provide more information about the ground truth graph than, say, learning an equivalence class that leave direction unspecified when it's unclear?  9) "(1) the cycles are disjoint" -- what does "disjoint" mean here? Why is this requirement necessary?  10) "our empirical results strongly suggest that the causal model is also identifiable" -- To me, this isn't sufficient for the same reason that association isn't sufficient for effect estimation contexts. Can the authors give justification that their experiments (non-sims) use data that satisfies the theoretical requirements implied by Thm 1?  11) "Imagine an extreme case: if there are enough samples ..." Why is is the case that this is identifiable? Can the authors please formalize this?  12) l_s > 2q - 1 -- What's the intuition behind this bound? How is it used in the proof of theorem 1? E.g. "We first show..." -- it seems the authors cite Vandermeulen and Scott 2015 rather than proving this is a sufficient bound in their setting.  13) The proof of theorem 1 seems incomplete. There doesn't appear to be a complete, formal proof in the appendix. It's not obvious from the cited papers that the same conclusions (from those citations) will hold in this setting. Can the authors please give a formal proof?  14) In Sec. 4.1, what is being adapted from SAEM and what is a new contribution? It seems the general EM is from SAEM and the Gibbs sampling procedure is novel?  15) "The computational complexity (...) is O(m^2 n M T0). This is very slow, especially since it is on a per-iteration level. Can the authors give a characterization of types of data where it would be feasible to run this procedure? Obviously the experiments in the penultimate section provide an example but it's not clear what scale of data they used there (e.g. was a very small subset of the total available fMRI data used and would a neuroscientist need to be able to use this procedure on a data set many orders of magnitude larger?) Additionally, how can one be sure that the Gibbs procedure has converged?  16) "It is east to add prior knowledge of causal connections" -- how is this achieved? An imposed independence or dependence constraint in Eq. 1?  17) For Gibbs and other procedures that require parameter initializations, is there some characterization available of how reliant these procedures' performance is on those initializations?  18) "We randomly generated acyclic causal structures according to the Erdos-Renyi model" -- ER gives undirected graphs. How did the authors choose directions of edges and ensure acyclicity in this sim?  19) "Other parameters were set as follows. sigma^2_{k, i, j} = U(.01, .1)" In theorem 1 the authors state that the distributions should be no variance -- why does this sim use distributions with non-zero variance? The authors should consider adding a sim that exactly matches the conditions that are understood according to theory.  20) fMRI and Cellular Signaling Networks data: is this non-gaussian data? How do we know that it is (non-Gaussian)?  21) fMRI "We assume that the causal relations are fixed on the same day, but may change across different days" -- Can the authors provide some insight from neuroscience that backs up this assumption? To me, it seems a little odd that the brain would be re-wired and electric flows would switch from one day to the next. Is there a well understood mechanism that explains this behavior?  22) Cellular: "With different interventions in different conditions, the causal relations over the 11 variables may change across them" -- Unless these are different cells in the different conditions, it would seem more reasonable to model this as having unobserved confounding rather than having causal direction switch according to interventions. Can the authors provide justification for this construction?