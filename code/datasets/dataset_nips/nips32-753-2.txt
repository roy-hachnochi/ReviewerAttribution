 This paper tries to leverage the generative behavior of classifiers to perform a range of image processing tasks, including image generation, inpainting, translation, super-resolution.  I like this paper and I think it's a super fun read.  That being said, I have some reservations about publishing it.  Here's my major criticisms: 1)  The whole thesis of this paper seems to be that *robustness* is the key to unlocking the generative behavior needed to perform these tasks.  However, no comparisons are made with non-robust models, and I find this odd. My experience is that even non-robust models can exhibit generative behavior, and I'm curious what would happen if non-robust models were used.  This is especially interesting for problems like ImageNet where even the best adversarially trained models aren't very robust.  Can you really observe a difference between robust and non-robust in this case?   For perspective, this well-known distill article does visualization on NON-robust networks, and gets (in many ways) even better results than those presented in the paper under review: https://distill.pub/2017/feature-visualization/ The paper also cites a long list of articles that optimize images to maximize the activation of an output neuron (just like the paper under review) with often spectacular results.  Not only do these papers have huge conceptual overlap with the paper under review, but they do it all without adversarial training. 2)  This paper has a large amount of conceptual overlap with the Tsipras paper.  The most impressive results in the paper under review are for image generation, but these experiments are nearly identical to what was done in the Tsipras paper (although with a wider range of datasets).  The strong overlap with (https://distill.pub/2017/feature-visualization/) and the many citations therein is also concerning. 3) Other similar variational methods that also solve inpainting and super-resolution problems are not discussed or compared to.  What about the "deep image prior"? Plug-and-play methods? Or "regularization by denoising"? 4)  There are no real surprises in this paper.  By and large, the results presented are pretty much what I'd expect: these simple optimization methods can perform basic imaging tasks, but can't compete with (or even come close to) the state of the art because of the artifacts that arise from adversarial behavior.    I also have one more minor criticism:  the performance of these methods is not good.  Normally I'd be ok with this, since I like to see exploratory ideas rather than just engineering to achieve high benchmarks (which is why I list this as a minor rather than a major criticism). However, in this case, it feels like the authors are making a lot of unjustified claims that their methods work great.  If I just read the text of the paper without looking at figures, I'd have the impression that these methods compete with state of the art performance.  Claims that the produced images are "realistic" are a bit bombastic.  Furthermore, bragging about how the method achieves higher inception scores than BigGAN is strange when it can't even scratch the surface of what BigGAN does.  I take the results here to be a confirmation that inception score is a meaningless metric, rather than a confirmation that robust models produce good results.  I find it odd that the paper never seems to acknowledge the gap between this approach and other generative methods, or other variational methods.  Finally, the following is a curiosity rather than a criticism:  I can see a lot of pixelation in the super-resolution results.  This clearly arises because of the nearest-neighbor interpolation that is used as a base image.  What happens if you just treat this like an inpainting or deblurring problem, which is the approach more commonly taken in the super-resolution literature?  Overall this is a fun paper, and the sketch-to-image stuff is clever.  I'm not sure I'd prioritize this paper over other good papers for the reasons describes above.  Despite the fun, there's not a lot of novelty in it.  Image generation has been done before by lots of other authors, including methods that maximize class labels as is done here.  The main contribution here is doing it with robust nets rather than clean trained nets.  I'm not sure how significant this is though, especially since the generative behaviors the authors claim are unique to robust models have been observed many times before on non-robust models, and the authors present no comparisons to similar variational methods methods or non-robust nets.  Update:  I read the rebuttal and I'm sympathetic to some of the arguments.  I see how the authors think that their results are better than those in the links they provided.  However the authors used a specialized initialization (a Gaussian with a specially chosen covariance) rather than an iid random initialization, and may have a number of other differences in their setup.  I'm confident the specialized initialization the authors used made an impact on the quality of their results, otherwise they wouldn't have used it.  How would this initializer impact the quality of results from a non-robust network?  I don't know.     The above comments aren't means to doubt the superiority of a robust network approach, nor am I assuming that the initializer would bring a non-robust network result up to the quality of the robust network result.  My major concern with the paper is that I shouldn't have to speculate on these issues.  Most papers fall into the category of either a theory paper or an experiments paper.  For an experiments paper, I expect there to be ablation studies (where appropriate), and comparisons to the state of the art (where appropriate). How do your methods compare when I plug in a non-robust network?  Is there an ablation study to show in impact of the initialization?  What if you did inpainting using a standard loss function?  How does this compare to another variational inpainting method, like plug and play or RED?     The first question I ask above still seems somewhat glaring.  Given how prominent the claims in the paper are about the importance of using a robust classifier (it's mentioned in the title), this issue should be addressed.  Finally - I like the new title you suggested.  This is really a paper about image synthesis and not "computer vision."