Summary:  The paper presents a privacy system that works with trusted enclaves (e.g. SGX) to collect data and run (globally) differentially private algorithms.  Practical deployments of differential privacy usually are in the local model, where data is privatized prior to aggregation on the server.  The benefit of the local model is that users can ensure their data is privatized before submission, thus no trust is implied.  However, the local model of DP suffers from a significant utility loss, even for moderate privacy levels.  This paper provides a solution to use a combination of Trusted Execution Environments and global differential privacy to benefit from the better utility of the global model while not requiring implicit user trust in the system.  Critique:  This paper addresses a very important problem faced by privacy practitioners that want to obtain the accuracy of differential privacy in the global model while also not needing to store the users’ data in an unencrypted format or requiring users’ trust.  This work opens the door for lots of future work that combines security hardware and privacy software, which is a natural combination but not really explored before.  The future work will be both theoretical, developing new ODP algorithms, as well as application driven, showing results for particular use cases.    My main critique is that the paper quickly addresses other side channel attacks, beyond memory access patterns, to say that the framework can be extended.  However, how do the algorithms change if we were to include both timing attacks and memory access patterns?  Are there impossibility results with trying to protect against several side channel attacks while ensuring data-obliviousness?  Minor Comments: some missing “the”s in the paper. To me, the problem of heavy hitters is more interesting that histograms, so I would like to see more detail about the heavy hitters algorithm in the camera ready instead of the histogram use. 