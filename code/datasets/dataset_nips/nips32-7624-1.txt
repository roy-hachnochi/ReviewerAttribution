This paper proposes a formal langauge to describe the search space of architecture search problem. This langauge is a domain specific language embedded in python. Users can write modular, composable, and reusable search space by using this langauge.  Originality: The contribution is new. This is the first work that tries to provide a formal langauge for the space definition.   Quality: The semantics of the langauge is thoroughly described. However, this is an embedded langauge in python. It does not have its own text format. So the syntax of the language is unclear.  Because it has to follow the restriction of the host langauge (Python), the grammer of this langauge is also not very concise. This langauge combines the ideas of mordern deep learing frameworks and hyperparameter search frameworks. The idea of hierachycal 'substitution module' has already appears in some deep learning frameworks (e.g. the 'Block" structure in gluon API of mxnet)).  Clarity: The paper is well written with adequate background information.  Significance: This is a good tool to formulate the search spaces. I expect many people are willing to use it. It will be better if it can support multiple backends (e.g. tensorflow, pytorch, ...)  Questions: 1. Besides modularity, how does this language compared to existing ways to specify search space? Can it also reduce the number of lines of code? 2. I don't like the design of `A['out'].connect(B['in'])`. Deep learning frameworks do not need to explicitly assign these edges in the computational graph. They build the graph by using inputs as arguments and using outputs as return values. 3. How does it handle network transformation based architecture search (e.g. Efficient Architecture Search by Network Transformation, Path-Level Network Transformation for Efficient Architecture Search)? Their search space is basically defined by some network transformation operations.  Minors: 1. Add an explanation for Figure 4. Fig. 4 is not cited in the paper.