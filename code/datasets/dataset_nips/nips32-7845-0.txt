General comments and questions (mainly related to quality/clarity; for originality/significance; see elsewhere in the review) - Overall, I enjoyed reading the paper, but the paper is very technical and dense with many inline equations which makes the paper difficult to appreciate the first time around. I appreciate that these are needed to reproduce the paper. - The technical contributions appear sound and non-trivial. - The rationale and justification for the composite likelihood should be improved in the main text for the reader to appreciate line 86-96. Should $phi$ be included in Fig 2? Is $phi$ fixed once estimated or threated as a hyperparameter in the subsequent learning (and why)?  Is the composite likelihood still part of the MR-DGP model (and why)? - The experiments are relevant and appear well-executed. If time permits, I think a very basic baseline would be appreciated, e.g. a very basic GP. For comparison, I think it would also be of relevance to include results for the MR-GPRN without the composite likelihood for the real-world dataset, Tab. 2). - The paper argues (line 62-63) that it is looking for large scale and quality uncertainty quantification. Mentioning the dataset size and perhaps reporting predictive log-likelihood for the real-world experiment would be appreciated to provide better evidence that has been achieved. - The std deviation on the (MSE and MAPE) predictions appears rather large; I think it would be helpful to explain/comment on this...?.   Minor: - Check that $\theta$ defined in the main text. - Check that MAPE is clearly defined. 