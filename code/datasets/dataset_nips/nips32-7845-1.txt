-- Paper Summary --  This paper uses a practical real-world problem involving measuring air pollution across London in order to frame two important modelling aspects for multi-task Gaussian process models. The first contribution draws from the literature on GPRNs for combining latent functions in multi-output problems so as to cater for aggregated outputs while also including composite likelihoods. The second primary contribution of the paper goes a step further by tackling possible intra-task dependencies arising by way of outputs for the same auxiliary task observed with increasing fidelity or resolution. The experiments compare the proposed MR-GPRN model, and its deep counterpart (MR-DGP), against a baseline method and recently published work by Law et al. (2018) on developing scalable GPs for aggregate count data. The evaluation indicates that MR-DGP outperforms the aforementioned techniques, while also exposing weaknesses in these methods (Figure 2).   -- Originality and Significance --  Although the contributions of this work are predominantly framed within the real-world case study featured throughout the paper, there are indeed several interesting contributions being presented here, especially in relation to recent work by Law et al. (2018), Moreno-Munoz et al. (2018), and Cutajar et al. (2019). In many ways, the model presented here unifies several features of the aforementioned work, while also presenting a more general framework for modelling complex relationships between tasks which may also require more intricate intra-modelling. To this end, I think that the model being proposed in this paper should be of particular interest to practitioners relying on Gaussian processes for their work. I find the first segment of the paper to be particularly interesting. Perhaps the distinction to other work could be made clearer, however, especially in relation to the work of Law et al. (the section provided in the supplementary is great, but part of it should be included in the main paper in favour of other less essential material), and the variation of AutoGP by Krauth et al. (2017) which places a GPRN likelihood in a GP for multi-output problems.  On the contrary, I must admit to feeling somewhat ambivalent about the DGP aspect of the paper. Although I see how the multi-resolution requirement arises from the real-world problem being considered in this work, I feel as though it adds very little to the more interesting theoretical aspects of the paper featured in Section 3. The resulting graphical model is fairly similar to that presented in Cutajar et al. (2019), sans the mixture of experts approached championed for here. Perhaps because it is not the primary scope of the paper, there is currently little information on the choice of kernel for the intermediate-layer GPs combining low-resolution outputs and input points from the actual domain. This could perhaps be confusing to an audience who isn’t familiar with such multi-fidelity models. Either way, making the distinction between multi-fidelity and multi-resolution more explicit would further clarify the contributions of this paper.  On a related note, in its current format, the discussion on DGPs comes across as overly cumbersome. Given that the discussion on inducing points for MRDGP appears to be fairly standard, I believe this can be shortened or moved to the supplementary in order to reduce clutter in the main text. Tangentially, I don’t fully understand the emphasis on how the method ‘learn[s] a forward mapping between observation processes’ as opposed to ‘trusting and propagating the mean’[L191/192]. Perhaps explicitly re-emphasising how this relates to the individual bias associated with intermediate layers could be helpful here.   -- Technical Quality/Evaluation --  The formulation of the model is thoroughly explained throughout the paper, and it is clear from the extensive and rigorous supplementary material that the authors made an effort in ensuring that all results can be re-derived. The theoretical aspect of the paper appears to be correct, although I admit to having only briefly skimmed through the supplementary material. The implementation of the model as an extension to GPflow should also encourage greater reproducibility and extendibility due to widespread familiarity with the library.  The evaluation is interesting since it teases apart a very complex real-world problem, while also highlighting individual aspects of the model by way of synthetic experiments (featured in both the main paper and the supplement). Overall, this appears to be suitably comprehensive and gives credence to the practical appeal of the method, whereby the performance gains are quite substantial.  -- Writing/Clarity --  Overall, this is a well-written paper with a clearly motivated problem statement. I liked that the initial example describing pollution sensors in London is developed from the introduction through to the end, as this effectively showcases the contributions featured in the paper in a consistent manner. The graphical models and algorithm snippets are also clear and helpful, and are appropriately tied to the main text.   A few comments on the paper’s presentation:  - Some minor typos/preferences: L29L: I would change the last part of the sentence to ‘… contraction, as well as degradation of performance and uncertainty calibration.’; L44: Related work precedes the experiments;  L70: task $p$; L75: model directly -> directly model; L75: , but it; Eqn1: Wrong punctuation; Eqn2: Wrong punctuation; L109: I don’t think $R_a$ has been used elsewhere?; L128: ‘weigh higher’ -> ‘assign more weight’; Algorithm2: Italicise ‘l’ in method signature; L180: missing citation; L185/193/197/203: Strange punctuation;   - Some references are inconsistent for the same venue, e.g. [12] and [16]; - The use of \textsc{} and \textit{} is overly abundant, and makes the paper looks messy at times; - Having so many inline equations sometimes makes for difficult reading and cluttered presentation. Judging by the length of the supplementary material, I appreciate that the authors have already had to cut a fair amount of content from the paper. However, I believe there is still some fine-tuning to be done by shifting other well-known or easily-derived results to the supplementary.   -- Overall recommendation --  In spite of some minor issues and lack of finesse in its presentation, I consider this to be a solid paper overall. However, my primary concern is that the authors tried to fit in too much content instead of judiciously expanding upon and highlighting more significant contributions. One of my suggestions would be to reduce the space which is currently dedicated to explaining the deep aspect of the model, which doesn’t deviate too far from related work and consequently doesn’t add much nuance to the discussion. On the contrary, I personally think that the focus of the paper should be placed on the components targeting inter-dependencies between processes, with the capability to handle intra-dependencies treated as an additional nice-to-have feature.  P.S. A paper having similar goals appeared on arXiv shortly following the NeurIPS deadline: “Multi-task Learning for Aggregated Data using Gaussian Processes”, by Yousefi et al. In order to judge this submission fairly, I did not draw any comparisons to this paper in my review. Optionally, the authors may choose to briefly comment on the similarities/differences to this work.   ** Post-rebuttal Update **  Thank you for your rebuttal. My opinion of the paper remains fairly similar to that expressed in my original review. I think it can definitely benefit from further refinement in the exposition of the various model components, and the experiments can also be broadened beyond the recurring case study given in the paper. Including more synthetic examples such as Figure 1 in the supplementary material could be a step in the right direction.  Addressing the remarks made by Reviewer4 regarding the weights by including the extra experiments proposed in the rebuttal (L33) should also help alleviate these concerns, while also clarifying the composite likelihood aspect of the model. Overall, I think that the overall contributions of the paper are varied and interesting, although having more time to improve it further may work in its favour. My vote still tends towards acceptance, but I do not feel inclined to make a strong case for it.