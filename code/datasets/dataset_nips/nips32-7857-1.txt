As far as I am aware, the contribution of this paper is novel. The authors propose a novel method for dealing with constraints in RL by solving a minimax game.  The paper is very well written with great attention to detail, and I believe this could be of interest to the RL community given the increasing interest in safety.  There are a few details that were not completely clear, so I would appreciate the effort in trying to address my concerns: - line 79: what is Delta(pi)? I don't think this was properly introduced. - line 90: if z is a vector and C a set, how do you define a distance between them? Is is the distance between z and the projected point to C? If so, what is the impact on the type of projection being used (e.g., orthogonal, oblique)?  - Are lambda and zeta vectors? Is the reward represented as the dot product of these vectors? If so, the reward is a still a scalar, so how is this different from specifying the constraints as an added term in the reward function of standard RL? This is not completely clear to me.  - I would appreciate some more general comment on the formulation. How does this game-theoretic framework compare to other techniques like projected methods? For ex. PNAC [1].  Why should one choose a game-theoretic approach over projected methods?  Granted, I am not very familiar with the game-theory literature, but it is not clear to me what the benefit would be. Could you elaborate on that?  - Figure 1: why are results a function of trajectories? Is this the same as episodes?   [1] Thomas P., Dabney W., Giguere S., Mahadevan S. Projected Natural Actor Critic (NIPS 2013)     