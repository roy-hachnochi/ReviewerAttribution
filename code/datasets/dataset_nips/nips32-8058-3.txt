The authors study the problem of intervention design for learning tree causal structures. The proposed approach is adaptive, in which at each step a Bayesian prior over the underlying structures is updated and the next intervention target is chosen based on the updated prior. The authors first assume that infinite observational and interventional data are available, and then provide the following extensions: 1. Specific set of nodes cannot be intervened on 2. K interventions are designed simultaneously 3. finite interventional data  The assumptions of the work are the following:  - Infinitely many observational samples are available. - There are no latent confounders and no selection bias. - Underlying causal structure is an undirected tree. (Therefore, the causal model can be specified completely by identifying of the root vertex). - Causal Markov and faithfulness assumptions.  The authors assume that the underlying structure is a tree with no v-structures (otherwise the graph can be decomposed into smaller subgraphs with this property). Although reasonable in theory, there is a major issue with this assumption. In the case that the essential graph graph is tree, it is highly unlikely to have large chain components in the essential graph. In fact, checking a random directed acyclic tree, we see that majority of the edges will be learned in the essential graph and the chain components are usually of very small sizes compared to the whole essential graph. Therefore, chain components of size, say n=100, usually never occur in the essential graph. Therefore, it seems necessary that the authors provide a strategy to deal with the case that we have several separate tree chain components (not just one component).  It seems that the main contribution of this work is Lemma 1 and connection of this lemma to existing results, which is explained in lines 141-143. But the intuition behind lemma 1 and the explanation in lines 141-143 is not quite clear. I would appreciate it if the authors elaborate these parts.  The interventions are assumed to be single target. Is there any straight forward way to extend the updates in Lemma 1 to simulations interventions?  Following Lemma 1, the authors say that "This result implies that the only relevant interventional values are those of the neighbors of the intervened node. This is a critical observation that informs the development of our approach." This statement seems obvious, since having observational essential graph, an interventional essential graph is only dependent on the neighbors of the intervened variable. See [Hauser and Buhlmann, "Characterization and greedy learning of interventional Markov equivalence classes of directed acyclic graphs," 2012].  The type of interventions used in this work is Pearl's atomic intervention, in which the value of the intervened variable is set to a certain value. The issue with this type of intervention is that it may be possible that the cause affects the effect only under certain outcomes. Therefore, the specific outcome tested under the atomic intervention may not influence the effect. (for instance, consider a switch that only for certain values activates another variable). Due to this fact, is there another assumption regarding the influence of the atomic interventions needed in this work?  Should condition 1 also contain the case for do(X_i=0)?  In line 256, the authors state that "For simplicity, we restrict our discussion to the case in which the X_i are binary variables, although our techniques may be applied to more general settings as well." Unfortunately, the extension is not clear. I would appreciate it if the authors clarify how the extension should be done.  There are similarities between the main idea in this work and [Ghassami et al. "Optimal Experiment Design for Causal Discovery from Fixed Number of Experiments" 2017], which is also on tree structures. For instance, here, the main idea is finding a central node (Definition 1) and there, the main idea is finding a separator node (Definition 8), which have the same definition. A comparison seems necessary, of course the setting in that paper is non-adaptive.   Experiments:  In the experiments, the authors have restricted themselves to binary variables. It seems necessary to evaluate the results for other type of variables as well.  There are no real comparison of the results with other approaches. Perhaps the most relevant work is [Hauser and Buhlmann, "Two optimal strategies for active learning of causal models from interventional data," 2014] which also considers an adaptive setup. the authors can comparing required number of interventions. Also, the reason for high interest in the literature towards non-adaptive setup is that an adaptive setup can be viewed as a non-adaptive, in which we only design one intervention. Therefore, one can compare one step of an adaptive setup with a non-adaptive with intervention size 1.