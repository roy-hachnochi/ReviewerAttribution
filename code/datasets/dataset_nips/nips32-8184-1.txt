Originality: while the principle is certainly common in the literature, this is the first paper to demonstrate frequentist regret guarantees for perturbation induced exploration. Proof techniques do not appear to be terribly different than the prior arm, with the key differences appearing in Lemmas 4-5.  Quality: The work appears generally correct, and the proofs are readable and succinct.   Clarity: the proofs appear generally correct however, I believe that the third inequality beneath line 360 in the appendix could be explained more thoroughly, since justifying this statement crucially relies on conditioning on H_{k-1}, which is not indicated in the notation. Moreover, I think in the description of the algorithm, it should be stressed that the data augmentation is solely for planning, and not for estimation of transition probabilities.  Significance: I think the significance of the paper lies in the argument that optimism is not a realistic framework for more complicated RL settings, and that randomized data augmentation gives a more plausible approach which is still amenable to theoretical analysis.  However, I do not know if the fact that randomized value functions do in fact ensure frequentist regret guarantees is terribly surprising.   In sum, my inclination to accept the paper is not so much for its technical novelty, as for bringing to light the fact that there are other algorithm design paradigms for RL that may generalize better than optimism in more complex settings, but which are nevertheless theoretically sound. 