Overall, I think this is a well-written paper that provides a significant technical contribution on an important problem in differential privacy, and it would be a good addition to the NeurIPS program. Minor comments, mostly on presentation, are given below.  --pg 2, Thm 1: does alpha need to be known in advance? If not (and alpha has to be chosen by the user), then what happens if no such H* exists?  This is all made clear later in the technical sections, but should be clarified here. --pg 2, lines 57-61: For applications where m is so large that Omega(m) is inefficient, then this algorithms runtime of m^2 is even more infeasible. --pg 3, lines 90-92,103: Is d still the VC-based measure from a few paragraphs ago? Relatedly the earlier mention of Theorem 3 feels sufficiently separated that I thought the mention of it here was a typo.  These paragraphs could be better linked together. --pg 5, lines 200-201: What does it mean that a distribution behaves like a function applied to a set?   I can imagine when thinking of a distribution as a hypothesis as the average label over that set (although I'm not sure this is the correct interpretation since we're not talking about labels here), but then there is P(W_1) and P is the true distribution.  When defining W_1, should \mathcal{X} be D?  Confusion over these details also let to some confusion when interpreting the results. --pg 6, proof of Lemma 2: The claim that Gamma(H_1,H_2) has sensitivity 1 is not obvious and should be proven/argued.  This confusion is related to the point above because Gamma is a piecewise-linear functions whose conditionals and values depend on the terms W_1, p_1, p_2, and tau that were unclear. --pg 6, line 263: "indepdently" --pg 7, line 267: concentrated differential privacy hasn't been mentioned yet. It should be either defined (formally or informally) in the body or include a pointer to a formal definition in the supplementary materials.