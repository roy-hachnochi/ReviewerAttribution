Originality: the work proposed in this paper looks rather original, since it seems to be the first time that a paper addresses the problem of data poisoning in batch reinforcement learning.  Quality: the paper presents interesting ideas, and shows that the policy poisoning problem can be reformulated as a bi-level optimisation problem. Two derivations of this optimisation problem are proposed (TCE and LQR), for which the authors propose analyses regarding the feasibility and costs of potential attacks. The paper also proposes 4 sets of experiments demonstrating the fact that the attack can actually force the RL agent to learn a policy chosen by the attack.  Clarity: the paper is quite well structured.  Section 4.2 could be a bit more structured, for instance by proposing claims and proofs in order to better guide the reader in the argumentation.  Significance: this is indeed a crucial topic. The paper seems to open interesting discussions regarding the problem of damaging data in order to influence the decision of a potential victim controller.  *** Post feedback *** Thanks to the authors for the feedback and clarification. I have updated the overall score accordingly.