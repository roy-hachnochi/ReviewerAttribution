The paper is well written and organized. It discusses the possibilities of attacks on an RL system by just modifying the rewards, where the RL algorithms are table based Q function and linear quadratic regulator. I think, that it is pretty obvious, that it is possible to change the policy in any way, if one has full control over the rewards.  The paper provides a couple of experiments in which the changes to the rewards look surprisingly small, like 12%. But this does not mean much. If I change the reward in only one state transition sufficiently much, all other rewards might not need changes, and so by dividing the one large change by the number of state transitions in the data gives a small relative change.  In addition, I criticize the definition of the poisoning ratio ||r - r^0|| / ||r|| for two reasons,  1. if all rewards are increased by an offset of let's say 1e9, the policy will not change, but the poisoning ratio does, 2. it seems odd to divide by ||r||, r being the changed reward, more natural would be ||r^0||, the original reward. I think a definition for the poisoning ratio as ||r-r^0|| / ||r^0 - mean(r^0)||, would be a better measure.  AFTER FEEDBACK I am pleased with the author's feedback. In addition, after reading the comments of reviewers 1 and 4, I think that I slightly under-estimated the importance of the topic.  Therefore I increased the "overall score" to 6.  