This paper modifies upon the contextual zooming algorithm (reference [22]) to learn a nonparametric contextual bandits. When the metric among the arms is unknown, a partitioning in the space of estimated reward function is used. Theoretical guarantees for the regret is provided.  The result does seem to make sense. Although I must admit that I didn't check all the proofs. One fact that seems curious to me is that the overall regret bound can get better when the estimate for the Lipschitz constant of the reward function is looser. For example, in Eq. (9), the overall regret scales inversely with L^2. I wonder whether this artifact of the subpartitioning step in the contextual zooming algorithm can be easily removed?