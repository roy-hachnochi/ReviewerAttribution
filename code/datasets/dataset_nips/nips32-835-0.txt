Overall, the proposed work is interesting but the work is not clearly presented. The questions are:  1. The first experiments showed better results by eSURE than those of SURE. How is SURE trained using "twice more data"? Is it by increasing the batch size by 2? It would be good to see the results by twice batch size: 1) with two realizations of the same image; 2) different images.  2. For the second experiments with imperfect ground truth, what is the sigma in the training? The eSURE requires sigma in Eq. (10). Is that sigma_noisy in Tables 2 and 3? Does eSURE need to know sigma_gt?  3. Line 244, it seems that each network is trained for each noise level. So 7 DnCNN-eSURE networks were trained for Table 2 or 3? This is not practical and does not make sense. Normally, sigma_gt is unknown and may vary in the same dataset. It is reasonable to see one network for all different noise levels, like that in Table 1 for blind denoising. 