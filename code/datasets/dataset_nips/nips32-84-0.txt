The point about strong bounds on parameters not being required is somewhat subtle (and perhaps overstated in the abstract and intro) because bounds on these parameters are required to be known, but the sample complexity depends only polynomially and polylogarithmically on these bounds, so an analyst can have very loose bounds on these terms and it will not affect the sample complexity significantly.  From a first read of the abstract/intro, it seems like these parameters are not required to known at all.  I would encourage the authors to re-phrase the informal statements of these claims to more accurately represent the results of the paper.  The algorithm works similarly to that of Achlioptas and McSherry by using PCA to project the data into a low-dimensional space and then recursively clustering data points.  It differs from this previous work by using differentially private versions of PCA and clustering.  The authors develop a new algorithm for private clustering that is based on private clustering algorithms of Nissim, Stemmer, and Vadhan, but satisfies additional properties needed for this particular problem.  The authors also derive sample complexity results for solving the problem using subsample-and-aggregate, and show their algorithm has asymptotically better sample complexity.  Overall, this paper provides novel technical results on a relevant problem in private machine learning, and would be a good fit for NeurIPS.  The writing and presentation is also very clear.  Minor comment: pg 4, line 132: "an secluded cluster"