Authors could further explain why should the Assumption in Def 1 hold for natural images e.g. for the considered architecture in eq3? Also, If the model approximates natural images e.g. similar to wavelets, what's the approximation bound based on DIP size {k_l, d_l}?  Why DIP approach could beat compressed sensing algorithms using learned priors?  Theorem1 and its proof are not very new. Results for iterative hard thresholding for sparse coding and its generalised variants for nonconvex signal constraints, cover similar claims in Theorem 1.   Also theorem 1 is said to guarantee image recovery by algorithm 1. But  algorithm 1 itself has a line 4 which we do not know how to exactly solve it i.e. the projection step (similar for theorem 2). Therefore global convergence guarantees are not really meaningful/practical to be discussed.  What is the advantage of NetPGD over NetGD? experiments show similar runtime although NetPGD may require solving subproblems at each iteration. Further experiment details could make this point clear.   Statement of Theorems 1&2: there should be a condition on step size somewhere  Line 462 (typo) two W1s  