Originality: The paper is an extension of [1] to apply the Power Mean Laplacian to semi-supervised learning. The paper provides some insights about the new algorithm for the choice of p, depending on the noise assumption on the graphs.  Quality: The theorems in the paper is insightful for understanding the algorithm. The provided numerical analysis is also convincing to demonstrate the theoretical results. The proposed method for solving the linear system efficiently also makes the algorithm more practical. However, I’m not sure if the empirical results were convincing enough as the authors claimed they didn’t tune to the parameters for all algorithms. Some of the baselines gives pretty terrible results, e.g. SMACD, which contradicts with the original paper.  Clarity: The paper was written clearly. I can follow the paper pretty easily. There are a few typos I found in the paper:  Page 2, line 71, “Moreover, not that” should be “note that” Page 5, line 183, “its overal performance is larger than the proposed approach”. overal -> overall, performance -> error?   Significance: The proposed algorithm seems an interesting direction for semi-supervise learning. Even though the paper provides some efficient method for solving the linear system, the complexity of the algorithm was still pretty high, which might hinder the wide adoption of the algorithm.  [1] A. Subramanya and P. P. Talukdar. Graph-Based Semi-Supervised Learning. Morgan & Claypool Publishers, 2014. 