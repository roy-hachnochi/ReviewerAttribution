Overall Comments This paper tackles an ambitious question of providing an algorithm in the offline contextual bandit setting that satisfies fairness guarantees that are specified as constraints. The paper provides a high probability guarantee for this algorithm and also empirically tests the algorithm on a variety of different data sets. The paper seeks an algorithm that satisfies a few conditions: 1) that the fairness constraints be user specified, 2) that a solution is returned if one exists 3) and that the 'sample complexity' of this algorithm is 'reasonable'. The combination of these contributions make this a high quality submission in my opinion. Areas for improvement are noted below.  Originality As far as I can tell, this is the first offline contextual bandit algorithm that satisfies a user defined fairness constraints.  In general, the goal of developing algorithms that satisfy user defined fairness definitions is not new, however, the formulation in this paper is new, challenging, and interesting in the offline batch setting. Previous work, see Cotter et. al. 2018ab, noted below has focused on developing algorithms that include rate constraints as part of the training process. In principle, the fairness constraints presented here are conceptually in this family.   Quality Overall, this is a high quality paper that tries to solve an important problem in a comprehensive manner. As with any paper, it does not solve all of the problems and leaves open the question about the exact sample complexity of the proposed algorithm; however, the paper demonstrates empirically that it is likely similar to other proposed methods.   Clarity Overall this paper is clear and relatively easy to follow. My biggest suggestion for improvement is in section 5 (theoretical analyses section). In section 5, it would have helped substantially to provide a proof sketch or general overview of how and why assumptions 1-5 are necessary for theorem 2. Most of this is left to the appendix, which is fine, but since these proofs are a key contribution of this work, doing more to set them up would have been great.   Significance This work is significant since it moves the area towards providing algorithms that help satisfy fairness constraints while also providing the option for providing answers like 'I don't know' or 'No solution found'. The paper also demonstrates the utility of the proposed Robinhood algorithm in a 3 settings that are significant.   Minor Fixes Page 8, figure 1: Include a caption and figure label. In addition, can you improve on the color selection for some of the algorithms ? It is currently difficult to tell apart POEM vs OffsetTree since the lines are both red.   l296: Include brackets in this equation, right now it is somewhat difficult to read.   l422: Citation 29 is empty.   Areas for Possible Improvement/Questions Here are some questions that the authors could possibly clarify about this paper. 1) The guarantee that is given in the high probability proofs are mostly because of the iid assumptions that the authors make. One of the exciting things about the contextual bandit framework/bandits in general is that one can do away with this assumption. What are the potential avenues one has for giving this kind guarantee for a non-iid setting?  Perhaps it makes sense to require this because the authors are operating in the batch setting here.   2) Presentation of theorem 2 in the appendix. I spent quite a bit of time with this theorem, however, it is still difficult to understand the importance of the different pieces that the paper uses to make this claim. Ultimately, I couldn't spot an error, but I would've liked the authors to clarify why each property/assumption is needed for their claim. Some are obvious like the use of the hoeffding's inequality. Assumption 3 for example, indicates that a fair solution, for a constraint, $g(\theta^\ast)$ exists. This seems to me like a very strong assumption that should be relaxed somewhat. Ultimately, more clarification in these portion would help the reader.   3) Figure 1 does not include the loan approval figures.   4) Column 3 in the figures is interesting; it suggests that as you train the baseline algorithms that the paper compares against with more samples, these algorithms start to approach failure that is close to the proposed robinhood approach. Can the authors help provide insight to these finding?   5) Demographic parity/Statistical Parity. As I am sure the authors are aware, there are other statistical definitions like equalized odds and other variants. Is it straightforward to extend this to those definitions provided an appropriate $g$ is given?   Update I have read the author rebuttal, and will maintain my rating. The plan to provide clarification for section 5 in the final version. I consider to work to be sound and addressing a very challenging question.