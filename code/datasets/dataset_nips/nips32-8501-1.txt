Originality. The paper seems to be a simple extension of known results for non-convex optimization to saddle-point problems. I think, it is obvious that since the saddle-point problem is concave or restricted strongly concave in the variable w.r.t. which we maximize, we can use some method to find the approximate gradient w.r.t. variable in which we minimize. Then a gradient method with inexact oracle, e.g. http://papers.nips.cc/paper/6565-learning-supervised-pagerank-with-gradient-based-and-gradient-free-optimization-methods, can be applied to find an approximate stationary point.  It is quite strange that the classical paper https://epubs.siam.org/doi/pdf/10.1137/S1052623403425629 is not cited in line 31. Also it seems that the general algorithm https://link.springer.com/article/10.1007/s10589-014-9673-9 can be applied to the setting considered in this submission. Probably, the complexity would be the same.  Quality. As far as I see, the proof of Lemma A.5 is not complete. To use the Taylor expansion for g(.) one first needs to prove that it is a smooth function. Moreover, the expansion is used up to the second-order term and more smoothness is needed. Thus, the contribution for the PL-games is questionable. Other proofs seem to be correct. Nevertheless, it would be nice to add some more details on how the first inequality in line after line 530 in the supplementary is obtained. The same is for line after line 449 in the supplementary. In the experiments it would be nice to compare the results with the results of [37]. Does CNN have advantage in comparison with convex classifier?  Clarity. Except the above things the paper is well written and easy to follow.  Significance. Despite the optimization contribution seems to be marginal, the algorithm can be interesting to practitioners in the ML community.   =============After rebuttal=============   The authors have mostly resolved my concerns by their rebuttal. I still think that the paper is borderline in terms of the contribution. Not much is new made in terms of the optimization, but the resulting algorithms can be interesting to the ML community. I'm increasing my score.     