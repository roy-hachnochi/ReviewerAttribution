----- Originality ----- The basic idea of this work is not new, but the practical construction is neat and can be of interest to the machine learning community.   ----- Quality -----  The technical parts appear correct to me, although I have not been digging into the mathematical details. I enjoy the probabilistic kernel model, since my own impression of highly parametrised approaches for increased expressiveness is that they tend to be very challenging to train. The fact that the proposed approach easily extends to multiple input- and output dimensions is promising, since this is required in many real-world applications.  Although the proposed method can describe the entire class of stationary covariance functions (which is a limitation, although of interest for a broad class of problems), it seems to me that the particular interest is functions with periodic behaviour. Therefore, it seems a bit strange to me that no comparison is made to the standard periodic covariance function obtained through the warping u(x)=(cos(x),sin(x)), which have shown promising results in modelling periodic functions elsewhere (see e.g. [1] below). I think that would be the most natural and simplest design choice to capture periodic behaviour.  Furthermore, the focus in the one-dimensional comparison with other methods is on extrapolation; apart from the RBF kernel, the interpolation performance seems similar across all methods. In the multiple input case when focus is on interpolation, the performance difference as compared to the Matern kernel decreases - it would be interesting to hear the authors view on whether this improvement is justified by the higher model complexity.  Finally, I am wondering about the time scaling properties when solving problems of multiple input dimensions. Intuitively it seems like the numerical integration (Eq. 3) is a bottleneck in these cases, so it would be interesting to know more about it.  [1] Ghassemi & Deisenroth, "Analytic long-term forecasting with periodic Gaussian processes", AISTATS 2014.  ----- Clarity -----  The paper is very well-written, easy to follow, with clear methodological descriptions.  ----- Significance -----  I believe that this paper by itself is significant to the sub-field of GP modelling that focuses on functions with periodic behaviour. Although I am not sure that there are plenty of problems that will benefit from this particular construction, I have a feeling that it has good potential of inspiring more powerful extensions and developments.