UPDATE: I'd like to thank the authors for their detailed response.  In light of this response I have increased my score to a 7.  Originality This paper presents Meta-MinibatchProx, an algorithm for model and algorithm agnostic meta learning that, unlike MAML and friends, comes with theoretical guarantees of convergence.  To the best of my knowledge it is the first such algorithm to offer any convergence guarantees, and also has the potential to scale to very large problems.   Quality Something I would like to have seen addressed explicitly in this paper is the distinction between what I will call the "finite" and "infinite" versions of MMP.  The distinction here is related to the comment "Usually we are only provided with n observed tasks..." on line 135. In particular:   1. The number of tasks n is fairly small (say 10s) and we can permanently materialize the per task parameters w_T for each task (the "finite" case).  2. The number of tasks n is infinite (as in the sin wave experiments) or effectively so (as in the few shot image net experiments) where a single task is unlikely to be seen more than once, so permanent materialization of the task specific parameters is not useful (the "infinite" case).  The paper focuses exclusively on the second setting (which is the typical framing for meta learning), but it seems to me like one of the big advantages of MMP is its ability to deal well with the finite setting as well.  In the finite case I think the MMP framework offers a starting point for thinking about how to deal with issues like:   1. Task spaces where some tasks have vastly more data than others  2. Hierarchically structured task spaces (for example, the structured labels in tieredImageNet could be used to construct hierarchical priors).  3. Task spaces with non-uniform input or output structures, where task specific models share only some of their parameters (perhaps also with a graph structure over   4. dependencies between model parts)  5. And so onâ€¦   This paper presents itself as a better MAML than MAML, which is justified through convergence theory and empirical results.  It would be vastly more compelling if it also demonstrated the capability to deal with problems that are hard or impossible to express with MAML.  I feel that not doing so is a quite a missed opportunity.  Clarity I found the paper quite clear and well presented. There is necessarily a lot of notation in a paper of this sort, but I found it well presented and reasonably easy to follow.   Significance As mentioned in the quality section, I think the biggest weakness of this paper is a missed opportunity to present an algorithm that can do more than the existing meta learning formulations.  It is one thing to have a slightly better meta learning algorithm than the baselines, it is quite another to have that in a framework that is also general enough to address a wider class of problems.  Typos 139: "inra-meta-task" 271: The text says 15 steps of SGD, but the legend in Figure 1(a) says 32 steps.