The proposed loss functions seem novel and theoretical analysis are well presented to support their validation.   These Bi-Tempered Logistic loss functions are variants of existing ones. They are derived by introducing a temperature into the exponential function and also by replacing the softmax with a high temperature generalization. Besides all these well presented derivation, Iâ€™d like to see some statistical properties of these functions, and how they are compared to the existing ones.   The authors claim the proposed loss functions are robust to noise and outliers. The authors are encouraged to present more theoretical & emperical analysis on this part.  This new loss function is not convex. Although the conventional logistic loss is not convex with respect to some parameters if neural network is used, its convexity still enables researchers to theoretically analyze the performance of the learning algorithm. If this new non-convex function is used, is the analysis still possible?