Orginality: Moderate to high  The idea of using better, more human-aligned risks is a nice idea that extends recent interest in having more risk-averse losses and training procedures.  Approaching the problem through the lens of behavioral economics is different from many of the machine learning based ideas.  Quality: Moderate.  The evaluation and comparisons to prior work are sound (with some minor omissions, like `Fairness Risk Measures' by Williamson which cover similar ideas about risk measures and fairness).   The paper has minor conceptual issues that prevent it from being a great paper. The main problem is that CPT is justified relatively briefly in section 2, and then a large part of the remaining paper is about the analysis of CPT. While CPT is clearly a reasonable framework for behavioral economics, it is not clear that the (surrogate) losses used in machine learning are at all similar to monetary losses and gains. In this case, should we still assume that CPT is the right way to weight losses? What is missing in this paper is the 'human' in human risk minimization - quantifying whether losses used in ML + CPT matches human utility would go a long way to convincing the reader.  Additionally, many of the goals of CPT can be achieved by simply using more risk averse losses like CVaR. Is the upweighting of tail gains necessary? I would think that this can in fact result in unfairness when one tries to optimize tail gains at the expense of losses. It might be worthwhile to include something like CVaR in your experiments as well.  Clarity: Moderate to high.  Section 2.1 that covers CPT was clear, and motivated the reasons for using CPT. I do think Section 4 is a bit low level, and cutting some material there to show some examples of how CPT would work on toy examples would be helpful.   I did not follow the phrasing of the 3 bullet points from lines 126 to 128.   Typo (?) at line 50 ``doomed larger than gains''?   Significance: Moderate to high   Despite some minor complaints about whether CPT truly matches human risk, I think the ideas and approach are new, and the writing is fairly good at making the case for CPT as a way to adjust losses. The paper may serve to interest other researchers in more human-aligned loss measures as well. 