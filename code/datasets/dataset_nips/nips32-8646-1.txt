My summary of the paper: Most relaxation-based methods for certifying the robustness of neural networks use the "triangle approximation," which adds a constraint between each pre-ReLU activation and the corresponding post-ReLU activation.  Unfortunately, by only treating each unit independently, the triangle approximation loses a lot of precision, i.e. the relaxation is very loose.  Consider a ReLU layer with n units.  The tightest possible convex relaxation is the convex hull, which is described by 2^n sets of linear inequalities, one for each possible "activation pattern" (an activation pattern is a choice of - or + for each ReLU).  Enumerating exponentially many inequalities is computationally intractable, so the authors instead propose the following "K-ReLU" relaxation: arbitrarily partition the units in the layer into mutually exclusive sets of size K, and add the linear inequalities corresponding to the convex hull of each K-sized set.  Apparently, this too is computationally intractable in practice for K > 2, so when K > 2, the authors propose to use a further relaxation which (I think) only adds linear inequalities that involve at most two units.  The authors employ this K-ReLU relaxation as a way to tighten the bounds for DeepPoly, a neural network certification method; to be honest, though, I didn't understand all the details involved (see below).   Remark:   - I do not understand where exactly DeepPoly enters into the proposed method.  From what I gather, you compute the lower and upper interval bounds l'_x and u'_x using a linear programming solver.  Now, you _could_ use that LP solver to also compute the 'intercepts' for the octagonal constraints.  But you apparently use DeepPoly for that --- why?  It's unclear to me why DeepPoly is necessary at all.  (Is it because of speed?)  Moreover, it's also unclear to me where the DeepPoly ordering restriction (that each unit's constraint only depend on the preceding units) enters into the proposed algorithm.  There was some confusing notation in this paper:  - on line 136, 148, and elsewhere, the authors speak of the "union" of constraints when they actually mean the intersection.  (I understand why "union" arguably applies too, I just think it's confusing, given that union and intersection are opposites).  Also, I believe that in Equation 8, this is explicitly wrong -- you need to use \cap instead of \cup.   - in line 142, the authors define "boxy \cap" (I don't know the actual latex command) to mean the intersection of two polyhedra, and "boxy \cup" to mean the convex hull of two polyhedra.  This is confusing for three reasons: (1) boxy \cup looks very similar to \cup, yet you use it to mean something very different (convex hull vs. union); (2) in your definitions, there's a weird asymmetry between boxy \cap and boxy \cup; (3) in your definitions, boxy \cap is the same thing as \cap.    Here is my suggestion: just use \cap and \cup to mean intersection and union, and use conv() to mean the convex hull of a set.  - on line 151, it's not "2^n convex hulls", it's one convex hull that requires 2^n inequalities  - in Theorem 3.1, I have no idea what that symbol means -- you should define it in the text.  - on line 147, each S is actually a subset of R^{h x h} and not (as is stated) R^h, right?  Advantages of the proposed method:   - can be used to obtain superior to robustness certificates to DeepPoly and RefineZono.  I don't understand how these numbers stack up to those from other methods, e.g. https://arxiv.org/abs/1805.12514 or https://arxiv.org/abs/1810.12715, but comparisons to other methods might not be necessary, since the K-ReLU idea is generic and could be used with other relaxation-based certification methods.   Disadvantages of the proposed method:  - requires arbitrary choice for the partitioning of ReLUs in each layer  - requires arbitrary choice for P_{R, i}  Rubric:  - originality: the idea of tightening relaxation-based bounds by considering multiple ReLUs is a natural one, but to my knowledge, it has not been thoroughly explored in the literature yet.  Therefore, this work is original.  - quality: the paper is of good quality.  - clarity: as I've mentioned in this review, the clarity can definitely be improved, but the paper is certainly readable.  - significance: I am not quite sure of the significance of this work to the literature.   Therefore, I am rating my confidence in this review as low.    === response =====  I've read the author rebuttal.  The other reviewers agree that the notation is at a minimum confusing, and possibly wrong.  I encourage the authors to improve the clarity of the mathematical presentation in the revision.