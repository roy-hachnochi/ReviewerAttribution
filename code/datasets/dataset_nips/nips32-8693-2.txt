[Originality] This paper considers an interesting problem of rematerialization problem, with the motivation from the present situation of the complexity of neural networks and state-of-the-art machinery. [Quality & Clarity] * The general description using a DAG (in Section 2) is quite simple while I feel that it captures the motivation sufficiently. Given a DAG, where each vertex corresponds to computation and each edge corresponds data dependency, the objective is to find a short sequence of nodes with small peak memory, whose definition is natural. * The precise problem formulation and the proposed algorithm are not convincing, though Theorem 4 itself is technically sound. Instead of considering to optimize either length or peak memory of the schedule, the authors considered to provide an algorithm that computes a valid schedule whose length and schedule depends on treewidth. Since there is a tradeoff between the peak memory and schedule length, it is more natural to formulate an optimization problem of peak memory (or length) given a fixed length (or peak memory). E.g., Figure 3 shows that TwRemat runs 3 times as long as the other baselines; what if one wants to get a schedule that is twice as long as the baselines? Section 4.3 claims that we can interpolate TwRemat vs. NoRemat by changing the recursion limit, but it seems hard to find a schedule of desired length unless trying all the possible recursion limit. * Experimental evaluation is well described; the section reports the result of TwRemat and two baselines on several deep networks. It is effectively demonstrated that TwRemat can significantly reduce the peak memory at the price of schedule length, and the memory usage does not increase with the number of layers. It is also clearly presented that the treewidth of computation graphs of the real model is bounded. [Significance] Overall, I thought this is a reasonable paper. This work formulates a new rematerialization problem for complex neural networks, develops an algorithm that works very well for bounded-treewidth cases, and verifies the effectiveness by experimental evaluations using real deep networks.