This paper considers a setting in which we are given some hierarchical clustering over data, and we want to find some pruning/cut of this hierarchy by adaptively querying for must-link/cannot-link constraints among its leaves. There are three settings considered in this paper, each with its own algorithms and analysis: (i) the noiseless setting, where each queried pair is consistent with some true cut of the tree, (ii) the persistent noise setting, where each queried pair is consistent with some true cut of the tree except for some randomly selected subset of pairs for which the response is flipped, and (iii) the agnostic setting, in which no assumptions are made over the distribution of responses.  The paper presents active learning algorithms for each of these settings, demonstrating that the number of queries can be upper bounded by quantities that depend on the tree and possibly the ground truth clustering. Some of these bounds are also accompanied by nearly-tight lower bounds on the query complexity of any active learning algorithm.  In all, this paper represents a very thorough investigation into this problem, and I vote for acceptance. The settings considered here are quite diverse, and the algorithms are both practical and have rigorous query complexity and running time guarantees. The comparison to related work is also quite thorough, showing improvement over the bounds given in more generic active learning algorithms.    Minor comments: - The notation is a little difficult to follow, possibly due to the overloading of notation. In particular, defining the prior distribution over cuts as P(c) in terms of the values P(i) makes certain statements confusing.  Typos:  - Line 22: obiquitous 