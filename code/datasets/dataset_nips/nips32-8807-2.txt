Even though the proposed expect relabeling technique can augument the training data to help alleviate the reward sparsisty problem, the introduced goals, which are   intermediate states, are different from the groundtruth goal and this may introduce a large number of noises especially when the true rewards are limited. I don't know how to alleviate or avoid this problem or equivalently how to guarantee that the benefit of augumenting data will be larger than the negative effect of the introduced noises.  Line 171: different than->different from  ------------------------------------------------------------------------------------------  Authors' response partially clarifies my concern.