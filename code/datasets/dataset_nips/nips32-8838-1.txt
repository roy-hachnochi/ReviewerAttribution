The derived results for KTR3 with non-zero regularization parameters is a strict improvement in the regime $2\beta + b<1$ upon the best-known bound of KRR and stochastic gradient methods. The derived results for KTR3 also indicate that in the regime of easy problems the best among of regularization is exactly zero.  -------------After rebuttal----------------- The comparisons with related results have been made clearly by Fischer/Steinwart in Table 1 of the nice paper (https://arxiv.org/pdf/1702.07254.pdf). (For ease of comparisons, I use the same notations from that Table in the following). The focus of the paper is on the case $\alpha =1$. In my opinion, this paper gave optimal rates for the case $\alpha =1$, and the results indeed improve previous results, closing a gap (but only for the case $\alpha =1$). Note that for the general case $0<\alpha\leq 1$, it is still an unresolved problem. And in my opinion, the technique of the paper under review may demonstrate some further new results for the general case $\alpha\leq 1$.  Thus, I keep my scores unchanged.  A further comment on the nice paper (https://arxiv.org/pdf/1702.07254.pdf) is needed in the final version.     The derived results are very interesting, closing a long-standing gap between upper and lower bounds.  The proof technique developed may be also interesting to the community.  The paper is well written. I did a high-level check of the proof. I believe the proof should be correct. Minor comments:\Line 70 on Page 2, $X$ is compact..\Line 71 on Page 2, a citation is needed here for $f_{\rho} \in \bar{H_K}$; ... which is the closer of $H_K$ in $L_{\rho}^2$ \Line 80 on page 3,  $L_K$ is compact ?\