This paper presents a theoretical analysis of the representational power of graph convolutional network (GCN) models. It is shown that these models are in many cases incapable of learning topological features of the graph such as graph moments, and these shortcomings are used to motivate new GCN architectures combining several propagation rules and incorporating multiple residual connections. The analysis seems to be sound (albeit distant to my area of expertise), and the obtained emprical results seem to support it. I believe that this paper could serve to better improve understanding of GCNs' representational power, and therefore I would vote for (marginal) acceptance.  I have a few comments that could be used to improve the work:  - In its current form, it is somewhat unclear what "GCN" exactly refers to. It seems that the authors use it interchangeably to refer to the GCN model of Kipf and Welling, and to convolutional layers on graphs more generally. I would recommend a thorough pass through the paper to make it clear what the authors are referring to at different points.  - The point that multiple propagation models can be helpful for easing learning has already been empirically pointed out by related work. For example, the graph attention network (GAT) paper (ICLR 2018) finds it critical to use multi-head attention on a graph to achieving strong performance. This effect is probably more pronounced in attention-based models where the propagation model itself is learnable, but it might be worth positioning the proposed architecture in the context of such works as well.  - Very similarly, the idea of using residual connections resonates heavily with the jumping knowledge network architecture (Xu et al., ICML 2018), and it would be good to position the work with respect to it as well.  - Minor: when referring to the propagation models in sect. 4, I believe the references for Hamilton et al. and Kipf and Welling are flipped with respect to their propagation models.  - One thing I found unclear for the graph classification setup is how exactly the graph-level features are computed. The propagation rule explains how to obtain node-level representations, and it's clear how these can be used for node-level classification, but how are these aggregated to a graph-level representations? Is simple mean-pooling used? I invite the authors to clarify.  - The experimental analysis is good, thorough and seems to support the theoretical observations - I believe it could be interesting to test the method on more "real-world" graphs as well. Would it make sense to launch the architecture on the standard graph classification datasets (as used in the GIN paper)?  --- After rebuttal --- I thank the authors for constructively addressing my comments and providing improvements to the clarity of the setup. I am still unable to fully gauge the contribution of the paper, and the lack of additional benchmarks makes it hard for me to position the proposed operator against prior work (such as GIN).  Especially related to the point the rebuttal makes about GATs, I believe that the authors might be overlooking a relevant point: each of the K attention heads are *learnable*, and thus can and often will learn K separate propagation rules. The reason for suggesting real-world benchmarks simply is to show the benefit of choosing K different "hard-coded" propagation models as the authors do here, as opposed to being able to learn them (as GAT/GIN do).  I still think the work contains worthy theoretical contribution on an overlooked problem, and I will retain my score.