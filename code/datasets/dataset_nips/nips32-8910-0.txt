Updated review: Authors responded to most of the concerns and hence increasing my score by one. Please include the additional experiments performed after submission that was included in rebuttal in the final copy if the paper was accepted. --- Quality: High, it’s a well-written paper justifying and then describing the model step by step and testing it on one simulated and one real dataset. Clarity: Medium. Most of the paper is clear and easy to follow. The learning section could be improved by perhaps describing the algorithm in an algorithm box. Significance: low: It’s a bit hard to evaluate the significance as the architecture seems to specifically designed for the driving domain and there is no discussion how this could be used or generalized in other applications.  -The assumption of small cardinality of latent code and its discrete nature is a strong one. A discussion on how limiting this could be and potential solutions to extend this model would be useful.  -L172: Could you expand here, as what would be the E step. -Fig 2-a: typo: y_[t+1]