Review of "Multiple Futures Prediction"  Summary They propose a method for predicting multiple possible rollouts in a stochastic dynamic environment. Their approach involves extending seq2seq to have a population of RNN agents (i.e. teacher-forcing => classmates-forcing), so it is able to predict multimodal states. In addition, each RNN can represent a particular agent in the environment, and implicitly model agent-to-agent interactions and incorporate other agent behavior directly in future predictions. They demonstrate SOTA results on NGSIM dataset, and also experiment their approach on data collected from CARLA simulation environment.  I thought the paper was well written; the text is clear and well reasoned, and it feels the authors have put effort into making polished visualizations, diagrams and figures. I particularly liked the effort that also went into the supplementary materials to ensure details are described to facilitate reproduction (the qualitative results were also interesting). Existing work specific to vehicle trajectory prediction is described. They obtained good results of the benchmark dataset in their domain. I think this work should be accepted, however I would like to suggest a few improvements that will make the paper much more solid for NeurIPS, if the authors want to try to improve a bit. Right now I feel the paper is at a level where I can assign a score of 6 (will explain the points I think is lacking below), but with a bit more work, it can easily be a paper with a score of 7 or 8 from me (see below).  The motivation behind this paper, as quoted from the abstract, is "Temporal prediction is critical for making intelligent and robust decisions in complex dynamic environments" and clearly the approach should look to find use cased in decision-making applications (i.e. an agent acting an a real or simulation environment that has complicated dynamics), so the thing I found lacking in the paper was that all the experiments were only based on how well the approach can be used to model a pre-recorded dataset in log-likelihood estimation metrics. The experiments are important, don't get me wrong, especially the fact that they can compare to a large body of existing work using NGSIM, but I think for this paper to have a much higher impact beyond niche (i.e. to the larger NeurIPS community), the authors should consider applying their method to actual tasks where they can measure performance in terms of rewards, task objects, etc. Given that the authors have used the CARLA simulator (for the purpose of collecting a dataset, and fitting their model to that dataset only), one can consider using CARLA environment to define actual difficult tasks (it is an RL environment afterall), and seeing how the approach facilitates an agent to solve difficult, but important tasks that self-driving agents need to tackle.  With that being said, in the RL literature, there is an existing body of work (though may not deal directly with autonomous driving domain) that also tackles the problems motivated by "Motion prediction needs to model the inherently uncertain future which often contains multiple potential outcomes, due to multi-agent interactions and the latent goals of others." For instance, some examples in this line of work in RL [1, 2, 3] proposed methods to build generative latent models of the environment from collected data, and sample multi-model tragectories of the future, fits a model to collected dataset of experiences, and more importantly address the (IMO) more critical question of how to use these models to actually solve difficult problems. Would be nice to see a discussion that links the line of work of this paper, to the literature in probabilistic generative models used in RL domain that has similar goals and motivation. I believe this will make the work more impactful, since readers can find ideas from other subfields and be inspired to creatively devise more innovative solutions down the road to tackle these important problems.  Overall, I like this paper and the proposed approach, and think this is a thoughtful and encouraging work. I'm recommending acceptance (with a score of 6 for now), but if the authors address some of these concerns (esp if they can get results on RL tasks, and report performance on the actual task, rather than log likelihood), then I should be able to improve the score by 1-2 points.  [1] Racani√®re and Weber and Reichert et al., Imagination-Augmented Agents for Deep Reinforcement Learning, NIPS2017. https://arxiv.org/abs/1707.06203  [2] Ha and Schmidhuber, Recurrent World Models Facilitate Policy Evolution, NeurIPS2018. https://arxiv.org/abs/1809.01999  [3] Hafner et al., Learning Latent Dynamics for Planning from Pixels, ICML2019 (arxiv, Nov 2018). https://arxiv.org/abs/1811.04551