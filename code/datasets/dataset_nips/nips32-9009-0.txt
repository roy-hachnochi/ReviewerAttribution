The authors introduce AMDIM. Their aim is to maximize the mutual information between representations of different 'views' of the same `context'. They demonstrate the benefits of such a procedure on multiple tasks.  The authors are inspired by Deep InfoMax (DIM). They claim to extend DIM by using independently augmented versions of each input and also by generating features across multiple scales. They also claim to use a more powerful encoder. The authors show an NCE based setup also demonstrate a mechanism to maximize multi scale mutual information. They end by showing mixture based representations and experiments related to the proposed techniques on a variety of data sets.    Their main contribution seems to be the multiscale setup and the usage of data augmentation for generating multiple features of the same input. Thee mutual information between these features is then maximized. The f_1 features from the trained model are then used as inputs to linear and MLP classifiers.  The extensions to DIM introduced by the authors are interesting and seem to be useful. They seem to be a logical step forward in the space of procedures that maximize mutual information for generating better data representations.   There are, however, some questions that come to mind.  -- It might be beneficial to add more details/explanations  about the procedures being discussed in this work. For example, an explanation of the different steps in Fig 1c will make it easier to read.  -- It might be beneficial to add a pictorial representation of the network architecture used to represent m_k  -- Figure 3 might need a more detailed explanation. In say Fig 3a) what do the different rows represent. Furthermore, similarity between 2 entities of interest say A and B is often a single number. How is it being represented in Fig 3a)  -- So often the multi-layer structure of a NN helps in capturing different levels of information at different levels. In this perspective, what does it exactly mean to have high mutual information between say f_5 and f_7 (or any such set of hidden layer features)?  -- In principle DIM can be used with a similar encoder as AMDIM. It will be very interesting to see the performance of DIM in such a setup as a baseline result. This will help in gauging the importance/influence of the augmentation/multi-scale setup used in AMDIM  -- In the context of views, what are the authors' thoughts on different views generated through say a different camera angle for images instead of processing done to produce augmented version of an image.   Originality:  The work is an extension of a known technique (DIM). It seems to be a logical step forward in the space of procedures that maximize mutual information for generating better data representations. Their main contributions seem to be the multiscale setup and the usage of data augmentation for generating multiple features of the same input. The mutual information between these features is then maximized. The f_1 features from the trained model are then used as inputs to linear and MLP classifiers.   Quality:  The authors do try to give the mathematical formulations behind their work and also provide empirical evaluations.  Clarity :  The manuscript seems to be written in a somewhat ok manner. There is, however room for improvement with certain places perhaps being a bit too concise.  Significance:  The work shows useful insights into the usefulness of modern Mutual Information maximization and can perhaps encourage more work in using such techniques for learning representations.