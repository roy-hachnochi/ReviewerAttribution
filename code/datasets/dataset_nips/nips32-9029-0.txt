Although the paper addresses an important problem and can be of practical use, I have some concerns about the novelty of this submission. Imitation learning (or supervised learning) is the standard techniques used in many applications. Lots of works have used GCNN for different combinatorial optimization problems and achieves good performance, and I didn't see strong novelty here. Furthermore, with limited ablation analysis, we don't have a good understanding on what's going on. With pure imitation learning, did the proposed approach actually generalize better, compared to the original strong branching it is mimicking? Or is the improvement just because of the speedup from the learned network?   Another question is that since the trained network can mimic strong branching heuristics, it might have learned something interesting that takes the place of two LP evaluations. I am curious about what it learns. Did it learn easy cases and give random answers to corner cases? Does it actually learn to address hard cases (if so then we could even replace LP with Neural Network)?   Code is available, which is great. I roughly checked the code and it is quite clean and easy to understand.    Eqn. 3 is very confusing, since the paper doesn't do reinforcement learning (either from scratch or from pre-trained models). I suggest removing all RL components to make the paper clear.   No number in Table. 2, #nodes, Set Covering, Hard case.   ===============  Update after rebuttal.   The rebuttal is generally well-written with additional experiments. It also shows that the performance boost is largely due to an increase of the training data (compared to SVMrank etc). While the algorithmic contribution is not that novel, this can serve as a good baseline for ML-based branching method. In addition, the code is really well-written and available. 