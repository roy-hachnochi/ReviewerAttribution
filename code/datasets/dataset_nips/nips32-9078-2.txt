Comments: - (lines 156-158) I understand the reasoning behind removing proteins with 30% sequence identity. Would it suffice to just remove those proteins which have similarity with the DB5 test set only, and keep the ones which are similar to the DB5 training set? This way, you get a larger training dataset without having the cross-contamination issue. - Instead of the proposed voxelizing technique (which can result in abrupt jumps if the atom falls closer to the voxel boundaries), would it help to use approaches which are smoother? For example, each atom could be modeled as a sphere of a certain radius, and each voxel would get a weight based on the area overlap with the sphere. - It is clear that the competing methods' hand-crafted features are unable to use the larger dataset to improve their performance. My guess is that some features are generalizable and some are not. A more careful study of this would be very informative. - It would be nice to have some information about the voxel size, number of voxels, how many amino acids does the input typically cover, etc in the experiments section.  - Would the model be able to predict contact maps, or two regions within the same protein which interact with each other? If yes, then it opens up a few more options, like getting an even bigger training dataset, pre-training the models using contact map predictors, etc. - The experimental setup of Fig 3A could be better explained. Grid size here refers to the entire window surrounding the amino acid right? Is the voxel size kept constant or scaled appropriately? What happens if it is kept constant or scaled?  Originality: Novel  Clarity: The presentation of the paper is clear.  Significance: Moderate