POST REBUTTAL UPDATE: The authors answered my concerns, and I'm increasing the score to 8.  The authors train RNNs on a basic NLP task – sentiment classification. They then use dynamical systems tools to show that the network implements this as a line attractor – perhaps the simplest model of evidence accumulation. Every word is projected onto the line attractor according to its valence, and moves the dynamics towards the correct decision. This mechanism was shown in tasks that were neuroscience-inspired [1], and it’s an important contribution to show that it also arises in tasks that are “pure” machine learning. Major comments: 1. There is inherent variability in the dynamical objects observed: a. Different architectures have different input projection separation (LSTM on IMDB for instance). b. Different points on the line attractor have different q values (not shown, but likely given prior work [2], [3]) c. Different points on the line attractor have different time constants (Fig. 3c for instance) d. Different points on the line attractor have different linearized dynamics error (Fig. 5b) All this variability can be harnessed to try and understand which factors contribute to performance[3]. For instance, If the drift is suddenly larger – do you see that evidence accumulates faster at these points?  2. Bigrams are mentioned, but not analyzed. It could be that this analysis is complex, or the results are inconclusive. But this should be reported. At the very least, show what happens in the dynamical level for the expression “not bad”.    Minor comments: 3. Appendix A2 shows that bag of words is not always worse than trained RNNS. (line 238-239) 4. Figure 1 is not clear. Is this an individual neuron for many documents? Many neurons for one document?  5. Section 3.1 – add a reference to appendix A2 6. Line 111 “no input”. Is the natural choice zero input, or the average of all neutral words, or average of all words? 7. Line 114 – Figure 1D does not exist 8. 123: “that THAT the” 9. LSTM vs. VRNN on SST seem to show an opposite trend in their performance compared to their input projections.   [1] V. Mante, D. Sussillo, K. V. Shenoy, and W. T. Newsome, “Context-dependent computation by recurrent dynamics in prefrontal cortex,” Nature, vol. 503, no. 7474, pp. 78–84, Nov. 2013. [2] D. Sussillo and O. Barak, “Opening the Black Box: Low-dimensional dynamics in high-dimensional recurrent neural networks,” Neural Comput., vol. 25, no. 3, pp. 626–649, 2013. [3] D. Haviv, A. Rivkind, and O. Barak, “Understanding and Controlling Memory in Recurrent Neural Networks,” ArXiv190207275 Cs Stat, Feb. 2019.  