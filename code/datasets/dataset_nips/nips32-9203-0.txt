ORIGINALITY: although the paper introduces no new methodology, their dataset is to my knowledge a first-of-its-kind and their design, construction, and use of the robotic camera rig to generate is novel and unusual in the field. This kind of work is innovative and shows an attention to experimental design that is sometimes lacking in machine learning.  QUALITY: All parts of the paper (dataset design, camera design and construction, dataset construction, and empirical studies) are well executed. I have no complaints at this time.  CLARITY: The paper is well-written and fairly easy to understand across all parts. It covers a lot of ground and as such, must sequester a lot of details in the appendix: robot schematics, model hyperparameters, and detailed results, in particular. However, they are nonetheless included and described in detail, enabling reproducibility.  SIGNIFICANCE: As disentanglement is not my area of expertise, it is hard to say for sure how the community will respond, but in my experience, the appetite among researchers for clean, detailed, easy-to-use datasets -- especially with ground truth labels -- is enormous, and as such, I expect this dataset will be widely used and will become a de facto standard. I wouldn't be surprised if it picks up a hundred citations within a few years, if not faster.  Here is a laundry list of questions for the authors (I don't have a ton):  * It seems unfortunate that the "3Dprinted-realistic" dataset is a lower resolution (256 x 256) than the real world data (512 x 512)? Is this a limitation of the creation process using Autodesk (the text indicates that at full res, the differences between real and simulated images are more obvious)...  * When transferring from lower resolution, e.g., synthetic, images, is it necessary to downsample the higher resolution, e.g., real images? If so, how might this impact performance?