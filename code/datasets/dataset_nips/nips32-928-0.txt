This work proposes a method of estimating and using the higher-order information, i.e. acceleration, for optical flow estimation such that the interpolated frames can capture motions more naturally. The idea is interesting and straightforward and I am surprised that no one has done this before.    The work is very well presented with sufficient experiments. The SM is well prepared.   The flow reversal layer is somehow novel, but it is not very clear what exactly learned by the reversal layer. What is the performance of the learned layer compared to a reversal layer with fixed parameters?  I am not sure about the contribution of the adaptive flow filtering. It is hard to get the logic why the proposed method is a better way of reducing artifacts. The result in Table 4 also shows very marginal improvements by using this adaptive flow filtering. It will be great to see the same ablation study on other datasets.  