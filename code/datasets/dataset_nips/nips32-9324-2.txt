* Line 55-63 * is confusing. Why p(\dot|\theta) represents a discrete distribution?  For the classification task the authors mentioned, p(x|\theta_i) can be supported on some absolutely continuous measure (w.r.t Lebesgue measure in finite dimension space). One possible explanation is the observation \hat{x} is discrete, so we use the empirical measure of \hat{x} as the base measure, which seems consistent with the following paper (especially Assumption 2.2). But the authors should make the meaning of notation p(\dot|\theta) clear.  *Line 67-76* the authors connect their proposed optimistic likelihood estimation with some existing optimum in the face of uncertainty method. However, these methods always consider the optimistic feedback (e.g. UCB in bandits, planning and Bayesian optimization) but not the optimistic likelihood. Can the authors comment more on this?   *Theorem 2.4* missing definition of *e*.  The authors only discuss the problem when we have some observation S and want to get the likelihood of one point x inside or outside S, but how to deal with the situation we want to simultaneously get the likelihood of several evaluation points (likelihood for each observation, not the sum of log-likelihood just in Appendix B.4)?  This can be simply handled with some traditional methods like KDE and ABC methods introduced in the Section 1. And in real worlds, there exists such cases, for example when we approximate the ELBO with monte carlo estimators, we need to evaluate the likelihood from the samples of q at the same time. We cannot use this optimistic likelihood approximation individually for each sample because this may make the measure unnormalized (because we optimistically assign density to S\cup x in each optimization, if I understand correctly).  Overall, this paper proposed a novel optimistic non-parametric likelihood estimation. The authors provide some practical estimators with ambiguity sets constructed by f-divergence, moment conditions and Wasserstein distance and all of the claims from the authors have strong theoretical guarantees. The experiments seem not so supportive. 