The authors propose that the optimal densification for OPH can actually be further optimized. In usual OPH, we get one permutation of the sparse vector, break the vector into K equal sized bins. In the usual Consistent Weighted Sampling (CWS) approach, we sample non-empty bins from these K bins and retrieve a fixed hash code for these bins. In this new approach, the authors suggest to treat each of the K bins as a separate sparse vector and perform MinHash on these retrieved bins to get a hash code instead of directly getting a Hash code. This is called re-randomization. The authors theoretically prove that this re-randomization achieves the smallest variance among densification schemes(that are used to retrieve hash codes from empty buckets).  Also, they extend this idea to weighted non-negative sparse vectors (by a method called Bin-wise CWS)  The paper seems to be a subtle improvement over prior work. It's fairly well written barring some typos (listed below). It is a significant observation but not entirely new.  Typos: 1. well behavored ---> well behaved  (in multiple places) 2. In section 2, the sentence "we use in J(S,T) to denote Jaccard similarity and J(S,T) to denote generalized Jaccard similarity" sounds weird. Are both denoted by J(S,T)? 3. In section 3, I_s1 = {1,2,3} is wrong. It should be I_s1 = {2,3,4}  <===================== POST AUTHOR RESPONSE=================>  I've read the author response. I'm still positive abt the submission and I'm retaining my score.